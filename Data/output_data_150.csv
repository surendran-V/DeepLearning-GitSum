id,description,readme,Summary
1190,Cascading deletes for Eloquent models that implement soft deletes,"# Cascading soft deletes for the Laravel PHP Framework

[![Build Status](https://github.com/michaeldyrynda/laravel-cascade-soft-deletes/workflows/run-tests/badge.svg)](https://github.com/michaeldyrynda/laravel-cascade-soft-deletes/actions?query=workflow%3Arun-tests)
[![Latest Stable Version](https://poser.pugx.org/dyrynda/laravel-cascade-soft-deletes/v/stable)](https://packagist.org/packages/dyrynda/laravel-cascade-soft-deletes)
[![Total Downloads](https://poser.pugx.org/dyrynda/laravel-cascade-soft-deletes/downloads)](https://packagist.org/packages/dyrynda/laravel-cascade-soft-deletes)
[![License](https://poser.pugx.org/dyrynda/laravel-cascade-soft-deletes/license)](https://packagist.org/packages/dyrynda/laravel-cascade-soft-deletes)
[![Buy us a tree](https://img.shields.io/badge/Treeware-%F0%9F%8C%B3-lightgreen)](https://plant.treeware.earth/michaeldyrynda/laravel-cascade-soft-deletes)

## Introduction

In scenarios when you delete a parent record - say for example a blog post - you may want to also delete any comments associated with it as a form of self-maintenance of your data.

Normally, you would use your database's foreign key constraints, adding an `ON DELETE CASCADE` rule to the foreign key constraint in your comments table.

It may be useful to be able to restore a parent record after it was deleted. In those instances, you may reach for Laravel's [soft deleting](https://laravel.com/docs/5.2/eloquent#soft-deleting) functionality.

In doing so, however, you lose the ability to use the cascading delete functionality that your database would otherwise provide. That is where this package aims to bridge the gap in functionality when using the `SoftDeletes` trait.

## Code Samples

```php
<?php

namespace App;

use App\Comment;
use Dyrynda\Database\Support\CascadeSoftDeletes;
use Illuminate\Database\Eloquent\Model;
use Illuminate\Database\Eloquent\SoftDeletes;

class Post extends Model
{
    use SoftDeletes, CascadeSoftDeletes;

    protected $cascadeDeletes = ['comments'];

    protected $dates = ['deleted_at'];

    public function comments()
    {
        return $this->hasMany(Comment::class);
    }
}
```

Now you can delete an `App\Post` record, and any associated `App\Comment` records will be deleted. If the `App\Comment` record implements the `CascadeSoftDeletes` trait as well, it's children will also be deleted and so on.

```php
$post = App\Post::find($postId)
$post->delete(); // Soft delete the post, which will also trigger the delete() method on any comments and their children.
```

**Note**: It's important to know that when you cascade your soft deleted child records, there is no way to know which were deleted by the cascading operation, and which were deleted prior to that. This means that when you restore the blog post, the associated comments will not be.

Because this trait hooks into the `deleting` Eloquent model event, we can prevent the parent record from being deleted as well as any child records, if any exception is triggered. A `LogicException` will be triggered if the model does not use the `Illuminate\Database\Eloquent\SoftDeletes` trait, or if any of the defined `cascadeDeletes` relationships do not exist, or do not return an instance of `Illuminate\Database\Eloquent\Relations\Relation`.

## Installation

This trait is installed via [Composer](http://getcomposer.org/). To install, simply add to your `composer.json` file:

```
$ composer require dyrynda/laravel-cascade-soft-deletes
```

## Support

If you are having general issues with this package, feel free to contact me on [Twitter](https://twitter.com/michaeldyrynda).

If you believe you have found an issue, please report it using the [GitHub issue tracker](https://github.com/michaeldyrynda/laravel-cascade-soft-deletes/issues), or better yet, fork the repository and submit a pull request.

If you're using this package, I'd love to hear your thoughts. Thanks!

## Treeware

You're free to use this package, but if it makes it to your production environment you are required to buy the world a tree.

It’s now common knowledge that one of the best tools to tackle the climate crisis and keep our temperatures from rising above 1.5C is to plant trees. If you support this package and contribute to the Treeware forest you’ll be creating employment for local families and restoring wildlife habitats.

You can buy trees [here](https://plant.treeware.earth/michaeldyrynda/laravel-cascade-soft-deletes)

Read more about Treeware at [treeware.earth](https://treeware.earth)
","This package aims to bridge the gap in functionality when using the
`SoftDeletes` trait. It hooks into the `deleting` Eloquent model event. This
means we can prevent the parent record from being deleted as well as any child
records, if any exception is triggered. It's important to know that when you
cascade your soft deleted child records there is no way to know which were
deleted by the cascading operation, andWhich were deleted prior to that. This is
one of the best tools to tackle the climate crisis and keep temperatures from
rising above 1.5C."
2439,"Simple, elegant content placeholder","# mocka
Simple, elegant content placeholder

![Mocka](/docs/demo.gif)

```
npm install mocka-placeholder
```

## Introduction

The **mocka** placeholder is a very simple content placeholder that you can use for your website or web application, while loading your page's content. It weighs very little (about 500 bytes minified and gzipped), is fully customizable and you can easily include it in your project's CSS file, by using the Sass mixin provided. Alternatively, you can copy its code and inline it in your HTML for even faster loading.

## Usage

After loading the css, you can create a placeholder using the code provided below:

```html
<div class=""mocka-container"">
  <span class=""mocka-media""></span>
  <span class=""mocka-heading""></span>
  <span class=""mocka-text""></span>
</div>
```

## Customization

Download the npm package, add the mixin to your project, then `@import` the file and `@include` the mixin, passing a single map as an argument. The map contains all the information needed to generate the classes from the mixin. You can find the map with the default values in the [mocka.scss](https://github.com/Chalarangelo/mocka/blob/master/src/mocka/mocka.scss) file.

## License

**Mocka** is an open-source Sass/CSS component and is licensed under the [MIT License](https://github.com/Chalarangelo/mocka/blob/master/LICENSE).
","The **mocka** placeholder is a very simple content placeholder that you can use
for your website or web application, while loading your page's content. It
weighs very little (about 500 bytes minified and gzipped), is fully customizable
and you can easily include it in your project's CSS file, by using the Sass
mixin provided. Alternatively, you can copy its code and inline it into your
HTML for even faster loading.**Mocka*** is an open-source Sass/CSS component and
is licensed under the [MIT
License](https://github.com/Chalarangelo/mockA/blob/master/src/
mocka/mocksa.scss)"
2258,Code for some of my articles,"# Tutorials

This repository contains the code for all my articles and videos.

| Name         | Article | Video | Code |
|:---------------:|:--------:|:----------:|:------:|
| Generating text using a Recurrent Neural Network | [Link](https://gilberttanner.com/blog/generating-text-using-a-recurrent-neuralnetwork) | - | [Link](https://github.com/TannerGilbert/Tutorials/blob/master/Keras-Tutorials/4.%20LSTM%20Text%20Generation/Keras%20LSTM%20Text%20Generation.ipynb) |
| Building a book Recommendation System using Keras | [Link](https://gilberttanner.com/blog/building-a-book-recommendation-system-usingkeras) | [Link](https://youtu.be/4vwNkHFuZBk) | [Link](https://github.com/TannerGilbert/Tutorials/blob/master/Recommendation%20System/Recommendation%20System.ipynb) |
| Introduction to Web Scraping with BeautifulSoup | - | - | [Link](https://github.com/TannerGilbert/Tutorials/tree/master/Introduction%20to%20Web%20Scraping%20with%20BeautifulSoup) |
| Scraping Reddit data | [Link](https://gilberttanner.com/blog/scraping-redditdata) | - | [Link](https://github.com/TannerGilbert/Tutorials/tree/master/Reddit%20Webscraping%20using%20PRAW) |
| Introduction to Deep Learning with Keras | [Link](https://gilberttanner.com/blog/introduction-to-deep-learning-withkeras) | - | [Link](https://github.com/TannerGilbert/Tutorials/blob/master/Introduction%20to%20Deep%20Learning%20with%C2%A0Keras/Introduction%20to%20Deep%20Learning%20with%20Keras.ipynb) |
| Introduction to Data Visualization in Python | [Link](https://gilberttanner.com/blog/introduction-to-data-visualization-inpython) | - | [Link](https://github.com/TannerGilbert/Tutorials/tree/master/Introduction%20to%20Data%20Visualization%20in%C2%A0Python) |
| Live Object Detection with the Tensorflow Object Detection API | - | - | [Link](https://github.com/TannerGilbert/Tutorials/blob/master/Tensorflow%20Object%20Detection/detect_object_in_webcam_video.ipynb) |
| FastAI Image Classification | - | - | [Link](https://github.com/TannerGilbert/Tutorials/blob/master/FastAI/Animal%20detector%20from%20Google%20images.ipynb) |
| FastAI Multi-label image classification | - | - | [Link](https://github.com/TannerGilbert/Tutorials/blob/master/FastAI/%20Multi-label%20prediction%20with%20Planet%20Amazon%20dataset.ipynb) |
| Introduction to Uber’s Ludwig | - | - | [Link](https://github.com/TannerGilbert/Tutorials/tree/master/Uber%20Ludwig%20Introduction) |
| Productionizing your Machine Learning model | - | - | [Link](https://github.com/TannerGilbert/Tutorials/tree/master/Deploying%20your%20ML%20Model) |
| Creating a discord sentiment analysis bot using VADER | - | - | [Link](https://github.com/TannerGilbert/Tutorials/tree/master/Discord%20Sentiment%20Analysis%20Bot) |
| FastAI Image Segmentation | - | - | [Link](https://github.com/TannerGilbert/Tutorials/blob/master/FastAI/Image%20segmentation%20on%20CamVid%20dataset.ipynb) |
| Collaborative filtering with FastAI | - | - | [Link](https://github.com/TannerGilbert/Tutorials/blob/master/FastAI/Book%20Recommendation%20System.ipynb) |
| FastAI Sentiment Analysis | - | - | [Link](https://github.com/TannerGilbert/Tutorials/blob/master/FastAI/Twitter%20US%20Airline%20Sentiment.ipynb) |
| Uber Ludwig Applications | - | - | [Link](https://github.com/TannerGilbert/Tutorials/tree/master/Uber%20Ludwig%20Examples) |
| Introduction to Ensemble Learning | - | - | [Link](https://github.com/TannerGilbert/Tutorials/tree/master/A%20guide%20to%20Ensemble%C2%A0Learning) |
| Introduction to Machine Learning in C# with ML.NET | [Link](https://gilberttanner.com/blog/introduction-to-machine-learning-in-c-with-ml-net) | - | [Link](https://github.com/TannerGilbert/Tutorials/tree/master/Introduction%20to%20Machine%20Learning%20in%20C%23%20with%20ML.NET/CreditCardFraudDetection) |
| Turn your data science scripts into websites with Streamlit | [Link](https://gilberttanner.com/blog/turn-your-data-science-script-into-websites-with-streamlit) | - | [Link](https://github.com/TannerGilbert/Tutorials/tree/master/Streamlit) |
| Deploying your Streamlit dashboard with Heroku | [Link](https://gilberttanner.com/blog/deploying-your-streamlit-dashboard-with-heroku) | - | [Link](https://github.com/TannerGilbert/Tutorials/tree/master/Streamlit/Deploy-Application-with-Heroku) |

## Author
 **Gilbert Tanner**
 
## Support me

<a href=""https://www.buymeacoffee.com/gilberttanner"" target=""_blank""><img src=""https://www.buymeacoffee.com/assets/img/custom_images/orange_img.png"" alt=""Buy Me A Coffee"" style=""height: 41px !important;width: 174px !important;box-shadow: 0px 3px 2px 0px rgba(190, 190, 190, 0.5) !important;-webkit-box-shadow: 0px 3px 2px 0px rgba(190, 190, 190, 0.5) !important;"" ></a>

## License

This project is licensed under the MIT License - see the [LICENSE.md](LICENSE) file for details
","This repository contains the code for all my articles and videos.summarize: #
Tutorials # Video # Article # Source code:
http://gilberttanner.com/blog/generating-text-using-a-recurrent-neuralnetwork."
166,QuickCheck for Swift,"[![Carthage compatible](https://img.shields.io/badge/Carthage-compatible-4BC51D.svg?style=flat)](https://github.com/Carthage/Carthage)
[![Build Status](https://travis-ci.org/typelift/SwiftCheck.svg?branch=master)](https://travis-ci.org/typelift/SwiftCheck)
[![Gitter chat](https://badges.gitter.im/DPVN/chat.png)](https://gitter.im/typelift/general?utm_source=share-link&utm_medium=link&utm_campaign=share-link)
 
 
SwiftCheck
==========

QuickCheck for Swift.

For those already familiar with the Haskell library, check out the source.  For
everybody else, see the [Tutorial Playground](Tutorial.playground) for a
beginner-level introduction to the major concepts and use-cases of this library.
 
Introduction
============

SwiftCheck is a testing library that automatically generates random data for 
testing of program properties.  A property is a particular facet of an algorithm
or data structure that must be invariant under a given set of input data,
basically an `XCTAssert` on steroids.  Where before all we could do was define
methods prefixed by `test` and assert, SwiftCheck allows program properties and 
tests to be treated like *data*.

To define a program property the `forAll` quantifier is used with a type
signature like `(A, B, C, ... Z) -> Testable where A : Arbitrary, B : Arbitrary ...
Z : Arbitrary`.  SwiftCheck implements the `Arbitrary` protocol for most Swift 
Standard Library types and implements the `Testable` protocol for `Bool` and 
several other related types.  For example, if we wanted to test the property 
that every Integer is equal to itself, we would express it as such:

```swift
func testAll() {
    // 'property' notation allows us to name our tests.  This becomes important
    // when they fail and SwiftCheck reports it in the console.
    property(""Integer Equality is Reflexive"") <- forAll { (i : Int) in
        return i == i
    }
}
```

For a less contrived example, here is a program property that tests whether
Array identity holds under double reversal:

```swift
property(""The reverse of the reverse of an array is that array"") <- forAll { (xs : [Int]) in
    // This property is using a number of SwiftCheck's more interesting 
    // features.  `^&&^` is the conjunction operator for properties that turns
    // both properties into a larger property that only holds when both sub-properties
    // hold.  `<?>` is the labelling operator allowing us to name each sub-part
    // in output generated by SwiftCheck.  For example, this property reports:
    //
    // *** Passed 100 tests
    // (100% , Right identity, Left identity)
    return
        (xs.reversed().reversed() == xs) <?> ""Left identity""
        ^&&^
        (xs == xs.reversed().reversed()) <?> ""Right identity""
}
```

Because SwiftCheck doesn't require tests to return `Bool`, just `Testable`, we
can produce tests for complex properties with ease:

```swift
property(""Shrunken lists of integers always contain [] or [0]"") <- forAll { (l : [Int]) in
    // Here we use the Implication Operator `==>` to define a precondition for
    // this test.  If the precondition fails the test is discarded.  If it holds
    // the test proceeds.
    return (!l.isEmpty && l != [0]) ==> {
        let ls = self.shrinkArbitrary(l)
        return (ls.filter({ $0 == [] || $0 == [0] }).count >= 1)
    }
}
```

Properties can even depend on other properties:

```swift
property(""Gen.one(of:) multiple generators picks only given generators"") <- forAll { (n1 : Int, n2 : Int) in
    let g1 = Gen.pure(n1)
    let g2 = Gen.pure(n2)
    // Here we give `forAll` an explicit generator.  Before SwiftCheck was using
    // the types of variables involved in the property to create an implicit
    // Generator behind the scenes.
    return forAll(Gen.one(of: [g1, g2])) { $0 == n1 || $0 == n2 }
}
```

All you have to figure out is what to test.  SwiftCheck will handle the rest.  

Shrinking
=========
 
What makes QuickCheck unique is the notion of *shrinking* test cases.  When fuzz
testing with arbitrary data, rather than simply halt on a failing test, SwiftCheck
will begin whittling the data that causes the test to fail down to a minimal
counterexample.

For example, the following function uses the Sieve of Eratosthenes to generate
a list of primes less than some n:

```swift
/// The Sieve of Eratosthenes:
///
/// To find all the prime numbers less than or equal to a given integer n:
///    - let l = [2...n]
///    - let p = 2
///    - for i in [(2 * p) through n by p] {
///          mark l[i]
///      }
///    - Remaining indices of unmarked numbers are primes
func sieve(_ n : Int) -> [Int] {
    if n <= 1 {
        return []
    }

    var marked : [Bool] = (0...n).map { _ in false }
    marked[0] = true
    marked[1] = true

    for p in 2..<n {
        for i in stride(from: 2 * p, to: n, by: p) {
            marked[i] = true
        }
    }

    var primes : [Int] = []
    for (t, i) in zip(marked, 0...n) {
        if !t {
            primes.append(i)
        }
    }
    return primes
}

/// Short and sweet check if a number is prime by enumerating from 2...⌈√(x)⌉ and checking 
/// for a nonzero modulus.
func isPrime(n : Int) -> Bool {
    if n == 0 || n == 1 {
        return false
    } else if n == 2 {
        return true
    }
    
    let max = Int(ceil(sqrt(Double(n))))
    for i in 2...max {
        if n % i == 0 {
            return false
        }
    }
    return true
}

```

We would like to test whether our sieve works properly, so we run it through 
SwiftCheck with the following property:

```swift
import SwiftCheck

property(""All Prime"") <- forAll { (n : Int) in
    return sieve(n).filter(isPrime) == sieve(n)
}
```

Which produces the following in our testing log:

```
Test Case '-[SwiftCheckTests.PrimeSpec testAll]' started.
*** Failed! Falsifiable (after 10 tests):
4
```

Indicating that our sieve has failed on the input number 4.  A quick look back
at the comments describing the sieve reveals the mistake immediately:

```diff
- for i in stride(from: 2 * p, to: n, by: p) {
+ for i in stride(from: 2 * p, through: n, by: p) {
```

Running SwiftCheck again reports a successful sieve of all 100 random cases:

```
*** Passed 100 tests
```

Custom Types
============

SwiftCheck implements random generation for most of the types in the Swift 
Standard Library. Any custom types that wish to take part in testing must 
conform to the included `Arbitrary` protocol.  For the majority of types, this
means providing a custom means of generating random data and shrinking down to 
an empty array. 

For example:

```swift
import SwiftCheck
 
public struct ArbitraryFoo {
    let x : Int
    let y : Int

    public var description : String {
        return ""Arbitrary Foo!""
    }
}

extension ArbitraryFoo : Arbitrary {
    public static var arbitrary : Gen<ArbitraryFoo> {
        return Gen<(Int, Int)>.zip(Int.arbitrary, Int.arbitrary).map(ArbitraryFoo.init)
    }
}

class SimpleSpec : XCTestCase {
    func testAll() {
        property(""ArbitraryFoo Properties are Reflexive"") <- forAll { (i : ArbitraryFoo) in
            return i.x == i.x && i.y == i.y
        }
    }
}
```

There's also a `Gen.compose` method which allows you to procedurally compose 
values from multiple generators to construct instances of a type:

``` swift
public static var arbitrary : Gen<MyClass> {
    return Gen<MyClass>.compose { c in
        return MyClass(
            // Use the nullary method to get an `arbitrary` value.
            a: c.generate(),

            // or pass a custom generator
            b: c.generate(Bool.suchThat { $0 == false }),

            // .. and so on, for as many values and types as you need.
            c: c.generate(), ...
        )
    }
}
```

`Gen.compose` can also be used with types that can only be customized with setters:

``` swift
public struct ArbitraryMutableFoo : Arbitrary {
    var a: Int8
    var b: Int16
    
    public init() {
        a = 0
        b = 0
    }
    
    public static var arbitrary: Gen<ArbitraryMutableFoo> {
        return Gen.compose { c in
            var foo = ArbitraryMutableFoo()
            foo.a = c.generate()
            foo.b = c.generate()
            return foo
        }
    }
}
```

For everything else, SwiftCheck defines a number of combinators to make working
with custom generators as simple as possible:

```swift
let onlyEven = Int.arbitrary.suchThat { $0 % 2 == 0 }

let vowels = Gen.fromElements(of: [ ""A"", ""E"", ""I"", ""O"", ""U"" ])

let randomHexValue = Gen<UInt>.choose((0, 15))

let uppers = Gen<Character>.fromElements(in: ""A""...""Z"")
let lowers = Gen<Character>.fromElements(in: ""a""...""z"")
let numbers = Gen<Character>.fromElements(in: ""0""...""9"")
 
/// This generator will generate `.none` 1/4 of the time and an arbitrary
/// `.some` 3/4 of the time
let weightedOptionals = Gen<Int?>.frequency([
    (1, Gen<Int?>.pure(nil)),
    (3, Int.arbitrary.map(Optional.some))
])
```
 
For instances of many complex or ""real world"" generators, see 
[`ComplexSpec.swift`](Tests/SwiftCheckTests/ComplexSpec.swift).

System Requirements
===================

SwiftCheck supports OS X 10.9+ and iOS 7.0+.

Setup
=====

SwiftCheck can be included one of two ways:
 
**Using The Swift Package Manager**

- Add SwiftCheck to your `Package.swift` file's dependencies section:

```swift
.package(url: ""https://github.com/typelift/SwiftCheck.git"", from: ""0.8.1"")
```
 
**Using Carthage**

- Add SwiftCheck to your Cartfile
- Run `carthage update`
- Drag the relevant copy of SwiftCheck into your project.
- Expand the Link Binary With Libraries phase
- Click the + and add SwiftCheck
- Click the + at the top left corner to add a Copy Files build phase
- Set the directory to `Frameworks`
- Click the + and add SwiftCheck

**Using CocoaPods**

- Add [our Pod](https://cocoapods.org/pods/SwiftCheck) to your podfile.
- Run `$ pod install` in your project directory.
 
**Framework**

- Drag SwiftCheck.xcodeproj into your project tree
  as a subproject
- Under your project's Build Phases, expand Target Dependencies
- Click the + and add SwiftCheck
- Expand the Link Binary With Libraries phase
- Click the + and add SwiftCheck
- Click the + at the top left corner to add a Copy Files build phase
- Set the directory to Frameworks
- Click the + and add SwiftCheck

License
=======

SwiftCheck is released under the MIT license.
","SwiftCheck is a testing library that automatically generates random data for
testing of program properties. A property is a particular facet of an algorithm
or data structure that must be invariant under a given set of input data.
SwiftCheck implements the `Arbitrary` protocol for most Swift types and the
`Testable' protocol for other types."
2160,"Create PowerPoint presentations with a powerful, concise JavaScript API.","<h1 align=""center"">PptxGenJS</h1>
<h5 align=""center"">
  Create JavaScript PowerPoint Presentations
</h5>
<p align=""center"">
  <a href=""https://github.com/gitbrent/PptxGenJS/"">
    <img alt=""PptxGenJS Sample Slides"" title=""PptxGenJS Sample Slides"" src=""https://raw.githubusercontent.com/gitbrent/PptxGenJS/gh-pages/img/readme_banner.png""/>
  </a>
</p>
<br/>

[![Known Vulnerabilities](https://snyk.io/test/npm/pptxgenjs/badge.svg)](https://snyk.io/test/npm/pptxgenjs) [![npm downloads](https://img.shields.io/npm/dm/pptxgenjs.svg)](https://www.npmjs.com/package/pptxgenjs) [![jsdelivr downloads](https://data.jsdelivr.com/v1/package/gh/gitbrent/pptxgenjs/badge)](https://www.jsdelivr.com/package/gh/gitbrent/pptxgenjs) [![typescripts definitions](https://img.shields.io/npm/types/pptxgenjs)](https://img.shields.io/npm/types/pptxgenjs)

# Table of Contents

- [Table of Contents](#table-of-contents)
- [Introduction](#introduction)
- [Features](#features)
	- [Works Everywhere](#works-everywhere)
	- [Full Featured](#full-featured)
	- [Simple and Powerful](#simple-and-powerful)
	- [Export Your Way](#export-your-way)
	- [HTML to PowerPoint](#html-to-powerpoint)
- [Live Demos](#live-demos)
- [Installation](#installation)
	- [Npm](#npm)
	- [Yarn](#yarn)
	- [CDN](#cdn)
	- [Download](#download)
	- [Additional Builds](#additional-builds)
- [Documentation](#documentation)
	- [Quick Start Guide](#quick-start-guide)
		- [Angular/React, ES6, TypeScript](#angularreact-es6-typescript)
		- [Script/Web Browser](#scriptweb-browser)
	- [Library API](#library-api)
	- [HTML-to-PowerPoint Feature](#html-to-powerpoint-feature)
- [Library Ports](#library-ports)
- [Issues / Suggestions](#issues--suggestions)
- [Need Help?](#need-help)
- [Contributors](#contributors)
- [Sponsor Us](#sponsor-us)
- [License](#license)

# Introduction

This library creates Open Office XML (OOXML) Presentations which are compatible with Microsoft PowerPoint, Apple Keynote, and other applications.

# Features

## Works Everywhere

- Every modern desktop and mobile browser is supported
- Integrates with Node, Angular, React, and Electron
- Compatible with PowerPoint, Keynote, and more

## Full Featured

- All major object types are available (charts, shapes, tables, etc.)
- Master Slides for academic/corporate branding
- SVG images, animated gifs, YouTube videos, RTL text, and Asian fonts

## Simple and Powerful

- The absolute easiest PowerPoint library to use
- Learn as you code will full typescript definitions included
- Tons of demo code comes included (over 75 slides of features)

## Export Your Way

- Exports files direct to client browsers with proper MIME-type
- Other export formats available: base64, blob, stream, etc.
- Presentation compression options and more

## HTML to PowerPoint

- Includes powerful [HTML-to-PowerPoint](#html-to-powerpoint-feature) feature to transform HTML tables into presentations with a single line of code

# Live Demos

Visit the demos page to create a simple presentation to see how easy it is to use pptxgenjs, or check out the complete demo which showcases every available feature.

- [PptxGenJS Demos](https://gitbrent.github.io/PptxGenJS/demos/)

# Installation

## Npm

[PptxGenJS NPM Home](https://www.npmjs.com/package/pptxgenjs)

```bash
npm install pptxgenjs --save
```

## Yarn

```bash
yarn add pptxgenjs
```

## CDN

[jsDelivr Home](https://www.jsdelivr.com/package/gh/gitbrent/pptxgenjs)

Bundle: Modern Browsers and IE11

```html
<script src=""https://cdn.jsdelivr.net/gh/gitbrent/pptxgenjs@3.11.0/dist/pptxgen.bundle.js""></script>
```

Min files: Modern Browsers

```html
<script src=""https://cdn.jsdelivr.net/gh/gitbrent/pptxgenjs@3.11.0/libs/jszip.min.js""></script>
<script src=""https://cdn.jsdelivr.net/gh/gitbrent/pptxgenjs@3.11.0/dist/pptxgen.min.js""></script>
```

## Download

[GitHub Latest Release](https://github.com/gitbrent/PptxGenJS/releases/latest)

Bundle: Modern Browsers

- Use the bundle for IE11 support

```html
<script src=""PptxGenJS/dist/pptxgen.bundle.js""></script>
```

Min files: Modern Browsers

```html
<script src=""PptxGenJS/libs/jszip.min.js""></script>
<script src=""PptxGenJS/dist/pptxgen.min.js""></script>
```

## Additional Builds

- CommonJS: `dist/pptxgen.cjs.js`
- ES Module: `dist/pptxgen.es.js`

---

# Documentation

## Quick Start Guide

PptxGenJS PowerPoint presentations are created via JavaScript by following 4 basic steps:

### Angular/React, ES6, TypeScript

```typescript
import pptxgen from ""pptxgenjs"";

// 1. Create a new Presentation
let pres = new pptxgen();

// 2. Add a Slide
let slide = pres.addSlide();

// 3. Add one or more objects (Tables, Shapes, Images, Text and Media) to the Slide
let textboxText = ""Hello World from PptxGenJS!"";
let textboxOpts = { x: 1, y: 1, color: ""363636"" };
slide.addText(textboxText, textboxOpts);

// 4. Save the Presentation
pres.writeFile();
```

### Script/Web Browser

```javascript
// 1. Create a new Presentation
let pres = new PptxGenJS();

// 2. Add a Slide
let slide = pres.addSlide();

// 3. Add one or more objects (Tables, Shapes, Images, Text and Media) to the Slide
let textboxText = ""Hello World from PptxGenJS!"";
let textboxOpts = { x: 1, y: 1, color: ""363636"" };
slide.addText(textboxText, textboxOpts);

// 4. Save the Presentation
pres.writeFile();
```

That's really all there is to it!

---

## Library API

Full documentation and code examples are available

- [Creating a Presentation](https://gitbrent.github.io/PptxGenJS/docs/usage-pres-create/)
- [Presentation Options](https://gitbrent.github.io/PptxGenJS/docs/usage-pres-options/)
- [Adding a Slide](https://gitbrent.github.io/PptxGenJS/docs/usage-add-slide/)
- [Slide Options](https://gitbrent.github.io/PptxGenJS/docs/usage-slide-options/)
- [Saving a Presentation](https://gitbrent.github.io/PptxGenJS/docs/usage-saving/)
- [Master Slides](https://gitbrent.github.io/PptxGenJS/docs/masters/)
- [Adding Charts](https://gitbrent.github.io/PptxGenJS/docs/api-charts/)
- [Adding Images](https://gitbrent.github.io/PptxGenJS/docs/api-images/)
- [Adding Media](https://gitbrent.github.io/PptxGenJS/docs/api-media/)
- [Adding Shapes](https://gitbrent.github.io/PptxGenJS/docs/api-shapes/)
- [Adding Tables](https://gitbrent.github.io/PptxGenJS/docs/api-tables/)
- [Adding Text](https://gitbrent.github.io/PptxGenJS/docs/api-text/)
- [Speaker Notes](https://gitbrent.github.io/PptxGenJS/docs/speaker-notes/)
- [Using Scheme Colors](https://gitbrent.github.io/PptxGenJS/docs/shapes-and-schemes/)
- [Integration with Other Libraries](https://gitbrent.github.io/PptxGenJS/docs/integration/)

---

## HTML-to-PowerPoint Feature

Easily convert HTML tables to PowerPoint presentations in a single call.

```javascript
let pptx = new PptxGenJS();
pptx.tableToSlides(""tableElementId"");
pptx.writeFile({ fileName: ""html2pptx-demo.pptx"" });
```

Learn more:

- [HTML-to-PowerPoint Docs/Demo](https://gitbrent.github.io/PptxGenJS/html2pptx/)

---

# Library Ports

React: [react-pptx](https://github.com/wyozi/react-pptx) - thanks to [Joonas](https://github.com/wyozi)!

---

# Issues / Suggestions

Please file issues or suggestions on the [issues page on github](https://github.com/gitbrent/PptxGenJS/issues/new), or even better, [submit a pull request](https://github.com/gitbrent/PptxGenJS/pulls). Feedback is always welcome!

When reporting issues, please include a code snippet or a link demonstrating the problem.
Here is a small [jsFiddle](https://jsfiddle.net/gitbrent/L1uctxm0/) that is already configured and uses the latest PptxGenJS code.

---

# Need Help?

Sometimes implementing a new library can be a difficult task and the slightest mistake will keep something from working. We've all been there!

If you are having issues getting a presentation to generate, check out the code in the `demos` directory. There
are demos for both client browsers, node and react that contain working examples of every available library feature.

- Use a pre-configured jsFiddle to test with: [PptxGenJS Fiddle](https://jsfiddle.net/gitbrent/L1uctxm0/)
- [View questions tagged `PptxGenJS` on StackOverflow](https://stackoverflow.com/questions/tagged/pptxgenjs?sort=votes&pageSize=50). If you can't find your question, [ask it yourself](https://stackoverflow.com/questions/ask?tags=PptxGenJS) - be sure to tag it `PptxGenJS`.

---

# Contributors

Thank you to everyone for the issues, contributions and suggestions! ❤️

Special Thanks:

- [Dzmitry Dulko](https://github.com/DzmitryDulko) - Getting the project published on NPM
- [Michal Kacerovský](https://github.com/kajda90) - New Master Slide Layouts and Chart expertise
- [Connor Bowman](https://github.com/conbow) - Adding Placeholders
- [Reima Frgos](https://github.com/ReimaFrgos) - Multiple chart and general functionality patches
- [Matt King](https://github.com/kyrrigle) - Chart expertise
- [Mike Wilcox](https://github.com/clubajax) - Chart expertise
- [Joonas](https://github.com/wyozi) - React port

PowerPoint shape definitions and some XML code via [Officegen Project](https://github.com/Ziv-Barber/officegen)

---

# Sponsor Us

If you find this library useful, please consider sponsoring us through a [donation](https://gitbrent.github.io/PptxGenJS/sponsor/)

---

# License

Copyright &copy; 2015-present [Brent Ely](https://github.com/gitbrent/PptxGenJS)

[MIT](https://github.com/gitbrent/PptxGenJS/blob/master/LICENSE)
","PptxGenJS creates Open Office XML (OOXML) Presentations which are compatible
with Microsoft PowerPoint, Apple Keynote, and other applications. Every modern
desktop and mobile browser is supported. Integrates with Node, Angular, React,
and Electron. Includes powerful [ HTML-to-PowerPoint] feature to transform HTML
tables into presentations with a single line of code. Visit the demos page to
create a simple presentation to see how easy it is to use pptxgenjs."
1116,APISIX Ingress Controller for Kubernetes,"<!--
#
# Licensed to the Apache Software Foundation (ASF) under one or more
# contributor license agreements.  See the NOTICE file distributed with
# this work for additional information regarding copyright ownership.
# The ASF licenses this file to You under the Apache License, Version 2.0
# (the ""License""); you may not use this file except in compliance with
# the License.  You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an ""AS IS"" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
#
-->

# Apache APISIX for Kubernetes

[![Go Report Card](https://goreportcard.com/badge/github.com/apache/apisix-ingress-controller)](https://goreportcard.com/report/github.com/apache/apisix-ingress-controller)
[![Slack](https://badgen.net/badge/Slack/Join%20Apache%20APISIX?icon=slack)](https://apisix.apache.org/slack)

Use [Apache APISIX](https://github.com/apache/apisix#apache-apisix) for Kubernetes [Ingress](https://kubernetes.io/docs/concepts/services-networking/ingress/).

All configurations in `apisix-ingress-controller` are defined with Kubernetes CRDs (Custom Resource Definitions).
Support configuring [plugins](https://github.com/apache/apisix/blob/master/docs/en/latest/plugins), service registration discovery mechanism for upstreams, load balancing and more in Apache APISIX.

`apisix-ingress-controller` is an Apache APISIX control plane component. Currently it serves for Kubernetes clusters. In the future, we plan to separate the submodule to adapt to more deployment modes, such as virtual machine clusters.

The technical architecture of `apisix-ingress-controller`:

<img src=""./docs/assets/images/module-0.png"" alt=""Architecture"" width=""743"" height=""559"" />

## Status

This project is currently general availability.

## Features

* Declarative configuration for Apache APISIX with Custom Resource Definitions(CRDs), using k8s yaml struct with minimum learning curve.
* Hot-reload during yaml apply.
* Native Kubernetes Ingress (both `v1` and `v1beta1`) support.
* Auto register k8s endpoint to upstream (Apache APISIX) node.
* Support load balancing based on pod (upstream nodes).
* Out of box support for node health check.
* Plug-in extension supports hot configuration and immediate effect.
* Support SSL and mTLS for routes.
* Support traffic split and canary deployments.
* Support TCP 4 layer proxy.
* Ingress controller itself as a pluggable hot-reload component.
* Multi-cluster configuration distribution.

[More about comparison among multiple Ingress Controllers.](https://docs.google.com/spreadsheets/d/191WWNpjJ2za6-nbG4ZoUMXMpUK8KlCIosvQB0f-oq3k/edit?ts=5fd6c769#gid=907731238)

## Get started

* [How to install](./install.md)
* [Get Started](./docs/en/latest/getting-started.md)
* [Design introduction](./docs/en/latest/design.md)
* [FAQ](./docs/en/latest/FAQ.md)

## Prerequisites

Apisix ingress controller requires Kubernetes version 1.16+. Because we used `CustomResourceDefinition` v1 stable API.
From the version 1.0.0, APISIX-ingress-controller need to work with Apache APISIX version 2.7+.

## Works with APISIX Dashboard

Currently, APISIX Ingress Controller automatically manipulates some APISIX resources, which is not very compatible with APISIX Dashboard. In addition, users should not modify resources labeled `managed-by: apisix-ingress-controllers` via APISIX Dashboard.

## Internal Architecture

<img src=""./docs/assets/images/apisix-ingress-controller-arch.png"" alt=""module"" width=""74.3%"" height=""55.9%"" />

## Apache APISIX Ingress vs. Kubernetes Ingress Nginx

* The control plane and data plane are separated, which can improve security and deployment flexibility.
* Hot-reload during yaml apply.
* [More convenient canary deployment.](./docs/en/latest/concepts/apisix_route.md)
* Verify the correctness of the configuration, safe and reliable.
* [Rich plugins and ecology.](https://github.com/apache/apisix/tree/master/docs/en/latest/plugins)
* Supports APISIX custom resources and Kubernetes native Ingress resources.

## Contributing

We welcome all kinds of contributions from the open-source community, individuals and partners.

* [Contributing Guide](./docs/en/latest/contribute.md)

### How to contribute

Most of the contributions that we receive are code contributions, but you can
also contribute to the documentation or simply report solid bugs
for us to fix.

 For new contributors, please take a look at issues with a tag called [Good first issue](https://github.com/apache/apisix-ingress-controller/issues?q=is%3Aissue+is%3Aopen+label%3A%22good+first+issue%22) or [Help wanted](https://github.com/apache/apisix-ingress-controller/issues?q=is%3Aissue+is%3Aopen+label%3A%22help+wanted%22).

### How to report a bug

* **Ensure the bug was not already reported** by searching on GitHub under [Issues](https://github.com/apache/apisix-ingress-controller/issues).

* If you're unable to find an open issue addressing the problem, [open a new one](https://github.com/apache/apisix-ingress-controller/issues/new). Be sure to include a **title and clear description**, as much relevant information as possible, and a **code sample** or an **executable test case** demonstrating the expected behavior that is not occurring.

### Contributor over time

[![Contributor over time](https://contributor-overtime-api.git-contributor.com/contributors-svg?chart=contributorOverTime&repo=apache/apisix-ingress-controller)](https://git-contributor.com/?chart=contributorOverTime&repo=apache/apisix-ingress-controller)

## Community

* Mailing List: Mail to dev-subscribe@apisix.apache.org, follow the reply to subscribe the mailing list.
* QQ Group - 578997126
* ![Twitter Follow](https://img.shields.io/twitter/follow/ApacheAPISIX?style=social) - follow and interact with us using hashtag `#ApacheAPISIX`
* [Bilibili video](https://space.bilibili.com/551921247)

## Todos

* More todos will display in [issues](https://github.com/apache/apisix-ingress-controller/issues?q=is%3Aopen+is%3Aissue+label%3Atriage%2Faccepted)

## User stories

- [How Does Zoom Use APISIX Ingress in Its Continuous Delivery Pipeline? - API7.ai](https://api7.ai/blog/zoom-uses-apisix-ingress)
- [Copernicus Reference System Software](https://github.com/COPRS/infrastructure/wiki/Networking-trade-off)
- [From Traefik to APISIX, Horizon Robotics's Exploration in Ingress Controller - API7.ai](https://api7.ai/blog/why-horizon-robotics-migrated-from-traefik-to-apche-apisix)
- [Why Jiakaobaodian Chooses APISIX Ingress Controller - API7.ai](https://api7.ai/blog/why-jiakaobaodian-chooses-apisix-ingress-controller)
- [Why AISpeech Chooses Apache APISIX Instead of NGINX as k8s Ingress Controller - API7.ai](https://api7.ai/blog/why-aispeech-chooses-apache-apisix-instead-of-nginx-as-k8s-ingress-controller)
- [Tencent Cloud: Why choose Apache APISIX to implement the k8s ingress controller?(Chinese)](https://cloud.tencent.com/developer/article/1592281)
- [aispeech: Why we create a new k8s ingress controller?(Chinese)](https://mp.weixin.qq.com/s/bmm2ibk2V7-XYneLo9XAPQ)

If you are willing to share with us some scenarios and use cases when you use APISIX Ingress,
please reply to the [issue](https://github.com/apache/apisix-ingress-controller/issues/501),
or submit PR to update [Powered-BY](./powered-by.md) file

## Who Uses APISIX Ingress?

A wide variety of companies and organizations use APISIX Ingress for research, production and commercial product, below are some of them:

- AISpeech
- European Copernicus Reference System
- Jiakaobaodian(驾考宝典)
- Horizon Robotics(地平线)
- Tencent Cloud
- UPYUN
- Zoom

## Milestone

* [Milestone](https://github.com/apache/apisix-ingress-controller/milestones)

## Terminology

* APISIX Ingress: the whole service that contains the proxy ([Apache APISIX](https://apisix.apache.org)) and ingress controller (apisix-ingress-controller).
* apisix-ingress-controller: the ingress controller component.
","Apache APISIX for Kubernetes is an Apache control plane component. It provides
declarative configuration for Apache APISix with Custom Resource Definitions
(CRDs), using k8s yaml struct with minimum learning curve. It also provides a
service registration discovery mechanism for upstreams, load balancing and more."
978,Kata Containers version 1.x runtime (for version 2.x see https://github.com/kata-containers/kata-containers).,"[![Build Status](https://travis-ci.org/kata-containers/runtime.svg?branch=master)](https://travis-ci.org/kata-containers/runtime)
[![Build Status](http://jenkins.katacontainers.io/job/kata-containers-runtime-ubuntu-18-04-master/badge/icon)](http://jenkins.katacontainers.io/job/kata-containers-runtime-ubuntu-18-04-master/)
[![Go Report Card](https://goreportcard.com/badge/github.com/kata-containers/runtime)](https://goreportcard.com/report/github.com/kata-containers/runtime)
[![GoDoc](https://godoc.org/github.com/kata-containers/runtime?status.svg)](https://godoc.org/github.com/kata-containers/runtime)

# Runtime

This repository contains the runtime for the
[Kata Containers](https://github.com/kata-containers) project.

For details of the other Kata Containers repositories, see the
[repository summary](https://github.com/kata-containers/kata-containers).

* [Introduction](#introduction)
* [License](#license)
* [Platform support](#platform-support)
    * [Hardware requirements](#hardware-requirements)
* [Download and install](#download-and-install)
* [Quick start for developers](#quick-start-for-developers)
* [Architecture overview](#architecture-overview)
* [Configuration](#configuration)
* [Logging](#logging)
    * [Kata OCI](#kata-oci)
    * [Kata containerd shimv2](#kata-containerd-shimv2)
* [Debugging](#debugging)
* [Limitations](#limitations)
* [Community](#community)
    * [Contact](#contact)
* [Further information](#further-information)
* [Additional packages](#additional-packages)

## Introduction

`kata-runtime`, referred to as ""the runtime"", is the Command-Line Interface
(CLI) part of the Kata Containers runtime component. It leverages the
[virtcontainers](virtcontainers)
package to provide a high-performance standards-compliant runtime that creates
hardware-virtualized [Linux](https://www.kernel.org/) containers running on Linux hosts.

The runtime is
[OCI](https://github.com/opencontainers/runtime-spec)-compatible,
[CRI-O](https://github.com/cri-o/cri-o)-compatible, and
[Containerd](https://github.com/containerd/containerd)-compatible,
 allowing it
to work seamlessly with both Docker and Kubernetes respectively.

## License

The code is licensed under an Apache 2.0 license.

See [the license file](LICENSE) for further details.

## Platform support

Kata Containers currently works on systems supporting the following
technologies:

- [Intel](https://www.intel.com) VT-x technology.
- [ARM](https://www.arm.com) Hyp mode (virtualization extension).
- [IBM](https://www.ibm.com) Power Systems.
- [IBM](https://www.ibm.com) Z mainframes.
### Hardware requirements

The runtime has a built-in command to determine if your host system is capable
of running and creating a Kata Container:

```bash
$ kata-runtime kata-check
```

> **Note:**
>
> - By default, only a brief success / failure message is printed.
> If more details are needed, the `--verbose` flag can be used to display the
> list of all the checks performed.
>
> - `root` permission is needed to check if the system is capable of running
> Kata containers. In this case, additional checks are performed (e.g., if another
> incompatible hypervisor is running).

## Download and install

[![Get it from the Snap Store](https://snapcraft.io/static/images/badges/en/snap-store-black.svg)](https://snapcraft.io/kata-containers)

See the [installation guides](https://github.com/kata-containers/documentation/tree/master/install/README.md)
available for various operating systems.

## Quick start for developers

See the
[developer guide](https://github.com/kata-containers/documentation/blob/master/Developer-Guide.md).

## Architecture overview

See the [architecture overview](https://github.com/kata-containers/documentation/blob/master/design/architecture.md)
for details on the Kata Containers design.

## Configuration

The runtime uses a TOML format configuration file called `configuration.toml`.
The file contains comments explaining all options.

> **Note:**
>
> The initial values in the configuration file provide a good default configuration.
> You may need to modify this file to optimise or tailor your system, or if you have
> specific requirements.

Since the runtime supports a
[stateless system](https://clearlinux.org/about),
it checks for this configuration file in multiple locations, two of which are
built in to the runtime. The default location is
`/usr/share/defaults/kata-containers/configuration.toml` for a standard
system. However, if `/etc/kata-containers/configuration.toml` exists, this
takes priority.

The below command lists the full paths to the configuration files that the
runtime attempts to load. The first path that exists will be used:

```bash
$ kata-runtime --kata-show-default-config-paths
```

Aside from the built-in locations, it is possible to specify the path to a
custom configuration file using the `--kata-config` option:

```bash
$ kata-runtime --kata-config=/some/where/configuration.toml ...
```

The runtime will log the full path to the configuration file it is using. See
the [logging](#logging) section for further details.

To see details of your systems runtime environment (including the location of
the configuration file being used), run:

```bash
$ kata-runtime kata-env
```

## Logging

For detailed information and analysis on obtaining logs for other system
components, see the documentation for the
[`kata-log-parser`](https://github.com/kata-containers/tests/tree/master/cmd/log-parser)
tool.

For runtime logs, see the following sections for the CRI-O and containerd shimv2 based runtimes.

### Kata OCI

The Kata OCI runtime (including when used with CRI-O), provides `--log=` and `--log-format=` options.
However, the runtime also always logs to the system log (`syslog` or `journald`).

To view runtime log output:

```bash
$ sudo journalctl -t kata-runtime
```

### Kata containerd shimv2

The Kata containerd shimv2 runtime logs through `containerd`, and its logs will be sent
to wherever the `containerd` logs are directed. However, the
shimv2 runtime also always logs to the system log (`syslog` or `journald`) under the
identifier name of `kata`.

To view the `shimv2` runtime log output:

```bash
$ sudo journalctl -t kata
```

## Debugging

See the
[debugging section of the developer guide](https://github.com/kata-containers/documentation/blob/master/Developer-Guide.md#troubleshoot-kata-containers).

## Limitations

See the
[limitations file](https://github.com/kata-containers/documentation/blob/master/Limitations.md)
for further details.

## Community

See [the community repository](https://github.com/kata-containers/community).

### Contact

See [how to reach the community](https://github.com/kata-containers/community/blob/master/CONTRIBUTING.md#contact).

## Further information

See the
[project table of contents](https://github.com/kata-containers/kata-containers)
and the
[documentation repository](https://github.com/kata-containers/documentation).

## Additional packages

For details of the other packages contained in this repository, see the
[package documentation](pkg).
","Kata Containers is an open-source container orchestration tool. It works with
Docker and Kubernetes. The code is licensed under an Apache 2.0 license. It is
available for various operating systems. It has a built-in command to determine
if your host system is capable of running and creating a Kata Container. It uses
a TOML format configuration file called `configuration.toml`. The default
location is for a standard system, but it can be customised."
1344,":electron: Build cross platform desktop apps with ASP.NET Core (Razor Pages, MVC, Blazor).","[![Electron.NET Logo](https://github.com/ElectronNET/Electron.NET/blob/master/assets/images/electron.net-logo.png)](https://github.com/ElectronNET/Electron.NET)

[![donate](https://img.shields.io/badge/Donate-Donorbox-green.svg)](https://donorbox.org/electron-net)


AppVeyor (Win/Linux): [![Build status](https://ci.appveyor.com/api/projects/status/q95h4xt14papwi05/branch/master?svg=true)](https://ci.appveyor.com/project/robertmuehsig/electron-net/branch/master)

* Checkout AppVeyor Artifacts: Contains the WebApp sample built for Windows & Linux!

Travis-CI (Win/macOS/Linux): [![Build Status](https://travis-ci.org/ElectronNET/Electron.NET.svg?branch=master)](https://travis-ci.org/ElectronNET/Electron.NET)

Build cross platform desktop apps with .NET 5 and ASP.NET NET Core (Razor Pages, MVC), Blazor. 

Electron.NET is a __wrapper__ around a ""normal"" Electron application with an embedded ASP.NET Core application. Via our Electron.NET IPC bridge we can invoke Electron APIs from .NET.

The CLI extensions hosts our toolset to build and start Electron.NET applications.

## Wait - you host a .NET Core app inside Electron? Why?

Well... there are lots of different approaches how to get a X-plat desktop app running. We thought it would be nice for .NET devs to use the ASP.NET Core environment and just embed it inside a pretty robust X-plat enviroment called Electron. Porting Electron to .NET is not a goal of this project, at least we don't have any clue how to do it. We just combine ASP.NET Core & Electron. 

## 📦 NuGet:

* API [![NuGet](https://img.shields.io/nuget/v/ElectronNET.API.svg?style=flat-square)](https://www.nuget.org/packages/ElectronNET.API/) 
* CLI [![NuGet](https://img.shields.io/nuget/v/ElectronNET.CLI.svg?style=flat-square)](https://www.nuget.org/packages/ElectronNET.CLI/)

## 🛠 Requirements to run:

The current Electron.NET CLI builds Windows/macOS/Linux binaries. Our API multi-targets .NET 5 & .NET6, so our minimum base OS is the same as [.NET 5](https://github.com/dotnet/core/blob/master/release-notes/5.0/5.0-supported-os.md) or [.NET 6](https://github.com/dotnet/core/blob/main/release-notes/6.0/supported-os.md).

Also you should have installed:

* npm [contained in nodejs](https://nodejs.org)

## 💬 Community

[![Gitter](https://badges.gitter.im/ElectronNET/community.svg)](https://gitter.im/ElectronNET/community?utm_source=badge&utm_medium=badge&utm_campaign=pr-badge)

## 🙏 Donate

We do this open source work in our free time. If you'd like us to invest more time on it, please [donate](https://donorbox.org/electron-net). Donation can be used to increase some issue priority. Thank you!

[![donate](https://img.shields.io/badge/Donate-Donorbox-green.svg)](https://donorbox.org/electron-net)

## 👩‍🏫 Usage

To activate and communicate with the ""native"" (sort of native...) Electron API include the [ElectronNET.API NuGet package](https://www.nuget.org/packages/ElectronNET.API/) in your ASP.NET Core app.

````
PM> Install-Package ElectronNET.API
````
### Program.cs

You start Electron.NET up with an `UseElectron` WebHostBuilder-Extension. 

```csharp
public static IHostBuilder CreateHostBuilder(string[] args) =>
    Host.CreateDefaultBuilder(args)
        .ConfigureWebHostDefaults(webBuilder =>
        {
            webBuilder.UseElectron(args);
            webBuilder.UseStartup<Startup>();
        });
```

### Startup.cs

Open the Electron Window in the Startup.cs file: 

```csharp
public void Configure(IApplicationBuilder app, IWebHostEnvironment env)
{
    ...

    // Open the Electron-Window here
    Task.Run(async () => await Electron.WindowManager.CreateWindowAsync());
}
```

## 🚀 Start the Application

To start the application make sure you have installed the ""[ElectronNET.CLI](https://www.nuget.org/packages/ElectronNET.CLI/)"" packages as global tool:

```
dotnet tool install ElectronNET.CLI -g
```

At the first time, you need an Electron.NET project initialization. Type the following command in your ASP.NET Core folder:

```
electronize init
```

* Now a electronnet.manifest.json should appear in your ASP.NET Core project
* Now run the following:

```
electronize start
```

### Note
> Only the first electronize start is slow. The next will go on faster.

## 🔭 Develop Electron.NET apps using a file watcher

The file watcher is included with version 8.31.1 of Electron.NET. For example, a file change can trigger compilation, test execution, or deployment. The Electron.NET window will automatically refresh and new code changes will be visible more quickly. The following Electron.NET CLI command is required:

```
electronize start /watch
```

### Note
> Only the first electronize start is slow. The next will go on faster.

## 🐞 Debug

Start your Electron.NET application with the Electron.NET CLI command. In Visual Studio attach to your running application instance. Go in the __Debug__ Menu and click on __Attach to Process...__. Sort by your projectname on the right and select it on the list.


## 📔 Usage of the Electron-API

A complete documentation will follow. Until then take a look in the source code of the sample application:  
[Electron.NET API Demos](https://github.com/ElectronNET/electron.net-api-demos)  

In this YouTube video, we show you how you can create a new project, use the Electron.NET API, debug a application and build an executable desktop app for Windows: [Electron.NET - Getting Started](https://www.youtube.com/watch?v=nuM6AojRFHk)  
  
## ⛏ Build

Here you need the Electron.NET CLI as well. Type the following command in your ASP.NET Core folder:

```
electronize build /target win
```

There are additional platforms available:

```
electronize build /target win
electronize build /target osx
electronize build /target osx-arm64
electronize build /target linux
```

Those four ""default"" targets will produce packages for those platforms.

Note that the `osx-arm64` build requires that the project target `net6.0`. `osx-arm64` is for Apple Silicon Macs.

For certain NuGet packages or certain scenarios you may want to build a pure x86 application. To support those things you can define the desired [.NET Core runtime](https://docs.microsoft.com/en-us/dotnet/core/rid-catalog), the [electron platform](https://github.com/electron-userland/electron-packager/blob/master/docs/api.md#platform) and [electron architecture](https://github.com/electron-userland/electron-packager/blob/master/docs/api.md#arch) like this:

```
electronize build /target custom ""win7-x86;win32"" /electron-arch ia32 
```

### Additional DotNet Publish Flags

For certain scenarios additional `dotnet publish` arguments may be required. To add additional publish flags use the `/dotnet-publish` flag and add any additional publish flags after. For example if you want to skip the default nuget restore you can do that like this:

```
electronize build /target osx /dotnet-publish --no-restore
```

#### Self-Contained 
> `--self-contained` is enabled by default, to disable use `--no-self-contained` or `--self-contained false`

#### Ignored Flags
> `-r|--runtime`, `-o|--output`, `-c|--configuration`, `--interactive` &amp; `-h|--help` are ignored by design


The end result should be an electron app under your __/bin/desktop__ folder.

### Note
> macOS builds can't be created on Windows machines because they require symlinks that aren't supported on Windows (per [this Electron issue](https://github.com/electron-userland/electron-packager/issues/71)). macOS builds can be produced on either Linux or macOS machines.

## 👨‍💻 Authors

* **Gregor Biswanger** - (Microsoft MVP, Intel Black Belt and Intel Software Innovator) is a freelance lecturer, consultant, trainer, author and speaker. He is a consultant for large and medium-sized companies, organizations and agencies for software architecture, web- and cross-platform development. You can find Gregor often on the road attending or speaking at international conferences. - [Cross-Platform-Blog](http://www.cross-platform-blog.com) - Twitter [@BFreakout](https://www.twitter.com/BFreakout)  
* **Robert Muehsig** - Software Developer - from Dresden, Germany, now living & working in Switzerland. Microsoft MVP & Web Geek. - [codeinside Blog](https://blog.codeinside.eu) - Twitter [@robert0muehsig](https://twitter.com/robert0muehsig)  
  
See also the list of [contributors](https://github.com/ElectronNET/Electron.NET/graphs/contributors) who participated in this project.
  
  
## 🙋‍♀️🙋‍♂ Contributing
Feel free to submit a pull request if you find any bugs (to see a list of active issues, visit the [Issues section](https://github.com/ElectronNET/Electron.NET/issues).
Please make sure all commits are properly documented.

## 🧪 Working with this Repo

This video provides an introduction to development for Electron.NET: [Electron.NET - Contributing Getting Started](https://youtu.be/Po-saU_Z6Ws)  
  
This repository consists of the main parts (API & CLI) and it's own ""playground"" ASP.NET Core application. Both main parts produce local NuGet packages, that are versioned with 99.0.0. The first thing you will need is to run one of the buildAll scripts (.cmd for Windows, the other for macOS/Linux).

If you look for pure __[demo projects](https://github.com/ElectronNET)__ checkout the other repositories. 

The problem working with this repository is, that NuGet has a pretty aggressive cache, see [here for further information](https://github.com/ElectronNET/Electron.NET/wiki).

## 🙏 Donate

We do this open source work in our free time. If you'd like us to invest more time on it, please [donate](https://donorbox.org/electron-net). Donation can be used to increase some issue priority. Thank you!

[![donate](https://img.shields.io/badge/Donate-Donorbox-green.svg)](https://donorbox.org/electron-net)

## 🎉 License
MIT-licensed

**Enjoy!**

## 📝 Important notes

### ElectronNET.API & ElectronNET.CLI Version 13.5.1

Make sure you also have the new Electron.NET API & CLI 13.5.1 version.

```
dotnet tool update ElectronNET.CLI -g
```

 This now uses [electron-builder](https://www.electron.build/configuration/configuration) and the necessary configuration to build is made in the **electron.manifest.json** file (on the build part). In addition, own Electron.NET configurations are stored (on the root). Please make sure that your **electron.manifest.json** file has the following new structure:

```
{
  ""executable"": ""{{executable}}"",
  ""splashscreen"": {
    ""imageFile"": """"
  },
  ""name"": ""{{executable}}"",
  ""author"": """",
  ""singleInstance"": false,
  ""build"": {
    ""appId"": ""com.{{executable}}.app"",
    ""productName"": ""{{executable}}"",
    ""copyright"": ""Copyright © 2020"",
    ""buildVersion"": ""1.0.0"",
    ""compression"": ""maximum"",
    ""directories"": {
      ""output"": ""../../../bin/Desktop""
    },
    ""extraResources"": [
      {
        ""from"": ""./bin"",
        ""to"": ""bin"",
        ""filter"": [""**/*""]
      }
    ],
    ""files"": [
      {
        ""from"": ""./ElectronHostHook/node_modules"",
        ""to"": ""ElectronHostHook/node_modules"",
        ""filter"": [""**/*""]
      },
      ""**/*""
    ]
  }
}
```

### ElectronNET.CLI Version 0.0.9

In the Version 0.0.9 the CLI was not a global tool and needed to be registred like this in the .csproj:

```
<ItemGroup>
     <DotNetCliToolReference Include=""ElectronNET.CLI"" Version=""0.0.9"" />
</ItemGroup>
```

After you edited the .csproj-file, you need to restore your NuGet packages within your Project. Run the following command in your ASP.NET Core folder:

```
dotnet restore
```


If you still use this version you will need to invoke it like this:

```
electronize ...
```

### Node Integration
Electron.NET requires Node Integration to be enabled for IPC to function.  If you are not using the IPC functionality you can disable Node Integration like so:

```csharp
WebPreferences wp = new WebPreferences();
wp.NodeIntegration = false;
BrowserWindowOptions browserWindowOptions = new BrowserWindowOptions
{
    WebPreferences = wp
}

```

### Dependency Injection

ElectronNET.Api can be added to your DI container within the Startup class. All of the modules available in Electron will be added as Singletons.

```csharp
using ElectronNET.API;

public void ConfigureServices(IServiceCollection services)
{
    services.AddElectron()
}
```
","Electron.NET combines ASP.NET Core with an embedded Electron application. Via
our Electron IPC bridge we can invoke Electron APIs from.NET. Our API multi-
targets.NET 5 &.NET6, so our minimum base OS is the same as 5.0 or 6."
2768,"A repository for  ebooks， including C, C plus plus, Linux Kernel, Compiler, OS, Algorithm, Security, Database, Network, ML and DL","# ebooks

A repository for  ebooks， including C, C plus plus, Linux Kernel, Compiler, OS, Algorithm, Security, ML and DL

整个文件的结构将以下面形式展现

```
.
├── Algorithm
│   ├── Algorithms v4.pdf
│   └── 算法图解.pdf
├── Compiler
│   ├── Parsing Techniques--a practical guide.pdf
│   ├── 编译原理 龙书 第2版.pdf
│   ├── 自制编译器.pdf
│   └── 自己动手写编译器、链接器.pdf
├── Cpp
│   ├── C
│   │   ├── ASCII字符表.jpg
│   │   ├── C专家编程.pdf
│   │   ├── C语言标准.pdf
│   │   ├── C陷阱与缺陷.pdf
│   │   ├── Learn C the Hard Way.pdf
│   │   ├── 啊哈C语言书.pdf
│   │   └── 明解C语言  中级篇.pdf
│   └── Cpp
│       ├── Accelerated C++ 简体中文版 .pdf
│       ├── C++ Primer Plus 第5版 中文版.pdf
│       ├── C++ STL源码剖析 侯捷版本.pdf
│       ├── C++ Templates 简体中文版.pdf
│       ├── C++标准程序库.pdf
│       ├── C++编程思想[第一卷].pdf
│       ├── C++编程思想[第二卷].pdf
│       ├── Effective STL 简体中文版.pdf
│       └── 现代 C++ 教程：高速上手 C++.pdf
├── Java
│   ├── Head First Java-第2版 中文完整高清版.pdf
│   └── 深入理解Java虚拟机：JVM高级特性与最佳实践.pdf
├── LinuxKernel
│   ├── Advanced Programming in the UNIX Environment_Third Edition.pdf
│   ├── Linux内存地址映射.pdf
│   ├── Linux内核源代码完全注释 v3 带标签.pdf
│   ├── tool
│   │   ├── Docker容器与容器云 第2版.pdf
│   │   ├── Learning GNU Emacs_Third Edition.pdf
│   │   └── 图解HTTP.epub
│   ├── Understanding the Linux Kernel_3rd Edition.pdf
│   ├── Unix内核源码剖析.pdf
│   ├── UNIX环境高级编程 第2版.pdf
│   ├── UNIX 环境高级编程 第3版.pdf
│   ├── UNIX编程艺术.pdf
│   ├── 深入理解Linux内核 完整版.pdf
│   └── 电子科大Linux内核技术课程
│       ├── 李林_Part
│       │   ├── code
│       │   │   ├── 1
│       │   │   │   ├── 1.1
│       │   │   │   │   ├── PrintingDriver
│       │   │   │   │   │   ├── DriverFileOperations.c
│       │   │   │   │   │   ├── DriverFileOperations.h
│       │   │   │   │   │   ├── DriverMain.c
│       │   │   │   │   │   ├── DriverMain.h
│       │   │   │   │   │   ├── Makefile
│       │   │   │   │   │   └── ToolFunctions.h
│       │   │   │   │   └── UserApp
│       │   │   │   │       └── main.cpp
│       │   │   │   └── 1.2
│       │   │   │       ├── DriverFileOperations.c
│       │   │   │       ├── DriverFileOperations.h
│       │   │   │       ├── DriverMain.c
│       │   │   │       ├── DriverMain.h
│       │   │   │       ├── Makefile
│       │   │   │       └── ToolFunctions.h
│       │   │   ├── 2
│       │   │   │   ├── 2.1
│       │   │   │   │   ├── PrintingDriver
│       │   │   │   │   │   ├── DriverFileOperations.c
│       │   │   │   │   │   ├── DriverFileOperations.h
│       │   │   │   │   │   ├── DriverMain.c
│       │   │   │   │   │   ├── DriverMain.h
│       │   │   │   │   │   ├── IoCtlSupport.h
│       │   │   │   │   │   ├── Makefile
│       │   │   │   │   │   ├── ToolFunctions.c
│       │   │   │   │   │   └── ToolFunctions.h
│       │   │   │   │   └── Userapp
│       │   │   │   │       └── main.cpp
│       │   │   │   ├── 2.10
│       │   │   │   │   ├── DriverFileOperations.c
│       │   │   │   │   ├── DriverFileOperations.h
│       │   │   │   │   ├── DriverMain.c
│       │   │   │   │   ├── DriverMain.h
│       │   │   │   │   ├── Makefile
│       │   │   │   │   ├── ToolFunctions.c
│       │   │   │   │   └── ToolFunctions.h
│       │   │   │   ├── 2.2
│       │   │   │   │   ├── PrintingDriver
│       │   │   │   │   │   ├── DriverFileOperations.c
│       │   │   │   │   │   ├── DriverFileOperations.h
│       │   │   │   │   │   ├── DriverMain.c
│       │   │   │   │   │   ├── DriverMain.h
│       │   │   │   │   │   ├── Makefile
│       │   │   │   │   │   ├── ToolFunctions.c
│       │   │   │   │   │   └── ToolFunctions.h
│       │   │   │   │   └── UserApp
│       │   │   │   │       └── main.cpp
│       │   │   │   ├── 2.3
│       │   │   │   │   ├── PrintingDriver
│       │   │   │   │   │   ├── DriverFileOperations.c
│       │   │   │   │   │   ├── DriverFileOperations.h
│       │   │   │   │   │   ├── DriverMain.c
│       │   │   │   │   │   ├── DriverMain.h
│       │   │   │   │   │   ├── Makefile
│       │   │   │   │   │   ├── ToolFunctions.c
│       │   │   │   │   │   └── ToolFunctions.h
│       │   │   │   │   └── UserApp
│       │   │   │   │       └── main.cpp
│       │   │   │   ├── 2.4
│       │   │   │   │   ├── PrintingDriver
│       │   │   │   │   │   ├── DriverFileOperations.c
│       │   │   │   │   │   ├── DriverFileOperations.h
│       │   │   │   │   │   ├── DriverMain.c
│       │   │   │   │   │   ├── DriverMain.h
│       │   │   │   │   │   ├── Makefile
│       │   │   │   │   │   ├── ToolFunctions.c
│       │   │   │   │   │   └── ToolFunctions.h
│       │   │   │   │   └── UserApp
│       │   │   │   │       └── main.cpp
│       │   │   │   ├── 2.5
│       │   │   │   │   ├── PrintingDriver
│       │   │   │   │   │   ├── DriverFileOperations.c
│       │   │   │   │   │   ├── DriverFileOperations.h
│       │   │   │   │   │   ├── DriverMain.c
│       │   │   │   │   │   ├── DriverMain.h
│       │   │   │   │   │   ├── Makefile
│       │   │   │   │   │   ├── ToolFunctions.c
│       │   │   │   │   │   └── ToolFunctions.h
│       │   │   │   │   └── UserApp
│       │   │   │   │       └── main.cpp
│       │   │   │   ├── 2.6
│       │   │   │   │   ├── DriverFileOperations.c
│       │   │   │   │   ├── DriverFileOperations.h
│       │   │   │   │   ├── DriverMain.c
│       │   │   │   │   ├── DriverMain.h
│       │   │   │   │   ├── Makefile
│       │   │   │   │   └── ToolFunctions.h
│       │   │   │   ├── 2.7
│       │   │   │   │   ├── DriverFileOperations.c
│       │   │   │   │   ├── DriverFileOperations.h
│       │   │   │   │   ├── DriverMain.c
│       │   │   │   │   ├── DriverMain.h
│       │   │   │   │   ├── Makefile
│       │   │   │   │   ├── ToolFunctions.c
│       │   │   │   │   └── ToolFunctions.h
│       │   │   │   ├── 2.8
│       │   │   │   │   └── PageOperations.h
│       │   │   │   └── 2.9
│       │   │   │       ├── DriverFileOperations.c
│       │   │   │       ├── DriverFileOperations.h
│       │   │   │       ├── DriverMain.c
│       │   │   │       ├── DriverMain.h
│       │   │   │       ├── Makefile
│       │   │   │       ├── ToolFunctions.c
│       │   │   │       └── ToolFunctions.h
│       │   │   ├── 3
│       │   │   │   ├── 3.1
│       │   │   │   │   ├── DriverFileOperations.c
│       │   │   │   │   ├── DriverFileOperations.h
│       │   │   │   │   ├── DriverMain.c
│       │   │   │   │   ├── DriverMain.h
│       │   │   │   │   ├── Makefile
│       │   │   │   │   ├── ToolFunctions.c
│       │   │   │   │   └── ToolFunctions.h
│       │   │   │   ├── 3.10
│       │   │   │   │   ├── DriverFileOperations.c
│       │   │   │   │   ├── DriverFileOperations.h
│       │   │   │   │   ├── DriverMain.c
│       │   │   │   │   ├── DriverMain.h
│       │   │   │   │   ├── Makefile
│       │   │   │   │   ├── ToolFunctions.c
│       │   │   │   │   └── ToolFunctions.h
│       │   │   │   ├── 3.11
│       │   │   │   │   ├── DriverFileOperations.c
│       │   │   │   │   ├── DriverFileOperations.h
│       │   │   │   │   ├── DriverMain.c
│       │   │   │   │   ├── DriverMain.h
│       │   │   │   │   ├── Makefile
│       │   │   │   │   ├── ToolFunctions.c
│       │   │   │   │   └── ToolFunctions.h
│       │   │   │   ├── 3.12
│       │   │   │   │   ├── DriverFileOperations.c
│       │   │   │   │   ├── DriverFileOperations.h
│       │   │   │   │   ├── DriverMain.c
│       │   │   │   │   ├── DriverMain.h
│       │   │   │   │   ├── Makefile
│       │   │   │   │   ├── ToolFunctions.c
│       │   │   │   │   ├── ToolFunctions.h
│       │   │   │   │   └── UserApp
│       │   │   │   │       └── main.cpp
│       │   │   │   ├── 3.13
│       │   │   │   │   ├── DriverFileOperations.c
│       │   │   │   │   ├── DriverFileOperations.h
│       │   │   │   │   ├── DriverMain.c
│       │   │   │   │   ├── DriverMain.h
│       │   │   │   │   ├── Makefile
│       │   │   │   │   ├── ToolFunctions.c
│       │   │   │   │   └── ToolFunctions.h
│       │   │   │   ├── 3.14
│       │   │   │   │   ├── DriverFileOperations.c
│       │   │   │   │   ├── DriverFileOperations.h
│       │   │   │   │   ├── DriverMain.c
│       │   │   │   │   ├── DriverMain.h
│       │   │   │   │   ├── Makefile
│       │   │   │   │   ├── ToolFunctions.c
│       │   │   │   │   └── ToolFunctions.h
│       │   │   │   ├── 3.2
│       │   │   │   │   ├── DriverFileOperations.c
│       │   │   │   │   ├── DriverFileOperations.h
│       │   │   │   │   ├── DriverMain.c
│       │   │   │   │   ├── DriverMain.h
│       │   │   │   │   ├── Makefile
│       │   │   │   │   ├── ToolFunctions.c
│       │   │   │   │   └── ToolFunctions.h
│       │   │   │   ├── 3.3
│       │   │   │   │   ├── DriverFileOperations.c
│       │   │   │   │   ├── DriverFileOperations.h
│       │   │   │   │   ├── DriverMain.c
│       │   │   │   │   ├── DriverMain.h
│       │   │   │   │   ├── Makefile
│       │   │   │   │   ├── ToolFunctions.c
│       │   │   │   │   └── ToolFunctions.h
│       │   │   │   ├── 3.4
│       │   │   │   │   ├── DriverFileOperations.c
│       │   │   │   │   ├── DriverFileOperations.h
│       │   │   │   │   ├── DriverMain.c
│       │   │   │   │   ├── DriverMain.h
│       │   │   │   │   ├── Makefile
│       │   │   │   │   ├── ToolFunctions.c
│       │   │   │   │   └── ToolFunctions.h
│       │   │   │   ├── 3.5
│       │   │   │   │   ├── DriverFileOperations.c
│       │   │   │   │   ├── DriverFileOperations.h
│       │   │   │   │   ├── DriverMain.c
│       │   │   │   │   ├── DriverMain.h
│       │   │   │   │   ├── Makefile
│       │   │   │   │   ├── ToolFunctions.c
│       │   │   │   │   └── ToolFunctions.h
│       │   │   │   ├── 3.6
│       │   │   │   │   ├── DriverFileOperations.c
│       │   │   │   │   ├── DriverFileOperations.h
│       │   │   │   │   ├── DriverMain.c
│       │   │   │   │   ├── DriverMain.h
│       │   │   │   │   ├── Makefile
│       │   │   │   │   ├── ToolFunctions.c
│       │   │   │   │   └── ToolFunctions.h
│       │   │   │   ├── 3.7
│       │   │   │   │   ├── DriverFileOperations.c
│       │   │   │   │   ├── DriverFileOperations.h
│       │   │   │   │   ├── DriverMain.c
│       │   │   │   │   ├── DriverMain.h
│       │   │   │   │   ├── Makefile
│       │   │   │   │   ├── ToolFunctions.c
│       │   │   │   │   └── ToolFunctions.h
│       │   │   │   ├── 3.8
│       │   │   │   │   ├── DriverFileOperations.c
│       │   │   │   │   ├── DriverFileOperations.h
│       │   │   │   │   ├── DriverMain.c
│       │   │   │   │   ├── DriverMain.h
│       │   │   │   │   ├── Makefile
│       │   │   │   │   ├── ToolFunctions.c
│       │   │   │   │   └── ToolFunctions.h
│       │   │   │   └── 3.9
│       │   │   │       ├── DriverFileOperations.c
│       │   │   │       ├── DriverFileOperations.h
│       │   │   │       ├── DriverMain.c
│       │   │   │       ├── DriverMain.h
│       │   │   │       ├── Makefile
│       │   │   │       ├── ToolFunctions.c
│       │   │   │       └── ToolFunctions.h
│       │   │   └── 4
│       │   │       ├── 4.1
│       │   │       │   ├── DriverFileOperations.c
│       │   │       │   ├── DriverFileOperations.h
│       │   │       │   ├── DriverMain.c
│       │   │       │   ├── DriverMain.h
│       │   │       │   ├── IoCtlSupport.h
│       │   │       │   ├── Makefile
│       │   │       │   ├── ToolFunctions.c
│       │   │       │   └── ToolFunctions.h
│       │   │       ├── 4.10
│       │   │       │   ├── DriverFileOperations.c
│       │   │       │   ├── DriverFileOperations.h
│       │   │       │   ├── DriverMain.c
│       │   │       │   ├── DriverMain.h
│       │   │       │   ├── Makefile
│       │   │       │   ├── ToolFunctions.c
│       │   │       │   ├── ToolFunctions.h
│       │   │       │   └── UserApp
│       │   │       │       └── main.cpp
│       │   │       ├── 4.11
│       │   │       │   ├── DriverFileOperations.c
│       │   │       │   ├── DriverFileOperations.h
│       │   │       │   ├── DriverMain.c
│       │   │       │   ├── DriverMain.h
│       │   │       │   ├── Makefile
│       │   │       │   ├── ToolFunctions.c
│       │   │       │   └── ToolFunctions.h
│       │   │       ├── 4.12
│       │   │       │   ├── DriverFileOperations.c
│       │   │       │   ├── DriverFileOperations.h
│       │   │       │   ├── DriverMain.c
│       │   │       │   ├── DriverMain.h
│       │   │       │   ├── Makefile
│       │   │       │   ├── ToolFunctions.c
│       │   │       │   └── ToolFunctions.h
│       │   │       ├── 4.13
│       │   │       │   ├── DriverFileOperations.c
│       │   │       │   ├── DriverFileOperations.h
│       │   │       │   ├── DriverMain.c
│       │   │       │   ├── DriverMain.h
│       │   │       │   ├── Makefile
│       │   │       │   ├── ToolFunctions.c
│       │   │       │   ├── ToolFunctions.h
│       │   │       │   ├── UserApp
│       │   │       │   │   └── main.cpp
│       │   │       │   ├── VMallocSpaceMangement.c
│       │   │       │   └── VMallocSpaceMangement.h
│       │   │       ├── 4.14
│       │   │       │   ├── DriverFileOperations.c
│       │   │       │   ├── DriverFileOperations.h
│       │   │       │   ├── DriverMain.c
│       │   │       │   ├── DriverMain.h
│       │   │       │   ├── Makefile
│       │   │       │   ├── ToolFunctions.c
│       │   │       │   ├── ToolFunctions.h
│       │   │       │   ├── UserApp
│       │   │       │   │   └── main.cpp
│       │   │       │   ├── VMallocSpaceMangement.c
│       │   │       │   └── VMallocSpaceMangement.h
│       │   │       ├── 4.15
│       │   │       │   ├── DriverFileOperations.c
│       │   │       │   ├── DriverFileOperations.h
│       │   │       │   ├── DriverMain.c
│       │   │       │   ├── DriverMain.h
│       │   │       │   ├── Makefile
│       │   │       │   ├── ToolFunctions.c
│       │   │       │   └── ToolFunctions.h
│       │   │       ├── 4.16
│       │   │       │   ├── DriverFileOperations.c
│       │   │       │   ├── DriverFileOperations.h
│       │   │       │   ├── DriverMain.c
│       │   │       │   ├── DriverMain.h
│       │   │       │   ├── Makefile
│       │   │       │   ├── ToolFunctions.c
│       │   │       │   └── ToolFunctions.h
│       │   │       ├── 4.17
│       │   │       │   └── vfree.c
│       │   │       ├── 4.18
│       │   │       │   ├── DriverFileOperations.c
│       │   │       │   ├── DriverFileOperations.h
│       │   │       │   ├── DriverMain.c
│       │   │       │   ├── DriverMain.h
│       │   │       │   ├── Makefile
│       │   │       │   ├── ToolFunctions.c
│       │   │       │   └── ToolFunctions.h
│       │   │       ├── 4.19
│       │   │       │   ├── DriverFileOperations.c
│       │   │       │   ├── DriverFileOperations.h
│       │   │       │   ├── DriverMain.c
│       │   │       │   ├── DriverMain.h
│       │   │       │   ├── Makefile
│       │   │       │   ├── ToolFunctions.c
│       │   │       │   └── ToolFunctions.h
│       │   │       ├── 4.2
│       │   │       │   ├── DriverFileOperations.c
│       │   │       │   ├── DriverFileOperations.h
│       │   │       │   ├── DriverMain.c
│       │   │       │   ├── DriverMain.h
│       │   │       │   ├── Makefile
│       │   │       │   ├── ToolFunctions.c
│       │   │       │   └── ToolFunctions.h
│       │   │       ├── 4.3
│       │   │       │   ├── DriverFileOperations.c
│       │   │       │   ├── DriverFileOperations.h
│       │   │       │   ├── DriverMain.c
│       │   │       │   ├── DriverMain.h
│       │   │       │   ├── Makefile
│       │   │       │   ├── ToolFunctions.c
│       │   │       │   └── ToolFunctions.h
│       │   │       ├── 4.4
│       │   │       │   └── virt_addr_valid.c
│       │   │       ├── 4.5
│       │   │       │   ├── DriverFileOperations.c
│       │   │       │   ├── DriverFileOperations.h
│       │   │       │   ├── DriverMain.c
│       │   │       │   ├── DriverMain.h
│       │   │       │   ├── Makefile
│       │   │       │   ├── ToolFunctions.c
│       │   │       │   └── ToolFunctions.h
│       │   │       ├── 4.6
│       │   │       │   ├── DriverFileOperations.c
│       │   │       │   ├── DriverFileOperations.h
│       │   │       │   ├── DriverMain.c
│       │   │       │   ├── DriverMain.h
│       │   │       │   ├── Makefile
│       │   │       │   ├── ToolFunctions.c
│       │   │       │   └── ToolFunctions.h
│       │   │       ├── 4.7
│       │   │       │   ├── DriverFileOperations.c
│       │   │       │   ├── DriverFileOperations.h
│       │   │       │   ├── DriverMain.c
│       │   │       │   ├── DriverMain.h
│       │   │       │   ├── Makefile
│       │   │       │   ├── ToolFunctions.c
│       │   │       │   └── ToolFunctions.h
│       │   │       ├── 4.8
│       │   │       │   └── find_hole.c
│       │   │       └── 4.9
│       │   │           └── alloc_pages.c
│       │   ├── Linux内核01.pptx
│       │   ├── Linux内核02.pptx
│       │   ├── Linux内核03.pptx
│       │   ├── Linux内核04.pptx
│       │   └── 内核调试命令.txt
│       └── 段翰聪_Part
│           ├── 1_Intro.pptx
│           ├── 2_Arch_and_Kernels.pptx
│           ├── 3_process & Threads.pptx
│           ├── 4_Linux Kernel Scheduling Framework Slides.pptx
│           └── 5_Storage Devices & File_Systems.pptx
├── ML
│   ├── An Introduction to R.pdf
│   ├── DL
│   │   ├── An Introduction to Statistical Learning with Applications in R.pdf
│   │   ├── Deep Learning with Python.pdf
│   │   ├── Grokking Deep Learning V10.pdf
│   │   ├── Hands－On_Reinforcement_Learning_with_Python.epub
│   │   ├── Learning From Data.pdf
│   │   ├── Pattern Recognition and Machine Learning.pdf
│   │   ├── PRML_模式识别与机器学习.pdf
│   │   ├── 动手学深度学习.pdf
│   │   ├── 深度学习500问
│   │   │   ├── 深度学习500问-Tan-00目录.pdf
│   │   │   ├── 深度学习500问-Tan-01第一章 数学基础.pdf
│   │   │   ├── 深度学习500问-Tan-02第二章 机器学习基础.pdf
│   │   │   ├── 深度学习500问-Tan-03第三章 深度学习基础.pdf
│   │   │   ├── 深度学习500问-Tan-04第四章 经典网络.pdf
│   │   │   ├── 深度学习500问-Tan-05第五章 卷积神经网络（CNN）.pdf
│   │   │   ├── 深度学习500问-Tan-06第六章 循环神经网络（RNN）.pdf
│   │   │   ├── 深度学习500问-Tan-07第七章 目标检测.pdf
│   │   │   ├── 深度学习500问-Tan-08第八章 图像分割.pdf
│   │   │   ├── 深度学习500问-Tan-09第九章 强化学习.pdf
│   │   │   ├── 深度学习500问-Tan-10第十章 迁移学习.pdf
│   │   │   ├── 深度学习500问-Tan-13第十三章 优化算法.pdf
│   │   │   ├── 深度学习500问-Tan-14第十四章 超参数调整.pdf
│   │   │   ├── 深度学习500问-Tan-15第十五章 正则化.pdf
│   │   │   ├── 深度学习500问-Tan-16参考文献.pdf
│   │   │   └── 目录预览.pdf
│   │   ├── 深度学习入门：基于Python的理论与实现.pdf
│   │   ├── 神经网络与深度学习-3小时.pptx
│   │   └── 神经网络与深度学习.pdf
│   ├── ML
│   │   ├── Advanced Machine Learning with Python.pdf
│   │   ├── Mastering Machine Learning with scikitlearn.pdf
│   │   ├── Python Machine Learning.pdf
│   │   ├── The Hundred-Page Machine Learning Book.pdf
│   │   ├── Understanding the Mathematics behind Gradient Descent_.pdf
│   │   ├── 凸优化
│   │   │   ├── Adequacy of Solutions.pdf
│   │   │   ├── Convex Optimization.pdf
│   │   │   ├── L1L2-regularization.pdf
│   │   │   ├── Lecture24.pdf
│   │   │   └── Optimization.pdf
│   │   ├── 机器学习 周志华.pdf
│   │   └── 统计学习方法.pdf
│   ├── PL
│   │   ├── learn python the hard way.pdf
│   │   ├── Python项目开发实战 第2版 完整高清版 带书签 .pdf
│   │   ├── 利用Python进行数据分析.pdf
│   │   └── 笨办法学 Python 第4版.pdf
│   ├── 普林斯顿微积分读本.pdf
│   └── 集体智慧编程.pdf
├── OS
│   ├── 30天自制操作系统.pdf
│   ├── Assembly
│   │   ├── 汇编语言王爽 第2版 课后答案.pdf
│   │   └── 汇编语言 第3版 王爽著.pdf
│   ├── ELF 格式解析.pdf
│   ├── Minix File System.pdf
│   ├── ORANGE’S：一个操作系统的实现 高清晰版.pdf
│   ├── Writing a Simple Operating System from Scratch.pdf
│   ├── x86汇编语言  从实模式到保护模式.pdf
│   ├── 操作系统share
│   │   ├── Buddy System及应用.pptx
│   │   ├── linux段页存储.pptx
│   │   ├── Seminar2.2.pptx
│   │   ├── Unix OS的PCB分析.pptx
│   │   ├── Unix PCB structure and queue discilpine.ppsx
│   │   ├── Unix进程死锁解决策略.pptx
│   │   ├── unix进程调度策略.pptx
│   │   ├── 中断处理程序流程图(do_IRQ).doc
│   │   └── 操作系统2.3.pptx
│   ├── 现代操作系统 第3版.pdf
│   └── 自己动手写操作系统 完全版.pdf
├── README.md
└── Security
    ├── 会议时间.xlsx
    └── 现代密码学基础.pdf

```
","A repository for ebooks including C, C plus plus, Linux Kernel, Compiler, OS,
Algorithm, Security, ML and DL. Summarize: # ebooks. # ebook. # repository for
ebooks， including C,. C plusplus, Linux, OS and ML."
997,🔐 API key permissions for Django REST Framework,"# Django REST Framework API Key

API key permissions for the [Django REST Framework](https://www.django-rest-framework.org).

<div>
  <a href=""https://dev.azure.com/florimondmanca/public/_build/latest?definitionId=7&branchName=master"">
      <img src=""https://dev.azure.com/florimondmanca/public/_apis/build/status/florimondmanca.djangorestframework-api-key?branchName=master"" alt=""build status""/>
  </a>
  <a href=""https://codecov.io/gh/florimondmanca/djangorestframework-api-key"">
      <img src=""https://codecov.io/gh/florimondmanca/djangorestframework-api-key/branch/master/graph/badge.svg"" alt=""coverage"">
  </a>
  <a href=""https://pypi.org/project/djangorestframework-api-key"">
      <img src=""https://badge.fury.io/py/djangorestframework-api-key.svg"" alt=""package version""/>
  </a>
</div>
<div>
  <img src=""https://img.shields.io/pypi/pyversions/djangorestframework-api-key.svg"" alt=""python versions""/>
  <img src=""https://img.shields.io/pypi/djversions/djangorestframework-api-key.svg?colorB=44b78b"" alt=""django versions""/>
  <img src=""https://img.shields.io/badge/drf-3.8+-7f2d2d.svg"" alt=""drf versions""/>
</div>

## Introduction

**Django REST Framework API Key is a library for allowing server-side clients to safely use your API.** These clients are typically third-party backends and services (i.e. _machines_) which do not have a user account but still need to interact with your API in a secure way.

### Features

- ✌️ **Simple to use**: create, view and revoke API keys via the admin site, or use built-in helpers to create API keys programmatically.
- 🔒 **As secure as possible**: API keys are treated with the same level of care as user passwords. They are hashed using the default password hasher before being stored in the database, and only visible at creation.
- 🎨 **Customizable**: satisfy specific business requirements by building your own customized API key models, permission classes and admin panels.

### Should I use API keys?

There are important security aspects you need to consider before switching to an API key access control scheme. We've listed some of these in [Security caveats](docs/security.md#caveats), including serving your API over HTTPS.

Besides, see [Why and when to use API keys](https://cloud.google.com/endpoints/docs/openapi/when-why-api-key#top_of_page) for hints on whether API keys can fit your use case.

API keys are ideal in the following situations:

- Blocking anonymous traffic.
- Implementing API key-based [throttling](https://www.django-rest-framework.org/api-guide/throttling/). (Note that Django REST Framework already has may built-in utilities for this use case.)
- Identifying usage patterns by logging request information along with the API key.

They can also present enough security for authorizing internal services, such as your API server and an internal frontend application.

> Please note that this package is NOT meant for authentication. You should NOT use this package to identify individual users, either directly or indirectly.
>
> If you need server-to-server authentication, you may want to consider OAuth instead. Libraries such as [django-oauth-toolkit](https://django-oauth-toolkit.readthedocs.io/en/latest/index.html) can help.

## Quickstart

Install with `pip`:

```bash
pip install ""djangorestframework-api-key==2.*""
```

_**Note**: It is highly recommended to **pin your dependency** to the latest major version (as depicted above), as breaking changes may and will happen between major releases._

Add the app to your `INSTALLED_APPS`:

```python
# settings.py

INSTALLED_APPS = [
  # ...
  ""rest_framework"",
  ""rest_framework_api_key"",
]
```

Run the included migrations:

```bash
python manage.py migrate
```

To learn how to configure permissions and manage API keys, head to the [Documentation](https://florimondmanca.github.io/djangorestframework-api-key).

## Changelog

See [CHANGELOG.md](https://github.com/florimondmanca/djangorestframework-api-key/tree/master/CHANGELOG.md).

## Contributing

See [CONTRIBUTING.md](https://github.com/florimondmanca/djangorestframework-api-key/tree/master/CONTRIBUTING.md).

## License

MIT
","Django REST Framework API Key is a library for allowing server-side clients to
safely use your API. API keys are treated with the same level of care as user
passwords. They are hashed using the default password hasher before being stored
in the database, and only visible at creation. They can also present enough
security for authorizing internal services, such as your API server and an
internal frontend application. It is highly recommended to pin your dependency
to the latest major version of Django."
1798,Docker container orchestration platform,"Helios [![Circle CI](https://circleci.com/gh/spotify/helios/tree/master.png?style=badge)](https://circleci.com/gh/spotify/helios/tree/master) [![Slack Status](http://slackin.spotify.com/badge.svg)](http://slackin.spotify.com) [ ![Download](https://api.bintray.com/packages/spotify/deb/helios/images/download.svg) ](https://bintray.com/spotify/deb/helios/_latestVersion)
======

## Status: Bug-fix only

This project was created when there were no open source container orchestration frameworks.
Since the advent of Kubernetes and other tools, we've stopped adding new features to helios
and are now switching to other tools like Kubernetes. This project will no longer have new features
or accept PRs for new features. We will continue to accept bug fixes, however.

Helios is a Docker orchestration platform for deploying and managing
containers across an entire fleet of servers. Helios provides a HTTP
API as well as a command-line client to interact with servers running
your containers. It also keeps a history of events in your cluster including
information such as deploys, restarts and version changes.


Usage Example
-------------

```sh
# Create an nginx job using the nginx container image, exposing it on the host on port 8080
$ helios create nginx:v1 nginx:1.7.1 -p http=80:8080

# Check that the job is listed
$ helios jobs

# List helios hosts
$ helios hosts

# Deploy the nginx job on one of the hosts
$ helios deploy nginx:v1 <host>

# Check the job status
$ helios status

# Curl the nginx container when it's started running
$ curl <host>:8080

# Undeploy the nginx job
$ helios undeploy -a nginx:v1

# Remove the nginx job
$ helios remove nginx:v1
```

Getting Started
---------------

If you're looking for how to use Helios, see the [docs directory](docs).
Most probably the [User Manual](docs/user_manual.md) is what you're looking for.

If you're looking for how to download, build, install and run Helios, keep reading.

Prerequisites
--------------

The binary release of Helios is built for Ubuntu 14.04.1 LTS, but Helios should
be buildable on any platform with at least Java 8 and a recent Maven 3
available.

Other components that are required for a helios installation are:

* [Docker 1.0](https://github.com/docker/docker) or newer
* [Zookeeper 3.4.0](https://zookeeper.apache.org/) or newer


Install & Run
-------------

### Quick start for local usage
Use [helios-solo](https://github.com/spotify/helios/blob/master/docs/helios_solo.md)
to launch a local environment with a Helios master and agent.

First, ensure you have [Docker installed locally](http://docs.docker.com/engine/installation/).
Test this by making sure `docker info` works. Then install helios-solo:

```bash
# add the helios apt repository
$ sudo apt-key adv --keyserver hkp://keys.gnupg.net:80 --recv-keys 6F75C6183FF5E93D
$ echo ""deb https://dl.bintray.com/spotify/deb trusty main"" | sudo tee -a /etc/apt/sources.list.d/helios.list

# install helios-solo on Debian/Ubuntu
$ sudo apt-get update && sudo apt-get install helios-solo

# install helios-solo on OS X
$ brew tap spotify/public && brew install helios-solo
```

Once you've got it installed, bring up the helios-solo cluster:

```bash
# launch a helios cluster in a Docker container
$ helios-up

# check if it worked and the solo agent is registered
$ helios-solo hosts
```

You can now [use helios-solo](https://github.com/spotify/helios/blob/master/docs/helios_solo.md#usage)
as your local Helios cluster. If you have issues, see [the detailed helios-solo documentation](https://github.com/spotify/helios/blob/master/docs/helios_solo.md).

### Production on Debian, Ubuntu, etc.

Prebuilt Debian packages are available for production use. To install:

```bash
# add the helios apt repository
$ sudo apt-key adv --keyserver hkp://keys.gnupg.net:80 --recv-keys 6F75C6183FF5E93D
$ echo ""deb https://dl.bintray.com/spotify/deb trusty main"" | sudo tee -a /etc/apt/sources.list.d/helios.list

# install Helios command-line tools
$ sudo apt-get install helios

# install Helios master (assumes you have zookeeperd installed)
$ sudo apt-get install helios-master

# install Helios agent (assumes you have Docker installed)
$ sudo apt-get install helios-agent
```

Note that the Helios master and agent services both try to connect to ZooKeeper at `localhost:2181`
by default. We recommend reading [the Helios configuration & deployment guide](https://github.com/spotify/helios/blob/master/docs/how_to_deploy.md)
before starting a production cluster.

### Manual approach

The launcher scripts are in [bin/](bin). After you've built Helios following the
instructions below, you should be able to start the agent and master:

    $ bin/helios-master &
    $ bin/helios-agent &

If you see any issues, make sure you have the prerequisites (Docker and Zookeeper) installed.

Build & Test
------------

First, make sure you have Docker installed locally. If you're using OS X, we
recommend using [docker-machine](https://docs.docker.com/machine/).

Actually building Helios and running its tests should be a simple matter
of running:

    $ mvn clean package

For more info on setting up a development environment and an introduction to
the source code, see the [Developer Guide](docs/developer_guide.md).

How it all fits together
------------------------

The `helios` command line tool connects to your helios master via HTTP. The
Helios master is connected to a Zookeeper cluster that is used both as
persistent storage and as a communications channel to the agents. The
helios agent is a java process that typically lives on the same host as
the Docker daemon, connecting to it via a Unix socket or optionally TCP
socket.

Helios is designed for high availability, with execution state being confined
to a potentially highly available Zookeeper cluster. This means that several
helios-master services can respond to HTTP requests concurrently, removing
any single point of failure in the helios setup using straight forward HTTP
load balancing strategies.


Production Readiness
--------------------
We at Spotify are running Helios in production (as of October 2015) with dozens
of critical backend services, so we trust it.  Whether you should trust it to
not cause smoking holes in your infrastructure is up to you.


Why Helios?
-----------

There are a number of Docker orchestration systems, why should you
choose Helios?

* Helios is pragmatic.  We're not trying to solve everything *today*,
  but what we have, we try hard to ensure is rock-solid.  So we don't
  have things like resource limits or dynamic scheduling yet.  Today,
  for us, it has been more important to get the CI/CD use cases, and
  surrounding tooling solid first.  That said, we eventually want to
  do dynamic scheduling, composite jobs, etc. (see below for more).
  But what we provide, we use (i.e. we eat our own dogfood), so you
  can have reasonable assurances that anything that's been in the
  codebase for more than a week or two is pretty solid as we release
  frequently (usually, at least weekly) into production here at
  Spotify.

* Helios should be able to fit in the way you already do ops.  Of the
  popular Docker orchestration frameworks, Helios is the only one
  we're aware of that doesn't have anything much in the way of system
  dependencies.  That is, we don't require that you run in AWS or GCE,
  etc.  We don't require a specific network topology.  We don't
  require you run a specific operating system.  We don't require that
  you're using Mesos.  Our only requirement is that you have a
  ZooKeeper cluster somewhere and a JVM on the machines which
  Helios runs on.  So if you're using Puppet, Chef, etc., to manage the
  rest of the OS install and configuration, you can still continue to
  do so with whatever Linux OS you're using.

* Don't have to drink *all* the Kool-Aid.  Generally, we try to make
  it so you only have to take the features you want to use, and should
  be able to ignore the rest.  For example, Helios doesn't prescribe a
  discovery service: we happen to provide a plugin for SkyDNS, and we
  hear that someone else is working on one for another service, but if
  you don't want to even use a discovery service, you don't have to.

* Scalability.  We're already at hundreds of machines in
  production, but we're nowhere near the limit before the existing
  architecture would need to be revisited.  Helios can also scale down
  well in that you can run a single machine instance if you want to
  run it all locally.

Other Software You Might Want To Consider
-----------------------------------------
Here are a few other things you probably want to consider using alongside
Helios:
* [docker-gc](https://github.com/spotify/docker-gc) Garbage collects dead containers and removes unused images.
* [helios-skydns](https://github.com/spotify/helios-skydns) Makes it so you can auto register services in SkyDNS.  If you use leading underscores in your SRV record names, let us know, we have a patch for etcd which disables the ""hidden"" node feature which makes this use case break.
* [skygc](https://github.com/spotify/skygc)  When using SkyDNS, especially if you're using the Helios Testing Framework, can leave garbage in the skydns tree within etcd.  This will clean out dead stuff.
* [docker-maven-plugin](https://github.com/spotify/docker-maven-plugin)  Simplifies the building of Docker containers if you're using Maven (and most likely Java).

Findbugs
--------

To run [findbugs](http://findbugs.sourceforge.net) on the helios codebase, do
`mvn clean compile site`. This will build helios and then run an analysis,
emitting reports in `helios-*/target/site/findbugs.html`.

To silence an irrelevant warning, add a filter match along with a justification
in `findbugs-exclude.xml`.

The Nickel Tour
---------------

The sources for the Helios master and agent are under [helios-services](helios-services).
The CLI source is under [helios-tools](helios-tools).
The Helios Java client is under [helios-client](helios-client).

The main meat of the Helios agent is in [Supervisor.java](helios-services/src/main/java/com/spotify/helios/agent/Supervisor.java),
which revolves around the lifecycle of managing individual running Docker containers.

For the master, the HTTP response handlers are in [src/main/java/com/spotify/helios/master/resources](helios-services/src/main/java/com/spotify/helios/master/resources).

Interactions with ZooKeeper for the agent and master are mainly in [ZookeeperAgentModel.java](helios-services/src/main/java/com/spotify/helios/agent/ZooKeeperAgentModel.java)
and [ZooKeeperMasterModel.java](helios-services/src/main/java/com/spotify/helios/master/ZooKeeperMasterModel.java),
respectively.

The Helios services use [Dropwizard](http://www.dropwizard.io/0.7.1/docs/) which is a
bundle of Jetty, Jersey, Jackson, Yammer Metrics, Guava, Logback and
other Java libraries.


Community Ideas
---------------

These are things we want, but haven't gotten to.  If you feel
inspired, we'd love to talk to you about these (in no particular
order):

* Host groups
* ACLs - on jobs, hosts, and deployments
* Composite jobs -- be able to deploy related containers as a unit on a machine
* Run once jobs -- for batch jobs
* Resource specification and enforcement -- That is: restrict my container to *X* MB of RAM, *X* CPUs, and *X* MB disk and perhaps other things like IOPs, network bandwidth, etc.
* Dynamic scheduling of jobs -- either within Helios itself or as a layer on top
* Packaging/Config for other Linux distributions such as RedHat, CoreOS, etc.
","Helios is a Docker orchestration platform for deploying and managing containers.
Helios provides a HTTPAPI as well as a command-line client to interact with
servers running containers. It also keeps a history of events in your cluster
including deploys, restarts and version changes."
1254,"UIWidgets is a Unity Package which helps developers to create, debug and deploy efficient, cross-platform Apps.",":warning: The main repository of UIWidgets is migrated to https://github.com/UIWidgets/com.unity.uiwidgets and developed at the new place. Although you can still report issues here, please try visit the new site to obtain the latest UIWidgets. Thanks!


# UIWidgets 2.0 (preview)
[中文](README-ZH.md)

## :rocket:  Join us  :rocket:
The team is now providing several open positions for full-time software engineer based in Shanghai, Unity China :cn:. 

If you are skilled in Unity or flutter and interested in UIWidgets, please join our QQ Group: UIWidgets (Group ID: **234207153**), WeChat Group: UIWidgets 二群 or contact me directly (QQ: **541252510**) for the oppotunity to **Come and Build UIWidgets with us in Unity China**! 

## Introduction

UIWidgets is a plugin package for Unity Editor which helps developers to create, debug and deploy efficient,
cross-platform Apps using the Unity Engine.

UIWidgets is mainly derived from [Flutter](https://github.com/flutter/flutter). However, taking advantage of
the powerful Unity Engine, it offers developers many new features to improve their Apps
as well as the develop workflow significantly.

**UIWidgets 2.0** is developed for **Unity China version** deliberately and aims to **optimize the overall performance of the package**. Specifically, a performance gain around **10%** is observed on  mobile devices like iPhone 6 after upgrading to UIWidgets 2.0. 

If you still want to use the original UIWidgets 1.0, please download the archived packages from Releases or switch your working branch to uiwidgets_1.0.

#### Efficiency
Using the latest Unity rendering SDKs, a UIWidgets App can run very fast and keep >60fps in most times.


#### Cross-Platform
A UIWidgets App can be deployed on all kinds of platforms including PCs and mobile devices directly, like
any other Unity projects.

#### Multimedia Support
Except for basic 2D UIs, developers are also able to include 3D Models, audios, particle-systems to their UIWidgets Apps.


#### Developer-Friendly
A UIWidgets App can be debug in the Unity Editor directly with many advanced tools like
CPU/GPU Profiling, FPS Profiling.


## Example

<div style=""text-align: center""><table><tr>
<td style=""text-align: center"">
  <img src=""https://connect-prd-cdn.unity.com/20190323/p/images/2a27606f-a2cc-4c9f-9e34-bb39ae64d06c_uiwidgets1.gif"" width=""200""/>
</td>
<td style=""text-align: center"">
  <img src=""https://connect-prd-cdn.unity.com/20190323/p/images/097a7c53-19b3-4e0a-ad27-8ec02506905d_uiwidgets2.gif"" width=""200"" />
</td>
<td style=""text-align: center"">
  <img src=""https://connect-prd-cdn.unity.com/20190323/p/images/1f03c1d0-758c-4dde-b3a9-2f5f7216b7d9_uiwidgets3.gif"" width=""200""/>
</td>
<td style=""text-align: center"">
  <img src=""https://connect-prd-cdn.unity.com/20190323/p/images/a8884fbd-9e7c-4bd7-af46-0947e01d01fd_uiwidgets4.gif"" width=""200""/>
</td>
</tr></table></div>

### Projects using UIWidgets

#### Unity Connect App
The Unity Connect App is created using **UIWidgets 2.0** and available for both Android (https://unity.cn/connectApp/download)
and iOS (Searching for ""Unity Connect"" in App Store). This project is open-sourced @https://github.com/UIWidgets/ConnectAppCN2.

#### Unity Chinese Doc
The official website of Unity Chinese Documentation (https://connect.unity.com/doc) is powered by UIWidgets 1.0 and
open-sourced @https://github.com/UnityTech/DocCN.

## Requirements

#### Unity

:warning: **UIWidgets 2.0 are only compatible with Unity China version**

Specifically, the compatible Unity versions for each UIWidgets release are listed below. You can download the latest Unity on [https://unity.cn/releases](https://unity.cn/releases).

| UIWidgets version     |  Unity 2019 LTS  |  Unity 2020 LTS  | 
| -----------------------------------------------| ------------------------- | ------------------------- |
| 1.5.4 and below     | 2019.4.10f1 and above  | N\A |
| 2.0.1   | 2019.4.26f1c1  | N\A |
| 2.0.3   | 2019.4.26f1c1 ~ 2019.4.29f1c1 | N\A |
| 2.0.4 and above | 2019.4.26f1c1 ~ 2019.4.29f1c1 | 2020.3.24f1c2 and above |

#### UIWidgets Package ([video tutorial](https://www.bilibili.com/video/BV1zR4y1s7HN?share_source=copy_web))
Visit our Github repository https://github.com/Unity-Technologies/com.unity.uiwidgets
 to download the latest UIWidgets package.

Move the downloaded package folder into the **root** folder of your Unity project.

Generally, you can make it using a console (or terminal) application by just a few commands as below:

   ```none
    cd <YourProjectPath>
    git clone https://github.com/Unity-Technologies/com.unity.uiwidgets.git com.unity.uiwidgets
   ```

Note that there are many native libraries we built for UIWidget 2.0 to boost its performance, which are large files and hosted by
**Git Large File Storage**. You need to install [this service](https://docs.github.com/en/repositories/working-with-files/managing-large-files/installing-git-large-file-storage) first and then use it to fetch these libraries.

Finally, in PackageManger of unity, select add local file. select ```package.json``` under ```/com.unity.uiwidgets```

#### Runtime Environment

:warning: Though UIWidgets 1.0 is compatible to all platforms, currently **UIWidgets 2.0** only supports MacOS(**Intel64**, Metal/OpenGLCore), iOS(Metal/OpenGLes), Android(**OpenGLes**) and Windows(**Direct3D11**). More devices will be supported in the future.

## Getting Start

#### i. Overview
In this tutorial, we will create a very simple UIWidgets App as the kick-starter. The app contains
only a text label and a button. The text label will count the times of clicks upon the button.

First of all, please open or create a Unity Project and open it with Unity Editor.

#### ii. Scene Build
A UIWidgets App is usually built upon a Unity UI Canvas. Please follow the steps to create a
UI Canvas in Unity.
1. Create a new Scene by ""File -> New Scene"";
1. Create a UI Canvas in the scene by ""GameObject -> UI -> Canvas"";
1. Add a Panel (i.e., **Panel 1**) to the UI Canvas by right click on the Canvas and select ""UI -> Panel"". Then remove the
**Image** Component from the Panel.

#### iii. Create Widget
A UIWidgets App is written in **C# Scripts**. Please follow the steps to create an App and play it
in Unity Editor.

1. Create a new C# Script named ""UIWidgetsExample.cs"" and paste the following codes into it.
   ```csharp
    using System.Collections.Generic;
    using uiwidgets;
    using Unity.UIWidgets.cupertino;
    using Unity.UIWidgets.engine;
    using Unity.UIWidgets.ui;
    using Unity.UIWidgets.widgets;
    using Text = Unity.UIWidgets.widgets.Text;
    using ui_ = Unity.UIWidgets.widgets.ui_;
    using TextStyle = Unity.UIWidgets.painting.TextStyle;

    namespace UIWidgetsSample
    {
        public class UIWidgetsExample : UIWidgetsPanel
        {
            protected void OnEnable()
            {
                // if you want to use your own font or font icons.
                    // AddFont(""Material Icons"", new List<string> {""MaterialIcons-Regular.ttf""}, new List<int> {0});
                base.OnEnable();
            }

            protected override void main()
            {
                ui_.runApp(new MyApp());
            }

            class MyApp : StatelessWidget
            {
                public override Widget build(BuildContext context)
                {
                    return new CupertinoApp(
                        home: new CounterApp()
                    );
                }
            }
        }

        internal class CounterApp : StatefulWidget
        {
            public override State createState()
            {
                return new CountDemoState();
            }
        }

        internal class CountDemoState : State<CounterApp>
        {
            private int count = 0;

            public override Widget build(BuildContext context)
            {
                return new Container(
                    color: Color.fromARGB(255, 255, 0, 0),
                    child: new Column(children: new List<Widget>()
                        {
                            new Text($""count: {count}"", style: new TextStyle(color: Color.fromARGB(255, 0 ,0 ,255))),
                            new CupertinoButton(
                                onPressed: () =>
                                {
                                    setState(() =>
                                    {
                                        count++;
                                    });
                                },
                                child: new Container(
                                    color: Color.fromARGB(255,0 , 255, 0),
                                    width: 100,
                                    height: 40
                                )
                            ),
                        }
                    )
                );
            }
        }
    }
   ```

1. Save this script and attach it to **Panel 1** as its component.
1. Press the ""Play"" Button to start the App in Unity Editor.

#### iv. Build App
Finally, the UIWidgets App can be built to packages for any specific platform by the following steps.
1. Open the Build Settings Panel by ""File -> Build Settings...""
1. Choose a target platform and click ""Build"". Then the Unity Editor will automatically assemble
all relevant resources and generate the final App package.

#### How to load images?
1. Put your images files in StreamingAssets folder. e.g. image1.png.
2. Use Image.file(""image1.png"") to load the image.

UIWidgets supports Gif as well!
1. Put your gif files in StreamingAssets folder. e.g. loading1.gif.
2. Use Image.file(""loading1.gif"") to load the gif images.

#### Show Status Bar on Android
Status bar is always hidden by default when an Unity project is running on an Android device.
If you
want to show the status bar in your App, you can disable```Start in fullscreen``` and ```record outside safe area```, make sure ```showStatusBar``` is ```true``` under ```UIWidgetsAndroidConfiguration```

#### Image Import Setting
Please put images under StreamingAssets folder, a and loading it using ```Image.file```.

#### Show External Texture
You can use the new builtin API ``UIWidgetsExternalTextureHelper.createCompatibleExternalTexture`` to create a compatible render texture in Unity and render it on a ``Texture`` widget in UIWidgets. With the feature, you can easily embed 3d models, videos, etc.
in your App. 

Note that currently this feature is only supported for **OpenGLCore** (Mac), **OpenGLes** (iOS&Android) and **D3D11** (Windows) with **Unity 2020.3.37f1c1** and newer. A simple example (i.e., ``3DTest1.unity``) can be found in our sample project.

#### Performance Optimization on Mobile devices
By setting ```UIWidgetsGlobalConfiguration.EnableAutoAdjustFramerate = true``` in your project, UIWidgets will drop the frame rate of your App to 0 if the UI contents of UIWidgetsPanel is not changed for some time. This will help to prevent battery drain on mobile devices significantly. Note that this feature is disabled by default.

Long time garbage collection may cause App to stuck frequently. You can enable incremental garbage collection to avoid it. You can enable this feature by setting ```UIWidgetsGlobalConfiguration.EnableIncrementalGC = true```, and enabling ```Project Setting -> Player -> Other Settings -> Use incremental GC```.

## Debug UIWidgets Application

In the Editor, you can switch debug/release mode by “UIWidgets->EnableDebug”.

In the Player, the debug/development build will enable debug mode. The release build will disable debug mode automatically.

## Using Window Scope
If you see the error `AssertionError: Window.instance is null` or null pointer error of `Window.instance`,
it means the code is not running in the window scope. In this case, you can enclose your code
with window scope as below:
```csharp
using(Isolate.getScope(the isolate of your App)) {
    // code dealing with UIWidgets,
    // e.g. setState(() => {....})
}
```

This is needed if the code is in methods
not invoked by UIWidgets. For example, if the code is in `completed` callback of `UnityWebRequest`,
you need to enclose them with window scope.
Please see our HttpRequestSample for detail.
For callback/event handler methods from UIWidgets (e.g `Widget.build, State.initState...`), you don't need do
it yourself, since the framework ensure it's in window scope.

## Learn

#### Samples
You can find many UIWidgets sample projects on Github, which cover different aspects and provide you
learning materials in various levels:
* UIWidgetsSamples (https://github.com/Unity-Technologies/com.unity.uiwidgets). These samples are developed by the dev team in order to illustrates all the features of 
UIWidgets. 
you can find all the sample scenes under the **Scene** folder.
You can also try UIWidgets-based Editor windows by clicking the new **UIWidgetsTests** tab on the main menu
and open one of the dropdown samples.
* awesome-UIWidgets (https://plastichub.unity.cn/unity-tech-cn/awesome-uiwidgets). This Repo contains 
some UIWidget demo apps.
* UIWidgets-Templates (https://github.com/UIWidgets/uiwidgets-template). This Repo contains some useful out-of-box UIWidgets widgets.
* ConnectApp (https://github.com/UIWidgets/ConnectAppCN2). This is an online, open-source UIWidget-based App developed 
by the dev team. If you are making your own App with UIWidgets, this project will provides you with 
many best practice cases.


#### Wiki
The develop team is still working on the UIWidgets Wiki. However, since UIWidgets is mainly derived from Flutter,
 you can refer to Flutter Wiki to access detailed descriptions of UIWidgets APIs
 from those of their Flutter counterparts.
Meanwhile, you can join our [discussion channel](https://unity.cn/plate/uiwidgets) to keep in touch with the community.

#### FAQ

1. The editor crashes when openning a UIWidgets 2.0 project, e.g., the Sample projects.

      Please make sure that you are using campatible Unity versions to the specific UIWidgets version. For example, **UIWidgets 2.0.3** is only supported on Unity China version between 2019.4.26f1c1 and 2019.4.29f1c1. You can find the detailed information in 
this [section](#unity).


2. After openning a UIWidgets 2.0 project I receive an error **DllNotFoundException: libUIWidgets**.

      Please make sure that the native libraries are correctly downloaded to your project. You can find them under *UIWidgetsPackageRoot*/Runtime/Plugins. For example, the libUIWidgets.dll under the sub folder *X86_64* is the native library for Windows and the libUIWidgets.dylib under *osx* is for Mac.

      If the libraries are not there or their sizes are small (<1MB), please ensure that you have installed **Git Large File Storage** in your computer and then try the following command line inside the UIWidgets repository.
      ```
      git lfs pull
      ```

3. What is the difference between UIWidgets 2.0 and UIWidgets 1.0 ?

      In UIWidgets 1.0 we used Unity [Graphics API](https://docs.unity3d.com/ScriptReference/Graphics.html) for the rendering and all rendering codes are writen in C#. Therefore it is able to run freely on all platforms that Unity supports but relatively slow. The rendering result is also not exactly the same as in flutter due to the difference between the Unity rendering engine and flutter engine.

      In UIWidgets 2.0, we wrapped the flutter engine inside a native library which is writen in C++ and used it to render on Unity Textures. Its rendering result is the same as in flutter and the performance is also better. However, in order to ensure that the flutter engine works properly along with Unity, we modified both the flutter and Unity Engine. As the result, currently UIWidgets 2.0 can only run on specific Unity versions, i.e., Unity China version and supports only part of the build targets of Unity.

      For better rendering result, performance and continuous upgrade and support, you are always suggested to use UIWidgets 2.0 for your project. Use UIWidgets 1.0 only if you need to support specific target platforms like webgl.

4. I encountered with a link error with OpenGLES for iOS build using UIWidgets 2.0 with Unity 2020.3LTS.

      This is caused by Unity because it removed the dependency on OpenGLES library on Unity 2020.3. To fix this issue, please open the XCode project and manually add the OpenGLES library to the UnityFramework target.
      
## Contact Us

QQ Group: UIWidgets (Group ID: **234207153**)

## How to Contribute

Check [CONTRIBUTING.md](CONTRIBUTING.md)
","UIWidgets is a plugin package for Unity Editor which helps developers to create,
debug and deploy efficient, cross-platform Apps using the Unity Engine. A
performance gain around **10%** is observed on  mobile devices like iPhone 6
after upgrading to UIWidget 2.0. The official website of Unity Chinese
Documentation (https://connect.unity.com/doc) is powered by UIWIDgets 1.0 and
2.1. You can download the latest Unity on [https://unity.cn/releases]."
3073,HFS is a web file server to run on your computer. Share folders or even a single file thanks to the virtual file system.,"# HFS: HTTP File Server

![logo and motto](hfs-logo-color-motto.svg)

## Introduction

HFS is the best way via web to access or share files from your disk.

- It's a server software, share files **fresh from your disk**. Don't rely on services, be independent! 
- It's all very **fast**. Try download zipping 100GB, it starts immediately!
- **Easy to use**. HFS tries to detect problems and suggest solutions.
- Share **even a single file** with our *virtual file system*, even with a different name, all without touching the real file. Present things the way you want!
- **Watch** all activities in real-time.
- **Control bandwidth**, decide how much to give.

This project is in an early stage, few things are missing, but it already rocks!

This is a full rewrite of [the Delphi version](https://github.com/rejetto/hfs2).
You won't find all previous features here (yet), but still we got:

## How does it work

- run HFS on your computer, configuration page automatically shows up
- select what files and folders you want to be accessible
- possibly create accounts and limit access to files
- access those files from a phone or another computer just using a browser

## Features

- https
- unicode
- virtual file system
- mobile friendly front-end
- search
- accounts
- resumable downloads
- resumable uploads
- download folders as zip archive
- simple website serving
- plug-ins
- log file
- speed throttler
- admin web interface
- virtual hosting (plug-in)
- anti-brute-force (plug-in)

## Installation

1. go to https://github.com/rejetto/hfs/releases
2. click on `Assets`
3. **download** the right version for your computer
4. launch `hfs` file
5. the browser should automatically open on `localhost` address, so you can configure the rest in the Admin-panel.
   - if a browser cannot be opened on the computer where you are installing HFS, 
     you should enter this command in HFS console: `create-admin <PASSWORD>`

If you access *Admin-panel* via localhost, by default HFS **won't** require you to login.
If you don't like this behavior, disable it in the Admin-panel or enter this console command `config localhost_admin false`.

### Other systems

If your system is not Windows/Linux/Mac, you can try this alternative version:

0. [install node.js](https://nodejs.org)
1. execute: `sudo npm -g i hfs`
2. launch: `hfs`

Configuration and other files will be stored in `%HOME%/.vfs`

With this installation method, you can update with `sudo npm -g update hfs` .

### Service

If you want to run HFS as a service
- if you installed with `npm` on Windows 
  - service installation
      - run `npx qckwinsvc2 install name=""HFS"" description=""HFS"" path=""%APPDATA%\npm\node_modules\hfs\src\index.js"" args=""--cwd %HOMEPATH%\.hfs"" now`
  - service update 
    - run `npx qckwinsvc2 uninstall name=""HFS""`
    - run `npm -g update hfs`
    - run the service installation again

## Plug-ins

To install a plugin you just copy its folder inside `plugins` folder.

Delete it to uninstall.

HFS will ignore all folders with `-disabled` at the end of the name.

## Why you should upgrade from HFS 2.x to 3

As you can see from the list of features, we already have some goods that you cannot find in HFS 2.
Other than that, you can also consider: 

- it's more robust: it was designed to be an always-running server, while HFS 1-2 was designed for occasional usage (transfer and quit) 
- passwords are never really stored, just a non-reversible hash is
- faster search (up to 12x)
- more flexible permissions

But you may still want to stay with HFS 2.x (so far) for the following reasons

- smaller
- more tested
- classic window interface (can be easier for some people)

## Console commands

If you have access to HFS' console, you can enter commands. Start with `help` to have a full list. 

## Configuration

Configuration can be done in several ways
- accessing the Admin-panel with your browser
  - it will automatically open when you start HFS. Bookmark it. if your port is 8000 the address will be http://localhost:8000/~/admin 
- after HFS has started you can enter console command in the form `config NAME VALUE`
- passing via command line at start in the form `--NAME VALUE`
- directly editing the `config.yaml` file. As soon as you save it is reloaded and changes are applied

`NAME` stands for the property name that you want to change. See the complete list below.

### Where is it stored
Configuration is stored in the file `config.yaml`, which is stored in the same folder of `hfs.exe` if you are using this
kind of distribution on Windows, or `USER_FOLDER/.hfs` on other systems.

You can decide a different file and location by passing `--config SOME_FILE` at command line, or inside
an *env* called `HFS_CONFIG`. Any relative path provided is relative to the *cwd*.  

### Configuration properties
- `port` where to accept http connections. Default is 80.
- `vfs` the files and folders you want to expose. For details see the dedicated following section.
- `log` path of the log file. Default is `access.log`.
- `log_rotation` frequency of log rotation. Accepted values are `daily`, `weekly`, `monthly`, or empty string to disable. Default is `weekly`.
- `error_log` path of the log file for errors. Default is `error.log`.
- `errors_in_main_log` if you want to use a single file for both kind of entries. Default is false.
- `accounts` list of accounts. For details see the dedicated following section.
- `mime` command what mime-type to be returned with some files.
  E.g.: `""*.jpg"": image/jpeg`
  You can specify multiple entries, or separate multiple file masks with a p|pe.
  You can use the special value `auto` to attempt automatic detection.
- `max_kbps` throttle output speed. Default is Infinity.
- `max_kbps_per_ip` throttle output speed on a per-ip basis. Default is Infinity.
- `zip_calculate_size_for_seconds` how long should we wait before the zip archive starts streaming, trying to understand its finale size. Default is 1.
- `open_browser_at_start` should HFS open browser on localhost on start? Default is true.
- `https_port` listen on a specific port. Default is 443.
- `cert` use this file for https certificate. Minimum to start https is to give a cert and a private_key. Default is none.
- `private_key` use this file for https private key. Default is none.
- `allowed_referer` you can decide what domains can link to your files. Wildcards supported. Default is empty, meaning any.
- `block` a list of rules that will block connections. E.g.:
    ```
    block:
      - ip: 192.168.0.90
    ```
  Syntax supports, other than simple address, `*` as wildcard and CIDR format.
- `plugins_config` this is a generic place where you can find/put configuration for each plugin, at least those that need configuration.
- `enable_plugins` if a plugin is not present here, it won't run. Defaults is `[ antibrute ]`.
- `custom_header` provide HTML code to be put at the top of your Frontend. Default is none.
- `localhost_admin` should Admin be accessed without credentials when on localhost. Default is true.
- `proxies` number of proxies between server and clients to be trusted about providing clients' IP addresses. Default is 0.
- `keep_unfinished_uploads` should unfinished uploads be deleted immediately when interrupted. Default is true.

#### Virtual File System (VFS)

The virtual file system is a tree of files and folders, collectively called *nodes*.
By default, a node is a folder, unless you provide for it a source that's a file.
Valid keys in a node are:
- `name`: this is the name we'll use to display this file/folder. If not provided, HFS will infer it from the source. At least `name` or `source` must be provided.
- `source`: absolute or relative path of where to get the content
- `children`: just for folders, specify its virtual children.
  Value is a list and its entries are nodes.
- `rename`: similar to name, but it's  from the parent node point.
  Use this to change the name of  entries that are read from the source, not listed in the VFS.
  Value is a dictionary, where the key is the original name.
- `mime`: specify what mime to use for this resource. Use ""auto"" for automatic detection.
- `default`: to be used with a folder where you want to serve a default html. E.g.: ""index.html"". Using this will make `mime` default to ""auto"".
- `can_read`: specify who can download this entry. Value is a `WhoCan` descriptor, which is one of these values
    - `true`: anyone can, even people who didn't log in. This is normally the default value.
    - `false`: no one can.
    - `""*""`: any account can, i.e. anyone who logged in.
    - `[ frank, peter ]`: the list of accounts who can.
- `can_see`: specify who can see this entry. Even if a user can download you can still make the file not appear in the list.
- `can_upload` specify who can upload. Applies to folders with a source. Default is none. 
  Remember that to see in the list you must also be able to download, or else you won't see it anyway. Value is a `WhoCan` descriptor, refer above.
- `masks`: maps a file mask to a set of properties as the one documented in this section. E.g.
  ```
  masks:
    ""**/*.mp3"":
      can_read: false
    ""*.jpg|*.png"": 
      mime: auto
  ```

Permissions set on an inner element will override inherited permissions. This means that you can restrict access to folder1,
and yet decide to give free access to folder1/subfolder2.   

#### Accounts

All accounts go under `accounts:` property, as a dictionary where the key is the username.
E.g.
```
accounts:
    admin:
        password: hello123
        belongs: group1
    guest:
        password: guest
    group1:
```

As soon as the config is read HFS will encrypt passwords (if necessary) in a non-reversible way. It means that `password` property is replaced with an encrypted property: `srp`.

As you can see in the example, `group1` has no password. This implies that you cannot log in as `group1`, but still `group1` exists and its purpose is to
gather multiple accounts and refer to them collectively as `group1`, so you can quickly share powers among several accounts.

For each account entries, this is the list of properties you can have:

- `ignore_limits` to ignore speed limits. Default is `false`.
- `redirect` provide a URL if you want the user to be redirected upon login. Default is none.
- `admin` set `true` if you want to let this account log in to the Admin-panel. Default is `false`.
- `belongs` an array of usernames of other accounts from which to inherit their permissions. Default is none.

## License

[GPLv3](https://github.com/rejetto/hfs/blob/master/LICENSE.txt)
","HFS is the best way via web to access or share files from your disk. HFS tries
to detect problems and suggest solutions. It's a full rewrite of [the Delphi
version](https://github.com/rejetto/hfs2). It was designed to be an an-running
server, while HFS-2 was designed for occasional usage. It is free and open-
source, with no plans to release it to the general public. It can be downloaded
and installed from GitHub."
38,Pluggable Ruby translation framework,"Mobility
========

[![Gem Version](https://badge.fury.io/rb/mobility.svg)][gem]
[![Build Status](https://github.com/shioyama/mobility/workflows/CI/badge.svg)][actions]
[![Code Climate](https://api.codeclimate.com/v1/badges/72200f2b00c339ec4537/maintainability.svg)][codeclimate]
[![Gitter Chat](https://badges.gitter.im/mobility-ruby/mobility.svg)](https://gitter.im/mobility-ruby/mobility)

[gem]: https://rubygems.org/gems/mobility
[actions]: https://github.com/shioyama/mobility/actions
[codeclimate]: https://codeclimate.com/github/shioyama/mobility
[docs]: http://www.rubydoc.info/gems/mobility
[wiki]: https://github.com/shioyama/mobility/wiki

**This is the readme for version 1.x of Mobility. If you are using an earlier
version (0.8.x or earlier), you probably want the readme on the [0-8
branch](https://github.com/shioyama/mobility/tree/0-8).**

Mobility is a gem for storing and retrieving translations as attributes on a
class. These translations could be the content of blog posts, captions on
images, tags on bookmarks, or anything else you might want to store in
different languages. For examples of what Mobility can do, see the
<a href=""#companies-using-mobility"">Companies using Mobility</a> section below.

Storage of translations is handled by customizable ""backends"" which encapsulate
different storage strategies. The default way to store translations
is to put them all in a set of two shared tables, but many alternatives are
also supported, including [translatable
columns](http://dejimata.com/2017/3/3/translating-with-mobility#strategy-1) and
[model translation
tables](http://dejimata.com/2017/3/3/translating-with-mobility#strategy-2), as
well as database-specific storage solutions such as
[json/jsonb](https://www.postgresql.org/docs/current/static/datatype-json.html) and
[Hstore](https://www.postgresql.org/docs/current/static/hstore.html) (for
PostgreSQL).

Mobility is a cross-platform solution, currently supporting both
[ActiveRecord](http://api.rubyonrails.org/classes/ActiveRecord/Base.html)
and [Sequel](http://sequel.jeremyevans.net/) ORM, with support for other
platforms planned.

For a detailed introduction to Mobility, see [Translating with
Mobility](http://dejimata.com/2017/3/3/translating-with-mobility). See also my
talk at RubyConf 2018, [Building Generic
Software](https://www.youtube.com/watch?v=RZkemV_-__A), where I explain the
thinking behind Mobility's design.

If you're coming from Globalize, be sure to also read the [Migrating from
Globalize](https://github.com/shioyama/mobility/wiki/Migrating-from-Globalize)
section of the wiki.

Installation
------------

Add this line to your application's Gemfile:

```ruby
gem 'mobility', '~> 1.2.9'
```

### ActiveRecord (Rails)

Requirements:
- ActiveRecord >= 5.0 (including 6.x)

(Support for most backends and features is also supported with
ActiveRecord/Rails 4.2, but there are some tests still failing. To see exactly
what might not work, check pending specs in Rails 4.2 builds.)

To translate attributes on a model, extend `Mobility`, then call `translates`
passing in one or more attributes as well as a hash of options (see below).

If using Mobility in a Rails project, you can run the generator to create an
initializer and a migration to create shared translation tables for the
default `KeyValue` backend:

```
rails generate mobility:install
```

(If you do not plan to use the default backend, you may want to use
the `--without_tables` option here to skip the migration generation.)

The generator will create an initializer file `config/initializers/mobility.rb`
which looks something like this:

```ruby
Mobility.configure do

  # PLUGINS
  plugins do
    backend :key_value

    active_record

    reader
    writer

    # ...
  end
end
```

Each method call inside the block passed to `plugins` declares a plugin, along
with an optional default. To use a different default backend, you can
change the default passed to the `backend` plugin, like this:

```diff
 Mobility.configure do

   # PLUGINS
   plugins do
-    backend :key_value
+    backend :table
```

See other possible backends in the [backends section](#backends).

You can also set defaults for backend-specific options. Below, we set the
default `type` option for the KeyValue backend to `:string`.

```diff
 Mobility.configure do

   # PLUGINS
   plugins do
-    backend :key_value
+    backend :key_value, type: :string
   end
 end
```

We will assume the configuration above in the examples that follow.

See [Getting Started](#quickstart) to get started translating your models.

### Sequel

Requirements:
- Sequel >= 4.0

When configuring Mobility, ensure that you include the `sequel` plugin:

```diff
 plugins do
   backend :key_value

-    active_record
+    sequel
```

You can extend `Mobility` just like in ActiveRecord, or you can use the
`mobility` plugin, which does the same thing:

```ruby
class Word < ::Sequel::Model
  plugin :mobility
  translates :name, :meaning
end
```

Otherwise everything is (almost) identical to AR, with the exception that there
is no equivalent to a Rails generator, so you will need to create the migration
for any translation table(s) yourself, using Rails generators as a reference.

The models in examples below all inherit from `ApplicationRecord`, but
everything works exactly the same if the parent class is `Sequel::Model`.

Usage
-----

### <a name=""quickstart""></a>Getting Started

Once the install generator has been run to generate translation tables, using
Mobility is as easy as adding a few lines to any class you want to translate.
Simply pass one or more attribute names to the `translates` method with a hash
of options, like this:

```ruby
class Word < ApplicationRecord
  extend Mobility
  translates :name, :meaning
end
```

Note: When using the KeyValue backend, use the options hash to pass each attribute's type:

```ruby
class Word < ApplicationRecord
  extend Mobility
  translates :name,    type: :string
  translates :meaning, type: :text
end
```

This is important because this is how Mobility knows to which of the [two translation tables](https://github.com/shioyama/mobility/wiki/KeyValue-Backend) it should save your translation.

You now have translated attributes `name` and `meaning` on the model `Word`.
You can set their values like you would any other attribute:

```ruby
word = Word.new
word.name = ""mobility""
word.meaning = ""(noun): quality of being changeable, adaptable or versatile""
word.name
#=> ""mobility""
word.meaning
#=> ""(noun): quality of being changeable, adaptable or versatile""
word.save
word = Word.first
word.name
#=> ""mobility""
word.meaning
#=> ""(noun): quality of being changeable, adaptable or versatile""
```

Presence methods are also supported:

```ruby
word.name?
#=> true
word.name = nil
word.name?
#=> false
word.name = """"
word.name?
#=> false
```

What's different here is that the value of these attributes changes with the
value of `I18n.locale`:

```ruby
I18n.locale = :ja
word.name
#=> nil
word.meaning
#=> nil
```

The `name` and `meaning` of this word are not defined in any locale except
English. Let's define them in Japanese and save the model:

```ruby
word.name = ""モビリティ""
word.meaning = ""(名詞):動きやすさ、可動性""
word.name
#=> ""モビリティ""
word.meaning
#=> ""(名詞):動きやすさ、可動性""
word.save
```

Now our word has names and meanings in two different languages:

```ruby
word = Word.first
I18n.locale = :en
word.name
#=> ""mobility""
word.meaning
#=> ""(noun): quality of being changeable, adaptable or versatile""
I18n.locale = :ja
word.name
#=> ""モビリティ""
word.meaning
#=> ""(名詞):動きやすさ、可動性""
```

Internally, Mobility is mapping the values in different locales to storage
locations, usually database columns. By default these values are stored as keys
(attribute names) and values (attribute translations) on a set of translation
tables, one for strings and one for text columns, but this can be easily
changed and/or customized (see the [Backends](#backends) section below).

### <a name=""getset""></a> Getting and Setting Translations

The easiest way to get or set a translation is to use the getter and setter
methods described above (`word.name` and `word.name=`), enabled by including
the `reader` and `writer` plugins.

You may also want to access the value of an attribute in a specific locale,
independent of the current value of `I18n.locale` (or `Mobility.locale`). There
are a few ways to do this.

The first way is to define locale-specific methods, one for each locale you
want to access directly on a given attribute. These are called ""locale
accessors"" in Mobility, and can be enabled by including the `locale_accessors`
plugin, with a default set of accessors:

```diff
 plugins do
   # ...
+  locale_accessors [:en, :ja]
```

You can also override this default from `translates` in any model:

```ruby
class Word < ApplicationRecord
  extend Mobility
  translates :name, locale_accessors: [:en, :ja]
end
```

Since we have enabled locale accessors for English and Japanese, we can access
translations for these locales with `name_en` and `name_ja`:

```ruby
word.name_en
#=> ""mobility""
word.name_ja
#=> ""モビリティ""
word.name_en = ""foo""
word.name
#=> ""foo""
```

Other locales, however, will not work:

```ruby
word.name_ru
#=> NoMethodError: undefined method `name_ru' for #<Word id: ... >
```

With no plugin option (or a default of `true`), Mobility generates methods for
all locales in `I18n.available_locales` at the time the model is first loaded.

An alternative to using the `locale_accessors` plugin is to use the
`fallthrough_accessors` plugin. This uses Ruby's
[`method_missing`](http://apidock.com/ruby/BasicObject/method_missing) method
to implicitly define the same methods as above, but supporting any locale
without any method definitions. (Locale accessors and fallthrough locales can
be used together without conflict, with locale accessors taking precedence if
defined for a given locale.)

Ensure the plugin is enabled:

```diff
 plugins do
   # ...
+  fallthrough_accessors
```

... then we can access any locale we want, without specifying them upfront:

```ruby
word = Word.new
word.name_fr = ""mobilité""
word.name_fr
#=> ""mobilité""
word.name_ja = ""モビリティ""
word.name_ja
#=> ""モビリティ""
```

(Note however that Mobility will complain if you have
`I18n.enforce_available_locales` set to `true` and you try accessing a locale
not present in `I18n.available_locales`; set it to `false` if you want to allow
*any* locale.)

Another way to fetch values in a locale is to pass the `locale` option to the
getter method, like this:

```ruby
word.name(locale: :en)
#=> ""mobility""
word.name(locale: :fr)
#=> ""mobilité""
```

Note that setting the locale this way will pass an option `locale: true` to the
backend and all plugins. Plugins may use this option to change their behavior
(passing the locale explicitly this way, for example, disables
[fallbacks](#fallbacks), see below for details).

You can also *set* the value of an attribute this way; however, since the
`word.name = <value>` syntax does not accept any options, the only way to do this is to
use `send` (this is included mostly for consistency):

```ruby
word.send(:name=, ""mobiliteit"", locale: :nl)
word.name_nl
#=> ""mobiliteit""
```

Yet another way to get and set translated attributes is to call `read` and
`write` on the storage backend, which can be accessed using the method
`<attribute>_backend`. Without worrying too much about the details of
how this works for now, the syntax for doing this is simple:

```ruby
word.name_backend.read(:en)
#=> ""mobility""
word.name_backend.read(:nl)
#=> ""mobiliteit""
word.name_backend.write(:en, ""foo"")
word.name_backend.read(:en)
#=> ""foo""
```

Internally, all methods for accessing translated attributes ultimately end up
reading and writing from the backend instance this way.  (The `write` methods
do not call underlying backend's methods to persist the change. This is up to
the user, so e.g. with ActiveRecord you should call `save` write the changes to
the database).

Note that accessor methods are defined in an included module, so you can wrap
reads or writes in custom logic:

```ruby
class Post < ApplicationRecord
  extend Mobility
  translates :title

  def title(*)
    super.reverse
  end
end
```

### Setting the Locale

It may not always be desirable to use `I18n.locale` to set the locale for
content translations. For example, a user whose interface is in English
(`I18n.locale` is `:en`) may want to see content in Japanese. If you use
`I18n.locale` exclusively for the locale, you will have a hard time showing
stored translations in one language while showing the interface in another
language.

For these cases, Mobility also has its own locale, which defaults to
`I18n.locale` but can be set independently:

```ruby
I18n.locale = :en
Mobility.locale              #=> :en
Mobility.locale = :fr
Mobility.locale              #=> :fr
I18n.locale                  #=> :en
```

To set the Mobility locale in a block, you can use `Mobility.with_locale` (like
`I18n.with_locale`):

```ruby
Mobility.locale = :en
Mobility.with_locale(:ja) do
  Mobility.locale            #=> :ja
end
Mobility.locale              #=> :en
```

Mobility uses [RequestStore](https://github.com/steveklabnik/request_store) to
reset these global variables after every request, so you don't need to worry
about thread safety. If you're not using Rails, consult RequestStore's
[README](https://github.com/steveklabnik/request_store#no-rails-no-problem) for
details on how to configure it for your use case.

### <a name=""fallbacks""></a>Fallbacks

Mobility offers basic support for translation fallbacks. First, enable the
`fallbacks` plugin:

```diff
 plugins do
   # ...
+  fallbacks
+  locale_accessors
```

Fallbacks will require `fallthrough_accessors` to handle methods like
`title_en`, which are used to track changes. For performance reasons it's
generally best to also enable the `locale_accessors` plugin as shown above.

Now pass a hash with fallbacks for each locale as an option when defining
translated attributes on a class:

```ruby
class Word < ApplicationRecord
  extend Mobility
  translates :name,    fallbacks: { de: :ja, fr: :ja }
  translates :meaning, fallbacks: { de: :ja, fr: :ja }
end
```

Internally, Mobility assigns the fallbacks hash to an instance of
`I18n::Locale::Fallbacks.new`.

By setting fallbacks for German and French to Japanese, values will fall
through to the Japanese value if none is present for either of these locales,
but not for other locales:

```ruby
Mobility.locale = :ja
word = Word.create(name: ""モビリティ"", meaning: ""(名詞):動きやすさ、可動性"")
Mobility.locale = :de
word.name
#=> ""モビリティ""
word.meaning
#=> ""(名詞):動きやすさ、可動性""
Mobility.locale = :fr
word.name
#=> ""モビリティ""
word.meaning
#=> ""(名詞):動きやすさ、可動性""
Mobility.locale = :ru
word.name
#=> nil
word.meaning
#=> nil
```

You can optionally disable fallbacks to get the real value for a given locale
(for example, to check if a value in a particular locale is set or not) by
passing `fallback: false` (*singular*, not plural) to the getter method:

```ruby
Mobility.locale = :de
word.meaning(fallback: false)
#=> nil
Mobility.locale = :fr
word.meaning(fallback: false)
#=> nil
Mobility.locale = :ja
word.meaning(fallback: false)
#=> ""(名詞):動きやすさ、可動性""
```

You can also set the fallback locales for a single read by passing one or more
locales:

```ruby
Mobility.with_locale(:fr) do
  word.meaning = ""(nf): aptitude à bouger, à se déplacer, à changer, à évoluer""
end
word.save
Mobility.locale = :de
word.meaning(fallback: false)
#=> nil
word.meaning(fallback: :fr)
#=> ""(nf): aptitude à bouger, à se déplacer, à changer, à évoluer""
word.meaning(fallback: [:ja, :fr])
#=> ""(名詞):動きやすさ、可動性""
```

Also note that passing a `locale` option into an attribute reader or writer, or
using [locale accessors or fallthrough accessors](#getset) to get or set
any attribute value, will disable fallbacks (just like `fallback: false`).
(This will take precedence over any value of the `fallback` option.)

Continuing from the last example:

```ruby
word.meaning(locale: :de)
#=> nil
word.meaning_de
#=> nil
Mobility.with_locale(:de) { word.meaning }
#=> ""(名詞):動きやすさ、可動性""
```

For more details, see the [API documentation on
fallbacks](http://www.rubydoc.info/gems/mobility/Mobility/Plugins/Fallbacks)
and [this article on I18n
fallbacks](https://github.com/svenfuchs/i18n/wiki/Fallbacks).

### <a name=""default""></a>Default values

Another option is to assign a default value, using the `default` plugin:

```diff
 plugins do
   # ...
+  default 'foo'
```

Here we've set a ""default default"" of `'foo'`, which will be returned if a fetch would
otherwise return `nil`. This can be overridden from model classes:

```ruby
class Word < ApplicationRecord
  extend Mobility
  translates :name, default: 'foo'
end

Mobility.locale = :ja
word = Word.create(name: ""モビリティ"")
word.name
#=> ""モビリティ""
Mobility.locale = :de
word.name
#=> ""foo""
```

You can override the default by passing a `default` option to the attribute reader:

```ruby
word.name
#=> 'foo'
word.name(default: nil)
#=> nil
word.name(default: 'bar')
#=> 'bar'
```

The default can also be a `Proc`, which will be called with the context as the
model itself, and passed optional arguments (attribute, locale and options
passed to accessor) which can be used to customize behaviour. See the [API
docs][docs] for details.

### <a name=""dirty""></a>Dirty Tracking

Dirty tracking (tracking of changed attributes) can be enabled for models which
support it. Currently this is models which include
[ActiveModel::Dirty](http://api.rubyonrails.org/classes/ActiveModel/Dirty.html)
(like `ActiveRecord::Base`) and Sequel models (through the
[dirty](http://sequel.jeremyevans.net/rdoc-plugins/classes/Sequel/Plugins/Dirty.html)
plugin).

First, ensure the `dirty` plugin is enabled in your configuration, and that you
have enabled an ORM plugin (either `active_record` or `sequel`), since the
dirty plugin will depend on one of these being enabled.

```diff
 plugins do
   # ...
   active_record
+  dirty
```

(Once enabled globally, the dirty plugin can be selectively disabled on classes
by passing `dirty: false` to `translates`.)

Take this ActiveRecord class:

```ruby
class Post < ApplicationRecord
  extend Mobility
  translates :title
end
```

Let's assume we start with a post with a title in English and Japanese:

```ruby
post = Post.create(title: ""Introducing Mobility"")
Mobility.with_locale(:ja) { post.title = ""モビリティの紹介"" }
post.save
```

Now let's change the title:

```ruby
post = Post.first
post.title                      #=> ""Introducing Mobility""
post.title = ""a new title""
Mobility.with_locale(:ja) do
  post.title                    #=> ""モビリティの紹介""
  post.title = ""新しいタイトル""
  post.title                    #=> ""新しいタイトル""
end
```

Now you can use dirty methods as you would any other (untranslated) attribute:

```ruby
post.title_was
#=> ""Introducing Mobility""
Mobility.locale = :ja
post.title_was
#=> ""モビリティの紹介""
post.changed
[""title_en"", ""title_ja""]
post.save
```

You can also access `previous_changes`:

```ruby
post.previous_changes
#=>
{
  ""title_en"" =>
    [
      ""Introducing Mobility"",
      ""a new title""
    ],
  ""title_ja"" =>
    [
      ""モビリティの紹介"",
      ""新しいタイトル""
    ]
}
```

Notice that Mobility uses locale suffixes to indicate which locale has changed;
dirty tracking is implemented this way to ensure that it is clear what
has changed in which locale, avoiding any possible ambiguity.

For performance reasons, it is highly recommended that when using the Dirty
plugin, you also enable [locale accessors](#getset) for all locales which will
be used, so that methods like `title_en` above are defined; otherwise they will
be caught by `method_missing` (using fallthrough accessors), which is much slower.

For more details on dirty tracking, see the [API
documentation](http://www.rubydoc.info/gems/mobility/Mobility/Plugins/Dirty).

### Cache

The Mobility cache caches localized values that have been fetched once so they
can be quickly retrieved again. The cache plugin is included in the default
configuration created by the install generator:

```diff
 plugins do
   # ...
+  cache
```

It can be disabled selectively per model by passing `cache: false` when
defining an attribute, like this:

```ruby
class Word < ApplicationRecord
  extend Mobility
  translates :name, cache: false
end
```

You can also turn off the cache for a single fetch by passing `cache: false` to
the getter method, i.e. `post.title(cache: false)`. To remove the cache plugin
entirely, remove the `cache` line from the global plugins configuration.

The cache is normally just a hash with locale keys and string (translation)
values, but some backends (e.g. KeyValue and Table backends) have slightly more
complex implementations.

### <a name=""querying""></a>Querying

Mobility backends also support querying on translated attributes. To enable
this feature, include the `query` plugin, and ensure you also have an ORM
plugin enabled (`active_record` or `sequel`):

```diff
 plugins do
   # ...
   active_record
+  query
```

Querying defines a scope or dataset class method, whose default name is `i18n`.
You can override this by passing a default in the configuration, like
`query :t` to use a name `t`.

Querying is supported in two different ways. The first is via query methods
like `where` (and `not` and `find_by` in ActiveRecord, and `except` in Sequel).

So for ActiveRecord, assuming a model using KeyValue as its default backend:

```ruby
class Post < ApplicationRecord
  extend Mobility
  translates :title,   type: :string
  translates :content, type: :text
end
```

... we can query for posts with title ""foo"" and content ""bar"" just as we would
query on untranslated attributes, and Mobility will convert the queries to
whatever the backend requires to actually return the correct results:

```ruby
Post.i18n.find_by(title: ""foo"", content: ""bar"")
```

results in the SQL:

```sql
SELECT ""posts"".* FROM ""posts""
INNER JOIN ""mobility_string_translations"" ""Post_title_en_string_translations""
  ON ""Post_title_en_string_translations"".""key"" = 'title'
  AND ""Post_title_en_string_translations"".""locale"" = 'en'
  AND ""Post_title_en_string_translations"".""translatable_type"" = 'Post'
  AND ""Post_title_en_string_translations"".""translatable_id"" = ""posts"".""id""
INNER JOIN ""mobility_text_translations"" ""Post_content_en_text_translations""
  ON ""Post_content_en_text_translations"".""key"" = 'content'
  AND ""Post_content_en_text_translations"".""locale"" = 'en'
  AND ""Post_content_en_text_translations"".""translatable_type"" = 'Post'
  AND ""Post_content_en_text_translations"".""translatable_id"" = ""posts"".""id""
WHERE ""Post_title_en_string_translations"".""value"" = 'foo'
  AND ""Post_content_en_text_translations"".""value"" = 'bar'
```

As can be seen in the query above, behind the scenes Mobility joins two tables,
one with string translations and one with text translations, and aliases the
joins for each attribute so as to match the particular model, attribute(s),
locale(s) and value(s) passed in to the query. Details of how this is done can
be found in the [Wiki page for the KeyValue
backend](https://github.com/shioyama/mobility/wiki/KeyValue-Backend#querying).

You can also use methods like `order`, `select`, `pluck` and `group` on
translated attributes just as you would with normal attributes, and Mobility
will handle generating the appropriate SQL:

```ruby
Post.i18n.pluck(:title)
#=> [""foo"", ""bar"", ...]
```

If you would prefer to avoid the `i18n` scope everywhere, you can define it as
a default scope on your model:

```ruby
class Post < ApplicationRecord
  extend Mobility
  translates :title,   type: :string
  translates :content, type: :text
  default_scope { i18n }
end
```

Now translated attributes can be queried just like normal attributes:

```ruby
Post.find_by(title: ""Introducing Mobility"")
#=> finds post with English title ""Introducing Mobility""
```

If you want more fine-grained control over your queries, you can alternatively
pass a block to the query method and call attribute names from the block scope
to build Arel predicates:

```ruby
Post.i18n do
  title.matches(""foo"").and(content.matches(""bar""))
end
```

which generates the same SQL as above, except the `WHERE` clause becomes:

```sql
SELECT ""posts"".* FROM ""posts""
  ...
WHERE ""Post_title_en_string_translations"".""value"" ILIKE 'foo'
  AND ""Post_content_en_text_translations"".""value"" ILIKE 'bar'
```

The block-format query format is very powerful and allows you to build complex
backend-independent queries on translated and untranslated attributes without
having to deal with the details of how these translations are stored. The same
interface is supported with Sequel to build datasets.

<a name=""backends""></a>Backends
--------

Mobility supports different storage strategies, called ""backends"". The default
backend is the `KeyValue` backend, which stores translations in two tables, by
default named `mobility_text_translations` and `mobility_string_translations`.

You can set the default backend to a different value in the global
configuration, or you can set it explicitly when defining a translated
attribute, like this:

```ruby
class Word < ApplicationRecord
  translates :name, backend: :table
end
```

This would set the `name` attribute to use the `Table` backend (see below).
The `type` option (`type: :string` or `type: :text`) is missing here because
this is an option specific to the KeyValue backend (specifying which shared
table to store translations on). Backends have their own specific options; see
the [Wiki][wiki] and [API documentation][docs] for which options are available
for each.

Everything else described above (fallbacks, dirty tracking, locale accessors,
caching, querying, etc) is the same regardless of which backend you use.

### Table Backend (like Globalize)

The `Table` backend stores translations as columns on a model-specific table. If
your model uses the table `posts`, then by default this backend will store an
attribute `title` on a table `post_translations`, and join the table to
retrieve the translated value.

To use the table backend on a model, you will need to first create a
translation table for the model, which (with Rails) you can do using the
`mobility:translations` generator:

```
rails generate mobility:translations post title:string content:text
```

This will generate the `post_translations` table with columns `title` and
`content`, and all other necessary columns and indices. For more details see
the [Table
Backend](https://github.com/shioyama/mobility/wiki/Table-Backend) page of the
wiki and API documentation on the [`Mobility::Backend::Table`
class](http://www.rubydoc.info/gems/mobility/Mobility/Backends/Table).

### Column Backend (like Traco)

The `Column` backend stores translations as columns with locale suffixes on
the model table. For an attribute `title`, these would be of the form
`title_en`, `title_fr`, etc.

Use the `mobility:translations` generator to add columns for locales in
`I18n.available_locales` to your model:

```
rails generate mobility:translations post title:string content:text
```

For more details, see the [Column
Backend](https://github.com/shioyama/mobility/wiki/Column-Backend) page of the
wiki and API documentation on the [`Mobility::Backend::Column`
class](http://www.rubydoc.info/gems/mobility/Mobility/Backends/Column).

### PostgreSQL-specific Backends

Mobility also supports JSON and Hstore storage options, if you are using
PostgreSQL as your database. To use this option, create column(s) on the model
table for each translated attribute, and set your backend to `:json`, `:jsonb`
or `:hstore`. If you are using Sequel, note that you
will need to enable the [pg_json](http://sequel.jeremyevans.net/rdoc-plugins/files/lib/sequel/extensions/pg_json_rb.html)
or
[pg_hstore](http://sequel.jeremyevans.net/rdoc-plugins/files/lib/sequel/extensions/pg_hstore_rb.html)
extensions with `DB.extension :pg_json` or `DB.extension :pg_hstore` (where
`DB` is your database instance).

Another option is to store all your translations on a single jsonb column (one
per model). This is called the ""container"" backend.

For details on these backends, see the [Postgres
Backend](https://github.com/shioyama/mobility/wiki/Postgres-Backends-%28Column-Attribute%29)
and [Container
Backend](https://github.com/shioyama/mobility/wiki/Container-Backend)
pages of the wiki and in the API documentation
([`Mobility::Backend::Jsonb`](http://www.rubydoc.info/gems/mobility/Mobility/Backends/Jsonb)
and
[`Mobility::Backend::Hstore`](http://www.rubydoc.info/gems/mobility/Mobility/Backends/Hstore)).

*Note: The Json backend (`:json`) may also work with recent versions of MySQL
with JSON column support, although this backend/db combination is not tested.
See [this issue](https://github.com/shioyama/mobility/issues/226) for details.*

Development
-----------

### Custom Backends

Although Mobility is primarily oriented toward storing ActiveRecord model
translations, it can potentially be used to handle storing translations in
other formats. In particular, the features mentioned above (locale accessors,
caching, fallbacks, dirty tracking to some degree) are not specific to database
storage.

To use a custom backend, simply pass the name of a class which includes
`Mobility::Backend` to `translates`:

```ruby
class MyBackend
  include Mobility::Backend
  # ...
end

class MyClass
  extend Mobility
  translates :foo, backend: MyBackend
end
```

For details on how to define a backend class, see the [Introduction to Mobility
Backends](https://github.com/shioyama/mobility/wiki/Introduction-to-Mobility-Backends)
page of the wiki and the [API documentation on the `Mobility::Backend`
module](http://www.rubydoc.info/gems/mobility/Mobility/Backend).

### Testing Backends

All included backends are tested against a suite of shared specs which ensure
they conform to the same expected behaviour. These examples can be found in:

- `spec/support/shared_examples/accessor_examples.rb` (minimal specs testing
  translation setting/getting)
- `spec/support/shared_examples/querying_examples.rb` (specs for
  [querying](#querying))
- `spec/support/shared_examples/serialization_examples.rb` (specialized specs
  for backends which store translations as a Hash: `serialized`, `hstore`,
  `json` and `jsonb` backends)

A minimal test can simply define a model class and use helpers defined in
`spec/support/helpers.rb` to run these examples, by extending either
`Helpers::ActiveRecord` or `Helpers::Sequel`:

```ruby
describe MyBackend do
  extend Helpers::ActiveRecord

  before do
    stub_const 'MyPost', Class.new(ActiveRecord::Base)
    MyPost.extend Mobility
    MyPost.translates :title, :content, backend: MyBackend
  end

  include_accessor_examples 'MyPost'
  include_querying_examples 'MyPost'
  # ...
end
```

Shared examples expect the model class to have translated attributes `title`
and `content`, and an untranslated boolean column `published`. These defaults
can be changed, see the shared examples for details.

Backends are also each tested against specialized specs targeted at their
particular implementations.

Integrations
------------

* [friendly_id-mobility](https://github.com/shioyama/friendly_id-mobility): Use
  Mobility with [FriendlyId](https://github.com/norman/friendly_id).
* [mobility-ransack](https://github.com/shioyama/mobility-ransack): Search
  attributes translated by Mobility with
  [Ransack](https://github.com/activerecord-hackery/ransack).
* [mobility-actiontext](https://github.com/sedubois/mobility-actiontext): Translate
  Rails [Action Text](https://guides.rubyonrails.org/action_text_overview.html) rich text
  with Mobility.

Tutorials
---------

- [Polyglot content in a rails
  app](https://revs.runtime-revolution.com/polyglot-content-in-a-rails-app-aed823854955)
- [Translating with
  Mobility](https://dejimata.com/2017/3/3/translating-with-mobility)
- [JSONify your Ruby
  Translations](https://dejimata.com/2018/3/20/jsonify-your-ruby-translations)

More Information
----------------

- [Github repository](https://www.github.com/shioyama/mobility)
- [API documentation][docs]
- [Wiki][wiki]

<a name=""#companies-using-mobility""></a>Companies using Mobility
------------------------

<img alt=""Logos of companies using Mobility"" src=""./img/companies-using-mobility.png"" style=""width: 100%"" />

- [Doorkeeper](https://www.doorkeeper.jp/)
- [Oreegano](https://www.oreegano.com/)
- [Venuu](https://venuu.fi)
- ... <sup>&#10033;</sup>

<sup>&#10033;</sup> <small>Post an issue or email me to add your company's name to this list.</small>

License
-------

The gem is available as open source under the terms of the [MIT License](http://opensource.org/licenses/MIT).
","Mobility is a gem for storing and retrieving translations as attributes on a
class. These translations could be the content of blog posts, captions on
images, tags on bookmarks, or anything else you might want to store in different
languages. For examples of what Mobility can do, see the companies-using-
mobility section below."
1547,📖 A little guide book on Ethereum Development with Go (golang),"<p align=""center"">
  <a href=""https://goethereumbook.org""><img src=""https://github.com/miguelmota/ethereum-development-with-go-book/raw/master/assets/cover.jpg"" width=""320"" alt=""Book cover"" /></a>
</p>
<br>

# Ethereum Development with Go

> A little guide book on [Ethereum](https://www.ethereum.org/) Development with [Go](https://golang.org/) (golang)

[![License](http://img.shields.io/badge/license-MIT-blue.svg)](https://raw.githubusercontent.com/miguelmota/merkletreejs/master/LICENSE)
[![Mentioned in Awesome Go](https://awesome.re/mentioned-badge.svg)](https://github.com/avelino/awesome-go)
[![PRs Welcome](https://img.shields.io/badge/PRs-welcome-brightgreen.svg)](#contributing)

## Online

[https://goethereumbook.org](https://goethereumbook.org/)

## E-book

The e-book is avaiable in different formats.

- [PDF](https://goethereumbook.org/ethereum-development-with-go.pdf)
- [EPUB](https://goethereumbook.org/ethereum-development-with-go.epub)
- [MOBI](https://goethereumbook.org/ethereum-development-with-go.mobi)

## Languages

* [English](en/)
* [Chinese中文](zh/)

## Contents

* [Introduction](en/README.md)
* [Client](en/client/README.md)
  * [Setting up the Client](en/client-setup/README.md)
* [Accounts](en/accounts/README.md)
  * [Account Balances](en/account-balance/README.md)
  * [Account Token Balances](en/account-balance-token/README.md)
  * [Generating New Wallets](en/wallet-generate/README.md)
  * [Keystores](en/keystore/README.md)
  * [HD Wallets](en/hd-wallet/README.md)
  * [Address Check](en/address-check/README.md)
* [Transactions](en/transactions/README.md)
  * [Querying Blocks](en/block-query/README.md)
  * [Querying Transactions](en/transaction-query/README.md)
  * [Transferring ETH](en/transfer-eth/README.md)
  * [Transferring Tokens](en/transfer-tokens/README.md)
  * [Subscribing to New Blocks](en/block-subscribe/README.md)
  * [Create Raw Transaction](en/transaction-raw-create/README.md)
  * [Send Raw Transaction](en/transaction-raw-send/README.md)
* [Smart Contracts](en/smart-contracts/README.md)
  * [Smart Contract Compilation & ABI](en/smart-contract-compile/README.md)
  * [Deploying a Smart Contract](en/smart-contract-deploy/README.md)
  * [Loading a Smart Contract](en/smart-contract-load/README.md)
  * [Querying a Smart Contract](en/smart-contract-read/README.md)
  * [Writing to a Smart Contract](en/smart-contract-write/README.md)
  * [Reading Smart Contract Bytecode](en/smart-contract-bytecode/README.md)
  * [Querying an ERC20 Token Smart Contract](en/smart-contract-read-erc20/README.md)
* [Event Logs](en/events/README.md)
  * [Subscribing to Event Logs](en/event-subscribe/README.md)
  * [Reading Event Logs](en/event-read/README.md)
  * [Reading ERC-20 Token Event Logs](en/event-read-erc20/README.md)
  * [Reading 0x Protocol Event Logs](en/event-read-0xprotocol/README.md)
* [Signatures](en/signatures/README.md)
  * [Generating Signatures](en/signature-generate/README.md)
  * [Verifying Signatures](en/signature-verify/README.md)
* [Testing](en/test/README.md)
  * [Faucets](en/faucets/README.md)
  * [Using a Simulated Client](en/client-simulated/README.md)
* [Swarm](en/swarm/README.md)
  * [Setting Up Swarm](en/swarm-setup/README.md)
  * [Uploading Files to Swarm](en/swarm-upload/README.md)
  * [Download Files From Swarm](en/swarm-download/README.md)
* [Whisper](en/whisper/README.md)
  * [Connecting Whisper Client](en/whisper-client/README.md)
  * [Generating Whisper Key Pair](en/whisper-keys/README.md)
  * [Sending Messages on Whisper](en/whisper-send/README.md)
  * [Subscribing to Whisper Messages](en/whisper-subscribe/README.md)
* [Utilities](en/util/README.md)
  * [Collection of Utility Functions](en/util-go/README.md)
* [Glossary](en/GLOSSARY.md)
* [Resources](en/resources/README.md)

## Help & Support

- Join the [#ethereum](https://gophers.slack.com/messages/C9HP1S9V2/) channel on the [gophers slack](https://invite.slack.golangbridge.org/) for Go (golang) help

- The [Ethereum StackExchange](https://ethereum.stackexchange.com/) is a great place to ask general Ethereum question and Go specific questions

## Development

Install dependencies:

```bash
make install
```

Run gitbook server:

```bash
make serve
```

Generating e-book in pdf, mobi, and epub format:

```bash
make ebooks
```

Visit [http://localhost:4000](http://localhost:4000)

## Contributing

Pull requests are welcome!

If making general content fixes:

- please double check for typos and cite any relevant sources in the comments.

If updating code examples:

- make sure to update both the code in the markdown files as well as the code in the [code](code/) folder.

If wanting to add a new translation, follow these instructions:

1. Set up [development environment](#development)

2. Add language to `LANGS.md`

3. Copy the the `en` directory and rename it with the 2 letter language code of the language you're translating to (e.g. `zh`)

4. Translate content

5. Set `""root""` to `""./""` in `book.json` if not already set

## Thanks

Thanks to [@qbig](https://github.com/qbig) and [@gzuhlwang](https://github.com/gzuhlwang) for the Chinese translation.

And thanks to all the [contributors](https://github.com/miguelmota/ethereum-development-with-go-book/graphs/contributors) who have contributed to this guide book.

## License

Released under the [CC0-1.0](./LICENSE) license.

© [Miguel Mota](https://github.com/miguelmota)
","The e-book is avaiable in different formats. It is available in English,
Chinese, and MOBI. The book is available on GitHub and on the goethereum.org
website. It includes a guide book on developing with Go."
2551,FUSE filesystem for LXC,"# lxcfs

## Introduction
LXCFS is a small FUSE filesystem written with the intention of making Linux
containers feel more like a virtual machine. It started as a side-project of
`LXC` but is useable by any runtime.

LXCFS will take care that the information provided by crucial files in `procfs`
such as:

```
/proc/cpuinfo
/proc/diskstats
/proc/meminfo
/proc/stat
/proc/swaps
/proc/uptime
/proc/slabinfo
/sys/devices/system/cpu/online
```

are container aware such that the values displayed (e.g. in `/proc/uptime`)
really reflect how long the container is running and not how long the host is
running.

Prior to the implementation of cgroup namespaces by Serge Hallyn `LXCFS` also
provided a container aware `cgroupfs` tree. It took care that the container
only had access to cgroups underneath it's own cgroups and thus provided
additional safety. For systems without support for cgroup namespaces `LXCFS`
will still provide this feature but it is mostly considered deprecated.

## Upgrading `LXCFS` without restart

`LXCFS` is split into a shared library (a libtool module, to be precise)
`liblxcfs` and a simple binary `lxcfs`. When upgrading to a newer version of
`LXCFS` the `lxcfs` binary will not be restarted. Instead it will detect that
a new version of the shared library is available and will reload it using
`dlclose(3)` and `dlopen(3)`. This design was chosen so that the fuse main loop
that `LXCFS` uses will not need to be restarted. If it were then all containers
using `LXCFS` would need to be restarted since they would otherwise be left
with broken fuse mounts.

To force a reload of the shared library at the next possible instance simply
send `SIGUSR1` to the pid of the running `LXCFS` process. This can be as simple
as doing:

    rm /usr/lib64/lxcfs/liblxcfs.so # MUST to delete the old library file first
    cp liblxcfs.so /usr/lib64/lxcfs/liblxcfs.so # to place new library file
    kill -s USR1 $(pidof lxcfs) # reload

### musl

To achieve smooth upgrades through shared library reloads `LXCFS` also relies
on the fact that when `dlclose(3)` drops the last reference to the shared
library destructors are run and when `dlopen(3)` is called constructors are
run. While this is true for `glibc` it is not true for `musl` (See the section
[Unloading libraries](https://wiki.musl-libc.org/functional-differences-from-glibc.html).).
So users of `LXCFS` on `musl` are advised to restart `LXCFS` completely and all
containers making use of it.

## Building

In order to build LXCFS install fuse and the fuse development headers according
to your distro. LXCFS prefers `fuse3` but does work with new enough `fuse2`
versions:

    git clone git://github.com/lxc/lxcfs
    cd lxcfs
    meson setup -Dinit-script=systemd --prefix=/usr build/
    meson compile -C build/
    sudo meson install -C build/

To build with sanitizers you have to specify `-Db_sanitize=...` option to `meson setup`.
For example, to enable ASAN and UBSAN:

    meson setup -Dinit-script=systemd --prefix=/usr build/ -Db_sanitize=address,undefined
    meson compile -C build/

## Usage
The recommended command to run lxcfs is:

    sudo mkdir -p /var/lib/lxcfs
    sudo lxcfs /var/lib/lxcfs

A container runtime wishing to use `LXCFS` should then bind mount the
approriate files into the correct places on container startup.

### LXC
In order to use lxcfs with systemd-based containers, you can either use
LXC 1.1 in which case it should work automatically, or otherwise, copy
the `lxc.mount.hook` and `lxc.reboot.hook` files (once built) from this tree to
`/usr/share/lxcfs`, make sure it is executable, then add the
following lines to your container configuration:
```
lxc.mount.auto = cgroup:mixed
lxc.autodev = 1
lxc.kmsg = 0
lxc.include = /usr/share/lxc/config/common.conf.d/00-lxcfs.conf
```

## Using with Docker

```
docker run -it -m 256m --memory-swap 256m \
      -v /var/lib/lxcfs/proc/cpuinfo:/proc/cpuinfo:rw \
      -v /var/lib/lxcfs/proc/diskstats:/proc/diskstats:rw \
      -v /var/lib/lxcfs/proc/meminfo:/proc/meminfo:rw \
      -v /var/lib/lxcfs/proc/stat:/proc/stat:rw \
      -v /var/lib/lxcfs/proc/swaps:/proc/swaps:rw \
      -v /var/lib/lxcfs/proc/uptime:/proc/uptime:rw \
      -v /var/lib/lxcfs/proc/slabinfo:/proc/slabinfo:rw \
      -v /var/lib/lxcfs/sys/devices/system/cpu:/sys/devices/system/cpu:rw \
      ubuntu:18.04 /bin/bash
 ```

 In a system with swap enabled, the parameter ""-u"" can be used to set all values in ""meminfo"" that refer to the swap to 0.

 sudo lxcfs -u /var/lib/lxcfs

## Swap handling
If you noticed LXCFS not showing any SWAP in your container despite
having SWAP on your system, please read this section carefully and look
for instructions on how to enable SWAP accounting for your distribution.

Swap cgroup handling on Linux is very confusing and there just isn't a
perfect way for LXCFS to handle it.

Terminology used below:
 - RAM refers to `memory.usage_in_bytes` and `memory.limit_in_bytes`
 - RAM+SWAP refers to `memory.memsw.usage_in_bytes` and `memory.memsw.limit_in_bytes`

The main issues are:
 - SWAP accounting is often opt-in and, requiring a special kernel boot
   time option (`swapaccount=1`) and/or special kernel build options
   (`CONFIG_MEMCG_SWAP`).

 - Both a RAM limit and a RAM+SWAP limit can be set. The delta however
   isn't the available SWAP space as the kernel is still free to SWAP as
   much of the RAM as it feels like. This makes it impossible to render
   a SWAP device size as using the delta between RAM and RAM+SWAP for that
   wouldn't account for the kernel swapping more pages, leading to swap
   usage exceeding swap total.

 - It's impossible to disable SWAP in a given container. The closest
   that can be done is setting swappiness down to 0 which severly limits
   the risk of swapping pages but doesn't eliminate it.

As a result, LXCFS had to make some compromise which go as follow:
 - When SWAP accounting isn't enabled, no SWAP space is reported at all.
   This is simply because there is no way to know the SWAP consumption.
   The container may very much be using some SWAP though, there's just
   no way to know how much of it and showing a SWAP device would require
   some kind of SWAP usage to be reported. Showing the host value would be
   completely wrong, showing a 0 value would be equallty wrong.

 - Because SWAP usage for a given container can exceed the delta between
   RAM and RAM+SWAP, the SWAP size is always reported to be the smaller of
   the RAM+SWAP limit or the host SWAP device itself. This ensures that at no
   point SWAP usage will be allowed to exceed the SWAP size.

 - If the swappiness is set to 0 and there is no SWAP usage, no SWAP is reported.
   However if there is SWAP usage, then a SWAP device of the size of the
   usage (100% full) is reported. This provides adequate reporting of
   the memory consumption while preventing applications from assuming more
   SWAP is available.
","LXCFS is a small FUSE filesystem written with the intention of making Linux
containers feel more like a virtual machine. When upgrading to a newer version
of `LXcFS` the `lxcfs` binary will not be restarted. Instead it will detect that
a new version of the shared library is available and will reload it. LXCFS
prefers `fuse3` but does work with new enough `Fuse2`versions. It can be
upgraded by deleting the old library file first and loading the new one."
2839,"PyTorch and TensorFlow implementation of NCP, LTC, and CfC wired neural models","<div align=""center""><img src=""https://raw.githubusercontent.com/mlech26l/ncps/master/docs/img/banner.png"" width=""800""/></div>

# Neural Circuit Policies (for PyTorch and TensorFlow)

[![DOI](https://zenodo.org/badge/290199641.svg)](https://zenodo.org/badge/latestdoi/290199641)
![ci_badge](https://github.com/mlech26l/ncps/actions/workflows/python-test.yml/badge.svg) 
![pyversion](misc/pybadge.svg)
![PyPI version](https://img.shields.io/pypi/v/ncps)
![Documentation Status](https://readthedocs.org/projects/ncps/badge/?version=latest)
![downloads](https://img.shields.io/pypi/dm/ncps)

## 📜 Papers

[Neural Circuit Policies Enabling Auditable Autonomy (Open Access)](https://publik.tuwien.ac.at/files/publik_292280.pdf)

Neural Circuit Policies (NCPs) are designed sparse recurrent neural networks loosely inspired by the nervous system of the organism [C. elegans](http://www.wormbook.org/chapters/www_celegansintro/celegansintro.html). 
The goal of this package is to making working with NCPs in PyTorch and keras as easy as possible.

[📖 Docs](https://ncps.readthedocs.io/en/latest/index.html)

```python
import torch
from ncps.torch import CfC

rnn = CfC(20,50) # (input, hidden units)
x = torch.randn(2, 3, 20) # (batch, time, features)
h0 = torch.zeros(2,50) # (batch, units)
output, hn = rnn(x,h0)
```


## Installation

```bash
pip install ncps
```

## 🔖 Colab Notebooks

We have created a few Google Colab notebooks for an interactive introduction to the package

- [Google Colab (Pytorch) Basic usage](https://colab.research.google.com/drive/1VWoGcpyqGvrUOUzH7ccppE__m-n1cAiI?usp=sharing)
- [Google Colab (Tensorflow): Basic usage](https://colab.research.google.com/drive/1IvVXVSC7zZPo5w-PfL3mk1MC3PIPw7Vs?usp=sharing)
- [Google Colab (Tensorflow) Stacking NCPs with other layers](https://colab.research.google.com/drive/1-mZunxqVkfZVBXNPG0kTSKUNQUSdZiBI?usp=sharing)

## End-to-end Examples

- [Quickstart (torch and tf)](https://ncps.readthedocs.io/en/latest/quickstart.html)
- [Atari Behavior Cloning (torch and tf)](https://ncps.readthedocs.io/en/latest/examples/atari_bc.html)
- [Atari Reinforcement Learning (tf)](https://ncps.readthedocs.io/en/latest/examples/atari_ppo.html)

## Usage: Models and Wirings

The package provides two models, the liquid time-constant (LTC) and the closed-form continuous-time (CfC) models.
Both models are available as ```tf.keras.layers.Layer``` or ```torch.nn.Module``` RNN layers.

```python
from ncps.torch import CfC, LTC

input_size = 20
units = 28 # 28 neurons
rnn = CfC(input_size, units)
rnn = LTC(input_size, units)
```

The RNNs defined above consider fully-connected layers, i.e., as in LSTM, GRUs, and other RNNs.
The distinctiveness of NCPs is their structured wiring diagram. 
To combine the LTC or CfC model with a 

```python
from ncps.torch import CfC, LTC
from ncps.wirings import AutoNCP

wiring = AutoNCP(28, 4) # 28 neurons, 4 outputs
input_size = 20
rnn = CfC(input_size, wiring)
rnn = LTC(input_size, wiring)
```

![alt](https://github.com/mlech26l/ncps/raw/master/docs/img/things.png)

## Tensorflow

The Tensorflow bindings are available via the ```ncps.tf``` module.

```python
from ncps.tf import CfC, LTC
from ncps.wirings import AutoNCP

units = 28
wiring = AutoNCP(28, 4) # 28 neurons, 4 outputs
input_size = 20
rnn1 = LTC(units) # fully-connected LTC
rnn2 = CfC(units) # fully-connected CfC
rnn3 = LTC(wiring) # NCP wired LTC
rnn4 = CfC(wiring) # NCP wired CfC
```

We can then combine the NCP cell with arbitrary ```tf.keras.layers```, for instance to build a powerful image sequence classifier:

```python
from ncps.wirings import AutoNCP
from ncps.tf import LTC
import tensorflow as tf
height, width, channels = (78, 200, 3)

ncp = LTC(AutoNCP(32, output_size=8), return_sequences=True)

model = tf.keras.models.Sequential(
    [
        tf.keras.layers.InputLayer(input_shape=(None, height, width, channels)),
        tf.keras.layers.TimeDistributed(
            tf.keras.layers.Conv2D(32, (5, 5), activation=""relu"")
        ),
        tf.keras.layers.TimeDistributed(tf.keras.layers.MaxPool2D()),
        tf.keras.layers.TimeDistributed(
            tf.keras.layers.Conv2D(64, (5, 5), activation=""relu"")
        ),
        tf.keras.layers.TimeDistributed(tf.keras.layers.MaxPool2D()),
        tf.keras.layers.TimeDistributed(tf.keras.layers.Flatten()),
        tf.keras.layers.TimeDistributed(tf.keras.layers.Dense(32, activation=""relu"")),
        ncp,
        tf.keras.layers.TimeDistributed(tf.keras.layers.Activation(""softmax"")),
    ]
)
model.compile(
    optimizer=tf.keras.optimizers.Adam(0.01),
    loss='sparse_categorical_crossentropy',
)
```

```bib
@article{lechner2020neural,
  title={Neural circuit policies enabling auditable autonomy},
  author={Lechner, Mathias and Hasani, Ramin and Amini, Alexander and Henzinger, Thomas A and Rus, Daniela and Grosu, Radu},
  journal={Nature Machine Intelligence},
  volume={2},
  number={10},
  pages={642--652},
  year={2020},
  publisher={Nature Publishing Group}
}
```","Neural Circuit Policies (NCPs) are designed sparse recurrent neural networks.
They are loosely inspired by the nervous system of the organism [C. elegans] The
goal of this package is to make working with NCPs in PyTorch as easy as
possible."
1854,Package manager and build abstraction tool for FPGA/ASIC development,"# FuseSoC

[![CI status](https://github.com/olofk/fusesoc/workflows/CI/badge.svg)](https://github.com/olofk/fusesoc/actions?query=workflow%3ACI)
[![image](https://img.shields.io/pypi/dm/fusesoc.svg?label=PyPI%20downloads)](https://pypi.org/project/fusesoc/)
[![LibreCores](https://www.librecores.org/olofk/FuseSoC/badge.svg?style=flat)](https://www.librecores.org/olofk/FuseSoC)

## Introduction

FuseSoC is an award-winning package manager and a set of build tools for
HDL (Hardware Description Language) code.

Its main purpose is to increase reuse of IP (Intellectual Property)
cores and be an aid for creating, building and simulating SoC solutions.

FuseSoC makes it easier to

-   reuse existing cores
-   create compile-time or run-time configurations
-   run regression tests against multiple simulators
-   port designs to new targets
-   let other projects use your code
-   set up continuous integration

To learn more about FuseSoC head over to the
[User Guide](https://fusesoc.readthedocs.io/en/stable/user).

## Getting started

### Installing the latest release

FuseSoC works on Linux, Windows, and macOS. It is written in Python and can be
installed like any other Python package through ""pip"". Please refer to the
full list of system requirements and installation instructions in the
[Installation section in the User Guide](https://fusesoc.readthedocs.io/en/stable/user/installation.html).

### Quick start

To check if FuseSoC is working, and to get an initial feeling for how FuseSoC
works, you can try to simulate a simple hardware design from our core libray.

First, create and enter an empty workspace

    mkdir workspace
    cd workspace

Install the FuseSoc base library into the workspace

    fusesoc library add fusesoc-cores https://github.com/fusesoc/fusesoc-cores

Get a list of cores found in the workspace

    fusesoc core list

If you have any of the supported simulators installed, you can try to
run a simulation on one of the cores as well. For example,
`fusesoc run --target=sim i2c` will run a regression test on the core
i2c with Icarus Verilog. If you want to try another simulator instead,
add e.g. `--tool=modelsim` or `--tool=xcelium` between `run` and `i2c`.

`fusesoc --help` will give you more information on commands and switches.

Did it work? Great! FuseSoC can be used to create FPGA images, perform
linting, manage your IP libraries or do formal verification as well.
Check out the [online documentation](https://fusesoc.readthedocs.io/en/stable/)
documentation to learn more about creating your own core files and using
existing ones. If it didn't work, please get in touch (see below).

## Next steps

A good way to get your first hands-on experience with FuseSoC is to
contribute to the [LED to Believe](https://github.com/fusesoc/blinky)
project. This project aims to used FuseSoC to blink a LED on every
available FPGA development board in existence. There are already around
40 different boards supported. If your board is already supported,
great, then you can run your first FuseSoC-based design. If it's not
supported, great, you now have the chance to add it to the list of
supported boards. Either way, head over to [LED to
Believe](https://github.com/fusesoc/blinky) to learn more and see how to
go from a blinking LED to running a RISC-V core on an FPGA.

## Need help?

FuseSoC comes with extensive
[online documentation](https://fusesoc.readthedocs.io/en/stable/index.html).

For quick communication with the active developers, feel free to join us at the
[FuseSoC chat](https://gitter.im/librecores/fusesoc).

If you have found an issue, or want to know more about currently known problems,
check out the
[issue tracker on GitHub](https://github.com/olofk/fusesoc/issues).

If you are looking for professional paid support, we are happy to
provide feature additions, bug fixes, user training, setting up core
libraries, migrating existing designs to FuseSoC and other things.
Please contact <olof.kindgren@gmail.com> for more information.

## Contributing to FuseSoC

FuseSoC is developed by an active and friendly community, and you're welcome to
join! You can read more about setting up a development environment in our
[Developer's Guide](https://fusesoc.readthedocs.io/en/latest/dev/index.html).

You can file bug reports and propose changes in the [olofk/fusesoc repository on GitHub](https://github.com/olofk/fusesoc).

## Further reading

* A Scalable Approach to IP Management with FuseSoC [paper](https://osda.gitlab.io/19/kindgren.pdf) and [slides](https://osda.gitlab.io/19/kindgren-slides.pdf) from OSDA 2019
* Antmicro blog post on [how to use FuseSoC as a linter](https://antmicro.com/blog/2020/04/systemverilog-linter-and-formatter-in-fusesoc/)
* [FuseSoC-related posts on the Tales from Beyond the Register Map blog](https://blog.award-winning.me/search/label/FuseSoC)
* [Presentation from RISC-V Week 2022](https://www.award-winning.me/fusesoc-rvweek22)
* [Presentation from Latch-Up Portland 2019](https://www.youtube.com/watch?v=7eWRAOK9mns)
* [Presentation from WOSH 2019](https://www.youtube.com/watch?v=HOFYplIBSWM)
* [Presentation from ORConf 2017](https://www.youtube.com/watch?v=iPpT9k_H67k)
* [Presentation from ORConf 2016](https://www.youtube.com/watch?v=pKlJWe_HKPM)

## License

FuseSoC is licensed under the permissive 2-clause BSD license, freely allowing
use, modification, and distribution of FuseSoC for all kinds of projects.
Please refer to the [LICENSE](LICENSE) file for details.
","FuseSoC is an award-winning package manager and a set of build tools for
Hardware Description Language code. Its main purpose is to increase reuse of IP
(Intellectual Property)cores and be an aid for creating, building and simulating
SoC solutions. It is written in Python and can beinstalled like any other Python
package through ""pip"" It can be used to create FPGA images, manage your IP
libraries or do formal verification as well. It works on Linux, Windows, and
macOS."
2893,Execute one command (or mount one Node.js middleware) and get an instant high-performance GraphQL API for your PostgreSQL database!,"<img width=""120"" height=""120"" title=""PostGraphile logo"" src=""https://cdn.rawgit.com/graphile/graphile.github.io/a6225f8c3052df5c276ecef28aeb0cade1aec16a/logos/postgraphile.optimized.svg"" />

# PostGraphile

[![GitHub Sponsors](https://img.shields.io/github/sponsors/benjie?label=GitHub%20sponsors)](https://github.com/sponsors/benjie)
[![Patreon sponsor button](https://img.shields.io/badge/sponsor-via%20Patreon-orange.svg)](https://patreon.com/benjie)
[![Discord chat room](https://img.shields.io/discord/489127045289476126.svg)](http://discord.gg/graphile)
[![Package on npm](https://img.shields.io/npm/v/postgraphile.svg?style=flat)](https://www.npmjs.com/package/postgraphile)
![MIT license](https://img.shields.io/npm/l/postgraphile.svg)
[![Follow](https://img.shields.io/badge/twitter-@GraphileHQ-blue.svg)](https://twitter.com/GraphileHQ)

_**Instant lightning-fast GraphQL API backed primarily by your PostgreSQL database. Highly customisable and extensible thanks to incredibly powerful plugin system.**_ _Formerly ""PostGraphQL""._

## Documentation: [graphile.org/postgraphile](https://graphile.org/postgraphile)

<!-- SPONSORS_BEGIN -->

## Crowd-funded open-source software

To help us develop this software sustainably under the MIT license, we ask
all individuals and businesses that use it to help support its ongoing
maintenance and development via sponsorship.

### [Click here to find out more about sponsors and sponsorship.](https://www.graphile.org/sponsor/)

And please give some love to our featured sponsors 🤩:

<table><tr>
<td align=""center""><a href=""https://surge.io/""><img src=""https://graphile.org/images/sponsors/surge.png"" width=""90"" height=""90"" alt=""Surge"" /><br />Surge</a> *</td>
<td align=""center""><a href=""https://www.netflix.com/""><img src=""https://graphile.org/images/sponsors/Netflix.png"" width=""90"" height=""90"" alt=""Netflix"" /><br />Netflix</a> *</td>
<td align=""center""><a href=""https://qwick.com/""><img src=""https://graphile.org/images/sponsors/qwick.png"" width=""90"" height=""90"" alt=""Qwick"" /><br />Qwick</a> *</td>
<td align=""center""><a href=""https://www.the-guild.dev/""><img src=""https://graphile.org/images/sponsors/theguild.png"" width=""90"" height=""90"" alt=""The Guild"" /><br />The Guild</a> *</td>
</tr><tr>
<td align=""center""><a href=""http://chads.website""><img src=""https://graphile.org/images/sponsors/chadf.png"" width=""90"" height=""90"" alt=""Chad Furman"" /><br />Chad Furman</a> *</td>
<td align=""center""><a href=""https://www.fanatics.com/""><img src=""https://graphile.org/images/sponsors/fanatics.png"" width=""90"" height=""90"" alt=""Fanatics"" /><br />Fanatics</a> *</td>
<td align=""center""><a href=""https://dovetailapp.com/""><img src=""https://graphile.org/images/sponsors/dovetail.png"" width=""90"" height=""90"" alt=""Dovetail"" /><br />Dovetail</a> *</td>
<td align=""center""><a href=""https://www.enzuzo.com/""><img src=""https://graphile.org/images/sponsors/enzuzo.png"" width=""90"" height=""90"" alt=""Enzuzo"" /><br />Enzuzo</a> *</td>
</tr><tr>
<td align=""center""><a href=""https://stellate.co/""><img src=""https://graphile.org/images/sponsors/Stellate.png"" width=""90"" height=""90"" alt=""Stellate"" /><br />Stellate</a> *</td>
<td align=""center""><a href=""https://politicsrewired.com/""><img src=""https://graphile.org/images/sponsors/politics-rewired.png"" width=""90"" height=""90"" alt=""Politics Rewired"" /><br />Politics Rewired</a></td>
<td align=""center""><a href=""https://iasql.com/""><img src=""https://graphile.org/images/sponsors/IaSQL.png"" width=""90"" height=""90"" alt=""IaSQL"" /><br />IaSQL</a></td>
</tr></table>

<em>\* Sponsors the entire Graphile suite</em>

<!-- SPONSORS_END -->

## About

**GraphQL** is a new way of communicating with your server. It eliminates the problems of over- and under-fetching, incorporates strong data types, has built-in introspection, documentation and deprecation capabilities, and is implemented in many programming languages. This all leads to gloriously low-latency user experiences, better developer experiences, and much increased productivity. Because of all this, GraphQL is typically used as a replacement for (or companion to) RESTful API services.

**PostgreSQL** is the self-proclaimed “world’s most advanced open source database,” with each new release bringing more amazing features and performance gains. Thinking of your database as a plain CRUD store is now an archaic viewpoint as modern PostgreSQL can do so much for you &mdash; from authorization with Row-Level Security (RLS, introduced in PG9.5), through Foreign Data Wrappers (FDW), to real time notifications with `LISTEN`/`NOTIFY`.

**PostGraphile** pairs these two incredible technologies together, helping you not only build applications more rapidly, but to build lightning-fast applications. PostGraphile allows you to access the power of PostgreSQL through a well designed, extensible, customisable and incredibly performant GraphQL server. It automatically detects tables, columns, indexes, relationships, views, types, functions, comments, and more - providing a GraphQL server that is highly intelligent about your data, and that automatically updates itself without restarting when you change your database schema.

With PostGraphile, a well designed database schema should serve the basis for a well thought out API. PostgreSQL already has amazing authorization and relationship infrastructure, _why duplicate that logic_ in a custom API? A PostGraphile API is likely to provide a more performant and standards compliant GraphQL API than any created in-house, and can be built in a fraction of the time. Focus on your product and let PostGraphile worry about the API layer. Once you need to expand beyond this, we have a powerful plugin system including many [community contributed plugins](https://www.graphile.org/postgraphile/community-plugins/). For a critical evaluation of PostGraphile to determine if it fits in your tech stack, read [evaluating PostGraphile for your project](https://www.graphile.org/postgraphile/evaluating/).

## Introduction

Watch a talk by the original author [Caleb](https://twitter.com/calebmer) at GraphQL Summit for a walk-through of building an application with PostGraphile in under 7 minutes. This was using v2 (then called PostGraphQL); we're now up to v4 which has many more bells and whistles!

[![PostGraphile at GraphQL Summit](https://img.youtube.com/vi/b3pwlCDy6vY/0.jpg)](https://www.youtube.com/watch?v=b3pwlCDy6vY)

Hear from the current maintainer [Benjie](https://twitter.com/benjie) at GraphQL Finland about the benefits of Database-Driven GraphQL Development:

[![Database Driven GraphQL Development at GraphQL Finland](https://img.youtube.com/vi/XDOrhTXd4pE/0.jpg)](https://www.youtube.com/watch?v=XDOrhTXd4pE)

## Usage

**Documentation: [graphile.org/postgraphile](https://graphile.org/postgraphile)**

You can use PostGraphile via the CLI, as a Node.js middleware, or use the GraphQL schema directly. Make sure to check out the **[full usage instructions](https://graphile.org/postgraphile/usage/)** on the documentation website. We also have a [PostgreSQL schema design guide](https://www.graphile.org/postgraphile/postgresql-schema-design/) you can follow to build a fully functional PostGraphile API.

### CLI

To get started you can install PostGraphile globally:

```bash
npm install -g postgraphile
```

…and then just run it! By default, PostGraphile will connect to your local database at `postgres://localhost:5432` and introspect the `public` schema. See [the available CLI flags](https://www.graphile.org/postgraphile/usage-cli/) with:

```bash
postgraphile --help
```

When you're ready to use PostGraphile for your own project, you're advised to install it locally with `yarn`, and run it with `npx`:

```bash
yarn add postgraphile
npx postgraphile --help
```

**macOS users**: PostGraphile has used port 5000 by default for 5+ years; recently Apple decided to bind the AirPlay service to port 5000 causing a conflict. Please use the `--port` option to bind to a different port.

### Middleware

You can also use PostGraphile as [native HTTP, Connect, Express, or Koa (experimental) middleware](https://www.graphile.org/postgraphile/usage-library/), e.g.:

```bash
yarn add postgraphile
```

```js
import { createServer } from 'http';
import postgraphile from 'postgraphile';

createServer(postgraphile());
```

Check out [hapi-postgraphile](https://github.com/mshick/hapi-postgraphile) if you're interested in using PostGraphile as a [hapi](https://github.com/hapijs/hapi) server plugin.

### Docker

To run via Docker, simply pass the [CLI options](https://www.graphile.org/postgraphile/usage-cli/) to the Docker container:

```bash
docker pull graphile/postgraphile
docker run --init graphile/postgraphile --help
```

E.g. you might run this command (substituting the relevant variables):

```bash
docker run --init -p 5000:5000 graphile/postgraphile --connection postgres://POSTGRES_USER:POSTGRES_PASSWORD@POSTGRES_HOST:POSTGRES_PORT/POSTGRES_DATABASE --schema app_public --watch
```

**macOS users**: Please use a different port to avoid conflict with AirPlay.

## Read More

**Full documentation for PostGraphile is located at [graphile.org/postgraphile](https://graphile.org/postgraphile).**

PostGraphile features include:

- Authorization (security) provided by PostgreSQL:
  - [role-based access control (RBAC)](https://www.postgresql.org/docs/10/static/sql-grant.html)
  - [row-level security (RLS)][row-level-security]
- [Automatic GraphQL relations from SQL relations](https://www.graphile.org/postgraphile/relations/)
- [PostgreSQL procedure support][procedure documentation]:
  - [Custom queries][advanced queries documentation]
  - [Custom mutations](https://www.graphile.org/postgraphile/custom-mutations/)
  - [Computed columns](https://www.graphile.org/postgraphile/computed-columns/)
- Development UI (GraphiQL) built in
- `--watch` mode, auto-detects changes in SQL schema, hot-reloads changes into GraphiQL
- [Automatic documentation, enhanced by PostgreSQL `COMMENT`s](http://www.postgresql.org/docs/current/static/sql-comment.html)
- [Schema customisation through smart comments](https://www.graphile.org/postgraphile/smart-comments/)
- [Simple JWT authentication straight from the database](https://www.graphile.org/postgraphile/security/)
- [Cursor-based pagination, Relay (classic & modern) compatible](https://www.graphile.org/postgraphile/connections/)
- Global object identifiers (`nodeId` by default, but Relay-favoured `id` with `--classic-ids`)
- Relay-compatible mutations
- [Use direct from the CLI](https://www.graphile.org/postgraphile/usage-cli/)
- [Use as Express, Connect, or Koa middleware](https://www.graphile.org/postgraphile/usage-library/)
- [Just use the generated GraphQL schema](https://www.graphile.org/postgraphile/usage-schema/)

[procedure documentation]: https://www.graphile.org/postgraphile/procedures/
[advanced queries documentation]: https://www.graphile.org/postgraphile/custom-queries/
[row-level-security]: http://www.postgresql.org/docs/current/static/ddl-rowsecurity.html

## Requirements

[Full requirements are on the website](https://www.graphile.org/postgraphile/requirements/), but a basic summary is:

- Node v8.6+
- PostgreSQL 9.6+ (officially; but currently works with 9.4+)
- Linux, macOS or Windows

Caveats:

- PostGraphile does not have automated tests on Windows, if you notice any
  issues please file them (or send a PR!)

## Supporting PostGraphile

The fastest and easiest way you can help PostGraphile thrive is by [sponsoring
ongoing development and maintenance](https://graphile.org/sponsor/).

Want to help testing and developing PostGraphile? Check out the [contributing
document](CONTRIBUTING.md) to get started quickly!

Commercial support, consultancy and development services are available direct
from the maintainer; see [Professional Services](https://www.graphile.org/support/)
for more information, or get in touch!

The maintainer of this project is [@Benjie](https://twitter.com/benjie) -
follow him on Twitter!

## Thanks

Huge thanks to [the individuals and companies who sponsor PostGraphile's
development](SPONSORS.md) - their financial contributions enable more time to
be spent on the project: from bug fixes, to code review, to new features! If
you want to help the project advance more rapidly, please join them in
[supporting this project](https://graphile.org/sponsor/) 🙏

A humongous, heart-felt, thank you to the original author of PostGraphile -
[Caleb Meredith](https://twitter.com/calebmer) - for everything he put into
PostGraphile! He's now graduated from the project and we all wish him the best
for his future ventures!

Thanks also to the people working on
[PostgREST](https://github.com/begriffs/postgrest) which was a huge inspiration
for this project!

Thanks and enjoy 👍
","PostGraphile is an open source GraphQL API. You can use PostGraphile via the
CLI, as a Node.js middleware, or use the GraphQLschema directly. Read the full
documentation for Postgraphile at http://www.graphile.org/postgraphile/usage-
library. To run via Docker, simply pass the [CLI options] to the Docker
container:https:// www.graphileservice.com/post graphile/ Usage-CLI."
2164,A repository of different Algorithms and Data Structures implemented in many programming languages.,"# Data Structures and Algorithms 
Clean example implementations of data structures and algorithms written in different languages.
<br><br>
[![Gitter chat](https://badges.gitter.im/VAR-solutions/Algorithms.png)](https://gitter.im/VAR-solutions/Algorithms ""Gitter chat"")
[![MIT license](http://img.shields.io/badge/license-MIT-brightgreen.svg)](http://opensource.org/licenses/MIT)
[![Issues](http://img.shields.io/github/issues/VAR-solutions/Algorithms.svg)](https://github.com/VAR-solutions/Algorithms/issues)
#### List of implementations

[Algorithms list(not updated)](#)

## Contribution!
 * Contributions are always welcome. Language doesn't matter. Just make sure you're implementing an algorithm.
 * PRs are welcome. To begin developing, follow the structure:

   > Algorithm-Type/algorithm-name/language-name/file-name.extension
   
   e.g
   > Sorting/bubble-sort/python/bubble-sort.py

 * If there is an implementation of the same algorithm in your language, do not give a PR for that.
 * Please include a description for the algorithm that you are implementing. It doesn't matter if it's copied from somewhere as long as it helps people that are learning new algorithm.
 * Graphical examples would be very helpful too.
 * You can include tests as well.
 * Don't remove previous implementations of algorithms. Just add a new file with your own implementation.
 * Beautify and clean up your code for easier reading
 ### Note:
 * If your PR is closed without any comment, it means that your PR does not meet the above criteria. Make sure your PR is **not Duplicate** and it should be **well-documented**.

## Resources

 The curated list of resources dealing with algorithms.

 * **Sites**
   * [Algorithms - Tutorials point](https://www.tutorialspoint.com/data_structures_algorithms/index.htm)
   * [Algorithms - Princetone edu](http://algs4.cs.princeton.edu/home/)
   * [Data structures and algorithms - Hackr](https://hackr.io/tutorials/learn-data-structures-algorithms)
   * [Data science - Topcoder](https://www.topcoder.com/community/data-science/data-science-tutorials/)
   * [Fundamentals Of Algorithms- Geeks For Geeks](http://www.geeksforgeeks.org/fundamentals-of-algorithms/)
   * [Visual Algorithm - visualising data structures and algorithms through animation](https://visualgo.net/en)
   * [Rosetta Code](http://rosettacode.org/wiki/Rosetta_Code)
   * [GeeksforGeeks](https://www.geeksforgeeks.org)
* **Online classes (Free)**
  * Coursera 
      * [Introduction to algorithms Part 1](https://www.coursera.org/learn/algorithms-part1)
      * [Algorithms specialization 4 courses](https://www.coursera.org/specializations/algorithms)
   * Khan Academy 
     * [Algorithms](https://www.khanacademy.org/computing/computer-science/algorithms)
   * Udacity
      * [Computability, Complexity & Algorithms](https://www.udacity.com/course/computability-complexity-algorithms--ud061)
      * [Intro to algorithms](https://www.udacity.com/course/intro-to-algorithms--cs215)
   * EdX
      * [Algorithms](https://www.edx.org/course/algorithms-iitbombayx-cs213-3x-0)
      * [Algorithms and data structures](https://www.edx.org/course/algorithms-data-structures-microsoft-dev285x)
     * [Algorithm Design and Analysis](https://courses.edx.org/courses/course-v1:PennX+SD3x+2T2017/course/)
     * [Graph Algorithms](https://www.edx.org/course/graph-algorithms-uc-san-diegox-algs202x)
     * [Data Structures](https://www.edx.org/course/data-structures-uc-san-diegox-algs201x)
      * [Algorithmic Design and Techniques](https://www.edx.org/course/algorithmic-design-techniques-uc-san-diegox-algs200x)
     * [String Processing and Pattern Matching Algorithms](https://www.edx.org/course/string-processing-pattern-matching-uc-san-diegox-algs204x)
     * [Graph Algorithms in Genome Sequencing](https://www.edx.org/course/graph-algorithms-genome-sequencing-uc-san-diegox-algs206x)

     * [Algorithms and Data Structures Capstone](https://www.edx.org/course/algorithms-data-structures-capstone-uc-san-diegox-algs207x)
     * [Data Structures](https://www.youtube.com/user/mycodeschool)
     * [Algorithms and Data Structures Capstone](https://www.edx.org/course/algorithms-data-structures-capstone-uc-san-diegox-algs207x) 
     * [Data Structures and Algorithms](https://www.programiz.com/dsa)
   * GeeksForGeeks
     * [Algorithms](https://www.geeksforgeeks.org/fundamentals-of-algorithms/)
 * **Coding Practice Sites**
    * [HackerRank](https://www.hackerrank.com/)
    * [HackerEarth](https://www.hackerearth.com/)
    * [SPOJ](http://www.spoj.com/)
    * [TopCoder](https://www.topcoder.com/)
    * [CodeChef](https://www.codechef.com/)
    * [Codeforces](http://codeforces.com/)
    * [Project Euler](https://projecteuler.net/)
    * [LeetCode](https://leetcode.com/)
    * [CodinGame](https://www.codingame.com/)
    * [CodeWars](https://codewars.com/)
    * [Coderbyte](https://www.coderbyte.com/)
    * [HireVue](https://www.hirevue.com/)
    * [FreeCodeCamp](https://www.freecodecamp.org/)
    * [CodeSignal](https://codesignal.com/)
    * [AtCoder](https://atcoder.jp/)
    
# Project Maintainers.
* [Vishal Gaur](https://github.com/i-vishi) :tada:<br>
* [Ravi Varshney](https://github.com/ravivarshney01) :tada:<br>
* [Ananya Tewari](https://github.com/antew7) :tada:<br>
","Clean example implementations of data structures and algorithms written in
different languages. Contributions are always welcome. To begin developing,
follow the structure: Algorithm-Type/algorithm- name/language-name/file-name.
The curated list of resources dealing with algorithms."
2453,Learn Flexbox in 30 days with 30 code tidbits ✨,"Read this on my new website: [samanthaming.com/flexbox30/](https://www.samanthaming.com/flexbox30/)

# Flexbox30

Learn Flexbox in 30 days with 30 code tidbits ✨

<img src=""flexbox30-cover.png"" alt=""Flexbox Cover"" width=""350"">

## Table of Contents

1. [Introduction](#flexbox-intro)
1. [Flex Container & Flex Items](#flex-container-and-flex-items)
1. [Immediate Child Only](#immediate-child-only)
1. [Flexbox Axes](#flexbox-axes)
1. [Flexbox Module](#flexbox-module)
1. [Parent Properties](#parent-properties)
1. [Display](#display)
1. [block vs inline](#block-vs-inline)
1. [flex-direction](#flex-direction)
1. [flex-wrap](#flex-wrap)
1. [flex-flow](#flex-flow)
1. [justify-content [row]](#justify-content-row)
1. [justify-content [column]](#justify-content-column)
1. [space-around vs space-evenly](#space-around-vs-space-evenly)
1. [align-items [row]](#align-items-row)
1. [baseline](#baseline)
1. [align-items [column]](#align-items-column)
1. [align-content](#align-content)
1. [Child Properties](#child-properties)
1. [order](#order)
1. [flex-grow](#flex-grow)
1. [flex-grow calculation](#flex-grow-calculation)
1. [flex-shrink](#flex-shrink)
1. [flex-shrink calculation](#flex-shrink-calculation)
1. [flex-basis](#flex-basis)
1. [flex-basis vs widths](#flex-basis-vs-widths)
1. [flex](#flex)
1. [align-self](#align-self)
1. [Flexbox Properties](#flexbox-properties)
1. [Flexbox Cheatsheet](#flexbox-cheatsheet)
1. [Aligning with Auto Margins](#bonus-aligning-with-auto-margins)
1. [Resources](#resources)
1. [Say Hello](#say-hello)
1. [Download & Share](#download-and-share)
1. [Contribution](#contribution)
1. [License](#license)

## Flexbox Core Concepts

<a id=""flexbox-intro""></a>

### [Day 1: Introduction](#flexbox-intro)

Before Flexbox, we were mainly using floats for layout. And for those CSS developers, we all know the frustrations and limitations of the old way -- especially the ability to vertically center inside a parent. Ugh, that was so annoying! Not anymore! Flexbox for the win!

<p><img src=""code-tidbits/1-flexbox-intro.png"" alt=""Flexbox Introduction"" width=""500""></p>

<a id=""flex-container-and-flex-items""></a>

### [Day 2: Flex Container & Flex Items](#flex-container-and-flex-items)

In order to get Flexbox to work, you need to set up the Parent-Child relationship. The parent is the flex container, and everything within it is the children or flex items.

<p><img src=""code-tidbits/2-flex-container-and-flex-items.png"" alt=""Flex Container & Flex Items"" width=""500""></p>

<a id=""immediate-child-only""></a>

### [Day 3: Immediate Child Only](#immediate-child-only)

One VERY important thing I want to point out is that the flex container only wraps around its immediate children. The flex container doesn't wrap beyond one layer deep. Only the immediate children. So there is NOT a grandchildren or grand-grandchildren relationship. Only Parent ↔️ Immediate Children!

Of course, you can establish a Flexbox as long as there is a parent-child relationship. So a child can also be the flex container to its children. But it will be a separate flex container. And it doesn't carry over the grandparent flex properties.

This is probably one of the most important concepts that helped me understand how Flexbox works. And knowing this will help solve a lot of those ""hey, why isn't this working"" moments 😅

<p><img src=""code-tidbits/3-immediate-child-only.png"" alt=""Immediate Child Only"" width=""500""></p>

<a id=""flexbox-axes""></a>

### [Day 4: Flexbox Axes](#flexbox-axes)

Flexbox operates in a 2 axes system: a main and a cross axis. The main axis is your defining direction of how your flex items are placed in the flex container. Determining the cross axis is very simple, it's in the direction that's perpendicular to your main axis.

Remember in math class, we were taught **x** and **y** axis. Well, throw that out. Because the main axis can be horizontal or vertical. The **x** axis is not always the main axis. This was a mistake I made, so hopefully you won’t make the same incorrect assumption as I did 😅

<p><img src=""code-tidbits/4-flexbox-axes.png"" alt=""Flexbox Axes"" width=""500""></p>

<a id=""flexbox-module""></a>

### [Day 5: Flexbox Module](#flexbox-module)

Let's zoom in on one of the layouts and check out the anatomy of our Flexbox. On each axis, there is a start and an end.  If it's on the main axis, the starting position is called **main start** and if the ending position is called **main end**. The same concept applies to the cross axis. Knowing your start and end is important because you can control where your flex items are placed.

And this concludes our Flexbox Fundamentals.

<p><img src=""code-tidbits/5-flexbox-module.png"" alt=""Flexbox Module"" width=""500""></p>

**[⬆ back to top](#table-of-contents)**

## Parent Properties

<a id=""parent-properties""></a>

### [Day 6: Parent Properties](#parent-properties)

Now you know Flex operates in a Parent-Child relationship. So we have 2 entities involved to get this tango started. And each entity will have its own set of unique CSS properties that can be applied to them. That's why it's important that you know which element is the parent and which element(s) is the child. Let's get started with the parent properties 🤰

<p><img src=""code-tidbits/6-parent-properties.png"" alt=""Parent Properties"" width=""500""></p>

<a id=""display""></a>

### [Day 7: Display](#display)

To start this Flexbox party, we need to first create our flex container. This is done by applying `flex` to the `display` property on the parent element. Bam! Now all its immediate children will become flex items 🎊

There are 2 types of flex container: `flex` will create a *block* level flex container. And `inline-flex` will create an *inline* level flex container. More on *block* and *inline* tomorrow 😉

<p><img src=""code-tidbits/7-display.png"" alt=""Display"" width=""500""></p>

```css
.parent {
  display: flex /* default */
        or inline-flex
}
```

<a id=""block-vs-inline""></a>

### [Day 8: block vs inline](#block-vs-inline)

Very simply explained, `block` element takes up the entire width of the container. They look like building blocks where each block is stacked on each other. Whereas `inline` element only takes up the space it needs. So they appear to be in a line, or side by side of each other.

<p><img src=""code-tidbits/8-block-vs-inline.png"" alt=""block vs inline"" width=""500""></p>

<a id=""flex-direction""></a>

### [Day 9: flex-direction](#flex-direction)

This is the property that allows us to define our main axis. Remember I mentioned that our main axis can be horizontal or vertical. So if we want the main axis to be horizontal, that's called **row**. And if we want it to be vertical, that's called **column**. Also, remember we had a **main start** and **main end**. We simply add a `reverse` suffix to set our ""main start"" in the reverse direction. Pretty cool eh 👍

<p><img src=""code-tidbits/9-flex-direction.png"" alt=""flex-direction"" width=""500""></p>

```css
.parent {
  flex-direction: row /* default */
               or row-reverse
               or column
               or column-reverse
}
```

<a id=""flex-wrap""></a>

### [Day 10: flex-wrap](#flex-wrap)

By default, flex items will try to shrink itself to fit onto one line, in other words, `no wrap`. However if you want the flex items to maintain its size and have the overflow spread on multiple lines in the containers, then you can turn on `wrap`.

This property is what will allow flex items in your container to occupy more than one line.

<p><img src=""code-tidbits/10-flex-wrap.png"" alt=""flex-wrap"" width=""500""></p>

```css
.parent {
  flex-wrap: nowrap /* default */
          or wrap
          or wrap-reverse
}
```

<a id=""flex-flow""></a>

### [Day 11: flex-flow](#flex-flow)

So we've learned `flex-direction` and `flex-wrap`. If you understand those 2, you'll get `flex-flow`! Because it's just a shorthand for these two properties 👏

You can set both properties at the same time. Or you can just pass one of them. The default value is `row nowrap`. So if you just set one value, the property that you didn't set will just take on the default value.

<p><img src=""code-tidbits/11-flex-flow.png"" alt=""flex-flow"" width=""500""></p>

```css
.parent {
  flex-flow: row nowrap /* default */
          or <flex-direction> <flex-wrap>
          or <flex-direction>
          or <flex-wrap>
}
```

<a id=""justify-content-row""></a>

### [Day 12: justify-content [row]](#justify-content-row)

Here comes the fun part. This is the property that sets alignment along the main axis. In this example, the main axis lies horizontally. In other words, the flex-direction is set to `row`.

This is probably my most used parent property. You just choose the layout you like and BAM Flexbox automatically does it for you. And it's absolutely responsive. As your grow or shrink the window width, Flexbox will do the behind-the-scene calculation and ensure that your chosen layout is maintained. It's like one of those kitchen appliances where ""you set it and forget it"" 🍗

<p><img src=""code-tidbits/12-justify-content-row.png"" alt=""justify-content row"" width=""500""></p>

```css
.parent {
  justify-content: flex-start /* default */
                or flex-end
                or center
                or space-around
                or space-between
                or space-evenly
}
```

<a id=""justify-content-column""></a>

### [Day 13: justify-content [column]](#justify-content-column)

The main axis can also lie vertically. In that case, flex-direction is set to `column`. Here's how the flex items will be aligned in that instance.

<p><img src=""code-tidbits/14-justify-content-column.png"" alt=""justify-content column"" width=""500""></p>

```css
.parent {
  flex-direction: column;
  
  justify-content: flex-start /* default */
                or flex-end
                or center
                or space-around
                or space-between
                or space-evenly
}
```

<a id=""space-around-vs-space-evenly""></a>

### [Day 14: space-around vs space-evenly](#space-around-vs-space-evenly)

You might not notice the subtle difference between space-around and space-evenly. So let's talk about it. In `space-evenly`, the empty space in between the flex items is always equal. However, in `space-around`, only the inner items will have equal spacing in between each other. The first and last item will only be allocated half the spacing. Giving the visual appearance of it being more spread out. One may say these folks like to live life on the edge 😂

<p><img src=""code-tidbits/13-space-around-vs-space-evenly.png"" alt=""space-around vs space-evenly"" width=""500""></p>

<a id=""align-items-row""></a>

### [Day 15: align-items [row]](#align-items-row)

So justify-content controls how items are laid out on the main axis. What about their layout in the cross axis? Don't worry, that's where `align-items` come into play. Remember the cross axis is always perpendicular to the main axis. So if the main axis is sitting horizontally, where flex-direction is `row`. Then , the cross axis is sitting vertically. Aren't you glad we spend almost a week on the fundamentals, that knowledge is all being applied now 🤓

<p><img src=""code-tidbits/15-align-items-row.png"" alt=""align-items row"" width=""500""></p>

```css
.parent {
  align-items: stretch /* default */
            or flex-start
            or flex-end
            or center
            or baseline
}
```

<a id=""baseline""></a>

### [Day 16: baseline](#baseline)

The baseline value is a bit tricky. So let's make sure we understand what that is. Baseline has to do with typography or text. It is the imaginary line where the text sits. If you have the same font size, you really don't visually see a difference. However when you have different font sizes, then the text seems all over the place because the baseline is off. The way to ensure a uniform baseline where all the different sizes of text can rest on is to use the `baseline` value 👍

<p><img src=""code-tidbits/16-baseline.png"" alt=""baseline"" width=""500""></p>

<a id=""align-items-column""></a>

### [Day 17: align-items [column]](#align-items-column)

Now let's take a look at how our flex items are aligned if the cross axis is sitting horizontally. In other words, flex-direction is `column`.

<p><img src=""code-tidbits/17-align-items-column.png"" alt=""align-items column"" width=""500""></p>

```css
.parent {
  flex-direction: column;
  
  align-items: stretch /* default */
            or flex-start
            or flex-end
            or center
            or baseline
}
```

<a id=""align-content""></a>

### [Day 18: align-content](#align-content)

Remember we had `flex-wrap` where we allow flex items to wrap on separate lines. Well, with `align-content` we can control how those row of items are aligned on the cross axis. Since this is only for wrapped items, this property won't have any effect if you only have a singular line of flex items.

<p><img src=""code-tidbits/18-align-content.png"" alt=""align-content"" width=""500""></p>

```css
.parent {
  align-content: stretch /* default */
              or flex-start
              or flex-end
              or center
              or space-between
              or space-around
}
```

**[⬆ back to top](#table-of-contents)**

## Child Properties

<a id=""child-properties""></a>

### [Day 19: Child Properties](#child-properties)

Yay, you did it! We made it through the parent properties. Up next, let dig into the child properties. Take a breather today, tomorrow we go full speed again 🏎

<p><img src=""code-tidbits/19-child-properties.png"" alt=""Child Properties"" width=""500""></p>

<a id=""order""></a>

### [Day 20: order](#order)

By default, flex items are displayed in the same order they appear in your code. But what if you want to change that? No problem! Use the `order` property to change the ordering of your items 🔢

<p><img src=""code-tidbits/20-order.png"" alt=""order"" width=""500""></p>

```css
.child {
  order: 0 /* default */
      or <number>
}
```

<a id=""flex-grow""></a>

### [Day 21: flex-grow](#flex-grow)

I mentioned in the beginning that Flexbox is great for responsive design. This is where it shines. The `flex-grow` property allows our flex item to grow if necessary. So if there is extra free space in my container, I can tell a particular item to fill it up based on some proportion. That's pretty nuts! When I was learning CSS, I remember everything is pretty static. Now with this property, it's like it has its own brain and it will adjust its size depending on the container. That's so great. I don't have to monitor the size. It will adjust accordingly. This was a quite the mind blow for me 🤯

<p><img src=""code-tidbits/21-flex-grow.png"" alt=""flex-grow"" width=""500""></p>

```css
.child {
  flex-grow: 0 /* default */
          or <number>
}
```

<a id=""flex-grow-calculation""></a>

### [Day 22: flex-grow calculation](#flex-grow-calculation)

Being able to grow and fill the free space is pretty cool. Because we don't set the final width of our flex item, the size it grows to always seem so random to me. So let's look at the math. Honestly you don't need to know this to understand Flexbox. The browser takes care of this automatically for you. But knowing what's behind this sorcery might demystify this process and help you understand it better. It's like once you know the trick to the magic, you're no longer tricked by the magic 😉

<p><img src=""code-tidbits/22-flex-grow-calculation.png"" alt=""flex-grow calculation"" width=""500""></p>

<details>
  <summary><b>Expand to see the calculation</b></summary><br>

I know it can be quite overwhelming to see all numbers crammed into a tidbit. So let's walk through the calculation 👍

Here's the `HTML` and `CSS` we're working with:

_HTML_

```html
<div class=""parent"">
  <div class=""child green""></div>
  <div class=""child yellow""></div>
  <div class=""child blue""></div>
</div>
```

_CSS_

```css
.parent {
  width: 700px;
}
.child {
  width: 100px;
}
.green {
  flex-grow: 1;
}
.yellow {
  flex-grow: 0;
}
.blue {
  flex-grow: 3;
}
```

<br>

**Step 1: Breaking down the variables**

Here's the formula:

```code
new width = ( (flex grow / total flex grow) x free space) + width
```

Let's extract the variables required in the formula to this handy table we can fill in as we go:

Variables  |     |
---        | --- |
flex grow  | *provided from css*
total flex | *need to calculate*
free space | *need to calculate*
width      | *provided from css*

<br>

**Step 2: Fill in what we know**

From the `CSS` value, we can conclude the following:

- Each child element has a width `100`
- The parent element (container) has a width of `700`
- The child has a `flex-grow` of `1`, `0`, `3`

Let's update our chart with this information:

<i></i>    |  Green | Yellow | Blue
---        | ---    | ---    | --- |
flex grow  | 1      | 0      | 3
total flex |
free space |
width      | 100    | 100    | 100

<br>

**Step 3: Calculate ""free space""**

This is the formula:

```code
free space = parent width - total children widths
```

Remember what we know:

- Each child element has a width `100`
- The parent element (container) has a width of `700`

Great, we can use that information to calculate ""total children widths"":

```code
total children widths = green + yellow + blue
                      = 100   + 100    + 100

=> 300
```

Now we can calculate our ""free space"":

```code
free space = parent width - total children widths
           = 700          -  300

=> 400
```

Let's update our chart and add these additional information:

<i></i>    |  Green | Yellow | Blue | Total
---        | ---    | ---    | ---  | --- |
flex grow  | 1      | 0      | 3
total flex |
free space | -      | -      | -    | **400**
width      | 100    | 100    | 100

<br>

**Step 4: Calculate ""total flex grow""**

This is an easy one, we simply add up our total `flex-grow`:

```code
total flex grow = green + yellow + blue
                = 1     + 0      + 3

=> 4
```

Fill in our chart and Voilà! We have all the information we need for the final calculation 👍

<i></i>     |  Green | Yellow | Blue | Total
---         | ---    | ---    | ---  | --- |
flex grow   | 1      | 0      | 3    | **4**
free space  | -      | -      | -    | 400
width       | 100    | 100    | 100  |

<br>

**Final step: Calculate ""new width""**

Remember the formula:

```code
new width = ( (flex grow / total flex grow) x free space) + width
```

_a. Green_

```code
new width = ( (1/4 * 400) ) + 100

=> 200
```

_b. Yellow_

```code
new width = ( (0/4 * 400) ) + 100

=> 100
```

_c. Blue_

```code
new width = ( (3/4 * 400) ) + 100

=> 400
```

Done! We have successfully calculated the new width 🥳

<i></i>       |  Green   | Yellow  | Blue    | Total
---           | ---      | ---     | ---     | --- |
width         | 200      | 100     | 400  
flex grow     | 1        | 0       | 3       | 4
free space    |          |         |         | 400
**new width** | **200**  | **100** | **400**  

<hr>

</details>

<a id=""flex-shrink""></a>

### [Day 23: flex-shrink](#flex-shrink)

So `flex-grow` will expand to fill the extra space if there are any. The opposite of that is `flex-shrink`. What happens when you run out of space. This is the property that controls how much your flex items will shrink to fit. Note the larger the number, the more it will shrink 👍

<p><img src=""code-tidbits/23-flex-shrink.png"" alt=""flex-shrink"" width=""500""></p>

```css
.child {
  flex-shrink: 1 /* default */
            or <number>
}
```

<a id=""flex-shrink-calculation""></a>

### [Day 24: flex-shrink calculation](#flex-shrink-calculation)

This is another optional knowledge. But if you're like me and is curious how the browser calculates flex-shrink. Join me in this rabbit hole 🐰

The math behind `flex-shrink` is a bit more complicated then `flex-grow`. You need to take into account of it's existing proportion and shrink it accordingly to the flex shrink amount. Hence, a few more calculation involved. Again, if this is throwing you off. Skip it. You don't need to know this to understand Flexbox. Luckily the browser takes care of it for you, how wonderful 😌

<p><img src=""code-tidbits/24-flex-shrink-calculation.png"" alt=""flex-shrink calculation"" width=""500""></p>

<details>
  <summary><b>Expand to see the calculation</b></summary><br>

Indeed the calculation is a bit more complicated. But no worries, let's break it down we go through it step by step, you got this 💪

Here's the `HTML` and `CSS` we're working with:

_HTML_

```html
<div class=""parent"">
  <div class=""green""></div>
  <div class=""yellow""></div>
</div>
```

_CSS_

```css
.parent {
  width: 800px;
}
.green {
  width: 300px;
  flex-shrink: 4;
}
.yellow {
  width: 600px;
  flex-shrink: 6;
}
```

<br>

**Step 1: Breaking down the variables**

This is the formula:

```code
new width = width - (shrink space x shrink ratio)
```

Let's extract the variables required in the formula to this handy table we can fill in as we go:

Variables    |     |
---          | --- |
width        | *need to calculate*
shrink space | *need to calculate*
shrink ratio | *need to calculate*

<br>

**Step 2: Fill in what we know**

From the `CSS` value, we can conclude the following:

- The parent element (container) has a width of `800`
- Green child element has a width `300` and `flex-shrink` of `4`
- Yellow child element has a width `600` and `flex-shrink` of `6`

Let's update our chart with this information:

<i></i>     |  Green | Yellow |
---         | ---    | ---    |
flex shrink | 4      | 6
width       | 300    | 600

<br>

**Step 3: Calculate ""shrunk space""**

This is the formula:

```code
shrunk space = total children widths - parent width
```

Remember what we know:

- The parent element (container) has a width of `800`
- The child elements has a width of `300`, `600`

Great, we can use that information to calculate ""total children widths"":

```code
total children widths = green + yellow
                      = 300   + 600

=> 900
```

Now we can calculate our ""shrunk space"":

```code
shrunk space = total children widths - parent width
             = 900                   -  800

=> 100
```

Let's update our chart and add the additional information:

<i></i>      |  Green | Yellow | Total
---          | ---    | ---    | --- |
flex shrink  | 4      | 6
width        | 300    | 600
shrunk space | -      | -      | **100**

<br>

**Step 4: Calculate ""shrink ratio""**

This is the formula:

```code
shrink ratio = (width x flex shrink) / total shrink scaled width
```

Notice this new variable, `total shrink scaled width`. So we need to calculate that first to get our shrink ratio.

<br>

**Step 4-1: Calculate ""total shrink scaled width""**

This is the formula:

```code
total shrink scaled width = Σ(width x flex shrink)
```

""Σ"" Sigma is a math symbol that means the summation of something. So we need to apply `width x flex shrink` for all the child elements.

_Green_

```code
width x flex shrink = 300 x 4

=> 1200
```

_Yellow_

```code
width x flex shrink = 600 x 6

=> 3600
```

_Finally_

```code
total shrink scaled width = 1200 + 3600

=> 4800
```

Let's add this information to our chart:

<i></i>                   |  Green | Yellow | Total
---                       | ---    | ---    | --- |
flex shrink               | 4      | 6
width                     | 300    | 600
shrunk space              | -      | -      | 100
total shrink scaled width | -      | -      | **4800**

<br>

**Step 4-2: Back to calculating ""shrink ratio""**

Fantastic, now that we know the ""total shrink scaled width"", we can return with calculating the ""shrink ratio"". Remember the formula:

```code
shrink ratio = (width x flex shrink) / total shrink scaled width
```

_Green_

```code
shrink ratio = (300 x 4) / 4800

=> 0.25
```

_Yellow_

```code
shrink ratio = (600 x 6) / 4800

=> 0.75
```

Let's add this information to our chart:

<i></i>      |  Green   | Yellow   | Total
---          | ---      | ---      | --- |
flex shrink  | 4        | 6
width        | 300      | 600
shrunk space | -        | -        | 100
shrink ratio | **0.25** | **0.75**

<br>

**Final step: Calculate ""new width""**

Remember the formula:

```code
new width = width - (shrink space x shrink ratio)
```

_Green_

```code
new width = 300 - (100 x 0.25)

=> 275
```

_Yellow_

```code
new width = 600 - (100 x 0.75)

=> 525
```

Done! We have successfully calculated the new width 🥳

<i></i>       |  Green   | Yellow
---           | ---      | ---     |
width         | 300      | 600
shrunk space  | 4        | 6
shrink ratio  | 0.25     | 0.75
**new width** | **275**  | **525**

<hr>
</details>

<a id=""flex-basis""></a>

### [Day 25: flex-basis](#flex-basis)

With the flex-grow and flex-shrink property, we know the flex size changes. With the `flex-basis` property, this is where we set its initial size. You can think of this property as the width of our flex items. So your next question might be what's the difference between width and flex-basis. Of course, you can still use width and it will still work. The reason it works is because if you didn't set the flex-basis, it will default to the width. So your browser will always try to find the `flex-basis` value as the size indicator. And if it can't find it, then it has no choice but to go with your width property.  Don't make the browser do extra work. Do it the proper flex way and use `flex-basis`.

You may notice I referenced width in my previous formulas. That's because I had not cover flex-basis at that point. So if we want to be **flex** correct, please replace where I mentioned width with flex-basis 😝

<p><img src=""code-tidbits/25-flex-basis.png"" alt=""flex-basis"" width=""500""></p>

```css
.child {
  flex-basis: auto /* default */
           or <width>
}
```

Valid width values are absolute [`<length>`](https://developer.mozilla.org/en-US/docs/Web/CSS/length) and [`<percentage>`](https://developer.mozilla.org/en-US/docs/Web/CSS/percentage). You can see some examples and read more on MDN web docs:

- [`MDN: <length>`](https://developer.mozilla.org/en-US/docs/Web/CSS/length)
- [`MDN: <percentage>`](https://developer.mozilla.org/en-US/docs/Web/CSS/percentage)

<a id=""flex-basis-vs-widths""></a>

### [Day 26: flex-basis vs widths](#flex-basis-vs-widths)

Here you can see very clearly that when an item has a flex-basis and a width. The browser will always use the value set with `flex-basis` . Again, another reason to use the proper flex way 😉

But watch out, if you also set a `min-width` and `max-width`. In those cases, `flex-basis` will lose and will not be used as the width.

<p><img src=""code-tidbits/26-flex-basis-vs-widths.png"" alt=""flex-basis vs widths"" width=""500""></p>

<a id=""flex""></a>

### [Day 27: flex](#flex)

Sometimes, setting `flex-grow`, `flex-shrink` and `flex-basis` separately are tiring. Well, don't you worry. For the lazy programmers, I mean the efficient programmers 😜  You can set all 3 with the `flex` shorthand. The added bonus of this way is you don't have to set all 3 value, you can skip the properties you're not interested in and just set the one you are. And for the ones you skipped, it will just take on the default value. Awesome 👍

<p><img src=""code-tidbits/27-flex.png"" alt=""flex"" width=""500""></p>

```css
.child {
  flex: 0 1 auto /* default */
     or <flex-grow> <flex-shrink> <flex-basis>
     or <flex-grow>
     or <flex-basis>
     or <flex-grow> <flex-basis>
     or <flex-grow> <flex-shrink>
}
```

<a id=""align-self""></a>

### [Day 28: align-self](#align-self)

Remember our `align-items` property where we can set the flex item along the cross axis. The thing with `align-items` is that it forces ALL of the flex items to play with the rules. But what if you want one of them to break the rule. No worries, for  you independent thinkers, you can use `align-self`. This property accepts all of the same values given to `align-items`, so you can easily break from the pack 😎

<p><img src=""code-tidbits/28-align-self.png"" alt=""align-self"" width=""500""></p>

```css
.child-1 {
  align-self: stretch /* default */
           or flex-start
           or flex-end
           or center
           or baseline
}
```

## Summary

<a id=""flexbox-properties""></a>

### [Day 29: Flexbox Properties](#flexbox-properties)

YAY!!! You did it! You learned all the properties of Flexbox! You're a Flexbox ninja now! We covered a lot in this short amount of time. Go back and re-visit the ones you still don't understand. Don't just read my Flexbox lessons. Check out other Flexbox tutorials. Sometimes reading a different perspective will help solidify your knowledge and fill in any gaps. Remember the best way to get better is to apply. I gave you the knowledge, now it's on YOU to apply and build something with it 💪

<p><img src=""code-tidbits/29-flexbox-properties.png"" alt=""Flexbox Properties"" width=""500""></p>

<a id=""flexbox-cheatsheet""></a>

### [Day 30: Flexbox Cheatsheet](#flexbox-cheatsheet)

Final tidbit! Let me give you one more tidbit for the road. Memorizing all the available properties is not easy. Even after doing creating this entire tutorial, I still don't have all these properties memorized. Being a good programmer is not about how much you memorize, it's about problem solving. And that's why it's important for a programmer to continue to stay humble and learn. It's all about expanding our toolkit so when we do face a problem, we have a variety of tools that we can select from to fix it 🧰

Congratulation for completing Flexbox30! I hope you learned a lot and thank you for letting my tidbits be part of your programming journey 💛

<p><img src=""code-tidbits/30-flexbox-cheatsheet.png"" alt=""Flexbox Cheatsheet"" width=""500""></p>

**[⬆ back to top](#table-of-contents)**

<a id=""auto-margins""></a>

### [Bonus: Aligning with Auto Margins](#auto-margins)

Bonus content! Another way to align Flexbox child elements is to use auto margins. Although this isn't a Flexbox property, it's still important to be aware of it because it has a very interesting relationship with Flexbox. Check out my code notes on it if you're interested  👉 [Flexbox: Aligning with Auto Margins](/flexbox-aligning-with-auto-margins/README.md)

<p><img src=""code-tidbits/bonus-auto-margins.png"" alt=""Flexbox Cheatsheet"" width=""500""></p>

<a id=""resources""></a>

## 📚 Resources

**Learning Flexbox**

- [MDN web docs: Flexbox](https://developer.mozilla.org/en-US/docs/Learn/CSS/CSS_layout/Flexbox)
- [MDN web docs: Basic Concepts of flexbox](https://developer.mozilla.org/en-US/docs/Web/CSS/CSS_Flexible_Box_Layout/Basic_Concepts_of_Flexbox)
- [CSS-Tricks: A Complete Guide to Flexbox](https://css-tricks.com/snippets/css/a-guide-to-flexbox/)
- [Yoksel: Flex Cheatsheet](https://yoksel.github.io/flex-cheatsheet/)
- [JoniBologna.com: Flexbox Cheatsheet](http://jonibologna.com/flexbox-cheatsheet/)
- [Interneting is hard: Flexbox](https://internetingishard.com/html-and-css/flexbox/)

**Official Spec**

- [W3C: Flexbox](https://www.w3.org/TR/css-flexbox-1/)

**Community Suggestion**

- [Flexbox Zombies](https://flexboxzombies.com) $
- [Flexbox Froggy](https://flexboxfroggy.com/)
- [Wes Bos: What the Flexbox?!](https://flexbox.io/)

<a id=""say-hello""></a>

## 👋 Say Hello

> I share JS, HTML, CSS tidbits every week!

Twitter: [@samantha_ming](https://twitter.com/samantha_ming)  
Instagram: [@samanthaming](https://www.instagram.com/SamanthaMing/)  
Facebook: [@hi.samanthaming](https://www.facebook.com/hi.samanthaming/)  
Medium: [@samanthaming](https://medium.com/@samanthaming)  
Dev: [@samanthaming](https://dev.to/samanthaming)  
Official: [samanthaming.com](https://www.samanthaming.com/)

<a id=""download-and-share""></a>

## 💖 Download & Share

Absolutely! You are more than welcome to download and share my code tidbits. If you've gotten any value from my content and would like to help me reach more people, please do share!

One thing that I kindly ask is that you don't edit the images or crop my name out. Please leave the images intact. Thank you for choosing to do the right thing 😇

<a id=""contribution""></a>

## 🌟 Contribution

~~Yes! Anyone is welcome to contribute to the quality of this content. Please feel free to submit a PR request for typo fixes, spelling corrections, explanation improvements, etc. If you want to help translate the tutorial, that's even cooler! I'm hoping to at least create a Chinese version soon 👩🏻‍🏫~~

(Note: all updates will now appear in the new repo: https://github.com/samanthaming/samanthaming.com)

**[⬆ back to top](#table-of-contents)**

<a id=""license""></a>

## 👩🏻‍⚖️ License

Thank you for wanting to share and include my work in your project 😊 If you're wondering how to provide attributions. It simply means don't edi","Learn Flexbox in 30 days with 30 code tidbits. Read this on my new website:
[samanthaming.com/flexbox30/](https://www.samantha.com / flexbox30/) Read on to
learn more about Flexbox."
1214,【Nodejs-Roadmap】侧重于 Node.js 服务端的开发指南，公众号 “Nodejs技术栈”,"# Nodejs技术栈

[![stars](https://badgen.net/github/stars/qufei1993/Nodejs-Roadmap?icon=github&color=4ab8a1)](https://github.com/qufei1993/Nodejs-Roadmap) [![forks](https://badgen.net/github/forks/qufei1993/Nodejs-Roadmap?icon=github&color=4ab8a1)](https://github.com/qufei1993/Nodejs-Roadmap) [<img src=""https://img.shields.io/static/v1.svg?label=%E6%85%95%E8%AF%BE&message=7k%20stars&color=ef151f"">](https://www.imooc.com/u/2667395) [<img src=""https://img.shields.io/badge/%E5%BE%AE%E4%BF%A1-%E5%85%AC%E4%BC%97%E5%8F%B7-brightgreen"">](https://nodejsred.oss-cn-shanghai.aliyuncs.com/node_roadmap_wx.jpg?x-oss-process=style/may)

本文档是作者 **@五月君** 从事 Node.js 开发以来的学习历程，希望这些分享能帮助到正在学习、使用 Node.js 的朋友们，也真诚的希望能聚集所有 Node.js 爱好者，共建互帮互助的「Nodejs技术栈」交流平台。

如果本文能为您得到帮助，请给予支持！

**如何支持：**
- 关注公众号 👉 [**Nodejs技术栈**](https://nodejsred.oss-cn-shanghai.aliyuncs.com/node_roadmap_wx.jpg?x-oss-process=style/may)
- 点击**右上角 Star :star: 给予关注，勿 fork**
- 分享给您身边更多的小伙伴

**作者简介**：

五月君，Software Designer，公众号「**Nodejs技术栈**」|「**五月君**」作者，一个疯狂输出干货的技术博主。

**话题标签：**

> 所有相关话题均围绕 Node.js 讨论，例如数据库部分，会介绍在 Node.js 中使用 Redis、MySql、MongoDB 等常见数据库的一些基础应用、问题、实践记录。

`基础入门` `系统模块` `NPM 模块` `高级进阶` `好文翻译` `实践指南` `Node.js 小知识` `Node.js News` `数据库` `微服务`  `Serverless` `DevOps`

**在线预览：** [https://www.nodejs.red](https://www.nodejs.red/)

## 话题目录

- Introduction
    - [简介](README.md)

- 基础入门
    - [Node.js 是什么？我为什么选择它？](/docs/nodejs/base/what-is-nodejs.md)
    - [Node.js 版本知多少？又该如何选择？](/docs/nodejs/base/release.md)
    - [“3N 兄弟” 助您完成 Node.js 环境搭建](/docs/nodejs/base/install.md)
    - [Node.js 包管理器 NPM](/docs/nodejs/base/npm.md)
    - [使用 Chrome Devtools 来调试你的 Node.js 程序](/docs/nodejs/base/debug-nodejs-with-chrome-devtools.md)

- 系统模块
    - [`[Module]` CommonJS 模块机制](/docs/nodejs/module.md)
    - [`[Module]` ES Modules 入门基础](/docs/nodejs/modules/esm.md)
    - [`[Events]` 事件触发器](/docs/nodejs/events.md)
    - [`[Crypto]` 加解密模块](/docs/nodejs/crypto.md)
    - [`[Buffer]` 缓冲区模块](/docs/nodejs/buffer.md)
    - [`[Process]` 线程和进程](/docs/nodejs/process-threads.md)
    - [`[Console]` 日志模块](/docs/nodejs/console.md)
    - [`[Net]` 网络模块](/docs/nodejs/net.md)
    - [`[DNS]` 域名解析](/docs/nodejs/dns.md)
    - [`[Cluster]` 集群模块](/docs/nodejs/cluster-base.md)
    - [`[Stream]` 多文件合并实现](/docs/nodejs/modules/stream-mutil-file-merge.md)
    - [`[Stream]` pipe 基本使用与实现分析](/docs/nodejs/modules/stream-pipe.md)
    - [`[Stream]` internal/stremas/egacy.js 文件分析](/docs/nodejs/modules/stream-lib-internal-stremas-legacy.md)
    - [`[Util]` util.promisify 实现原理分析](/docs/nodejs/modules/util-promisify.md)
    - [`[FileSystem]` 如何在 Node.js 中判断一个文件/文件夹是否存在？](/docs/nodejs/modules/fs-file-exists-check.md)
    - [`[Report]` 在 Node.js 中使用诊断报告快速追踪问题](/docs/nodejs/modules/report.md)
    - [`[AsyncHooks]` 使用 Async Hooks 模块追踪异步资源](/docs/nodejs/modules/async-hooks.md)
    - [`[HTTP]` HTTP 请求与响应如何设置 Cookie 信息](/docs/nodejs/modules/http-set-cookies.md)

- NPM 模块
    - [Node.js + Socket.io 实现一对一即时聊天](/docs/nodejs/npm/private-chat-socketio.md)
    - [request 已废弃 - 推荐 Node.js HTTP Client undici](/docs/nodejs/npm/undici.md)

- 高级进阶
    - [Egg-Logger 模块实践](/docs/nodejs/logger.md)
    - [I/O 模型浅谈](/docs/nodejs/IO.md)
    - [Memory 内存管理和 V8 垃圾回收机制](/docs/nodejs/memory.md)
    - [Cache 缓存](/docs/nodejs/cache.md#缓存)
    - [Schedule 定时任务](/docs/nodejs/schedule.md#定时任务)
    - [Template 模板引擎](/docs/nodejs/template.md#模板引擎)
    - [Testing 测试](/docs/nodejs/test.md)
    - [Framework Web 开发框架选型](/docs/nodejs/framework.md#框架)
    - [ORM 对象关系映射](/docs/nodejs/orm.md#ORM)
    - [Middleware 常用 Web 框架&中间件汇总](/docs/nodejs/middleware.md)
    - [深入 Nodejs 源码探究 CPU 信息的获取与实时计算](/docs/nodejs/modules/os-cpu-usage.md)
    - [Node.js 中出现未捕获异常如何处理？](/docs/nodejs/advanced/uncaugh-exception.md)
    - [探索异步迭代器在 Node.js 中的使用](/docs/nodejs/advanced/asynciterator-in-nodejs.md)
    - [多维度分析 Express、Koa 之间的区别](/docs/nodejs/base/express-vs-koa.md)
    - [在 Node.js 中如何处理一个大型 JSON 文件？](/docs/nodejs/advanced/json-stream.md)
    - [Node.js 中遇到大数处理精度丢失如何解决？前端也适用！](/docs/nodejs/advanced/floating-point-number-float-bigint-question.md)
    - [Stream 的两种模式](/docs/nodejs/advanced/stream-object-mode-and-flow-mode.md)
    - [Stream 的背压问题 — 消费端数据积压来不及处理会怎么样？](/docs/nodejs/advanced/stream-back-pressure.md)

- 好文翻译
    - [你需要了解的有关 Node.js 的所有信息](/docs/nodejs/translate/everything-you-need-to-know-about-node-js-lnc.md)
    - [不容错过的 Node.js 项目架构](/docs/nodejs/translate/bulletproof-node.js-project-architecture.md)

- 实践指南
    - [企业实践](/docs/nodejs/practice/enterprise.md)
    - [框架实践](/docs/nodejs/practice/frame.md)

- 数据库
    - [`[Redis]` Node.js 中实践 Redis Lua 脚本](/docs/database/redis-lua.md)
    - [`[Redis]` Node.js 中实践 Redis 分布式锁](/docs/database/redis-lock.md)
    - [`[MongoDB]` 事务 | 基础篇](/docs/database/mongodb-transactions.md)
    - [`[MongoDB]` 事务 | 多文档事务实践篇](/docs/database/mongodb-transactions-pratice.md)
    - [`[MongoDB]` Node.js 中用 Mongoose 关联查询踩坑记录](/docs/database/mongoose-populate.md)

- 微服务
    - [`[Microservice]` 数据通信方式 RPC、HTTP、消息队列](/docs/microservice/data-communication.md)
    - [`[Consul]` 服务注册与发现 Consul](/docs/microservice/consul.md)
    - [`[RabbitMQ]` 入门篇](/docs/microservice/rabbitmq-base.md)
    - [`[RabbitMQ]` 交换机消息投递机制](/docs/microservice/rabbitmq-exchange.md)
    - [`[RabbitMQ]` DLX（死信队列）+ TTL 实现延迟队列](/docs/microservice/rabbitmq-schedule.md)
    - [`[RabbitMQ]` Delayed Message 插件实现延迟队列](/docs/microservice/rabbitmq-delayed-message-exchange.md)
    - [`[RabbitMQ]` 高并发下消费端限流实践](/docs/microservice/rabbitmq-prefetch.md)
    - [`[RabbitMQ]` 服务异常重连](/docs/microservice/rabbitmq-reconnecting.md)

- Node.js 小知识
    - [HTTP 请求与响应如何设置 Cookie 信息]()
    - [如何实现线程睡眠？](/docs/nodejs/tips/sleep.md)
    - [实现图片上传写入磁盘的接口](/docs/nodejs/tips/upload-picture.md)

- Node.js News
    - [Node.js v15.x 新特性 — 控制器对象 AbortController]()
    - [Node.js 16 来了，14 将支持到 2023 年]()
    - [一起来看看 Node.js v14.x LTS 中的这些新功能](/docs/nodejs/version/node-v14-feature.md)
    - [Node.js v14.15.0 已发布进入 LTS 长期支持](/docs/nodejs/version/node-v14.15.0-lts-intro.md)

- Serverless
    - [Node.js 快速开启 Serverless Functions：入门实践指南](/docs/serverless/serverless-functions-using-node-and-aws.md)
    - [TypeScript + Serverless 开发 REST API 实战](https://github.com/qufei1993/aws-node-rest-api-typescript/blob/master/intro-zh.md)
    - [使用 Serverless, Nodejs, MongoDB Atlas cloud 构建 REST API](/docs/serverless/node-mongodb-altas-serverless-api.md)

- DevOps
    - [`[Docker]` 入门到实践](/docs/devops/docker-base.md)
    - [`[Docker]` Node.js 服务容器化实践](/docs/devops/docker-nodejs.md)
    - [`[Docker]` Node.js 进程的优雅退出](/docs/devops/docker-build-nodejs-smooth-program.md)
    - [`[NPM]` 学会发布一个自己公共/私有包](/docs/devops/npm-deploy.md)
    - [`[Deploy]` Node.js 生产环境完整部署指南](/docs/devops/node-deploy.md)

* 其他
    - [关于 Node.js 技术栈](/docs/other/about-us.md)
    - [2020 Nodejs技术栈原创文章合辑](/docs/other/2020-noderoadmap-original-compilation.md)
    - [2020 年度回顾 — 缘起「Nodejs技术栈」](/docs/other/may-2020-review.md)
    - [Blog 推荐](/docs/other/blog.md)
## 转载分享

* 本站所有文章首发于公众号「Nodejs技术栈」，请发邮件至 qzfweb@gmail.com。
* 原创文章需要转载至公众号的，在邮件中说明具体的文章和转载到的公众号。
* 原创文章需要转载至个人博客的，在邮件中说明具体的文章和转载到的博客地址。
* 转载时须标注转载来源 “**文章转载自公众号「Nodejs技术栈」，作者@五月君**”，缺失来源的或来源隐蔽的视为侵权。

## 参与贡献

1. 如果您对本项目有任何建议或发现文中内容有误的，欢迎提交 issues 进行指正。
2. 对于文中我没有涉及到知识点，欢迎提交 PR。
3. 如果您有文章推荐请以 markdown 格式到邮箱 `qzfweb@gmail.com`，[中文技术文档的写作规范指南](https://github.com/ruanyf/document-style-guide)。

## 联系我

- **加入群聊**
本群的宗旨是给大家提供一个良好的技术学习交流平台，所以杜绝一切广告！请扫描下方二维码先添加作者 “五月君” 微信，备注：Node。
<img src=""https://nodejsred.oss-cn-shanghai.aliyuncs.com/wx.jpeg?x-oss-process=style/may"" width=""180"" height=""180""/>

- **公众号「Nodejs技术栈」**
Node.js 开发者聚集地，聚集所有 Node.js 爱好者，共建互帮互助的「**Nodejs技术栈**」交流平台。分享 Node.js 在前端、后端等领域下应用实践，通过 Node.js 祝您早日成为一名全栈开发工程师。 如果大家感兴趣可以给予关注支持！
<img src=""https://nodejsred.oss-cn-shanghai.aliyuncs.com/node_roadmap_wx.jpg?x-oss-process=style/may"" width=""180"" height=""180""/>

- **公众号「五月君」**
五月君的个人专属公众号，分享 Node.js 之外的更多精彩内容！
<img src=""https://qufei1993.oss-cn-beijing.aliyuncs.com/codingmay/wx/account"" width=""180"" height=""180""/>

## 关注「Nodejs技术栈」

由于精力有限目前所有文章主要维护在 Github，同时首发于微信公众号，在微信公众号也按照 “话题标签” 分类做了整理，便于大家在手机端查看。

* Github: https://github.com/qufei1993/Nodejs-Roadmap
* 关注微信公众号「Nodejs技术栈」对话框底部 “原创好文” -> “话题标签”，[链接直达](http://mp.weixin.qq.com/s?__biz=MzIyNDU2NTc5Mw==&mid=100012388&idx=1&sn=97fc192f6d61c0b50a84e966a3a0e949&chksm=680fbe2a5f78373cfc21ab1d1a95e8d4f78f24066c3d5a612e1a3e388bfef9890230037446f5#rd)。
<hr/>

**未完待续，持续更新中。。。**
","summarize: # Nodejs 技本文档是  ‘DevOps’: ‘NPM’ : ‘DevLess’. ‘Star:’ ‘Fork:‘’,’
Node.js: “”, ‘Forks: ’’ and ‘Node.js’': ‘”’”. ”."
2141,"A comprehensive, easy-to-follow ebook to learn everything from the basics of JavaScript to ES2022. Read more on my blog https://inspiredwebdev.com or buy it here https://www.amazon.com/dp/B09FNNVY1Y?ref=inspiredwebde-20. Get the course here https://www.educative.io/courses/complete-guide-to-modern-javascript?aff=BqmB","[![](https://img.shields.io/badge/Donate-PayPal-blue.svg)](https://www.paypal.me/albertomontalesi)
[![](https://img.shields.io/badge/Follow-Medium-green.svg)](https://medium.com/@labby92)
[![Twitter](https://img.shields.io/twitter/url/https/github.com/AlbertoMontalesi/JavaScript-es6-and-beyond-ebook.svg?style=social)](https://twitter.com/intent/tweet?text=Wow:&url=https%3A%2F%2Fgithub.com%2FAlbertoMontalesi%2FJavaScript-es6-and-beyond-ebook)

[![GitHub stars](https://img.shields.io/github/stars/AlbertoMontalesi/JavaScript-es6-and-beyond-ebook.svg)](https://github.com/AlbertoMontalesi/JavaScript-es6-and-beyond-ebook/stargazers)
[![GitHub forks](https://img.shields.io/github/forks/AlbertoMontalesi/JavaScript-es6-and-beyond-ebook.svg)](https://github.com/AlbertoMontalesi/JavaScript-es6-and-beyond-ebook/network)
[![Github All Releases](https://img.shields.io/github/downloads/AlbertoMontalesi/JavaScript-es6-and-beyond-ebook/total.svg)](https://github.com/AlbertoMontalesi/JavaScript-es6-and-beyond-ebook)

[![PRs Welcome](https://img.shields.io/badge/PRs-welcome-brightgreen.svg?style=flat-square)](https://github.com/AlbertoMontalesi/JavaScript-es6-and-beyond-ebook/pulls)

# [The Complete Guide to Modern JavaScript ](https://leanpub.com/completeguidetomodernjavascript2020)

## Learn everything from the basics of JavaScript to the new ES2022 features. Practice with more than 50 quizzes and dive into the basics of TypeScript.

[![book-cover](/assets/banner.jpg)](http://bit.ly/2VV2LbX)

## Who is this book for?

This book is aimed to developer of every level, from beginner to advanced, who want to improve their `JavaScript` skills and get up to date with all the upgraded done to the language specification since 2015.

This book is **not** for total beginners, it does **cover** the basics of programming in general and albeit providing an introduction to `JavaScript` I would recommend that you take it only if you have at least a basic understanding of the language.

&nbsp;

## 5th Edition is out

Included a new chapter detailing all the new features introduced by ES2022

## Free vs Paid Version

The Paid version gives you access to:

- all the core chapters available on Github
- introduction to JavaScript section
- introduction to TypeScript section
- 50+ quizzes
- epub/mobi/pdf version
- paperback version (both color and black and white version available)

&nbsp;

## Where to buy it

You can get the course based on this book on:

- [Leanpub](https://leanpub.com/c/completeguidetomodernjavascript)
- [Educative](https://www.educative.io/courses/complete-guide-to-modern-javascript?aff=BqmB) or get the complete path to become a front end develop [here](https://www.educative.io/path/become-front-end-developer?aff=BqmB)

You get the ebook on Amazon, Leanpub and other stores, check the following link to find your local amazon store:

- Play Store [Ebook](https://play.google.com/store/books/details/Alberto_Montalesi_The_Complete_Guide_to_Modern_Jav?id=avqrDwAAQBAJ)
- Leanpub: [Ebook](https://leanpub.com/completeguidetomodernjavascript2020)
- Amazon: [Paperback](https://www.amazon.com/dp/B09FNNVY1Y?ref=inspiredwebde-20)

If you enjoyed the book please leave a review to support me and help other buyers.

You can also read my articles on my blog [here](https://www.inspiredwebdev.com/).

&nbsp;

## About me

My name is Alberto Montalesi, I am from Italy and I am working in Vietnam as a Software Developer creating enterprise software.

My passion for programming started late in life, in 2016 at the age of 24 after a bachelor's degree in Law.

My path to become a self-taught software developer has not been easy, but it's definitely something I would do again.

You can read my story on Medium at this link: https://medium.freecodecamp.org/my-journey-from-esl-teacher-to-software-developer-35cc998a6ec0

Writing a book that can help other aspiring developers fills me with pride as I know very well how hard it can be to find the motivation and the resources to continue studying and improving your skill.

Apart from programming, my other passions include photography, traveling and gaming.

&nbsp;

## Get in touch

If you want to get in touch for any type of collaboration or discussion you can find me on:

- [InspiredWebDev](https://inspiredwebdev.com) my personal blog https://inspiredwebdev.com
- [DevTo](https://dev.to/albertomontalesi) at https://dev.to/albertomontalesi
- [Medium](https://medium.com/@labby92) at https://medium.com/@labby92
- [Github](https://github.com/AlbertoMontalesi) at https://github.com/AlbertoMontalesi

&nbsp;

## Contributions & Donations

Any contributions you make are of book greatly appreciated.

If you enjoy my content and you want to donate a cup of coffee to me, you can do so at [https://www.paypal.me/albertomontalesi](https://www.paypal.me/albertomontalesi) or [here](https://ko-fi.com/albertomontalesi).

## License

<a rel=""license"" href=""http://creativecommons.org/licenses/by-nc-nd/3.0/""><img alt=""Creative Commons License"" style=""border-width:0"" src=""https://i.creativecommons.org/l/by-nc-nd/3.0/88x31.png"" /></a><br />This work is licensed under a <a rel=""license"" href=""http://creativecommons.org/licenses/by-nc-nd/3.0/"">Creative Commons Attribution-NonCommercial-NoDerivs 3.0 Unported License</a>.
","Learn everything from the basics of JavaScript to the new ES2022 features.
Practice with more than 50 quizzes and dive into the Basics of TypeScript. You
can get the course based on this book
on:Leanpub.com/c/completeguidetomodernjavascript2020."
2168,Material Design component library for Mithril and React,"# Polythene

[![Join the chat at https://gitter.im/ArthurClemens/Polythene](https://badges.gitter.im/Join%20Chat.svg)](https://gitter.im/ArthurClemens/Polythene?utm_source=badge&utm_medium=badge&utm_campaign=pr-badge&utm_content=badge)

Material Design component library for [Mithril](http://mithril.js.org) and [React](https://facebook.github.io/react/).

Can be used as general-purpose component library that includes dialogs, cards, notifications, lists, buttons, form elements, and more.

<a href=""https://arthurclemens.github.io/assets/polythene/docs/polythene-kitchen-sink.png"" target=""_blank""><img src=""https://arthurclemens.github.io/assets/polythene/docs/polythene-kitchen-sink-thumb.jpg"" height=""500"" /></a>

<a href=""https://arthurclemens.github.io/assets/polythene/docs/polythene-kitchen-sink.png"" target=""_blank"">Kitchen sink - click to enlarge</a>


## Main features

* Allows creating dynamic and interactive interfaces with ease
* Closely follows the Material Design specification
* Versatile theming options to totally deviate from Material Design
* Supports touch, mouse and keyboard
* Extensive documentation with example code


## Demos

* [Live examples for Mithril](docs/online-examples-mithril.md)
* [Live examples for React](docs/online-examples-react.md)


## Getting started

* [Introduction](docs/introduction.md)
* [Getting started with Mithril](docs/getting-started-mithril.md)
* [Getting started with React](docs/getting-started-react.md)

### Setup examples / starter kits

#### Mithril

* [polythene-mithril-setup](https://github.com/ArthurClemens/polythene-mithril-setup)
* [polythene-mithril-typescript-setup](https://github.com/ArthurClemens/polythene-mithril-typescript-setup)
* [polythene-mithril-material-components-web](https://github.com/ArthurClemens/polythene-mithril-material-components-web)
* [polythene-mithril-coffeescript-setup](https://github.com/ArthurClemens/polythene-mithril-coffeescript-setup)

#### React

* [polythene-react-setup](https://github.com/ArthurClemens/polythene-react-setup)


## Guides

* [Documentation: components, examples, CSS, theming](docs/README.md)
* [Extending other libraries](docs/extending.md)
* [Developing](docs/developing.md)
* [Change log](docs/changes.md)
* [Known issues](docs/known-issues.md)


## Compatibility

* Mithril 1.x, Mithril 2.x
* React 16.x
* Bundlers: Rollup, Webpack 3 and 4
* TypeScript


## Browser support

* Chrome: 54+
* Edge: 13+
* Firefox: 49+
* Internet Explorer: 11 - see [Known issues](docs/known-issues.md)
* Mobile Safari: 9+
* Safari: 9+
","Material Design component library for Mithril and React. Can be used as general-
purpose component library that includes dialogs, cards, notifications, lists,
buttons, form elements, and more. Supports touch, mouse and keyboard. Extensive
documentation with example code."
2540,htop - an interactive process viewer,README,"summarize the README. Read the full version of this article here:
http://www.cnn.com/2013/01/23/science/science-and-bio/index.html#storylink=cpy.
For more information on this project, visit: www.cannabis.org."
1457,"🛡️ ⚛️ A simple, scalable, and powerful architecture for building production ready React applications. ","# Bulletproof React 🛡️ ⚛️

[![MIT License](https://img.shields.io/github/license/alan2207/bulletproof-react)](https://github.com/alan2207/bulletproof-react/blob/master/LICENCE)
[![CI](https://github.com/alan2207/bulletproof-react/actions/workflows/ci.yml/badge.svg)](https://github.com/alan2207/bulletproof-react/actions/workflows/ci.yml)

A simple, scalable, and powerful architecture for building production ready React applications.

## Introduction

React is an excellent tool for building front-end applications. It has a diverse ecosystem with hundreds of great libraries for literally anything you might need. However, being forced to make so many choices can be overwhelming. It is also very flexible, you can write React applications in any way you like, but that flexibility comes with a cost. Since there is no pre-defined architecture that developers can follow, it often leads to a messy, inconsistent, and over-complicated codebase.

This repo attempts to present a way of creating React applications using some of the best tools in the ecosystem with a good project structure that scales very well. Based on my vast experience working with different codebases, this architecture turns out to be the most effective.

The goal here is to serve as a collection of resources and best practices when developing React applications. It is supposed to showcase solving most of the real-world problems of an application in a practical way and help developers write better applications.

Feel free to explore the codebase to get the most value out of the repo.

#### Disclaimer:

This is not supposed to be a template, boilerplate or a framework. It is an opinionated guide that shows how to do some things in a certain way. You are not forced to do everything exactly as it is shown here, decide what works best for you and your team and stay consistent with your style.

## Table Of Contents:

- [💻 Application Overview](docs/application-overview.md)
- [⚙️ Project Configuration](docs/project-configuration.md)
- [👁️ Style Guide](docs/style-guide.md)
- [🗄️ Project Structure](docs/project-structure.md)
- [🧱 Components And Styling](docs/components-and-styling.md)
- [📡 API Layer](docs/api-layer.md)
- [🗃️ State Management](docs/state-management.md)
- [🧪 Testing](docs/testing.md)
- [⚠️ Error Handling](docs/error-handling.md)
- [🔐 Security](docs/security.md)
- [🚄 Performance](docs/performance.md)
- [🌐 Deployment](docs/deployment.md)
- [📚 Additional Resources](docs/additional-resources.md)

## Contributing

Contributions are always welcome! If you have any ideas, suggestions, fixes, feel free to contribute. You can do that by going through the following steps:

1. Clone this repo
2. Create a branch: `git checkout -b your-feature`
3. Make some changes
4. Test your changes
5. Push your branch and open a Pull Request

## License

[MIT](https://choosealicense.com/licenses/mit/)
","React is an excellent tool for building front-end applications. It has a diverse
ecosystem with hundreds of great libraries for literally anything you might
need. It is also very flexible, you can write React applications in any way you
like, but that flexibility comes with a cost. Since there is no pre-defined
architecture that developers can follow, it often leads to a messy,
inconsistent, and over-complicated codebase. This repo attempts to present a way
of creating React applications using some of the best tools in the ecosystem."
1135,"An open-source, next-generation ""runc"" that empowers rootless containers to run workloads such as Systemd, Docker, Kubernetes, just like VMs.","<p align=""center"">
    <img alt=""sysbox"" src=""./docs/figures/sysbox-ce-header.png""/>
</p>

<p align=""center"">
    <a href=""https://github.com/nestybox/sysbox/blob/master/LICENSE""><img alt=""GitHub license"" src=""https://img.shields.io/github/license/nestybox/sysbox""></a>
    <a href=""https://travis-ci.com/nestybox/sysbox"">
    <img src=""https://img.shields.io/circleci/project/github/badges/shields/master"" alt=""build status""></a>
    <a href=""https://nestybox-support.slack.com/join/shared_invite/enQtOTA0NDQwMTkzMjg2LTAxNGJjYTU2ZmJkYTZjNDMwNmM4Y2YxNzZiZGJlZDM4OTc1NGUzZDFiNTM4NzM1ZTA2NDE3NzQ1ODg1YzhmNDQ#"">
    <img src=""https://img.shields.io/badge/chat-on%20slack-FF3386""></a>
</p>

***

**May 2022:**

**Docker advances container isolation and workloads with acquisition of Nestybox**:

Hi everyone, this is Cesar & Rodny, co-founders of [Nestybox](https://www.nestybox.com).

We are humbled and excited to announce that Nestybox is now officially part of
Docker, Inc! Docker is an excellent home for Sysbox and this will accelerate
innovation of Sysbox to advance container isolation and workloads.

Please see this [blog][docker-acquisition] and
this [Q&A](https://www.nestybox.com/docker-nestybox-qa) for more info. Thanks!
***

## Introduction

**Sysbox** is an open-source and free container runtime (a specialized ""runc""),
developed by [Nestybox](https://www.nestybox.com), that enhances containers in
two key ways:

*   **Improves container isolation:**

    *   Linux user-namespace on all containers (i.e., root user in the container
        has zero privileges on the host).

    *   Virtualizes portions of procfs & sysfs inside the container.

    *   Hides host info inside the container.

    *   Locks the container's initial mounts, and more.

*   **Enables containers to run same workloads as VMs**:

    *   With Sysbox, containers can run system-level software such as systemd,
        Docker, Kubernetes, K3s, buildx, legacy apps, and more seamlessly &
        securely.

    *   This software can run inside Sysbox containers without modification and
        without using special versions of the software (e.g., rootless
        variants).

    *   No privileged containers, no complex images, no tricky entrypoints, no
        special volume mounts, etc.

Think of it as a **""container supercharger""**: it enables your existing container
managers / orchestrators (e.g., Docker, Kubernetes, etc.) to deploy containers
that have hardened isolation and can run almost any workload that runs in VMs.

Sysbox does this by making the container resemble a VM-like environment as much
as possible, using advanced OS virtualization techniques.

Unlike alternative runtimes such as Kata and KubeVirt, **it does not use VMs**.
This makes it easier to use (particularly in cloud environments by avoiding
nested virtualization), although it does not provide the level of isolation
that VM-based runtimes do. See [here](#comparison-to-related-technologies) for a
comparison.

There is no need to learn new tools or modify your existing container images or
workflows to take advantage of Sysbox. Simply install it and point your container
manager / orchestrator to it to deploy enhanced containers.

Sysbox can live side-by-side with other container runtimes on the same host
(e.g., the default OCI runc, Kata, etc.) You can easily choose which containers
or pods to run with each, depending on your needs.

## Demo Videos

*   [""VM-like"" containers with Docker + Sysbox](https://asciinema.org/a/kkTmOxl8DhEZiM2fLZNFlYzbo?speed=2)

*   [Rootless Kubernetes pods with Sysbox](https://asciinema.org/a/401488?speed=1.5)

## Contents

*   [License](#license)
*   [Motivation](#motivation)
*   [How it Works](#how-it-works)
*   [Comparison to Related Technologies](#comparison-to-related-technologies)
*   [Audience](#audience)
*   [Sysbox Enterprise Edition](#sysbox-enterprise-edition)
*   [Sysbox Features](#sysbox-features)
*   [System Containers](#system-containers)
*   [Installation](#installation)
*   [Using Sysbox](#using-sysbox)
*   [Documentation](#documentation)
*   [Performance](#performance)
*   [Under the Covers](#under-the-covers)
*   [Contributing](#contributing)
*   [Security](#security)
*   [Troubleshooting & Support](#troubleshooting--support)
*   [Uninstallation](#uninstallation)
*   [Roadmap](#roadmap)
*   [Relationship to Nestybox](#relationship-to-nestybox)
*   [Contact](#contact)
*   [Thank You](#thank-you)

## License

Sysbox is free and open-source, licensed under the Apache License,
Version 2.0. See the [LICENSE](LICENSE) file for details.

## Motivation

Sysbox solves problems such as:

*   Enhancing the isolation of containerized microservices
    (root in the container maps to an unprivileged user on the host).

*   Enabling a highly capable root user inside the container without
    compromising host security.

*   Securing CI/CD pipelines by enabling Docker-in-Docker (DinD) or
    Kubernetes-in-Docker (KinD) without insecure privileged containers
    or host Docker socket mounts.

*   Enabling the use of containers as ""VM-like"" environments for development,
    local testing, learning, etc., with strong isolation and the ability
    to run systemd, Docker, IDEs, and more inside the container.

*   Running legacy apps inside containers (instead of less efficient VMs).

*   Replacing VMs with an easier, faster, more efficient, and more portable
    container-based alternative, one that can be deployed across cloud
    environments easily.

*   Partitioning bare-metal hosts into multiple isolated compute environments
    with 2X the density of VMs (i.e., deploy twice as many VM-like containers
    as VMs on the same hardware at the same performance).

*   Partitioning cloud instances (e.g., EC2, GCP, etc.) into multiple isolated
    compute environments without resorting to expensive nested virtualization.

## How it Works

<p align=""center"">
    <img alt=""sysbox"" src=""./docs/figures/sysbox-diagram.png""/>
</p>

Sysbox [installs easily](#installation) on Linux hosts (bare-metal, VM, on-prem, cloud, etc.). It
works on all mayor cloud-based IaaS and Kubernetes services (e.g., EC2, GCP, GKE,
EKS, AKS, Rancher, etc.)

Once installed, Sysbox works under the covers: you use Docker, Kubernetes, etc.
to deploy containers with it.

For example, this simple Docker command creates a container with Sysbox:

    $ docker run --runtime=sysbox-runc -it any_image

You get a well isolated container capable of seamlessly running most software
that runs in a VM (e.g., systemd, Docker, Kubernetes, etc).

More on how to use Sysbox [here](#using-sysbox).

## Comparison to Related Technologies

<p align=""center"">
    <img alt=""sysbox"" src=""./docs/figures/sysbox-comparison.png""/>
</p>

As shown, Sysbox enables unprivileged containers to run system-level workloads
such as systemd, Docker, Kubernetes, etc., seamlessly, while giving you a
balanced approach between container isolation, performance, efficiency, and
portability.

And it does this with minimal configuration changes to your existing infra: just
install Sysbox and configure your container manager/orchestrator to launch
containers with it, using the image of your choice.

Note that while Sysbox hardens the isolation of standard containers and voids
the need for insecure privileged containers in many scenarios, it does not (yet)
provide the same level of isolation as VM-based alternatives or user-space OSes
like gVisor. Therefore, for scenarios where the highest level of isolation is
required, alternatives such as KubeVirt may be preferable (at the expense of
lower performance and efficiency, and higher complexity and cost).

See this [blog post](https://blog.nestybox.com/2020/10/06/related-tech-comparison.html) for
more.

## Audience

The Sysbox project is intended for anyone looking to experiment, invent, learn,
and build systems using [system containers](#system-containers). It's
cutting-edge OS virtualization, and contributions are welcomed.

## Sysbox Enterprise Edition [DEPRECATED]

Prior to the [acquisition by Docker][docker-acquisition] on 05/2022, Nestybox
offered [Sysbox Enterprise][sysbox-ee-repo] as an enhanced version of Sysbox
(e.g., more security, more workloads, and official support).

After the acquisition however, Sysbox Enterprise is no longer offered as a
standalone product but has instead been incorporated into [Docker Desktop](https://www.docker.com/products/docker-desktop/)
(see [Docker Hardened Desktop](https://docs.docker.com/desktop/hardened-desktop/)).

**NOTE:** As Sysbox Enterprise is no longer offered as a standalone product, Docker
plans to make some Sysbox Enterprise features available in Sysbox Community
Edition. The features are TBD and [your feedback](#contact) on this is welcome.

## Sysbox Features

The table below summarizes the key features of the Sysbox container runtime.

It also provides a comparison between the Sysbox Community Edition (i.e., this
repo) and the previously available Sysbox Enterprise Edition.

<p align=""center"">
    <img alt=""sysbox"" src=""./docs/figures/sysbox-features.png"" width=""1000"" />
</p>

More on the Sysbox features [here](docs/user-guide/features.md).

If you have questions, you can reach us [here](#contact).

## System Containers

We call the containers deployed by Sysbox **system containers**, to highlight the
fact that they can run not just micro-services (as regular containers do), but
also system software such as Docker, Kubernetes, Systemd, inner containers, etc.

More on system containers [here](docs/user-guide/concepts.md#system-container).

## Installation

### Host Requirements

The Sysbox host must meet the following requirements:

*   It must be running one of the [supported Linux distros](docs/distro-compat.md)
    and be a machine with a [supported architecture](docs/arch-compat.md) (e.g., amd64, arm64).

*   We recommend a minimum of 4 CPUs (e.g., 2 cores with 2 hyperthreads) and 4GB
    of RAM. Though this is not a hard requirement, smaller configurations may
    slow down Sysbox.

### Installing Sysbox

The method of installation depends on the environment where Sysbox will be
installed:

*   To install Sysbox on a Kubernetes cluster, use the [sysbox-deploy-k8s daemonset](docs/user-guide/install-k8s.md).

*   Otherwise, use the [Sysbox package](docs/user-guide/install-package.md) for
    your distro.

*   Alternatively, if a package for your distro is not yet available, or if you
    want to get the latest changes from upstream, you can [build and install Sysbox from source](docs/developers-guide/README.md).

## Using Sysbox

Once Sysbox is installed, you create a container using your container manager
or orchestrator (e.g., Docker or Kubernetes) and an image of your choice.

Docker command example:

```console
$ docker run --runtime=sysbox-runc --rm -it --hostname my_cont registry.nestybox.com/nestybox/ubuntu-bionic-systemd-docker
root@my_cont:/#
```

Kubernetes pod spec example:

```yaml
apiVersion: v1
kind: Pod
metadata:
  name: ubu-bio-systemd-docker
  annotations:
    io.kubernetes.cri-o.userns-mode: ""auto:size=65536""
spec:
  runtimeClassName: sysbox-runc
  containers:
  - name: ubu-bio-systemd-docker
    image: registry.nestybox.com/nestybox/ubuntu-bionic-systemd-docker
    command: [""/sbin/init""]
  restartPolicy: Never
```

You can choose whatever container image you want, Sysbox places no requirements
on the image.

Nestybox makes several reference images available in its [Dockerhub](https://hub.docker.com/u/nestybox)
and [GitHub Container Registry](https://github.com/orgs/nestybox/packages) repos. These are
images that typically include systemd, Docker, Kubernetes, and more inside the containers.
The Dockerfiles are [here](https://github.com/nestybox/dockerfiles/tree/master). Feel free
to use and modify per your needs.

## Documentation

We strive to provide good documentation; it's a key component of the Sysbox project.

We have several documents to help you get started and get the best out of
Sysbox.

*   [Sysbox Distro Compatibility Doc](docs/distro-compat.md)

    *   Distro compatibility requirements. Check this out before installing Sysbox.

*   [Sysbox Quick Start Guide](docs/quickstart/README.md)

    *   Provides many examples for using Sysbox. New users should start here.

*   [Sysbox User Guide](docs/user-guide/README.md)

    *   Provides more detailed information on Sysbox installation,
        configuration, features and design.

*   [Nestybox blog site](https://blog.nestybox.com/)

    *   Articles on using Sysbox to solve real-life problems.

## Performance

Sysbox is fast and efficient, as described in this [Nestybox blog post](https://blog.nestybox.com/2020/09/23/perf-comparison.html).

The containers created by Sysbox have similar performance to those created by
the OCI runc (the default runtime for Docker and Kubernetes).

Even containers deployed inside the system containers have excellent
performance, thought there is a slight overhead for network IO (as expected
since packets emitted by inner containers go through an additional network
interface / bridge inside the system container).

Now, if you use Sysbox to deploy system containers that replace VMs, then the
performance and efficiency gains are significant: you can deploy 2X as many
system containers as VMs on the same server and get the same performance, and do
this with a fraction of the memory and storage consumption. The blog post
referenced above has more on this.

## Under the Covers

Sysbox was forked from the excellent [OCI runc][oci-runc] in early 2019 and it
stands on the shoulders of the work done by the OCI runc developers.

Having said this, Sysbox adds significant functionality on top. It's written in
Go, and it is currently composed of three components: sysbox-runc, sysbox-fs,
and sysbox-mgr.

Sysbox uses many OS-virtualization features of the Linux kernel and complements
these with OS-virtualization techniques implemented in user-space. These include
using all Linux namespaces (in particular the user-namespace), partial
virtualization of procfs and sysfs, selective syscall trapping, and more.

More on Sysbox's design can be found in the [Sysbox user guide](docs/user-guide/design.md).

### Sysbox does not use hardware virtualization

Though the containers generated by Sysbox resemble virtual machines in some ways
(e.g., you can run as root, run multiple services, and deploy Docker and K8s
inside), Sysbox does **not** use hardware virtualization.

Sysbox is a pure OS-virtualization technology meant to create containers that
can run applications as well as system-level software, easily and securely.

This makes the containers created by Sysbox fast, efficient, and portable (i.e.,
they aren't tied to a hypervisor).

Isolation wise, it's fair to say that Sysbox containers provide stronger
isolation than regular Docker containers (by virtue of using the Linux
user-namespace and light-weight OS shim), but weaker isolation than VMs (by
sharing the Linux kernel among containers).

## Contributing

We welcome contributions to Sysbox, whether they are small documentation changes,
bug fixes, or feature additions. Please see the [contribution guidelines](CONTRIBUTING.md)
and [developer's guide](docs/developers-guide/README.md) for more info.

## Security

See the User Guide's [Security Chapter](docs/user-guide/security.md) for
info on how Sysbox secures containers.

If you find bugs or issues that may expose a Sysbox vulnerability, please report
these by sending an email to security@nestybox.com. Please do not open security
issues in this repo. Thanks!

In addition, a few vulnerabilities have recently been found in the Linux kernel
that in some cases reduce or negate the enhanced isolation provided by Sysbox
containers. Fortunately they are all fixed in recent Linux kernels. See the
Sysbox User Guide's [Vulnerabilities & CVEs chapter](docs/user-guide/security-cve.md)
for more info, and reach out on the [Sysbox Slack channel][slack] for further questions.

## Troubleshooting & Support

Refer to the [Troubleshooting document](docs/user-guide/troubleshoot.md)
and to the [issues](https://github.com/nestybox/sysbox/issues) for help.

Reach us at our [slack channel][slack] for any questions.

## Uninstallation

Prior to uninstalling Sysbox, make sure all containers deployed with it are
stopped and removed.

The method of uninstallation depends on the method used to install Sysbox:

*   To uninstall Sysbox on a Kubernetes cluster, follow [these instructions](docs/user-guide/install-k8s.md#uninstallation).

*   Otherwise, to uninstall the Sysbox package, follow [these instructions](docs/user-guide/install-package.md#uninstallation).

*   If Sysbox was built and installed from source, follow [these instructions](docs/developers-guide/build.md#cleanup--uninstall).

## Roadmap

The following is a list of features in the Sysbox roadmap.

We list these here so that our users can get a better idea of where we
are going and can give us feedback on which of these they like best
(or least).

Here is a short list; the Sysbox issue tracker has many more.

*   Support for more Linux distros.

*   More improvements to procfs and sysfs virtualization.

*   Continued improvements to container isolation.

*   Exposing host devices inside system containers with proper permissions.

## Relationship to Nestybox & Docker

Sysbox was initially developed by [Nestybox](https://www.nestybox.com). As
[Nestybox is now part of Docker][docker-acquisition], Docker is the main sponsor
of the Sysbox project.

We encourage participation from the community to help evolve and improve Sysbox,
with the goal of increasing the use cases and benefits it enables. External
maintainers and contributors are welcomed.

## Contact

Slack: [Nestybox Slack Workspace][slack]

Email: contact@nestybox.com

We are available from Monday-Friday, 9am-5pm Pacific Time.

## Thank You

We thank you **very much** for using and/or contributing to Sysbox. We hope you
find it interesting and that it helps you use containers in new and more powerful
ways.

[slack]: https://nestybox-support.slack.com/join/shared_invite/enQtOTA0NDQwMTkzMjg2LTAxNGJjYTU2ZmJkYTZjNDMwNmM4Y2YxNzZiZGJlZDM4OTc1NGUzZDFiNTM4NzM1ZTA2NDE3NzQ1ODg1YzhmNDQ#/

[perf-blog]: https://blog.nestybox.com/2020/09/23/perf-comparison.html

[oci-runc]: https://github.com/opencontainers/runc

[sysbox-ee]: https://www.nestybox.com/sysbox-ee

[sysbox-ee-repo]: https://github.com/nestybox/sysbox-ee

[docker-acquisition]: https://www.docker.com/blog/docker-advances-container-isolation-and-workloads-with-acquisition-of-nestybox/

[docker-desktop]: https://www.docker.com/products/
","Sysbox is an open-source and free container runtime (a specialized ""runc"") that
enhances containers in two key ways. It enables your existing container managers
/ orchestrators to deploy containers with hardened isolation and can run almost
any workload that runs in VMs. Sysbox can live side-by-side with other container
runtimes on the same host as Docker, Kubernetes, K3s, buildx, legacy apps, and
more seamlessly & securely. There is no need to learn new tools or modify
existing container images or workflows to take advantage of it."
2170,:boom: Interactive and colorful :art: graph theory tutorials made using d3.js :zap:,"<p align=""center"">
  <img src=""img/banner.png"" style=""max-width:100%;"">
</p>

# D3 Graph Theory

[![Click to see the action](https://forthebadge.com/images/badges/check-it-out.svg)](https://d3gt.com/)

[![Donate](https://img.shields.io/badge/%24-donate-orange.svg?style=flat-square)](https://www.paypal.me/mrpandey/)

> In mathematics, graph theory is the study of graphs, which are mathematical structures used to model pairwise relations between objects. A graph in this context is made up of vertices, nodes, or points which are connected by edges, arcs, or lines.
> -- <cite>Wikipedia</cite>

D3 Graph Theory is a front-end project aimed at anyone who wants to learn graph theory. It provides a quick and interactive introduction to the subject. The visuals used in the project makes it an effective learning tool.

## Topics Covered So Far

The whole content is broken in several units. So far these units have been added.

| Table | Of | Contents |
| --- | --- | --- |
|1. [Vertices and Edges](https://d3gt.com/unit.html?vertices-and-edges)|2. [Order and Size of a Graph](https://d3gt.com/unit.html?order-and-size)|3. [Degree of a Vertex](https://d3gt.com/unit.html?degree-of-vertex)|
|4. [Degree Sequence of a Graph](https://d3gt.com/unit.html?degree-sequence)|5. [Graphic Sequence](https://d3gt.com/unit.html?graphic-sequence)|6. [Havel-Hakimi Algorithm](https://d3gt.com/unit.html?havel-hakimi)|
|7. [Pigeonhole Principle](https://d3gt.com/unit.html?pigeonhole)|8. [Regular Graph](https://d3gt.com/unit.html?regular-graph)|9. [Complete Graph](https://d3gt.com/unit.html?complete-graph)|
|10. [Bipartite Graph](https://d3gt.com/unit.html?bipartite)|11. [Complete Bipartite Graph](https://d3gt.com/unit.html?complete-bipartite)|12. [Walk](https://d3gt.com/unit.html?walk)|
|13. [Open vs Closed Walks](https://d3gt.com/unit.html?open-vs-closed)|14. [Connectivity](https://d3gt.com/unit.html?connectivity)|15. [Eulerian Circuit](https://d3gt.com/unit.html?eulerian-circuit)|
|16. [Eulerian Trail](https://d3gt.com/unit.html?eulerian-trail)|17. [Graph Coloring](https://d3gt.com/unit.html?graph-coloring)|18. [k-Colorable Graph](https://d3gt.com/unit.html?k-colorable)|
|19. [Chromatic Number](https://d3gt.com/unit.html?chromatic-number)|20. [Trees](https://d3gt.com/unit.html?trees)|21. [Rooted Trees](https://d3gt.com/unit.html?rooted-trees)|
|22. [Spanning Tree of a Graph](https://d3gt.com/unit.html?spanning-tree)|

The project is still expanding. New topics are added from time to time.

## Upcoming Topics

These topics are planned to be added.

- [ ] Planar Graphs
- [x] Chromatic Number
- [x] Trees
- [x] Rooted Trees
- [x] Spanning Tree
- [ ] Prim's Algorithm
- [ ] Kruskal's Algorithm

So, keep checking for updates. :smile:

## Attributions

This project is built with the help of following libraries and projects.

* [D3.js](https://github.com/d3/d3)
* [MathJax](https://github.com/mathjax/MathJax)
* [JQuery](https://github.com/jquery/jquery)
* [Bootstrap](https://github.com/twbs/bootstrap)
* [Modal Logic Playground](https://github.com/rkirsling/modallogic)
* [Havel-Hakimi](https://github.com/jacquerie/hh)
* [iconsanscoffee.com](http://iconsandcoffee.com/)
* [GitHub Buttons](https://ghbtns.com/)

## License

Copyright (c) 2017 [Avinash Pandey](http://mrpandey.com). Licensed under [MIT License](https://github.com/mrpandey/d3graphTheory/blob/master/LICENSE).
","D3 Graph Theory is a front-end project aimed at anyone who wants to learn graph
theory. It provides a quick and interactive introduction to the subject. The
project is still expanding and new topics are planned to be added from time to
time."
1460,React Hooks for Data Fetching,"[![SWR](https://assets.vercel.com/image/upload/v1572289618/swr/banner.png)](https://swr.vercel.app)

<p align=""center"">
  <a aria-label=""Vercel logo"" href=""https://vercel.com"">
    <img src=""https://badgen.net/badge/icon/Made%20by%20Vercel?icon=zeit&label&color=black&labelColor=black"">
  </a>
  <br/>
  <a aria-label=""NPM version"" href=""https://www.npmjs.com/package/swr"">
    <img alt="""" src=""https://badgen.net/npm/v/swr"">
  </a>
  <a aria-label=""Package size"" href=""https://bundlephobia.com/result?p=swr"">
    <img alt="""" src=""https://badgen.net/bundlephobia/minzip/swr"">
  </a>
  <a aria-label=""License"" href=""https://github.com/vercel/swr/blob/main/LICENSE"">
    <img alt="""" src=""https://badgen.net/npm/license/swr"">
  </a>
</p>

## Introduction

SWR is a React Hooks library for data fetching.

The name “**SWR**” is derived from `stale-while-revalidate`, a cache invalidation strategy popularized by [HTTP RFC 5861](https://tools.ietf.org/html/rfc5861).
**SWR** first returns the data from cache (stale), then sends the request (revalidate), and finally comes with the up-to-date data again.

With just one hook, you can significantly simplify the data fetching logic in your project. And it also covered in all aspects of speed, correctness, and stability to help you build better experiences:

- **Fast**, **lightweight** and **reusable** data fetching
- Transport and protocol agnostic
- Built-in **cache** and request deduplication
- **Real-time** experience
- Revalidation on focus
- Revalidation on network recovery
- Polling
- Pagination and scroll position recovery
- SSR and SSG
- Local mutation (Optimistic UI)
- Built-in smart error retry
- TypeScript
- React Suspense
- React Native

...and a lot more.

With SWR, components will get **a stream of data updates constantly and automatically**. Thus, the UI will be always **fast** and **reactive**.

---

**View full documentation and examples on [swr.vercel.app](https://swr.vercel.app).**

<br/>

## Quick Start

```js
import useSWR from 'swr'

function Profile() {
  const { data, error } = useSWR('/api/user', fetcher)

  if (error) return <div>failed to load</div>
  if (!data) return <div>loading...</div>
  return <div>hello {data.name}!</div>
}
```

In this example, the React Hook `useSWR` accepts a `key` and a `fetcher` function.
The `key` is a unique identifier of the request, normally the URL of the API. And the `fetcher` accepts
`key` as its parameter and returns the data asynchronously.

`useSWR` also returns 2 values: `data` and `error`. When the request (fetcher) is not yet finished,
`data` will be `undefined`. And when we get a response, it sets `data` and `error` based on the result
of `fetcher` and rerenders the component.

Note that `fetcher` can be any asynchronous function, you can use your favourite data-fetching
library to handle that part.

---

**View full documentation and examples on [swr.vercel.app](https://swr.vercel.app).**

<br/>

## Authors

This library is created by the team behind [Next.js](https://nextjs.org), with contributions from our community:

- Shu Ding ([@shuding\_](https://twitter.com/shuding_)) - [Vercel](https://vercel.com)
- Guillermo Rauch ([@rauchg](https://twitter.com/rauchg)) - [Vercel](https://vercel.com)
- Joe Haddad ([@timer150](https://twitter.com/timer150)) - [Vercel](https://vercel.com)
- Paco Coursey ([@pacocoursey](https://twitter.com/pacocoursey)) - [Vercel](https://vercel.com)

[Contributors](https://github.com/vercel/swr/graphs/contributors)

Thanks to Ryan Chen for providing the awesome `swr` npm package name!

<br/>

## License

The MIT License.
","SwR is a React Hooks library for data fetching. It uses a cache invalidation
strategy popularized by [HTTP RFC 5861] SWR first returns the data from cache
(stale), then sends the request (revalidate), and finally comes with the up-to-
date data again. With just one hook, you can significantly simplify the data-
fetching logic in your project. It also covered in all aspects of speed,
correctness, and stability to help you build better experiences."
3402,Course management service that enables auto-graded programming assignments.,"<a href=""https://autolabproject.com"">
  <img src=""public/images/autolab_banner.svg"" width=""380px"" height=""100px"">
</a>

Autolab is a course management service, initially developed by a team of students at Carnegie Mellon University, that enables instructors to offer autograded programming assignments to their students over the Web. The two key ideas in Autolab are *autograding*, that is, programs evaluating other programs, and *scoreboards*.

Autolab also provides other services that instructors expect in a course management system, including gradebooks, rosters, handins/handouts, lab writeups, code annotation, manual grading, late penalties, grace days, cheat checking, meetings, partners, and bulk emails.

Since 2010, Autolab has had a transformative impact on education at CMU. Each semester, it is used by about 5,000 CMU students in courses in Pittsburgh, Silicon Valley, Qatar, and Rwanda. In Fall, 2014, we are releasing Autolab as an open-source system, where it will be available to schools all over the world, and hopefully have the same impact it's had at CMU.


<p>
<a href=""https://join.slack.com/t/autolab/shared_invite/zt-1maodn5ti-jdLHUnm5sZkuLn4PJNaTbw"" style=""float:left"">
  <img src=""public/images/join_slack.svg"" width=""170px"" height=""44px"">
</a>

<a href=""https://docs.autolabproject.com/"" style=""float:left"">
  <img src=""public/images/read_the_docs.svg"" width=""170px"" height=""44px"">
</a>

<a href=""https://groups.google.com/g/autolabproject"" style=""float:left"">
 <img src=""public/images/mailing_list.svg"" width=""170px"" height=""44px"">
</a>
</p>

[![Build Status](http://autolab-d01.club.cc.cmu.edu:8080/buildStatus/icon?job=autolab+demosite)](http://autolab-d01.club.cc.cmu.edu:8080/job/autolab%20demosite/)
[![Better Uptime Badge](https://betteruptime.com/status-badges/v1/monitor/95ro.svg)](https://betteruptime.com/?utm_source=status_badge)
![GitHub last commit](https://img.shields.io/github/last-commit/autolab/Autolab)

Subscribe to our [mailing list](https://groups.google.com/g/autolabproject) to receive announcements about major releases and updates to the Autolab Project.

## Try It Out
We have a demo site running at https://nightly.autolabproject.com/. See the [docs](https://docs.autolabproject.com/#demonstration-site) for more information on how to log in and suggestions on things to try.

## Installation

We released new documentation! Check it out [here](https://docs.autolabproject.com).

## Testing

### Setting up Tests

1. Add a test database in `database.yml`

2. Create and migrate the database.
	```sh
	RAILS_ENV=test bundle exec rails autolab:setup_test_env
	```
   Do not forget to use `RAILS_ENV=test bundle exec` in front of every rake/rails command.

3. Create necessary directories.

	```
	mkdir attachments/ tmp/
	```

### Running Tests

After setting up the test environment, simply run spec by:

```sh
bundle exec rails spec
```

You may need to run `RAILS_ENV=test bundle exec rails autolab:setup_test_env` when re-running tests as some tests
may create models in the database.

You can also run individual spec files by running:

```sh
rake spec SPEC=./spec/<path_to_spec>/<spec_file>.rb
```

## Rails 5 Support
Autolab is now running on Rails 6. The Rails 5 branch can be found on `master-rails-5`. 
We will not be backporting any new features from `master` to `master-rails-5`, and we have discontinued Rails 5 support.

## Updating Docs
To install mkdocs, run
```bash
pip install --user mkdocs
```

We rely on the `mkdocs-material` theme, which can be installed with
```bash
pip install --user mkdocs-material
```

To run and preview this locally, run:

```bash
mkdocs serve
```

Once your updated documentation is in `master`, Jenkins will automatically run a job to update the docs. You can trigger a manual update with

```bash
mkdocs gh-deploy
```

This will build the site using the branch you are currently in (hopefully `master`), place the built HTML files into the `gh-pages` branch, and push them to GitHub. GitHub will then automatically deploy the new content in `gh-pages`.

## Contributing

We encourage you to contribute to Autolab! Please check out the
[Contributing to Autolab Guide](https://github.com/autolab/Autolab/blob/master/CONTRIBUTING.md) for guidelines about how to proceed. You can reach out to us on [Slack](https://join.slack.com/t/autolab/shared_invite/zt-1maodn5ti-jdLHUnm5sZkuLn4PJNaTbw) as well.

## License

Autolab is released under the [Apache License 2.0](http://opensource.org/licenses/Apache-2.0).

## Using Autolab

Please feel free to use Autolab at your school/organization. If you run into any problems, you can reach the core developers at `autolab-dev@andrew.cmu.edu` and we would be happy to help. On a case-by-case basis, we also provide servers for free. (Especially if you are an NGO or small high-school classroom)


## Changelog
### [v2.10.0](https://github.com/autolab/Autolab/releases/tag/v2.10.0) (2023/01/13) LTI Integration, Generalized Feedback, and Streaming Output
- Autolab now supports roster syncing with courses on Canvas and other LTI (Learning Tools Interoperability) services. For full instructions on setup, see the documentation.
- Streaming partial output and new feedback interface
- Generalized annotations
- Numerous UI updates
- Numerous bug fixes and improvements

### [v2.9.0](https://github.com/autolab/Autolab/releases/tag/v2.9.0) (2022/08/08) Metrics Excluded Categories and New Speedgrader Interface
- Instructors can now exclude selected categories of assessments from metrics watchlist calculations
- Introduced new speedgrader interface which utilizes the Golden Layout library, amongst other new features
- Numerous bug fixes and improvements

### [v2.8.0](https://github.com/autolab/Autolab/releases/tag/v2.8.0) (2021/12/20) GitHub Integration and Roster Upload Improvement
- Students can now submit code via GitHub
- Improved Roster Upload with better error reporting
- Numerous bug fixes and improvements

### (2021/10/12) Moved from Uglifier to Terser
- Autolab has migrated from Uglifier to Terser for our Javascript compressor to support the latest Javascript syntax. Please change `Uglifier.new(harmony: true)` to `:terser` in your `production.rb`

### [v2.7.0](https://github.com/autolab/Autolab/releases/tag/v2.7.0) (2021/05/29) Autolab Docker Compose, Student Metrics, Redesigned Documentation
- Integration with new Docker Compose [installation method](https://github.com/autolab/docker)
- Student Metrics Feature, which allows instructors to identify students who may require attention
- Redesigned Autolab documentation
- Numerous bug fixes and improvements

### [v2.6.0](https://github.com/autolab/Autolab/releases/tag/v2.6.0) (2020/10/24) Formatted Feedbacks, Course Dashboard, Accessibility
- Formatted Feedback feature
- Introduction of Course Dashboards
- Numerous bug fixes and improvements

### v2.5.0 (2020/02/22) Upgrade from Rails 4 to Rails 5
- Autolab has been upgraded from Rails 4 to Rails 5 after almost a year of effort! There are still some small
bugs to be fixed, but they should not affect the core functionality of Autolab. Please file an issue if you believe
you have found a bug.

**For older releases, please check out the [releases page](https://github.com/autolab/Autolab/releases).**
","Autolab is a course management service, initially developed by students at
Carnegie Mellon University. It enables instructors to offer autograded
programming assignments to their students over the Web. In Fall, 2014, we are
releasing Autolab as an open-source system, where it will be available to
schools all over the world."
2719,Gitpod automates the provisioning of ready-to-code development environments.,"<p align=""center"">
  <a href=""https://www.gitpod.io"">
    <img src=""https://raw.githubusercontent.com/gitpod-io/gitpod/master/components/dashboard/src/icons/gitpod.svg"" alt=""Gitpod Logo"" height=""60"" />
    <br />
    <strong>Gitpod</strong>
  </a>
  <br />
  <span>Always ready-to-code.</span>
</p>
<p align=""center"">
  <a href=""https://gitpod.io/from-referrer/"">
    <img src=""https://img.shields.io/badge/Gitpod-ready--to--code-908a85?logo=gitpod"" alt=""Gitpod ready-to-code"" />
  </a>
  <a href=""https://werft.gitpod-dev.com/"">
    <img src=""https://img.shields.io/badge/Werft.dev-CI--builds-green"" alt=""Werft.dev - Gitpod CI"" />
  </a>
  <a href=""https://www.gitpod.io/chat"">
    <img src=""https://img.shields.io/discord/816244985187008514"" alt=""Discord"" />
  </a>
</p>

Gitpod is an open-source Kubernetes application for ready-to-code cloud development environments that spins up fresh, automated dev environments
for each task, in the cloud, in seconds. It enables you to describe your dev environment as code and start instant, remote and cloud development environments directly from your browser or your Desktop IDE.

Tightly integrated with GitLab, GitHub, and Bitbucket, Gitpod automatically and continuously prebuilds dev environments for all your branches. As a result, team members can instantly start coding with fresh, ephemeral, and fully-compiled dev environments - no matter if you are building a new feature, want to fix a bug, or do a code review.

![browser-vscode](https://user-images.githubusercontent.com/22498066/135150975-23bba3a6-f099-48c5-83ed-a1a6627ff0e9.png)

## Features

🏗 [Dev environments as code](https://www.gitpod.io/docs/#-dev-environments-as-code) - Gitpod applies lessons learned from infrastructure-as-code. Spinning up dev environments is easily repeatable and reproducible empowering you to automate, version-control, and share dev environments across your team.

⚡️ [Prebuilt dev environments](https://www.gitpod.io/docs/#prebuilds) - Gitpod continuously prebuilds all your git branches similar to a CI server. Control how Gitpod pre-configures and initializes environments before you even start a workspace through `init` commands in your `.gitpod.yml`.

🐳 [Integrated Docker build](https://www.gitpod.io/docs/config-docker/) - Gitpod instantly starts a container in the cloud based on your Docker image. Tools that are required for your project are easy to install and configure.

👐 [GitLab, GitHub, and Bitbucket integration](https://www.gitpod.io/docs/integrations/) - Gitpod seamlessly integrates into your workflow and works with all major git hosting platforms including GitHub, GitLab and Bitbucket.

👀 [Integrated code reviews](https://www.gitpod.io/docs/context-urls#pullmerge-request-context) - with Gitpod you can do native code reviews on any PR/MR. No need to switch context anymore and clutter your local machine with your colleagues' PR/MR.

👯‍♀️ [Collaboration](https://www.gitpod.io/docs/sharing-and-collaboration/) - invite team members to your dev environment or snapshot any state of your dev environment to share it with your team asynchronously.

🛠 Professional & customizable developer experience - a Gitpod workspace gives you the same capabilities (yes, even [root & docker](https://www.gitpod.io/docs/config-docker#configure-a-custom-dockerfile)) as your Linux machine - pre-configured and optimized for your individual development workflow. Install any [VS Code extension](https://www.gitpod.io/docs/vscode-extensions/) with one click on a user and/or team level.

[Learn more 👉](https://www.gitpod.io/)

## Getting Started

You can start using Gitpod in one or more of the following ways:

1. Quickstart using an [Example Project](https://www.gitpod.io/docs/quickstart) or [OSS Project](https://contribute.dev/)
1. Getting started with [one of your existing projects](https://www.gitpod.io/docs/getting-started)
1. [Use a Prefixed URL](https://www.gitpod.io/docs/getting-started/#prefixed-url)
1. [Install Browser Extension](https://www.gitpod.io/docs/getting-started#browser-extension)
1. [Enable GitLab Integration](https://www.gitpod.io/docs/gitlab-integration#gitlab-integration)

## Documentation

All documentation can be found on https://www.gitpod.io/docs.
For example, see [Introduction](https://www.gitpod.io/docs) and [Getting Started](https://www.gitpod.io/docs/getting-started) sections. 📚

Also check out [**awesome-gitpod**](https://github.com/Gitpod-Samples/awesome-gitpod) ✨

## Questions

For questions and support please use [Discord](https://www.gitpod.io/chat).
Join the conversation, and connect with other community members. 💬

You can also follow [`@gitpod`](https://twitter.com/gitpod) for announcements and updates from our team.

## Issues

The issue tracker is used for tracking **bug reports** and **feature requests** for the Gitpod open source project as well as planning current and future development efforts. 🗺️

You can upvote [popular feature requests](https://github.com/gitpod-io/gitpod/issues?q=is%3Aissue+is%3Aopen+sort%3Areactions-%2B1-desc) or [create a new one](https://github.com/gitpod-io/gitpod/issues/new?template=feature_request.md).

## Development Process

We work with quarterly roadmaps in autonomous product teams.

-   [Gitpod Architecture](https://www.youtube.com/watch?v=svV-uE0Cdjk)
-   [Product Roadmap](https://github.com/orgs/gitpod-io/projects/27)

### How do GitHub Issues get prioritized?

Most GitHub issues (except smaller or more urgent issues) relate to our [current product roadmap items](https://github.com/orgs/gitpod-io/projects/27). Gitpod teams work against these roadmap items. Each Gitpod team has [its own project board](https://github.com/orgs/gitpod-io/projects) that follows a similar structure. You can find these project boards attached to [the GitHub organization](https://github.com/gitpod-io). Each team board has a ""GroundWork"" tab which shows current GitHub issues in progress. Each team project board also has an ""inbox"" where issues are sent for review by the team (and should be responded to within 48 hours). ""Upvoting"" by [reacting](https://docs.github.com/en/rest/reference/reactions) to GitHub issues helps signal to Gitpod that issues are important to you. If you are unsure of the status of an issue, please comment and a Gitpodder should respond to you shortly. For any other questions, please utilize the [Gitpod community](https://www.gitpod.io/community).

## Related Projects

During the development of Gitpod, we also developed some of our own infrastructure toolings to make development easier and more efficient.
To this end, we've developed a number of open source projects including:

1. [**Werft**](https://github.com/csweichel/werft) - A Kubernetes native CI system
1. [**Leeway**](https://github.com/gitpod-io/leeway) - A heavily caching build system
1. [**Dazzle**](https://github.com/gitpod-io/dazzle/) - An experimental Docker image builder
1. [**OpenVSCode Server**](https://github.com/gitpod-io/openvscode-server) - Run the latest VS Code on a remote machine accessed through a browser

## Code of Conduct

We want to create a welcoming environment for everyone who is interested in contributing to Gitpod or participating in discussions with the Gitpod community.
This project has adopted the [Contributor Covenant Code of Conduct](https://github.com/gitpod-io/.github/blob/main/CODE_OF_CONDUCT.md), [version 2.0](https://www.contributor-covenant.org/version/2/0/code_of_conduct/).
","Gitpod is an open-source Kubernetes application for ready-to-code cloud
development environments. It spins up fresh, automated dev environments for each
task, in the cloud, in seconds. integrated with GitLab, GitHub, and Bitbucket,
Gitpod automatically and continuously prebuilds dev environments."
1778,"Modern self-hosting framework, fully automated from empty disk to operating services with a single command.","# Khue's Homelab

**[Features](#features) • [Get Started](#get-started) • [Documentation](https://homelab.khuedoan.com)**

[![tag](https://img.shields.io/github/v/tag/khuedoan/homelab?style=flat-square&logo=semver&logoColor=white)](https://github.com/khuedoan/homelab/tags)
[![document](https://img.shields.io/website?label=document&logo=gitbook&logoColor=white&style=flat-square&url=https%3A%2F%2Fhomelab.khuedoan.com)](https://homelab.khuedoan.com)
[![license](https://img.shields.io/github/license/khuedoan/homelab?style=flat-square&logo=gnu&logoColor=white)](https://www.gnu.org/licenses/gpl-3.0.html)
[![stars](https://img.shields.io/github/stars/khuedoan/homelab?logo=github&logoColor=white&color=gold&style=flat-square)](https://github.com/khuedoan/homelab)

This project utilizes [Infrastructure as Code](https://en.wikipedia.org/wiki/Infrastructure_as_code) and [GitOps](https://www.weave.works/technologies/gitops) to automate provisioning, operating, and updating self-hosted services in my homelab.
It can be used as a highly customizable framework to build your own homelab.

> **What is a homelab?**
>
> Homelab is a laboratory at home where you can self-host, experiment with new technologies, practice for certifications, and so on.
> For more information about homelab in general, see the [r/homelab introduction](https://www.reddit.com/r/homelab/wiki/introduction).

## Overview

Project status: **ALPHA**

This project is still in the experimental stage, and I don't use anything critical on it.
Expect breaking changes that may require a complete redeployment.
A proper upgrade path is planned for the stable release.
More information can be found in [the roadmap](#roadmap) below.

### Hardware

![Hardware](https://user-images.githubusercontent.com/27996771/98970963-25137200-2543-11eb-8f2d-f9a2d45756ef.JPG)

- 4 × NEC SFF `PC-MK26ECZDR` (Japanese version of the ThinkCentre M700):
    - CPU: `Intel Core i5-6600T @ 2.70GHz`
    - RAM: `16GB`
    - SSD: `128GB`
- TP-Link `TL-SG108` switch:
    - Ports: `8`
    - Speed: `1000Mbps`

### Features

- [x] Common applications: Gitea, Seafile, Jellyfin, Paperless...
- [x] Automated bare metal provisioning with PXE boot
- [x] Automated Kubernetes installation and management
- [x] Installing and managing applications using GitOps
- [x] Automatic rolling upgrade for OS and Kubernetes
- [x] Automatically update apps (with approval)
- [x] Modular architecture, easy to add or remove features/components
- [x] Automated certificate management
- [x] Automatically update DNS records for exposed services
- [x] VPN without port forwarding
- [x] Expose services to the internet securely with [Cloudflare Tunnel](https://www.cloudflare.com/products/tunnel/)
- [x] CI/CD platform
- [x] Private container registry
- [x] Distributed storage
- [x] Support multiple environments (dev, prod)
- [ ] Monitoring and alerting 🚧
- [ ] Automated offsite backups 🚧
- [ ] Single sign-on 🚧
- [x] Infrastructure testing

Some demo videos and screenshots are shown here.
They can't capture all the project's features, but they are sufficient to get a concept of it.

| Demo                                                                                        |
| :--:                                                                                        |
| [![][deploy-demo]](https://asciinema.org/a/xkBRkwC6e9RAzVuMDXH3nGHp7)                       |
| Deploy with a single command (after updating the configuration files)                       |
| [![][pxe-demo]](https://www.youtube.com/watch?v=y-d7btNNAT8)                                |
| PXE boot                                                                                    |
| [![][homepage-demo]][homepage-demo]                                                         |
| Homepage with Ingress discovery powered by [Hajimari](https://github.com/toboshii/hajimari) |
| [![][grafana-demo]][grafana-demo]                                                           |
| Monitoring dashboard powered by [Grafana](https://grafana.com/)                             |
| [![][gitea-demo]][gitea-demo]                                                               |
| Git server powered by [Gitea](https://gitea.io/en-us/)                                      |
| [![][matrix-demo]][matrix-demo]                                                             |
| [Matrix](https://matrix.org/) chat server                                                   |
| [![][tekton-demo]][tekton-demo]                                                             |
| Continuous integration with [Tekton](https://tekton.dev/)                                   |
| [![][argocd-demo]][argocd-demo]                                                             |
| Continuous deployment with [ArgoCD](https://argoproj.github.io/cd/)                         |
| [![][lens-demo]][lens-demo]                                                                 |
| Cluster management using [Lens](https://k8slens.dev/)                                       |
| [![][vault-demo]][vault-demo]                                                               |
| Secret management with [Vault](https://www.vaultproject.io/)                                |

[deploy-demo]: https://asciinema.org/a/xkBRkwC6e9RAzVuMDXH3nGHp7.svg
[pxe-demo]: https://user-images.githubusercontent.com/27996771/157303477-df2e7410-8f02-4648-a86c-71e6b7e89e35.png
[homepage-demo]: https://user-images.githubusercontent.com/27996771/149445807-0f869eb7-d8f5-4fef-ab97-ac281df91a06.png
[grafana-demo]: https://user-images.githubusercontent.com/27996771/149446631-1c5d056b-1fdc-48e6-96ba-e1abe1762be0.png
[gitea-demo]: https://user-images.githubusercontent.com/27996771/149444871-38889c9d-862f-41ff-8c05-8ece21da3e9c.png
[matrix-demo]: https://user-images.githubusercontent.com/27996771/149448510-7163310c-2049-4ccd-901d-f11f605bfc32.png
[tekton-demo]: https://user-images.githubusercontent.com/27996771/149445374-58fd0605-bb9a-46e4-81d6-5e584d2b94a9.png
[argocd-demo]: https://user-images.githubusercontent.com/27996771/149444716-fc0d7282-4cf7-4ddb-97a4-1a3fb47ff2b8.png
[lens-demo]: https://user-images.githubusercontent.com/27996771/149448896-9d79947d-468c-45c6-a81d-b43654e8ab6b.png
[vault-demo]: https://user-images.githubusercontent.com/27996771/149452309-de4a893b-e94c-4ba8-9119-ea87449cf77e.png

### Tech stack

<table>
    <tr>
        <th>Logo</th>
        <th>Name</th>
        <th>Description</th>
    </tr>
    <tr>
        <td><img width=""32"" src=""https://simpleicons.org/icons/ansible.svg""></td>
        <td><a href=""https://www.ansible.com"">Ansible</a></td>
        <td>Automate bare metal provisioning and configuration</td>
    </tr>
    <tr>
        <td><img width=""32"" src=""https://cncf-branding.netlify.app/img/projects/argo/icon/color/argo-icon-color.svg""></td>
        <td><a href=""https://argoproj.github.io/cd"">ArgoCD</a></td>
        <td>GitOps tool built to deploy applications to Kubernetes</td>
    </tr>
    <tr>
        <td><img width=""32"" src=""https://github.com/jetstack/cert-manager/raw/master/logo/logo.png""></td>
        <td><a href=""https://cert-manager.io"">cert-manager</a></td>
        <td>Cloud native certificate management</td>
    </tr>
    <tr>
        <td><img width=""32"" src=""https://avatars.githubusercontent.com/u/314135?s=200&v=4""></td>
        <td><a href=""https://www.cloudflare.com"">Cloudflare</a></td>
        <td>DNS and Tunnel</td>
    </tr>
    <tr>
        <td><img width=""32"" src=""https://www.docker.com/wp-content/uploads/2022/03/Moby-logo.png""></td>
        <td><a href=""https://www.docker.com"">Docker</a></td>
        <td>Ephemeral PXE server and convenient tools container</td>
    </tr>
    <tr>
        <td><img width=""32"" src=""https://github.com/kubernetes-sigs/external-dns/raw/master/docs/img/external-dns.png""></td>
        <td><a href=""https://github.com/kubernetes-sigs/external-dns"">ExternalDNS</a></td>
        <td>Synchronizes exposed Kubernetes Services and Ingresses with DNS providers</td>
    </tr>
    <tr>
        <td><img width=""32"" src=""https://upload.wikimedia.org/wikipedia/commons/thumb/3/3f/Fedora_logo.svg/267px-Fedora_logo.svg.png""></td>
        <td><a href=""https://getfedora.org/en/server"">Fedora Server</a></td>
        <td>Base OS for Kubernetes nodes</td>
    </tr>
    <tr>
        <td><img width=""32"" src=""https://upload.wikimedia.org/wikipedia/commons/b/bb/Gitea_Logo.svg""></td>
        <td><a href=""https://gitea.com"">Gitea</a></td>
        <td>Self-hosted Git service</td>
    </tr>
    <tr>
        <td><img width=""32"" src=""https://grafana.com/static/img/menu/grafana2.svg""></td>
        <td><a href=""https://grafana.com"">Grafana</a></td>
        <td>Operational dashboards</td>
    </tr>
    <tr>
        <td><img width=""32"" src=""https://cncf-branding.netlify.app/img/projects/helm/icon/color/helm-icon-color.svg""></td>
        <td><a href=""https://helm.sh"">Helm</a></td>
        <td>The package manager for Kubernetes</td>
    </tr>
    <tr>
        <td><img width=""32"" src=""https://cncf-branding.netlify.app/img/projects/k3s/icon/color/k3s-icon-color.svg""></td>
        <td><a href=""https://k3s.io"">K3s</a></td>
        <td>Lightweight distribution of Kubernetes</td>
    </tr>
    <tr>
        <td><img width=""32"" src=""https://cncf-branding.netlify.app/img/projects/kubernetes/icon/color/kubernetes-icon-color.svg""></td>
        <td><a href=""https://kubernetes.io"">Kubernetes</a></td>
        <td>Container-orchestration system, the backbone of this project</td>
    </tr>
    <tr>
        <td><img width=""32"" src=""https://github.com/grafana/loki/blob/main/docs/sources/logo.png?raw=true""></td>
        <td><a href=""https://grafana.com/oss/loki"">Loki</a></td>
        <td>Log aggregation system</td>
    </tr>
    <tr>
        <td><img width=""32"" src=""https://cncf-branding.netlify.app/img/projects/longhorn/icon/color/longhorn-icon-color.svg""></td>
        <td><a href=""https://longhorn.io"">Longhorn</a></td>
        <td>Cloud native distributed block storage for Kubernetes</td>
    </tr>
    <tr>
        <td><img width=""32"" src=""https://avatars.githubusercontent.com/u/60239468?s=200&v=4""></td>
        <td><a href=""https://metallb.org"">MetalLB</a></td>
        <td>Bare metal load-balancer for Kubernetes</td>
    </tr>
    <tr>
        <td><img width=""32"" src=""https://avatars.githubusercontent.com/u/1412239?s=200&v=4""></td>
        <td><a href=""https://www.nginx.com"">NGINX</a></td>
        <td>Kubernetes Ingress Controller</td>
    </tr>
    <tr>
        <td><img width=""32"" src=""https://cncf-branding.netlify.app/img/projects/prometheus/icon/color/prometheus-icon-color.svg""></td>
        <td><a href=""https://prometheus.io"">Prometheus</a></td>
        <td>Systems monitoring and alerting toolkit</td>
    </tr>
    <tr>
        <td><img width=""32"" src=""https://docs.renovatebot.com/assets/images/logo.png""></td>
        <td><a href=""https://www.whitesourcesoftware.com/free-developer-tools/renovate"">Renovate</a></td>
        <td>Automatically update dependencies</td>
    </tr>
    <tr>
        <td><img width=""32"" src=""https://avatars.githubusercontent.com/u/47602533?s=200&v=4""></td>
        <td><a href=""https://tekton.dev"">Tekton</a></td>
        <td>Cloud native solution for building CI/CD systems</td>
    </tr>
    <tr>
        <td><img width=""32"" src=""https://trow.io/trow.png""></td>
        <td><a href=""https://trow.io"">Trow</a></td>
        <td>Private container registry</td>
    </tr>
    <tr>
        <td><img width=""32"" src=""https://simpleicons.org/icons/vault.svg""></td>
        <td><a href=""https://www.vaultproject.io"">Vault</a></td>
        <td>Secrets and encryption management system</td>
    </tr>
    <tr>
        <td><img width=""32"" src=""https://docs.zerotier.com/img/ZeroTierIcon.png""></td>
        <td><a href=""https://zerotier.com"">ZeroTier</a></td>
        <td>VPN without port forwarding</td>
    </tr>
</table>

## Get Started

- [Try it out locally](https://homelab.khuedoan.com/installation/sandbox) without any hardware (just 4 commands!)
- [Deploy on real hardware](https://homelab.khuedoan.com/installation/production/prerequisites) for production workload

## Roadmap

See [roadmap](https://homelab.khuedoan.com/reference/roadmap) and [open issues](https://github.com/khuedoan/homelab/issues) for a list of proposed features and known issues.

## Contributing

Any contributions you make are greatly appreciated.

Please see [contributing guide](https://homelab.khuedoan.com/reference/contributing) for more information.

## License

Copyright &copy; 2020 - 2022 Khue Doan

Distributed under the GPLv3 License.
See [license page](https://homelab.khuedoan.com/reference/license) or `LICENSE.md` file for more information.

## Acknowledgements

References:

- [Ephemeral PXE server inspired by Minimal First Machine in the DC](https://speakerdeck.com/amcguign/minimal-first-machine-in-the-dc)
- [ArgoCD usage and monitoring configuration in locmai/humble](https://github.com/locmai/humble)
- [README template](https://github.com/othneildrew/Best-README-Template)
- [Run the same Cloudflare Tunnel across many `cloudflared` processes](https://developers.cloudflare.com/cloudflare-one/tutorials/many-cfd-one-tunnel)
- [MAC address environment variable in GRUB config](https://askubuntu.com/questions/1272400/how-do-i-automate-network-installation-of-many-ubuntu-18-04-systems-with-efi-and)
- [Official k3s systemd service file](https://github.com/k3s-io/k3s/blob/master/k3s.service)
- [Official Cloudflare Tunnel examples](https://github.com/cloudflare/argo-tunnel-examples)
- [Initialize GitOps repository on Gitea and integrate with Tekton by RedHat](https://github.com/redhat-scholars/tekton-tutorial/tree/master/triggers)
- [SSO configuration from xUnholy/k8s-gitops](https://github.com/xUnholy/k8s-gitops)
- [Pre-commit config from k8s-at-home/flux-cluster-template](https://github.com/k8s-at-home/flux-cluster-template)
- [Diátaxis technical documentation framework](https://diataxis.fr)
- [Official Terratest examples](https://github.com/gruntwork-io/terratest/tree/master/test)

Here is a list of the contributors who have helped to improve this project.
Big shout-out to them!

- ![](https://github.com/locmai.png?size=24) [@locmai](https://github.com/locmai)
- ![](https://github.com/MatthewJohn.png?size=24) [@MatthewJohn](https://github.com/MatthewJohn)
- ![](https://github.com/karpfediem.png?size=24) [@karpfediem](https://github.com/karpfediem)
- ![](https://github.com/linhng98.png?size=24) [@linhng98](https://github.com/linhng98)
- ![](https://github.com/BlueHatbRit.png?size=24) [@BlueHatbRit](https://github.com/BlueHatbRit)
- ![](https://github.com/dotdiego.png?size=24) [@dotdiego](https://github.com/dotdiego)
- ![](https://github.com/Crimrose.png?size=24) [@Crimrose](https://github.com/Crimrose)
- ![](https://github.com/eventi.png?size=24) [@eventi](https://github.com/eventi)
- ![](https://github.com/Bourne-ID.png?size=24) [@Bourne-ID](https://github.com/Bourne-ID)
- ![](https://github.com/akwan.png?size=24) [@akwan](https://github.com/akwan)
- ![](https://github.com/trangmaiq.png?size=24) [@trangmaiq](https://github.com/trangmaiq)

If you feel you're missing from this list, feel free to add yourself in a PR.

## Stargazers over time

[![Stargazers over time](https://starchart.cc/khuedoan/homelab.svg)](https://starchart.cc/khuedoan/homelab)
","Khue's Homelab is an open-source, self-hosted cloud computing platform. It can
be used as a highly customizable framework to build your own homelab. It uses
GitOps and Infrastructure as Code to automate provisioning, operating, and
updating self-Hosted services."
397,Awesome Frida - A curated list of Frida resources http://www.frida.re/ (https://github.com/frida/frida),"# Awesome Frida [![Awesome](https://cdn.rawgit.com/sindresorhus/awesome/d7305f38d29fed78fa85652e3a63e154dd8e8829/media/badge.svg)](https://github.com/sindresorhus/awesome)

A curated list of awesome projects, libraries, and tools powered by Frida.

## What is Frida?

Frida is [Greasemonkey](https://en.wikipedia.org/wiki/Greasemonkey) for native apps, or, put in more technical terms, it’s a dynamic code instrumentation toolkit. It lets you inject snippets of JavaScript into native apps that run on Windows, Mac, Linux, iOS and Android.

Frida is an open source software.

More info [here](http://www.frida.re/).

## Table of Contents

<!-- MarkdownTOC depth=4 -->
- [Libraries](#libraries)
- [Projects](#projects)
- [Talks & Papers](#talks-and-papers)
- [Powered by Frida](#frida-powered-by)
- [Videos](#videos)
- [Blog posts](#blogs)
- [Community](#community)

<!-- /MarkdownTOC -->

<a name=""libraries"" />

## Libraries
* [frida-android-hooks](https://github.com/antojoseph/frida-android-hooks) - Hook method calls in Android
* [FridaAndroidTracer](https://github.com/Piasy/FridaAndroidTracer) - A runnable jar that generate Javascript hook script to hook Android classes
* [frida-panic](https://github.com/nowsecure/frida-panic) - Easy crash-reporting for Frida-based applications
* [frida-compile](https://github.com/frida/frida-compile) - Compile a Frida script comprised of one or more Node.js modules
* [frida-trace](https://github.com/nowsecure/frida-trace) - Trace APIs declaratively
* [frida-screenshot](https://github.com/nowsecure/frida-screenshot) - Grab (iOS) screenshots
* [frida-uiwebview](https://github.com/nowsecure/frida-uiwebview) - Inspect and manipulate UIWebView-hosted GUIs
* [frida-uikit](https://github.com/nowsecure/frida-uikit) - Inspect and manipulate UIKit-based GUIs
* [frida-contrib](https://github.com/dweinstein/node-frida-contrib) - Frida utility-belt
* [frida-load](https://github.com/frida/frida-load) - Load a Frida script comprised of one or more Node.js modules (Deprecated, use [frida-compile](https://github.com/frida/frida-compile))
* [frida-remote-stream](https://github.com/nowsecure/frida-remote-stream) - Create an outbound stream over a message transport.
* [frida-memory-stream](https://github.com/nowsecure/frida-memory-stream) - Create a stream from one or more memory regions.
* [frida-fs](https://github.com/nowsecure/frida-fs) - Create a stream from a filesystem resource.
* [frida-push](https://github.com/AndroidTamer/frida-push) - Automatically `adb push` the correct frida-server matching your current frida installation.
* [frida-definitions-generator](https://git.sr.ht/~yotam/frida-definitions-generator) - Generate TypeScript definitions for a given APK file or unpacked apk directory.

<a name=""projects"" />

## Projects
- [as0ler/frida-scripts](https://github.com/as0ler/frida-scripts) - Repository including some useful frida script for iOS Reversing
- [0xdea/frida-scripts](https://github.com/0xdea/frida-scripts) - instrumentation scripts to facilitate reverse engineering of android and iOS Apps.
- [roxanagogonea/frida-scripts](https://gitlab.com/roxanagogonea/frida-scripts) - Repository including some useful frida scripts for Android
- [iddoeldor/frida-snippets](https://github.com/iddoeldor/frida-snippets) - another useful frida snippets repository
- [IDA Pro plugin](https://github.com/techbliss/Frida_For_Ida_Pro) - IDA Pro plugin
- [poxyran/misc](https://github.com/poxyran/misc) - Misc Frida scripts [read-process-memory.py](https://github.com/poxyran/misc/blob/master/frida-read-process-memory.py), [write-process-memory.py](https://github.com/poxyran/misc/blob/master/frida-write-process-memory.py), [frida-heap-trace](https://github.com/poxyran/misc/blob/master/frida-heap-trace.py),
- [frida-cycript](https://github.com/nowsecure/frida-cycript) - Fork of cycript with new runtime called [Mjølner](https://github.com/nowsecure/mjolner) powered by Frida.
- [r2frida](https://github.com/nowsecure/r2frida) - static and dynamic analysis synergy
- [ios-inject-custom](https://github.com/oleavr/ios-inject-custom) - use Frida for standalone injection of a custom payload for iOS.
- [davuxcom/frida-scripts](https://github.com/davuxcom/frida-scripts) - Repository including scripts for COM, .NET and WinRT for Windows
- [XposedFridaBridge](https://github.com/monkeylord/XposedFridaBridge) - A frida script implement XposedBridge & load xposed modules, without installing xposed framwork.
- [Arida](https://github.com/lateautumn4lin/arida) - A Frida-RPC tool based on FastAPI, Help users quickly realize interface exposure.
- [easy-frida](https://github.com/tacesrever/easy-frida) - A tool for easily develop frida agent script/module when reversing, including some useful frida scripts.

<a name=""talks-and-papers"" />

## Talks & Papers
* [OSDC 2015](http://act.osdc.no/osdc2015no/):
  [Putting the open back into closed software](http://act.osdc.no/osdc2015no/talk/6165)
  ([PDF](osdc-2015-putting-the-open-back-into-closed-software.pdf) · [Recording](https://youtu.be/tmpjftTHzH8))
* [OSDC 2015](http://act.osdc.no/osdc2015no/):
  [The engineering behind the reverse engineering](http://act.osdc.no/osdc2015no/talk/6195)
  ([PDF](osdc-2015-the-engineering-behind-the-reverse-engineering.pdf) · [Recording](https://youtu.be/uc1mbN9EJKQ))
* [NLUUG 2015](https://www.nluug.nl/activiteiten/events/nj15/index.html):
  [Frida: Putting the open back into closed software](https://www.nluug.nl/activiteiten/events/nj15/abstracts/ab08.html)
  ([Slides](http://slides.com/oleavr/nluug-2015-frida-putting-the-open-back-into-closed-software)
  · [Demos](https://github.com/frida/frida-presentations/tree/master/NLUUG2015)
  · [Recording](https://youtu.be/3lo1Y2oKkE4))
* [ZeroNights 2015](http://2015.zeronights.org/):
  [Cross-platform reversing with Frida](http://2015.zeronights.org/workshops.html)
  ([PDF](zeronights-2015-cross-platform-reversing-with-frida.pdf)
  · [Demos](https://github.com/frida/frida-presentations/tree/master/ZeroNights2015))
* [r2con 2016 - r2frida](http://rada.re/con/) ([PDF](https://github.com/radareorg/r2con/raw/master/2016/talks/08-r2frida/r2frida.pdf) · [Recording](https://www.youtube.com/watch?v=ivCucqeVeZI))
* [RMLL 2017](https://2017.rmll.info/) Unlocking secrets of proprietary software (@oleavr) ([slides](https://slides.com/oleavr/frida-rmll-2017#/) · [Recording](https://rmll.ubicast.tv/videos/frida_03038/))

<a name=""frida-powered-by"" />

## Powered by Frida
* [Aurora](https://github.com/frida/aurora) - Web app built on top of Frida
* [CloudSpy](https://github.com/frida/cloudspy) - Web app built on top of Frida
* [CryptoShark](https://github.com/frida/cryptoshark) - Self-optimizing cross-platform code tracer based on dynamic recompilation
* [diff-gui](https://github.com/antojoseph/diff-gui) - Web GUI for instrumenting Android
* ~~[Lobotomy](https://github.com/LifeForm-Labs/lobotomy)~~[Lobotomy Fork](https://github.com/AndroidSecurityTools/lobotomy) - Android Reverse Engineering Framework & Toolkit
* [Appmon](https://github.com/dpnishant/appmon) - Runtime Security Testing Framework for iOS, Mac OS X and Android Apps
* [Fridump](https://github.com/Nightbringer21/fridump) - A universal memory dumper using Frida
* [frida-extract](https://github.com/OALabs/frida-extract) - Automatically extract and reconstruct a PE file that has been injected using the RunPE method
* [r2frida](https://github.com/nowsecure/r2frida) [memory search](https://www.nowsecure.com/blog/2017/03/14/spearing-data-mobile-memory-building-better-r2frida-memory-search/)
* [r2frida-wiki](https://github.com/enovella/r2frida-wiki) - Unofficial wiki that provides practical examples on how to use r2frida
* [friTap](https://github.com/fkie-cad/friTap) - Decrypts and logs a process's SSL/TLS traffic on all major platforms. Beside this it intercepts the generation of encryption keys used by SSL/TLS and logs them as a SSLKEYLOGFILE.
* [google/ssl_logger](https://github.com/google/ssl_logger) - Decrypts and logs a process's SSL traffic.
* [google/tcp_killer](https://github.com/google/tcp_killer) - Shuts down a TCP connection based using output from a `netstat` cmd.
* [brida](https://github.com/federicodotta/Brida) - Bridge between Burp Suite and Frida
* [objection](https://github.com/sensepost/objection) - Runtime Mobile Exploration for iOS and Android
* [passionfruit](https://github.com/chaitin/passionfruit) - iOS App Analyzer with Web UI
* [House](https://github.com/nccgroup/house) - A runtime mobile application analysis toolkit with a Web GUI, powered by Frida
* [Dwarf](https://github.com/igio90/Dwarf) - A debugger built on top of PyQt5 and frida
* [Dexcalibur](https://github.com/FrenchYeti/dexcalibur) - A dynamic binary instrumentation tool designed for Android apps and powered by Frida
* [bagbak](https://github.com/ChiChou/bagbak) - Decrypt apps from AppStore on jailbroken devices. Supports decrypting app extensions.
* [Runtime Mobile Security (RMS)](https://github.com/m0bilesecurity/RMS-Runtime-Mobile-Security) - A powerful web interface that helps you to manipulate Android and iOS Apps at Runtime
* [CatFrida](https://github.com/neil-wu/CatFrida) - A macOS app for inspecting a running iOS app. Building with frida-swift, CatFrida provide an awesome easy way to dive into an app.
* [PAPIMonitor](https://github.com/Dado1513/PAPIMonitor) - **P**ython **API** **Monitor** for Android apps is a tool, powered by Frida, to monitor user-selected APIs during app execution.

<a name=""videos"" />

## Videos
* [Frida vs Spotify](https://www.youtube.com/watch?v=dvOdwHpQycw) - Spotify RE
* [CryptoShark](https://www.youtube.com/watch?v=hzDsxtcRavY) - a self-optimizing cross-platform code tracer based on dynamic recompilation, powered by Frida and Capstone
* [Frida Memory Hacking - Angry Birds](https://www.youtube.com/watch?v=nk3rUn2ip0g) - Frida having fun with Angry Birds running on an iPhone
* [Frida Memory Hacking - Windows Live Messenger](https://www.youtube.com/watch?v=0Blc0T-Z-ys) - Frida having fun with Windows Live Messenger
* [Frida Intro @ NowSecure](https://www.youtube.com/watch?v=4Ag-2LZQM8g) - Frida introduction by Ole
* ~~[Lobotomy - Frida Demo](https://asciinema.org/a/24269) - This demo is leveraging the Frida toolkit to instrument a target app's Activity calls.~~
* [Install SSL CA to device via ManagedConfiguration tracing](https://www.youtube.com/watch?v=qfOm5b9MZtk)

<a name=""blogs"" />

## Blog posts
* [Build a debugger in 5 minutes](https://medium.com/@oleavr/build-a-debugger-in-5-minutes-1-5-51dce98c3544#.mn48pvhok)
* [Reverse Engineering with Javascript](https://www.nowsecure.com/blog/2015/08/06/reverse-engineering-with-javascript/)
* [iOS 9 Reverse Engineering with Javascript](https://www.nowsecure.com/blog/2015/11/16/ios-9-reverse-engineering-with-javascript/)
* [iOS Instrumentation without Jailbreak](https://www.nowsecure.com/blog/2015/11/23/ios-instrumentation-without-jailbreak/)
* [Introduction to Fridump](http://pentestcorner.com/introduction-to-fridump/) - Fridump is an open source memory dumper tool
* [Hacking Android apps with Frida part1](https://www.codemetrix.net/hacking-android-apps-with-frida-1/), [part2/crackme](https://www.codemetrix.net/hacking-android-apps-with-frida-2/), [part3](https://www.codemetrix.net/hacking-android-apps-with-frida-3/)
* [OWASP iOS crackme tutorial: Solved with Frida](https://www.nowsecure.com/blog/2017/04/27/owasp-ios-crackme-tutorial-frida/)
* Detecting Frida [poxyran](https://crackinglandia.wordpress.com/2015/11/10/anti-instrumentation-techniques-i-know-youre-there-frida/), [Bernhard Mueller](http://www.vantagepoint.sg/blog/90-the-jiu-jitsu-of-detecting-frida)
* [Maddie Stone, Google project Zero - Blackhat 2020 - Reversing the Root. Identifying the Exploited Vulnerability in 0-days Used In-The-Wild](https://i.blackhat.com/USA-20/Wednesday/us-20-Stone-Reversing-The-Root-Identifying-The-Exploited-Vulnerability-In-0-Days-Used-In-The-Wild.pdf)
* [Natalie Silvanovich, Google Project Zero - January 2022 - Zooming in on Zero-click Exploits](https://googleprojectzero.blogspot.com/2022/01/zooming-in-on-zero-click-exploits.html)
* [BlackBerry - April 2021 - Malware analysis with dynamic binary instrumentation frameworks](https://blogs.blackberry.com/en/2021/04/malware-analysis-with-dynamic-binary-instrumentation-frameworks)


<a name=""community"" />

## Community
* [Stack Overflow](http://stackoverflow.com/questions/tagged/frida)
* [@fridaotre on Twitter](https://twitter.com/fridadotre)
* [@oleavr on Twitter](https://twitter.com/oleavr)
* [Reddit](https://www.reddit.com/r/frida)
* [Frida CodeShare](https://codeshare.frida.re/) - Share frida snippets and recipes with others.


<a name=""contributions"" />

## Contributions
Your contributions are always welcome!

If you want to contribute to this list (please do), send me a pull request or contact me [@insitusec](https://twitter.com/insitusec)

Also, if you notice that a listing should be deprecated or replaced:

* Repository's owner explicitly say that ""this library is not maintained"".
* Not committed for long time (2~3 years).

More info on the [guidelines](https://github.com/dweinstein/awesome-frida/blob/master/CONTRIBUTING.md)


<a name=""credits"" />

## Credits

* This awesome list was originally based on [Awesome TensorFlow](https://github.com/jtoy/awesome-tensorflow)
","A curated list of awesome projects, libraries, and tools powered by Frida. What
is Frida? It’s a dynamic code instrumentation toolkit. It lets you inject
snippets of JavaScript into native apps that run on Windows, Mac, Linux, iOS and
Android."
2700,Open source tutorial & information collector for hackintosh installation.,"


# Hackintosh-Installer-University
[![License](https://img.shields.io/badge/license-CC%204.0-blue.svg)](https://creativecommons.org/licenses/by/4.0/)
![progress](https://img.shields.io/badge/progress-developing-yellow.svg)
[![contributions](https://img.shields.io/badge/contributions-welcome-green.svg)](https://github.com/huangyz0918/Hackintosh-Installer-University) 


:loudspeaker: This is an open source tutorial & information collector for Hackintosh installations that does not charge readers any fee. 

:loudspeaker: We don't want to build a universal installation tutorial and, it's also impossible since every device is different. We are here because we want to gather information and experiences, we want to build an index for most successful builds in GitHub and make them be discovered more easily. When I was just a newbie, I didn't know how to get started building a Hackintosh since I didn't know what's a bootloader and an EFI partition. It took me a long time to find a helpful build in Github due to the deep location of that repo. So this is the purpose why we created this index.

:loudspeaker: As we know, Hackintosh is potentially illegal because doing this violates the end-user license agreement [(EULA)](http://images.apple.com/legal/sla/docs/macosx107.pdf) from Apple for macOS. Therefore, we just focus on the technologies related to Hackintosh and do not use it commercially. If you want to get started, please first read this license in detail and remember that you are a geek, not a criminal.

Here are some other language versions:
- [中文版本](README-CN.md)


## What's Hackintosh ?

When Apple announced their switch away from the PowerPC architecture to Intel's processors and chipsets, many were looking forward to having the ability to run Windows software on Apple hardware and Apple's operating systems on their non-Apple hardware. Apple was able to eventually build their Boot Camp feature in Mac OS X 10.5, later allowing Windows to run on Apple hardware. Those hoping to easily run Mac OS X on a standard PC didn't have it so easy.

Even though running Mac OS X on a generic PC is not supported by Apple, it is possible to accomplish given the right hardware and determination by users. Any system that is not made to run the Apple operating system is referred to as Hackintosh. This term comes from the fact that the software needs to be hacked to properly run on Non-Apple hardware. Of course, some of the hardware needs to be tweaked in a few cases as well.

## How to learn Hackintosh ?

:bell:There's a lot to learn if you want to figure out the secrets behind Hackintosh, please go this door ---> [:door:](slow/slow.md)

:bell:If you have no interest in those theories, and just want a quick installation, please go through this door ---> [:door:](quick/quick.md)

### Famous websites for hackintosh and macOS
- [Wikipedia](https://en.wikipedia.org/wiki/Hackintosh)
- [OSx86 Project](https://www.osx86project.org/)
- [Tonymacx86](https://www.tonymacx86.com/)
- [hackintosh.com](https://hackintosh.com/)
- [9to5mac](https://9to5mac.com/)
- [Rehabman Github](https://github.com/RehabMan)
- [Rehabman Bitbucket](https://bitbucket.org/RehabMan/)
- [PCbeta](http://mac.pcbeta.com/)
- [iMacHK](https://imac.hk/)

### Devices available in Res

- [Lenove B50-70](https://github.com/huangyz0918/Hackintosh-Installer-University/tree/master/Res/%20Lenove-B50-intelHD4600-success)
- [Asus-P8Z77-V-LX-10.12.6](https://github.com/huangyz0918/Hackintosh-Installer-University/tree/master/Res/Asus-P8Z77-V-LX-10.12.6)
- [Gigabyte Z270XP-SLI](https://github.com/huangyz0918/Hackintosh-Installer-University/tree/master/Res/Gigabyte-GA-Z270XP-SLI-10.13.4)

### Devices avaliable in Github

- [Acer Aspire E1-471G](https://github.com/matthew728960/Clover-ACER-E1-471G)
- [Acer A515-51G](https://github.com/SiddheshNan/Acer-A515-51G-Hackintosh)
- [Acer V5-573G](https://github.com/Kaijun/Acer-V5-573G-Hackintosh)
- [Acer Aspire E5-571-376T](https://github.com/GalaticStryder/Acer-E5-571-Hackintosh)
- [Acer Aspire V3-371-52FF](https://github.com/Ty3uK/52ff-elcapitan-toolbox)
- [Acer Aspire E5-473-30N5](https://github.com/b-ggs/aspire-e5-hackintosh)
- [Acer Aspire V3-572G](https://github.com/FREDwiz/Hackintosh)
- [Alienware 17 R4 KBL-1060 Dual Graphics](https://github.com/RockJesus/Alienware-17-R4-I7-7700HQ-MacOS-High-Sierra)
- [Asus FX50J/X550JX](https://github.com/Xc2333/Hackintosh-ASUS-FX50J)
- [Asus H81M-K](https://github.com/Slbomber/AsusH81MK-macos)
- [Asus Zenbook](https://github.com/hieplpvip/ASUS-ZENBOOK-HACKINTOSH)
- [Asus Vivobook S510UA](https://github.com/tctien342/Asus-Vivobook-S510UA-High-Sierra-10.13-Hackintosh)
- [Asus ROG Zephyrus S GX531](https://github.com/williambj1/Hackintosh-EFI-Asus-Zephyrus-S-GX531)
- [Dell 7559 4K SKL](https://github.com/RockJesus/Dell-7559-I7-6700HQ-4K-touch-MacOS-High-Sierra)
- [Dell G7 7588 OpenCore](https://github.com/Juan-VC/Hackintosh-macOS-Dell-G7-7588)
- [Dell XPS13-9350-Skylake](https://github.com/syscl/XPS9350-macOS)
- [Dell XPS15-9550](https://github.com/corenel/XPS9550-macOS)
- [Dell XPS15-9550](https://github.com/PromiseYo/XPS15-9550-macOS)
- [Dell XPS13-9360](https://github.com/the-darkvoid/XPS9360-macOS)
- [Dell XPS15-9530-Haswell](https://github.com/the-darkvoid/XPS9530-OSX)
- [Gigabyte GA-Z77-DS3H](https://github.com/tkrotoff/Gigabyte-GA-Z77-DS3H-rev1.1-Hackintosh)
- [Gigabyte GA-H97-D3H](https://github.com/korzhyk/Clover_GA-H97-D3H)
- [Gigabyte GA-Z270M-D3H](https://github.com/LER0ever/Hackintosh)
- [Gigabyte X99P-SLI](https://github.com/koush/EFI-X99)
- [Gigabyte Aero15-W](https://github.com/Errrneist/Hackintosh-Aero-15W)
- [Gigabyte z170x ud3 ultra](https://github.com/RoJoHub/Hackintosh)
- [Gigabyte Sabre15K](https://github.com/gnehs/Sabre15KClover)
- [Lenovo chao 5000](https://github.com/Xc2333/Hackintosh-Lenovo-chao5000)
- [Lenovo G50-70M](https://github.com/LEXUGE/macOS-Lenovo_G50-70M)
- [Lenovo G50-80](https://github.com/upupming/Lenovo-G50-80-Clover)
- [Lenovo Thinkpad P50](https://github.com/Errrneist/Hackintosh-Thinkpad-P50)
- [Lenove Thinkpad T450](https://github.com/shmilee/T450-Hackintosh)
- [Lenovo Thinkpad T460P](https://github.com/LER0ever/Hackintosh)
- [Lenovo T430s](https://github.com/dmitriypavlov/T430s-macOS)
- [Lenovo T430-NVS5400M](https://github.com/david-cako/T430-Hackintosh)
- [Lenovo T450s](https://github.com/stevenmirabito/T450s-Hackintosh)
- [Lenovo U330/U430/U530](https://github.com/RehabMan/Lenovo-U430-Touch-DSDT-Patch)
- [Lenovo Y470](https://github.com/Dwarven/Hackintosh/tree/master/Lenovo%20Y470)
- [Lenovo Y50-70](https://github.com/RehabMan/Lenovo-Y50-DSDT-Patch)
- [Lenovo Z50-70](https://github.com/Maxvien/hackintosh-lenovo-z5070)
- [Lenovo B470](https://github.com/0xE8551CCB/hackintosh)
- [Lenovo G470](https://github.com/hunterMG/DSDT-Lenovo-G470)
- [Lenovo T470 (i5-6300U)](https://github.com/okay/t470)
- [Lenovo x230 ](https://github.com/edu-rinaldi/Lenovo-x230-High-Sierra)
- [Lenovo Yoga 710](https://github.com/xiaoxx970/Hackintosh-Mojave-for-Lenovo-Yoga710)
- [Lenovo Yoga 3 Pro](https://github.com/zohaad/hackintosh-Yoga-3-Pro)
- [Lenovo-v3000-ISE](https://github.com/Xc2333/Hackintosh-Lenovo-v3000-ISE)
- [Lenovo-rescuer-15-isk](https://github.com/oneplusdash/lenovo-rescuer-15-isk-hackintosh)
- [Lenovo Ideapad 310-14IKB](https://github.com/29satnam/LenovoHackintoshEFI)
- [Lenovo-XiaoXin700-15ISK](https://github.com/athlonreg/Lenovo-XiaoXin700-15ISK)
- [HUANAN X79](https://github.com/cheneyveron/clover-x79-e5-2670-gtx650)
- [HP ProBook/EliteBook/ZBook](https://github.com/RehabMan/HP-ProBook-4x30s-DSDT-Patch)
- [HP Elitebook 8470p](https://github.com/minhphuc429/hackintosh-hp-elitebook-8470p)
- [HP Elitebook 8470p](https://github.com/dreadkopp/8470p_10.13.x)
- [HP Elitebook 840 G1/G2](https://github.com/loicpirez/HackintoshConfig)
- [HP Elitebook Folio 9480m](https://github.com/obviouslyerratic/clover_9480m)
- [HP EliteDesk 800 G2 TWR](https://github.com/sakoula/HP-EliteDesk-800-G2-6700)
- [HP Envy J-series](https://github.com/RehabMan/HP-Envy-DSDT-Patch)
- [HP Envy K-series](https://github.com/RehabMan/HP-Envy-K-DSDT-Patch)
- [HP Envy Q-series](https://github.com/RehabMan/HP-Envy-Q-DSDT-Patch)
- [HP Envy N-series](https://github.com/RehabMan/HP-Envy-N-DSDT-Patch)
- [HP Z420 Workstation](https://github.com/NTT123/Hackintosh-HP-Z420-MacOS-High-Sierra-10.13)
- [Samsung 450r5j](https://github.com/LER0ever/Hackintosh)
- [Samsung nt550p7c-IVY](https://github.com/RockJesus/samsung-nt550p7c-sierra)
- [Samsung NT900X3L-K501S](https://github.com/justiceserv/NT900X3L-Hackintosh)
- [XiaoMi NoteBook Pro](https://github.com/daliansky/XiaoMi-Pro)
- [Xiaomi Mi Air 13.3 Skylake-U 2016 (1rst Gen)](https://github.com/sakoula/XiaoMi-Air-6200U)


## * CLOVER Collections
We have collected some **CLOVER EFI configurations**, you can checkout in our repo:

- [Asus](https://github.com/huangyz0918/Hackintosh-Installer-University/tree/master/Clover-Configs/Asus)
- [Acer](https://github.com/huangyz0918/Hackintosh-Installer-University/tree/master/Clover-Configs/Acer)
- [Lenovo](https://github.com/huangyz0918/Hackintosh-Installer-University/tree/master/Clover-Configs/Lenovo)
- [Dell](https://github.com/huangyz0918/Hackintosh-Installer-University/tree/master/Clover-Configs/Dell)
- [Xiao Mi](https://github.com/huangyz0918/Hackintosh-Installer-University/tree/master/Clover-Configs/XiaoMi)
- [LG](https://github.com/huangyz0918/Hackintosh-Installer-University/tree/master/Clover-Configs/LG)

If you have a laptop, there are many good guides for laptops on Tonymacx86. Search your laptop and you may find a guide for it or similar one.

## How to contribute to this repository?

You need to `fork` this repository, just click the `fork` button at the top of this page.
After a fork, you can use git to clone this repository to your local device and make changes in your branches. We encourage you to  contribute to this repo by submitting a pull request.

### **Contribute to tutorials**
The core part of this repo are tutorials, we distribute all of them into these parts:

- **Buyer's guide**

    In this part, you can get a quick idea of Hackintosh and get to know what hardware is suitable for installing Mackintosh on PC hardware. You can learn a lot about computer hardware like CPU, Hard Drives and graphics cards in this chapter. We keep these in the standalone folder `Hardwares`.

- **Bootloader Installation Guide**

    In this part, we will focus on the bootloaders of Hackintosh, you can gain knowledge about how a computer(PC) boots and how a operation system launches. We also cover information about the Clover Bootloader and Chameleon Bootloader here. We keep these in the `Bootloader` folder.

- **System Installation Guide**
  
    This is a introduction about macOS system installation. We keep these articles in the  `System` floder.

- **Post Installation Guide**

    This part is intended for post installation. Here, you can learn about basic drivers and kexts of your system and macOS. If you want to contribute to this part, please put your articles into `Post` folder.

- **Troubleshooting**

    We have a specific part for addressing issues, if you have any questions you can open an issue and ask for help from others. Also, if you want to share your experience about fixing some issues during hackintosh installation, you can contribute to this part. Don't forget to attach your hardware information and put your experience into `troubleshooting` workspace.

We will improve the workspace tree day by day, so don't forget to give us your precious suggestions !

### **Contribute to resource**
We encourage you to upload your hackintosh configs and kexts if you don't mind. This repo has a workspace named `Res` and you can make your own workspace there, and share your successful configs and kexts with others if you want. It's a good place to make a backup and share. Be sure to follow thses rules:

- Build your device folder under `Res` folder, named your device like this: `Computer brand-model-macOS  version`
- Put your device information into a markdown file: `info.md`.
- Put your configs in the root of workspace and create a `kexts` folder to hold all your kexts.
- For `kexts` folder, you can create different subfolders for different kinds of kexts, such as `Wifi`, `Graphics Cards` and so on.
- Please give links rather than uploading many large files.
- If you are a lazy person who get tired with creating so many folders, it's good for you to put the whole `EFI` along with your system kexts & information in your workspace.

A good example may look like this:

```bash

Res/
└── Lenove-B50-10.12.6
    ├── config.plist
    ├── info.md
    └── kexts/

```
A good `info.md` file looks like:

```markdown
- Device name: GA-Z170-Gaming 7
- CPU: i7-6700K
- Graphics: Nvidia GeForce GT 640
- Graphics: Intel HD4600

```

We are all looking forward to your resources! :+1:

## License
[Attribution 4.0 International (CC BY 4.0)](https://creativecommons.org/licenses/by/4.0/)

<img width=""120"" src=""https://i.loli.net/2018/05/15/5afaddc9aa3f5.png""/><img width=""120"" src=""https://i.loli.net/2018/05/15/5afaddc9a9789.png""/>


","Hackintosh is a system that is not made to run the Apple operating system. This
term comes from the fact that the software needs to be hacked to properly run on
Non-Apple hardware. Running Mac OS X on a generic PC is not supported by Apple,
it is possible to accomplish given the right hardware and determination."
32,Vim plugin that provides additional text objects,"## Introduction

**Targets.vim** is a Vim plugin that adds various [text objects][textobjects]
to give you more targets to [operate][operator] on.  It expands on the idea of
simple commands like `di'` (delete inside the single quotes around the cursor)
to give you more opportunities to craft powerful commands that can be
[repeated][repeat] reliably. One major goal is to handle all corner cases
correctly.

## Table of Contents

<details>
<summary>Click here to show.</summary>

<!-- BEGIN-MARKDOWN-TOC -->

* [Installation](#installation)
* [Examples](#examples)
* [Overview](#overview)
	* [Pair Text Objects](#pair-text-objects)
		* [In Pair](#in-pair)
		* [A Pair](#a-pair)
		* [Inside Pair](#inside-pair)
		* [Around Pair](#around-pair)
		* [Next and Last Pair](#next-and-last-pair)
		* [Pair Seek](#pair-seek)
	* [Quote Text Objects](#quote-text-objects)
		* [In Quote](#in-quote)
		* [A Quote](#a-quote)
		* [Inside Quote](#inside-quote)
		* [Around Quote](#around-quote)
		* [Next and Last Quote](#next-and-last-quote)
		* [Quote Seek](#quote-seek)
	* [Separator Text Objects](#separator-text-objects)
		* [In Separator](#in-separator)
		* [A Separator](#a-separator)
		* [Inside Separator](#inside-separator)
		* [Around Separator](#around-separator)
		* [Next and Last Separator](#next-and-last-separator)
		* [Separator Seek](#separator-seek)
	* [Argument Text Objects](#argument-text-objects)
		* [In Argument](#in-argument)
		* [An Argument](#an-argument)
		* [Inside Argument](#inside-argument)
		* [Around Argument](#around-argument)
		* [Next and Last Argument](#next-and-last-argument)
		* [Argument Seek](#argument-seek)
	* [Multi Text Objects](#multi-text-objects)
		* [Any Block](#any-block)
		* [Any Quote](#any-quote)
* [Settings](#settings)
	* [g:targets_aiAI](#gtargets_aiai)
	* [g:targets_mapped_aiAI](#gtargets_mapped_aiai)
	* [g:targets_nl](#gtargets_nl)
	* [g:targets_seekRanges](#gtargets_seekranges)
	* [g:targets_jumpRanges](#gtargets_jumpranges)
	* [g:targets_gracious](#gtargets_gracious)
	* [targets#mappings#extend](#targets#mappings#extend)
* [Notes](#notes)
* [Issues](#issues)
* [Todos](#todos)

</details>

<!-- END-MARKDOWN-TOC -->

## Installation

| Plugin Manager         | Command                                                                       |
|------------------------|-------------------------------------------------------------------------------|
| [NeoBundle][neobundle] | `NeoBundle 'wellle/targets.vim'`                                              |
| [Vundle][vundle]       | `Bundle 'wellle/targets.vim'`                                                 |
| [Vim-plug][vim-plug]   | `Plug 'wellle/targets.vim'`                                                   |
| [Pathogen][pathogen]   | `git clone git://github.com/wellle/targets.vim.git ~/.vim/bundle/targets.vim` |
| [Dein][dein]		     | `call dein#add('wellle/targets.vim')`					                     |

## Examples

The following examples are displayed as three lines each. The top line denotes
cursor positions from where the presented command works. The middle line shows
the contents of the example line that we're working on. The last line shows the
part of the line that the command will operate on.

To change the text in the next pair of parentheses, use the `cin)` command

```
cursor position │    .....................
buffer line     │    This is example text (with a pair of parentheses).
selection       │                          └───────── cin) ─────────┘
```

To delete the item in a comma separated list under the cursor, use `da,`

```
cursor position │                                  .........
buffer line     │    Shopping list: oranges, apples, bananas, tomatoes
selection       │                                  └─ da, ─┘
```

Notice how the selection includes exactly one of the surrounding commas to
leave a proper comma separated list behind.

## Overview

Targets.vim comes with five kinds for text objects:

- Pair text objects
- Quote text objects
- Separator text objects
- Argument text objects
- Tag text objects

Each of those kinds is implemented by a targets source. Third party plugins can
provide additional sources to add even more text objects which behave like the
built in ones. See [plugins][Plugins] for details on how to implement your own
targets source.

### Pair Text Objects

These text objects are similar to the built in text objects such as `i)`.
Supported trigger characters:

- `(` `)` (work on parentheses)
- `{` `}` `B` (work on curly braces)
- `[` `]` (work on square brackets)
- `<` `>` (work on angle brackets)
- `t` (work on tags)

Pair text objects work over multiple lines and support seeking. See below for
details about seeking.

The following examples will use parentheses, but they all work for each listed
trigger character accordingly.

#### In Pair

`i( i) i{ i} iB i[ i] i< i> it`

- Select inside of pair characters.
- This overrides Vim's default text object to allow seeking for the next pair
  in the current line to the right or left when the cursor is not inside a
  pair. This behavior is similar to Vim's seeking behavior of `di'` when not
  inside of quotes, but it works both ways.
- Accepts a count to select multiple blocks.

```
      ............
a ( b ( cccccccc ) d ) e
   │   └── i) ──┘   │
   └───── 2i) ──────┘
```

#### A Pair

`a( a) a{ a} aB a[ a] a< a> at`

- Select a pair including pair characters.
- Overrides Vim's default text object to allow seeking.
- Accepts a count.

```
      ............
a ( b ( cccccccc ) d ) e
  │   └─── a) ───┘   │
  └────── 2a) ───────┘
```

#### Inside Pair

`I( I) I{ I} IB I[ I] I< I> It`

- Select contents of pair characters.
- Like inside of parentheses, but exclude whitespace at both ends. Useful for
  changing contents while preserving spacing.
- Accepts a count.

```
      ............
a ( b ( cccccccc ) d ) e
    │   └─ I) ─┘   │
    └──── 2I) ─────┘
```

#### Around Pair

`A( A) A{ A} AB A[ A] A< A> At`

- Select around pair characters.
- Like a pair, but include whitespace at one side of the pair. Prefers to
  select trailing whitespace, falls back to select leading whitespace.
- Accepts a count.

```
      ............
a ( b ( cccccccc ) d ) e
  │   └─── A) ────┘   │
  └────── 2A) ────────┘
```

#### Next and Last Pair

`in( an( In( An( il( al( Il( Al( ...`

Work directly on distant pairs without moving there separately.

All the above pair text objects can be shifted to the next pair by
including the letter `n`. The command `in)` selects inside of the next
pair. Use the letter `l` instead to work on the previous (last) pair. Uses
a count to skip multiple pairs. Skipping works over multiple lines.

See our [Cheat Sheet][cheatsheet] for two charts summarizing all pair mappings.

#### Pair Seek

If any of the normal pair commands (not containing `n` or `l`) is executed when
the cursor is not positioned inside a pair, it seeks for pairs before or after
the cursor by searching for the appropriate delimiter on the current line. This
is similar to using the explicit version containing `n` or `l`, but in only
seeks on the current line.

### Quote Text Objects

These text objects are similar to the built in text objects such as `i'`.
Supported trigger characters:

- `'`     (work on single quotes)
- `""`     (work on double quotes)
- `` ` `` (work on back ticks)

These quote text objects try to be smarter than the default ones. They count
the quotation marks from the beginning of the line to decide which of these are
the beginning of a quote and which ones are the end.

If you type `ci""` on the `,` in the example below, it will automatically skip
and change `world` instead of changing `,` between `hello` and `world`.

```
buffer │ join(""hello"", ""world"")
proper │      └─────┘  └─────┘
false  │            └──┘
```

Quote text objects work over multiple lines and support seeking. See below for
details about seeking.

The following examples will use single quotes, but they all work for each
mentioned separator character accordingly.

#### In Quote

`` i' i"" i` ``

- Select inside quote.
- This overrides Vim's default text object to allow seeking in both directions.

```
  ............
a ' bbbbbbbb ' c ' d ' e
   └── i' ──┘
```

#### A Quote

``a' a"" a` ``

- Select a quote.
- This overrides Vim's default text object to support seeking.
- Unlike Vim's quote text objects, this incudes no surrounding whitespace.

```
  ............
a ' bbbbbbbb ' c ' d ' e
  └─── a' ───┘
```

#### Inside Quote

``I' I"" I` ``

- Select contents of a quote.
- Like inside quote, but exclude whitespace at both ends. Useful for changing
  contents while preserving spacing.

```
  ............
a ' bbbbbbbb ' c ' d ' e
    └─ I' ─┘
```

#### Around Quote

``A' A"" A` ``

- Select around a quote.
- Like a quote, but include whitespace in one direction. Prefers to select
  trailing whitespace, falls back to select leading whitespace.

```
  ............
a ' bbbbbbbb ' c ' d ' e
  └─── A' ────┘
```

#### Next and Last Quote

`in' In' An' il' Il' Al' ...`

Work directly on distant quotes without moving there separately.

All the above pair text objects can be shifted to the next quote by
including the letter `n`. The command `in'` selects inside of the next
single quotes. Use the letter `l` instead to work on the previous (last)
quote. Uses a count to skip multiple quotation characters.

See our [Cheat Sheet][cheatsheet] for a chart summarizing all quote mappings.

#### Quote Seek

If any of the normal quote commands (not containing `n` or `l`) is executed
when the cursor is not positioned inside a quote, it seeks for quotes before or
after the cursor by searching for the appropriate delimiter on the current
line. This is similar to using the explicit version containing `n` or `l`.

### Separator Text Objects

These text objects are based on single separator characters like the comma in
one of our examples above. The text between two instances of the separator
character can be operated on with these targets.

Supported separators:

```
, . ; : + - = ~ _ * # / | \ & $
```

Separator text objects work over multiple lines and support seeking.

The following examples will use commas, but they all work for each listed
separator character accordingly.

#### In Separator

`i, i. i; i: i+ i- i= i~ i_ i* i# i/ i| i\ i& i$`

- Select inside separators. Similar to in quote.

```
      ...........
a , b , cccccccc , d , e
       └── i, ──┘
```

#### A Separator

`a, a. a; a: a+ a- a= a~ a_ a* a# a/ a| a\ a& a$`

- Select an item in a list separated by the separator character.
- Includes the leading separator, but excludes the trailing one. This leaves
  a proper list separated by the separator character after deletion. See the
  examples above.

```
      ...........
a , b , cccccccc , d , e
      └─── a, ──┘
```

#### Inside Separator

`I, I. I; I: I+ I- I= I~ I_ I* I# I/ I| I\ I& I$`

- Select contents between separators.
- Like inside separators, but exclude whitespace at both ends. Useful for
  changing contents while preserving spacing.

```
      ...........
a , b , cccccccc , d , e
        └─ I, ─┘
```

#### Around Separator

`A, A. A; A: A+ A- A= A~ A_ A* A# A/ A| A\ A& A$`

- Select around a pair of separators.
- Includes both separators and a surrounding whitespace, similar to `a'` and
  `A(`.

```
      ...........
a , b , cccccccc , d , e
      └─── A, ────┘
```

#### Next and Last Separator

`in, an, In, An, il, al, Il, Al, ...`

Work directly on distant separators without moving there separately.

All the above separator text objects can be shifted to the next separator by
including the letter `n`. The command `in,` selects inside of the next commas.
Use the letter `l` instead to work on the previous (last) separators. Uses the
count to skip multiple separator characters.

See our [Cheat Sheet][cheatsheet] for a chart summarizing all separator mappings.

#### Separator Seek

Like quote seeking. If any of the normal separator commands (not
containing `n` or `l`) is executed when the cursor is not positioned inside a
pair of separators, it seeks for the separator before or after the cursor.
This is similar to using the explicit version containing `n` or `l`.

### Argument Text Objects

These text objects are similar to separator text objects, but are specialized
for arguments surrounded by braces and commas. They also take matching braces
into account to capture only valid arguments.

Argument text objects work over multiple lines and support seeking.

#### In Argument

`ia`

- Select inside arguments. Similar to in quote.
- Accepts a count.

```
      ...........
a , b ( cccccccc , d ) e
       └── ia ──┘
```

#### An Argument

`aa`

- Select an argument in a list of arguments.
- Includes a separator if preset, but excludes surrounding braces. This leaves
  a proper argument list after deletion.
- Accepts a count.

```
      ...........
a , b ( cccccccc , d ) e
        └─── aa ──┘
```

#### Inside Argument

`Ia`

- Select content of an argument.
- Like inside separators, but exclude whitespace at both ends. Useful for
  changing contents while preserving spacing.
- Accepts a count.

```
      ...........
a , b ( cccccccc , d ) e
        └─ Ia ─┘
```

#### Around Argument

`Aa`

- Select around an argument.
- Includes both delimiters and a surrounding whitespace, similar to `a'` and
  `A(`.
- Accepts a count.

```
      ...........
a , b ( cccccccc , d ) e
      └─── Aa ────┘
```

#### Next and Last Argument

`ina ana Ina Ana ila ala Ila Ala`

Work directly on distant arguments without moving there separately.

All the above argument text objects can be shifted to the next argument by
including the letter `n`. The command `ina` selects inside of the next
argument. Use the letter `l` instead to work on the previous (last) argument.
Uses a [count] to skip multiple argument characters. The order is determined by
the nearest surrounding argument delimiter.

See our [Cheat Sheet][cheatsheet] for a chart summarizing all argument mappings.

#### Argument Seek

Like separator seeking. If any of the normal argument commands (not containing
`n` or `l`) is executed when the cursor is not positioned inside an argument,
it seeks for the argument before or after the cursor. This is similar to using
the explicit version containing `n` or `l`.

### Multi Text Objects

Two multi text objects are included in default settings. See the section on
settings below to see how to set up other similar multi text objects or
customize the built in ones.

#### Any Block

`inb anb Inb Anb ilb alb Ilb Alb`

Similar to pair text objects, if you type `dib` within `()` it will delete in
these. If you do the same within `{}` it will delete in those. If you type
`d2inb` it will skip one next pair (any kind) and delete in the one after (any
kind). If you're within `()` nested in `{}`, type `d2ib` to delete in `{}`. All
of the usual seeking, growing and skipping works.

#### Any Quote

`inq anq Inq Anq ilq alq Ilq Alq`

Similar to quote text objects, if you type `diq` within `""""` it will delete in
these. If you do the same within `''` it will delete in those. If you type
`d2inq` it will skip one next quote text object (any kind) and delete in the
one after (any kind). If you're within `""""` nested in `''`, type `d2iq` to
delete in `''`. All of the usual seeking, growing and skipping works.

## Settings

You can customize the mappings and text objects with the settings described
here.

### g:targets_aiAI

Default:

```vim
let g:targets_aiAI = 'aiAI'
```

Controls the normal mode operator mode maps that get created for In Pair (`i`),
A Pair (`a`), Inside Pair (`I`), and Around Pair (`A`). Required to be either a
string or a list with 4 characters/elements.

Use a space to deactivate a mode. If you want to use multiple keys, for example
`<Space>a` instead of `A`, you must use a list.

In contrast to `g:targets_nl`, special keys must not be escaped with a
backslash. For example, use `""<Space>""`
or `'<Space>'`, **not** `""\<Space>""`. Example for configuring `g:targets_aiAI`:

```vim
let g:targets_aiAI = ['<Space>a', '<Space>i', '<Space>A', '<Space>I']
```

### g:targets_mapped_aiAI

Default:

```vim
let g:targets_mapped_aiAI = g:targets_aiAI
```

If you can't get your g:targets_aiAI settings to work because they conflict
with other mappings you have, you might need to use g:targets_mapped_aiAI. For
example if you want to map `k` to `i` and use `k` as `i` in targets mappings,
you need to NOT map `k` to `i` in operator pending mode, and set
`g:targets_aiAI = 'akAI'` and `g:targets_mapped_aiAI = 'aiAI'`.

Has the same format as `g:targets_aiAI`.

For more details see issue #213 and don't hesitate to comment there or open a
new issue if you need assistance.

### g:targets_nl

Default:

```vim
let g:targets_nl = 'nl'
```

Controls the keys used in maps for seeking next and last text objects. For
example, if you want `n` to always search for the next object and `N` to search
for the last, you could set:

```vim
let g:targets_nl = 'nN'
```

Required to be either a string or a list with 2 characters/elements.

Use a space to deactivate a mode. If you want to use multiple keys, for example
`<Space>n` instead of `n`, you must use a list.

In contrast to `g:targets_aiAI`, special keys must be escaped with a backslash.
For example, use `""\<Space>""`, **not** `""<Space>""` nor `'<Space>'`. Example for
configuring `g:targets_nl`:

```vim
let g:targets_nl = [""\<Space>n"", ""\<Space>l""]
```

### g:targets_seekRanges

Default:

```vim
let g:targets_seekRanges = 'cc cr cb cB lc ac Ac lr rr ll lb ar ab lB Ar aB Ab AB rb al rB Al bb aa bB Aa BB AA'
```

Defines a priority ordered, space separated list of range types which can be
used to customize seeking behavior.

The default setting generally prefers targets around the cursor, with one
exception: If the target around the cursor is not contained in the current
cursor line, but the next or last target are, then prefer those. Targets
beginning or ending on the cursor are preferred over everything else.

Some other useful example settings:

Prefer multiline targets around cursor over distant targets within cursor line:
```vim
let g:targets_seekRanges = 'cc cr cb cB lc ac Ac lr lb ar ab lB Ar aB Ab AB rr ll rb al rB Al bb aa bB Aa BB AA'
```

Never seek backwards:
```vim
let g:targets_seekRanges = 'cc cr cb cB lc ac Ac lr rr lb ar ab lB Ar aB Ab AB rb rB bb bB BB'
```

Only seek if next/last targets touch current line:
```vim
let g:targets_seekRanges = 'cc cr cb cB lc ac Ac lr rr ll lb ar ab lB Ar aB Ab AB rb rB al Al'
```

Only consider targets fully visible on screen:
```vim
let g:targets_seekRanges = 'cc cr cb cB lc ac Ac lr lb ar ab rr rb bb ll al aa'
```

Only consider targets around cursor:
```vim
let g:targets_seekRanges = 'cc cr cb cB lc ac Ac lr lb ar ab lB Ar aB Ab AB'
```

Only consider targets fully contained in current line:
```vim
let g:targets_seekRanges = 'cc cr cb cB lc ac Ac lr rr ll'
```

If you want to build your own, or are just curious what those cryptic letters
mean, check out the full documentation in our [Cheat Sheet][cheatsheet].

### g:targets_jumpRanges

Default:

```vim
let g:targets_jumpRanges = 'bb bB BB aa Aa AA'
```

Defines an unordered, space separated list of range types which can be used to
customize the jumplist behavior (see documentation on seek ranges). It
controls whether or not to add the cursor position prior to selecting the text
object to the jumplist.

The default setting adds the previous cursor position to the jumplist if the
target that was operated on doesn't intersect the cursor line. That means it
adds a jumplist entry if the target ends above the cursor line or starts below
the cursor line.

Some other useful example settings (or build your own!):

Never add cursor position to jumplist:
```vim
let g:targets_jumpRanges = ''
```

Always add cursor position to jumplist:
```vim
let g:targets_jumpRanges = 'cr cb cB lc ac Ac lr rr ll lb ar ab lB Ar aB Ab AB rb al rB Al bb aa bB Aa BB AA'
```

Only add to jumplist if cursor was not inside the target:
```vim
let g:targets_jumpRanges = 'rr rb rB bb bB BB ll al Al aa Aa AA'
```

### g:targets_gracious

Default:

```vim
let g:targets_gracious = 0
```

If enabled (set to `1`) , both growing and seeking will work on the largest
available count if a too large count is given. For example:

- `v100ab` will select the most outer block around the cursor
- `v100inq` will select the most distant quote to the right/down
  (the last one in the file)

### targets#mappings#extend

This function can be used to modify an internal dictionary used to control the
mappings. The default value of that dictionary is:

```vim
{
    \ '(': {'pair': [{'o': '(', 'c': ')'}]},
    \ ')': {'pair': [{'o': '(', 'c': ')'}]},
    \ '{': {'pair': [{'o': '{', 'c': '}'}]},
    \ '}': {'pair': [{'o': '{', 'c': '}'}]},
    \ 'B': {'pair': [{'o': '{', 'c': '}'}]},
    \ '[': {'pair': [{'o': '[', 'c': ']'}]},
    \ ']': {'pair': [{'o': '[', 'c': ']'}]},
    \ '<': {'pair': [{'o': '<', 'c': '>'}]},
    \ '>': {'pair': [{'o': '<', 'c': '>'}]},
    \ '""': {'quote': [{'d': '""'}]},
    \ ""'"": {'quote': [{'d': ""'""}]},
    \ '`': {'quote': [{'d': '`'}]},
    \ ',': {'separator': [{'d': ','}]},
    \ '.': {'separator': [{'d': '.'}]},
    \ ';': {'separator': [{'d': ';'}]},
    \ ':': {'separator': [{'d': ':'}]},
    \ '+': {'separator': [{'d': '+'}]},
    \ '-': {'separator': [{'d': '-'}]},
    \ '=': {'separator': [{'d': '='}]},
    \ '~': {'separator': [{'d': '~'}]},
    \ '_': {'separator': [{'d': '_'}]},
    \ '*': {'separator': [{'d': '*'}]},
    \ '#': {'separator': [{'d': '#'}]},
    \ '/': {'separator': [{'d': '/'}]},
    \ '\': {'separator': [{'d': '\'}]},
    \ '|': {'separator': [{'d': '|'}]},
    \ '&': {'separator': [{'d': '&'}]},
    \ '$': {'separator': [{'d': '$'}]},
    \ 't': {'tag': [{}]},
    \ 'a': {'argument': [{'o': '[([]', 'c': '[])]', 's': ','}]},
    \ 'b': {'pair': [{'o':'(', 'c':')'}, {'o':'[', 'c':']'}, {'o':'{', 'c':'}'}]},
    \ 'q': {'quote': [{'d':""'""}, {'d':'""'}, {'d':'`'}]},
    \ }
```

The keys in this dictionary correspond to the trigger character. For example if
you type `di(`, `(` is the trigger and gets mapped to the `pair` target source
with arguments `'o':'('` (opening) and `'c':')'` (closing). Sources `quote` and
`separator` have argument `'d'` (delimiter), `tag` has no arguments and
`argument` text objects take `'o'` (opening), `'c'` (closing) and `'s'`
(separator). Notably the `b` (any block) and `q` (any quote) triggers map to
one source with three sets of `pair` and `quote` argument dictionaries
respectively.  That means if you type `dib` each of those sources get taken
into account to pick the proper target. Also note that it's even possible to
have one target mapped to multiple different sources, so you can select any of
those different text objects (see example below).

You can use the `targets#mappings#extend()` function to modify these internal
mappings. For example if you wanted to switch `b` back to the Vim default
behavior of operating on parentheses only, you can add this to your vimrc:

```vim
autocmd User targets#mappings#user call targets#mappings#extend({
    \ 'b': {'pair': [{'o':'(', 'c':')'}]}
    \ })
```

Note that you should always use that `autocmd` prefix to make sure your
modifications get applied at the right time. There's a similar autogroup for
plugins which can add other sources and default mappings, which gets triggered
before this `#user` one. That way the user mappings always take precedence over
the plugins default mappings

If you want to remove a mapping from the defaults, just set it to an empty list
of sources:

```vim
autocmd User targets#mappings#user call targets#mappings#extend({
    \ 'q': {},
    \ })
```

That way targets.vim will ignore it and fall back to Vim default behavior,
which for the case of `q` does nothing.

Finally here's a more complex example which adds two triggers `s` (any
separator text object) and `@` (anything at all). So you could type `das` to
delete the closest separator text object near the cursor, or `da@` to operate
on the closest text object available via targets.vim. All of those support
seeking and counts like `d3ins`.

```vim
autocmd User targets#mappings#user call targets#mappings#extend({
    \ 's': { 'separator': [{'d':','}, {'d':'.'}, {'d':';'}, {'d':':'}, {'d':'+'}, {'d':'-'},
    \                      {'d':'='}, {'d':'~'}, {'d':'_'}, {'d':'*'}, {'d':'#'}, {'d':'/'},
    \                      {'d':'\'}, {'d':'|'}, {'d':'&'}, {'d':'$'}] },
    \ '@': {
    \     'separator': [{'d':','}, {'d':'.'}, {'d':';'}, {'d':':'}, {'d':'+'}, {'d':'-'},
    \                   {'d':'='}, {'d':'~'}, {'d':'_'}, {'d':'*'}, {'d':'#'}, {'d':'/'},
    \                   {'d':'\'}, {'d':'|'}, {'d':'&'}, {'d':'$'}],
    \     'pair':      [{'o':'(', 'c':')'}, {'o':'[', 'c':']'}, {'o':'{', 'c':'}'}, {'o':'<', 'c':'>'}],
    \     'quote':     [{'d':""'""}, {'d':'""'}, {'d':'`'}],
    \     'tag':       [{}],
    \     },
    \ })
```

Also note how this example shows that you can set multiple triggers in a single
`targets#mappings#extend()` call. To keep the autocmd overhead minimal I'd
recommend to keep all your mappings setup in a single such call.

### Deprecated settings

If you have set any of the following settings in your vimrc, they will still be
respected when creating the default mappings dictionary. But it's not possible
to set up any multi source targets (like any block or any quote) this way. It's
recommended to retire those legacy settings and use `targets#mappings#extend()`
as described above.

```vim
g:targets_pairs
g:targets_quotes
g:targets_separators
g:targets_tagTrigger
g:targets_argClosing
g:targets_argOpening
g:targets_argSeparator
g:targets_argTrigger
```

However, those new mappings settings will only be respected when targets.vim
can use expression mappings, which need Neovim or Vim with version 7.3.338 or
later. If you are using an older Vim version, these legacy settings are still
the only way to do any customization. Please refer to an older version of this
README (before October 2018) for details. Or open an issue for me to describe
those legacy settings somewhere still.

## Notes

- [Repeating an operator-pending mapping forgets its last count.][repeatcount]
    Works since Vim 7.4.160

## Issues

- [Empty matches can't be selected because it is not possible to visually select
  zero-character ranges.][emptyrange]
- Forcing motion to work linewise by inserting `V` in `dVan(` doesn't work
  for operator-pending mappings. [See `:h o_v`][o_v].
- Report issues or submit pull requests to
  [github.com/wellle/targets.vim][targets].

## Todos

Create more mappings to support commands like `danw` or `danp` to delete the
next word or paragraph.

[plugins]: plugins.md
[cheatsheet]: cheatsheet.md
[textobjects]: http://vimdoc.sourceforge.net/htmldoc/motion.html#text-objects
[operator]: http://vimdoc.sourceforge.net/htmldoc/motion.html#operator
[repeat]: http://vimdoc.sourceforge.net/htmldoc/repeat.html#single-repeat
[neobundle]: https://github.com/Shougo/neobundle.vim
[vundle]: https://github.com/gmarik/vundle
[vim-plug]: https://github.com/junegunn/vim-plug
[pathogen]: https://github.com/tpope/vim-pathogen
[dein]: https://github.com/Shougo/dein.vim
[repeatcount]: https://groups.google.com/forum/?fromgroups#!topic/vim_dev/G4SSgcRVN7g
[emptyrange]: https://groups.google.com/forum/#!topic/vim_use/qialxUwdcMc
[targets]: https://github.com/wellle/targets.vim
[o_v]: http://vimdoc.sourceforge.net/htmldoc/motion.html#o_v
","Targets.vim** is a Vim plugin that adds various [text objects] to give you more
targets to [operate] on. It expands on the idea ofsimple commands like `di'`
(delete inside the single quotes around the cursor) It also gives you more
opportunities to craft powerful commands that can be              
 [repeated][repeat] reliably. One major goal is to handle all corner cases     
         correctly. The plugin is free to download and use, but not to install."
172,:earth_africa: Compass helps you setup a central navigation system for your application,"⚠️ DEPRECATED, NO LONGER MAINTAINED

![Compass logo](https://raw.githubusercontent.com/hyperoslo/Compass/master/Images/logo_v1.png)

[![Version](https://img.shields.io/cocoapods/v/Compass.svg?style=flat)](http://cocoadocs.org/docsets/Compass)
[![Carthage Compatible](https://img.shields.io/badge/Carthage-compatible-4BC51D.svg?style=flat)](https://github.com/Carthage/Carthage)
[![License](https://img.shields.io/cocoapods/l/Compass.svg?style=flat)](http://cocoadocs.org/docsets/Compass)
[![Platform](https://img.shields.io/cocoapods/p/Compass.svg?style=flat)](http://cocoadocs.org/docsets/Compass)
[![CI Status](http://img.shields.io/travis/hyperoslo/Compass.svg?style=flat)](https://travis-ci.org/hyperoslo/Compass)
![Swift](https://img.shields.io/badge/%20in-swift%203.0-orange.svg)

Compass helps you setup a central navigation system for your application.
This has many benefits, one of them being that controllers can now be
decoupled, meaning that the list that presents the detail no longer knows
about what its presenting. Controllers become agnostic and views stay
stupid. The user experience stays the same but the logic and separation of
concerns become clearer. The outcome is that your application will become
more modular by default. Anything could potentially be presented from
anywhere, but remember, with great power comes great responsibility.

## Getting Started

Below are tutorials on how to use Compass

- [URL Routing in iOS apps: Compass Beginner Guide](https://medium.com/flawless-app-stories/url-routing-with-compass-d59c0061e7e2): basic introduction to Compass, how to use Router and multiple use cases for deep linking, push notifications

## Setup

#### Step 1
First you need to register a URL scheme for your application.

<img src=""https://raw.githubusercontent.com/hyperoslo/Compass/master/Images/setup-url-scheme.png"">

#### Step 2
Now you need to configure Compass to use that URL scheme, a good place
to do this is in your `AppDelegate`. Then configure all the routes you wish you support.

```swift
func application(_ application: UIApplication,
                 didFinishLaunchingWithOptions launchOptions: [UIApplicationLaunchOptionsKey: Any]?) -> Bool {
  Navigator.scheme = ""compass""
  Navigator.routes = [""profile:{username}"", ""login:{username}"", ""logout""]
  return true
}
```

#### Step 3

Register your location request handler


```swift
Navigator.handle = { [weak self] location in
  let arguments = location.arguments

  let rootController = self?.window.rootViewController as? UINavigationController

  switch location.path {
    case ""profile:{username}"":
      let profileController = ProfileController(title: arguments[""username""])
      rootController?.pushViewController(profileController, animated: true)
    case ""login:{username}"":
      let loginController = LoginController(title: arguments[""username""])
      rootController?.pushViewController(loginController, animated: true)
    case ""logout"":
      self?.clearLoginSession()
      self?.switchToLoginScreen()
    default: 
      break
  }
}
```

#### Step 4

Anywhere in your application, you can just use `Navigator` to navigate

```swift
@IBOutlet func logoutButtonTouched() {
  Navigator.navigate(urn: ""logout"")
}
```

#### Step 5
Optional. If you want to support deep linking,  set up your application to respond to the URLs. Setting it up this way would mean that
you could open any view from a push notification depending on the contents of the payload.

```swift
func application(_ app: UIApplication,
                 open url: URL,
                 options: [UIApplicationOpenURLOptionsKey : Any]) -> Bool {
  do {
    try Navigator.navigate(url: url)
  } catch {
    // Handle error
  }

  return true
}
```

## Compass life hacks

### Tip 1. Router
We also have some conventional tools for you that could be used to organize your
route handling code and avoid huge `switch` cases.

- Implement `Routable` protocol to keep your single route navigation code
in one place:
```swift
struct ProfileRoute: Routable {

  func navigate(to location: Location, from currentController: CurrentController) throws {
    guard let username = location.arguments[""username""] else { return }

    let profileController = ProfileController(title: username)
    currentController.navigationController?.pushViewController(profileController, animated: true)
  }
}
```

- Create a `Router` instance and register your routes. Think of `Router` as a composite `Routable`
```swift
let router = Router()
router.routes = [
  ""profile:{username}"": ProfileRoute(),
  ""logout"": LogoutRoute()
]
```

- Parse URL with **Compass** and navigate to the route with a help of your
`Router` instance.
```swift
func application(_ app: UIApplication,
                 open url: URL,
                 options: [UIApplicationOpenURLOptionsKey : Any]) -> Bool {
  
  return handle(url)
}

func handle(_ url: URL) -> Bool {
  guard let location = Navigator.parse(url) else {
    return false
  }

  router.navigate(to: location, from: navigationController)

  return true
}
```

### Tip 2. Multiple routers
You could set up multiple routers depending on app states. For example, you could have 2 routers for pre and post login.

```swift
let preLoginRouter = Router()
preLoginRouter.routes = [
  ""profile:{username}"" : ProfileRoute()
]

let postLoginRouter = Router()
postLoginRouter.routes = [
  ""login:{username}"" : LoginRoute()
]

let router = hasLoggedIn ? postLoginRouter : preLoginRouter
router.navigate(to: location, from: navigationController)
```

## Installation

**Compass** is available through [CocoaPods](http://cocoapods.org). To install
it, simply add the following line to your Podfile:

```ruby
pod 'Compass'
```

**Compass** is also available through [Carthage](https://github.com/Carthage/Carthage).
To install just write into your Cartfile:

```ruby
github ""hyperoslo/Compass""
```

## Author

Hyper Interaktiv AS, ios@hyper.no

## Credits

The idea behind Compass came from [John Sundell](https://github.com/JohnSundell)'s tech talk ""*Components & View Models in the Cloud - how Spotify builds native, dynamic UIs*""

## License

**Compass** is available under the MIT license. See the LICENSE file for more info.
","Compass helps you setup a central navigation system for your application. It can
be used to make your application more modular by default. Controllers become
agnostic and views stay stupid. The user experience stays the same but the logic
and separation of concerns becomes clearer."
453,"🔥一个高效的多媒体支持操作库，可多方面的简单配置操作相册、拍照、录制、录音等功能。也支持配套使用的展示图片、视频、音频的九宫格功能。 （An efficient multimedia support operation library, can be a variety of simple configuration operation album, photo, recording, recording and other functions.Also support supporting the use of the display of pictures, video, audio of the nine grid function.）","# AlbumCameraRecorder

[![MinSdk](https://img.shields.io/badge/MinSdk-16-blue.svg)](https://developer.android.com/about/versions/android-4.1)
[![License](https://img.shields.io/badge/License-MIT-blue.svg)](https://github.com/zhongjhATC/AlbumCameraRecorder/blob/master/LICENSE)

## 目前已经投入到正式项目中使用。
## 有任何建议或者想添加的功能，都可提在Issues

## 中文
一个高效的多媒体支持操作库，可多方面的简单配置操作拍照、相册、录制、录音等功能。

也支持配套使用的展示图片、视频、音频的九宫格功能。


本开源库的部分代码来自[Matisse](https://github.com/zhihu/Matisse).

非常感谢知乎提供的这么棒的开源项目！    

## 特性
 - 支持自定义样式.支持更换里面的相关按钮.
 - 支持相册、录制、录音等多个嵌套功能，并且也可以通过配置只设置显示一个.
 - 丰富的回调接口和调试信息,可利用现有API实现丰富的效果.

## X版本分支
 - [AndroidX库版本](https://github.com/zhongjhATC/AlbumCameraRecorder/tree/androidx).
 
 
## 该分支已经完全弃用，以后只维护X版本了
 - 该分支不支持Android Q版本后的选择图片，如果您的项目SDK版本是28那是完全够用的.
 
 
## 引入

#### Step 1. Add the JitPack repository to your build file

	allprojects {
		repositories {
			...
			maven { url 'https://www.jitpack.io' }
		}
	}
#### Step 2. Add the dependency

	dependencies {
	     implementation 'com.github.zhongjhATC.AlbumCameraRecorder:albumCameraRecorderCommon:1.0.18'        // 公共库，必须使用此库
         implementation 'com.github.zhongjhATC.AlbumCameraRecorder:multilibrary:1.0.18'      // 核心lib，调用显示相册、录屏、录音等
         implementation 'com.github.zhongjhATC.AlbumCameraRecorder:progresslibrary:1.0.18' // 配套使用，主要用于获取数据后进行相关显示，相应的上传进度显示，如果你只需要获取照片录像录音等数据，自行写获取后呈现方式，可以不需要是用这个
	}

## 快照
![](https://github.com/zhongjhATC/AlbumCameraRecorder/blob/master/Demonstration.gif)
![](https://github.com/zhongjhATC/AlbumCameraRecorder/blob/master/DemonstrationShowImg.png)



## 市场上常用手机兼容测试
100%通过[兼容测试报告](https://github.com/zhongjhATC/AlbumCameraRecorder/blob/master/WeTest.md).
![](https://raw.githubusercontent.com/zhongjhATC/AlbumCameraRecorder/master/wetest/5.jpg)

## 使用   
#### 启动多媒体相关功能
 
        // 拍摄有关设置
        CameraSetting cameraSetting = new CameraSetting();
        cameraSetting.mimeTypeSet(MimeType.ofAll());// 支持的类型：图片，视频

        // 相册
        AlbumSetting albumSetting = new AlbumSetting(true)
                .mimeTypeSet(MimeType.ofAll())// 支持的类型：图片，视频
                .countable(true)// 是否显示多选图片的数字
                .addFilter(new GifSizeFilter(320, 320, 5 * Filter.K * Filter.K))// 自定义过滤器
                .originalEnable(true)// 开启原图
                .maxOriginalSize(10); // 最大原图size,仅当originalEnable为true的时候才有效

        // 录音机
        RecorderSetting recorderSetting = new RecorderSetting();

        // 全局
        GlobalSetting globalSetting = MultiMediaSetting.from(MainSimpleActivity.this).choose(MimeType.ofAll());

        if (mBinding.cbAlbum.isChecked())
            // 开启相册功能
            globalSetting.albumSetting(albumSetting);
        if (mBinding.cbCamera.isChecked())
            // 开启拍摄功能
            globalSetting.cameraSetting(cameraSetting);
        if (mBinding.cbRecorder.isChecked())
            // 开启录音功能
            globalSetting.recorderSetting(recorderSetting);

        globalSetting
                .setOnMainListener(errorMessage -> Toast.makeText(MainSimpleActivity.this.getApplicationContext(), ""自定义失败信息：录音已经达到上限"", Toast.LENGTH_LONG).show())
                .allStrategy(new SaveStrategy(true, ""com.zhongjh.cameraapp.fileprovider"", ""AA/test""))// 设置路径和7.0保护路径等等
                .imageEngine(new Glide4Engine())    // for glide-V4
                .maxSelectablePerMediaType(5 - alreadyImageCount, 1 - alreadyVideoCount, 1 - alreadyAudioCount)// 最大10张图片或者最大1个视频
                .forResult(REQUEST_CODE_CHOOSE);

#### 获取相关返回的数据

    @Override
    protected void onActivityResult(int requestCode, int resultCode, Intent data) {
        super.onActivityResult(requestCode, resultCode, data);
        if (resultCode != RESULT_OK)
            return;
        switch (requestCode) {
            case REQUEST_CODE_PREVIEW:
                ```
            case REQUEST_CODE_CHOOSE:
                // 获取类型，根据类型设置不同的事情
                switch (MultiMediaSetting.obtainMultimediaType(data)) {
                    case MultimediaTypes.PICTURE:
                        // 图片
                        List<String> path = MultiMediaSetting.obtainPathResult(data);
                        mBinding.mplImageList.addImagesStartUpload(path);
                        break;
                    case MultimediaTypes.VIDEO:
                        // 录像
                        List<String> videoPath = MultiMediaSetting.obtainPathResult(data);
                        mBinding.mplImageList.addVideoStartUpload(videoPath);
                        break;
                    case MultimediaTypes.AUDIO:
                        // 语音
                        RecordingItem recordingItem = MultiMediaSetting.obtainRecordingItemResult(data);
                        mBinding.mplImageList.addAudioStartUpload(recordingItem.getFilePath(), recordingItem.getLength());
                        break;
                    case MultimediaTypes.BLEND:
                        // 混合类型，意思是图片可能跟录像在一起.
                        mBinding.mplImageList.addImagesStartUpload(MultiMediaSetting.obtainPathResult(data));
                        break;
                }
                break;
        }
    }

#### 如果你需要用到九宫格展览数据，具体可以看[相关代码](https://github.com/zhongjhATC/AlbumCameraRecorder/blob/master/app/src/main/java/com/zhongjh/cameraapp/MainSeeActivity.java).

#### 相关API,更多API和支持持续丰富加入
 - [调用多媒体的公共配置API](https://github.com/zhongjhATC/AlbumCameraRecorder/blob/master/multilibrary/src/main/java/com/zhongjh/albumcamerarecorder/settings/api/GlobalSettingApi.java).
 - [调用多媒体的相册配置API](https://github.com/zhongjhATC/AlbumCameraRecorder/blob/master/multilibrary/src/main/java/com/zhongjh/albumcamerarecorder/settings/api/AlbumSettingApi.java).
 - [调用多媒体的录制配置API](https://github.com/zhongjhATC/AlbumCameraRecorder/blob/master/multilibrary/src/main/java/com/zhongjh/albumcamerarecorder/settings/api/CameraSettingApi.java).
 - [调用多媒体的录音配置API](https://github.com/zhongjhATC/AlbumCameraRecorder/blob/master/multilibrary/src/main/java/com/zhongjh/albumcamerarecorder/settings/api/RecorderSettingApi.java).
 - [多媒体UI相关属性配置](https://github.com/zhongjhATC/AlbumCameraRecorder/blob/master/multilibrary/src/main/res/values/styles.xml)

如果你使用展示的九宫库，那么下面这些api对你也有用
 - [九宫格相关API](https://github.com/zhongjhATC/AlbumCameraRecorder/blob/master/progresslibrary/src/main/java/com/zhongjh/progresslibrary/api/MaskProgressApi.java).
 - [九宫格相关事件](https://github.com/zhongjhATC/AlbumCameraRecorder/blob/master/progresslibrary/src/main/java/com/zhongjh/progresslibrary/listener/MaskProgressLayoutListener.java).
 - [九宫格相关属性，配置UI等等](https://github.com/zhongjhATC/AlbumCameraRecorder/blob/master/progresslibrary/src/main/res/values/attrs.xml)



## 历史更新
从1.0.1版本开始总结的[历史更新](https://github.com/zhongjhATC/AlbumCameraRecorder/blob/master/UPDATE.md).

## apk直接体验下载
 - 1.0.0版本，跟当前最新代码版本可能会有稍许不同
![](https://github.com/zhongjhATC/AlbumCameraRecorder/blob/master/qrcode.png)

 - 链接下载地址：https://fir.im/s9b6?release_id=5c84dcd3ca87a807f7ef5181&fir_source=%E7%89%88%E6%9C%AC1&fir_campaign=%E7%89%88%E6%9C%AC1

## 喜欢的麻烦在顶部点个star
","summarize: # AlbumCameraRecorder. Add the JitPack repository to your build file.
Add a dependency on Android 4.1 or later. Add an app dependency on Google Play
Services. Finally, test the app with the latest version of Android."
2803,TensorFlow template application for deep learning,"## Introduction

It is the generic golden program for deep learning with [TensorFlow](https://github.com/tensorflow/tensorflow).

![](./architecture.jpeg)

- [x] Data Formats
  - [x] [CSV](./data/)
  - [x] [LIBSVM](./data/)
  - [x] [TFRecords](./data/)
- [x] Predict Server
  - [x] [TensorFlow serving](./cpp_predict_server/)
  - [x] [Python HTTP server](./http_service/)
- [x] Predict Client
  - [x] [Python gPRC client](./python_predict_client/)
  - [x] [Java gPRC client](./java_predict_client/)
  - [x] [Scala gPRC client](./java_predict_client/)
  - [x] [Golang gRPC client](./golang_predict_client/)
  - [x] [C++ gRPC client](./cpp_predict_client/)
  - [x] [Spark client](./java_predict_client/)
  - [x] [Android client](./android_client/)
  - [x] [iOS client](./ios_client/)
- [x] Network Models
  - [x] Logistic regression
  - [x] Deep neural network
  - [x] Convolution neural network
  - [x] Wide and deep model
  - [x] Regression model
  - [x] Customized models
- [x] Other Features
  - [x] Checkpoint
  - [x] TensorBoard
  - [x] Exporter
  - [x] Dropout
  - [x] Optimizers
  - [x] Learning rate decay
  - [x] Batch normalization
  - [x] Benchmark mode
  - [x] [Distributed training](./distributed/)

## Usage

### Generate TFRecords

If your data is in CSV format, generate TFRecords like this.

```
cd ./data/cancer/

./generate_csv_tfrecords.py
```

If your data is in LIBSVM format, generate TFRecords like this.

```
cd ./data/a8a/

./generate_libsvm_tfrecord.py
```

For large dataset, you can use Spark to do that. Please refer to [data](./data/).

### Run Training

You can train with the default configuration.

```
./dense_classifier.py

./sparse_classifier.py
```

Using different models or hyperparameters is easy with TensorFlow flags.

```
./dense_classifier.py --batch_size 1024 --epoch_number 1000 --step_to_validate 10 --optmizier adagrad --model dnn --model_network ""128 32 8""
```

If you use other dataset like [iris](./data/iris/), no need to modify the code. Just run with parameters to specify the TFRecords files.

```
./dense_classifier.py --train_file ./data/iris/iris_train.csv.tfrecords --validate_file ./data/iris/iris_test.csv.tfrecords --feature_size 4 --label_size 3  --enable_colored_log

./dense_classifier.py --train_file ./data/iris/iris_train.csv --validate_file ./data/iris/iris_test.csv --feature_size 4 --label_size 3 --input_file_format csv --enable_colored_log
```

If you want to use CNN model, try this command.

```
./dense_classifier.py --train_file ./data/lung/fa7a21165ae152b13def786e6afc3edf.dcm.csv.tfrecords --validate_file ./data/lung/fa7a21165ae152b13def786e6afc3edf.dcm.csv.tfrecords --feature_size 262144 --label_size 2 --batch_size 2 --validate_batch_size 2 --epoch_number -1 --model cnn
```

For [boston housing](./data/boston_housing/) dataset.

```
./dense_classifier.py --train_file ./data/boston_housing/train.csv.tfrecords --validate_file ./data/boston_housing/train.csv.tfrecords --feature_size 13 --label_size 1 --scenario regression  --batch_size 1 --validate_batch_size 1
```

### Export The Model

After training, it will export the model automatically. Or you can export manually.

```
./dense_classifier.py --mode savedmodel
```

### Validate The Model

If we want to run inference to validate the model, you can run like this.

```
./dense_classifier.py --mode inference
```

### Use TensorBoard

The program will generate TensorFlow event files automatically.

```
tensorboard --logdir ./tensorboard/
```

Then go to `http://127.0.0.1:6006` in the browser.

### Serving and Predicting

The exported model is compatible with [TensorFlow Serving](https://github.com/tensorflow/serving). You can follow the document and run the `tensorflow_model_server`.

```
./tensorflow_model_server --port=9000 --model_name=dense --model_base_path=./model/
```

We have provided some gRPC clients for dense and sparse models, such as [Python predict client](./python_predict_client/) and [Java predict client](./java_predict_client/).

```
./predict_client.py --host 127.0.0.1 --port 9000 --model_name dense --model_version 1

mvn compile exec:java -Dexec.mainClass=""com.tobe.DensePredictClient"" -Dexec.args=""127.0.0.1 9000 dense 1""
```

## Contribution

This project is widely used for different tasks with dense or sparse data.

If you want to make contributions, feel free to open an [issue](https://github.com/tobegit3hub/deep_recommend_system/issues) or [pull-request](https://github.com/tobegit3hub/deep_recommend_system/pulls).
","TensorFlow is the generic golden program for deep learning with TensorFlow. Data
Formats: CSV, LIBSVM, TFRecords, Scala, GPRC, iOS, Golang, Python, Spark.
Network Models: Logistic regression, Convolution neural network, Benchmark mode,
Dropout mode, TensorBoard. Tensorflow is available on GitHub at:
http://www.tensorflow.com/developer/tensorFlow-deep-learning."
2537,Classic overhead run-and-gun game,"# ![C-Dogs SDL](http://cxong.github.io/cdogs-sdl/images/title.png)

[![Build Status](https://github.com/cxong/cdogs-sdl/workflows/Build/badge.svg)](https://github.com/cxong/cdogs-sdl/actions)
[![Build Status (Windows)](https://ci.appveyor.com/api/projects/status/github/cxong/cdogs-sdl?svg=true)](https://ci.appveyor.com/project/cxong/cdogs-sdl)
[![Github All Releases](https://img.shields.io/github/downloads/cxong/cdogs-sdl/total.svg)](https://github.com/cxong/cdogs-sdl/releases)
[![Release](http://img.shields.io/github/release/cxong/cdogs-sdl.svg)](https://github.com/cxong/cdogs-sdl/releases/latest)
[![Custom campaigns](https://img.shields.io/badge/%F0%9F%94%97-custom%20campaigns-brightgreen)](http://cdogs.morezombies.net/)

## ![](https://github.com/cxong/cdogs-sdl/blob/master/graphics/column.png) Introduction

C-Dogs SDL is a classic overhead run-and-gun game, supporting up to 4 players
in co-op and deathmatch modes. Customize your player, choose from many weapons,
and blast, slide and slash your way through over 100 user-created campaigns.
Have fun!

[Releases and release notes](https://github.com/cxong/cdogs-sdl/releases)

For more information about the original C-Dogs read [`original\_readme.txt`](https://raw.githubusercontent.com/cxong/cdogs-sdl/master/doc/original_readme.txt).

## ![](https://github.com/cxong/cdogs-sdl/blob/master/graphics/folder.png) What is C-Dogs SDL

![Walk cycle](https://github.com/cxong/cxong.github.io/blob/master/_posts/cdogs_walk_cycle_jones.gif)

[C-Dogs](https://en.wikipedia.org/wiki/C-Dogs) is a freeware DOS game made between 1997-2001 by Ronny Wester, who's also known for making Cyberdogs (1994). Although relatively obscure, it was one of the more well-known games of its kind, and built a small following with many fans creating custom campaigns for it. Players loved it for its simple yet addictive gameplay and wicked explosions.

![Explosions](https://github.com/cxong/cdogs-sdl/blob/gh-pages/_posts/shake.gif)

- Internet Archive: http://web.archive.org/web/20050305054405/http://www.orcsoftware.com/~ronny/C-Dogs.html

The story would have ended there had Ronny not been awesome enough to release the source code in 2002. There it was picked up by Jeremy Chin and Lucas Martin-King, who ported the game to SDL and made it available for modern PCs. A few other ports came and went, for systems as varied as BeOS and Wii.

These days the project is maintained by Cong Xu, who along with a few other contributors, have been making the game even better while staying true to the original game's vision. 4-player multiplayer, co-op AI, moddability and new campaigns/maps are just some of the enhancements available.

So what are you waiting for? Download C-Dogs SDL today and have a blast!


## ![](https://github.com/cxong/cdogs-sdl/blob/master/graphics/barrel_blue.png) Platforms

[![Packaging status](https://repology.org/badge/tiny-repos/cdogs-sdl.svg)](https://repology.org/project/cdogs-sdl/versions)

C-Dogs SDL runs on Windows, Linux and macOS. Other platforms and ports are also available, but may be outdated.

## ![](https://github.com/cxong/cdogs-sdl/blob/master/graphics/cd.png) Installation

The easiest way is to [download from **itch.io**](https://congusbongus.itch.io/cdogs-sdl). If you use the itch.io app, your game installation will be updated automatically.

For building on your platform, follow the [getting started wiki](https://github.com/cxong/cdogs-sdl/wiki#getting-started). You will need the SDL2 development libraries installed.

## ![](https://github.com/cxong/cdogs-sdl/blob/master/graphics/barrel_skull.png) License

tl;dr: **GPLv2** for code, **CC0/CC-BY/CC-BY-SA** for assets. Significant amounts of **BSD 2-clause** code.

Code is licensed under GPL version 2, with significant portions under BSD 2-clause. The code is free software; you can use, modify and redistribute for any purpose, as long as you follow the GPL and BSD licenses!

Data is licensed under various free terms, including CC0, CC-BY and CC-BY-SA. [The original C-Dogs data is also under CC-BY](https://raw.githubusercontent.com/cxong/cdogs-sdl/master/doc/README_DATA.md). New data is licensed as CC0 if not specified. You are free to use, modify and redistribute these for any purpose, as long as you follow their licenses.

## ![](https://github.com/cxong/cdogs-sdl/blob/master/graphics/circuit.png) Contact

If you have any questions, comments, bug reports, patches or anything else related to C-Dogs SDL:

- [Raise an issue](https://github.com/cxong/cdogs-sdl/issues)
- Email: [Cong](<mailto:congusbongus@gmail.com>)
","C-Dogs is a classic overhead run-and-gun game, supporting up to 4 players.
Customize your player, choose from many weapons, blast, slide and slash your way
through over 100 user-created campaigns. The game was made between 1997-2001 by
Ronny Wester, also known for making Cyberdogs (1994)"
1021,"Elkeid is an open source solution that can meet the security requirements of various workloads such as hosts, containers and K8s, and serverless. It is derived from ByteDance's internal best practices.","# Elkeid - Bytedance Cloud Workload Protection Platform

English | [简体中文](README-zh_CN.md)

**Elkeid** is an open source solution that can meet the security requirements of various workloads such as **hosts, containers and K8s, and serverless**. It is derived from ByteDance's internal best practices.

With the business development of enterprises, the situation of multi-cloud, cloud-native, and coexistence of multiple workloads has become more and more prominent. We hope that there can be a set of solutions that can meet the security requirements under different workloads, so **Elkeid** was born.



## Introduction

Elkeid has the following key capabilities:

* **Elkeid** not only has the traditional **HIDS (Host Intrusion Detection System)** ability for host layer intrusion detection and malicious file identification, but also can well identify malicious behaviors in containers. The host can meet the anti-intrusion security requirements of the host and the container on it, and the powerful kernel-level data collection capability at the bottom of Elkeid can satisfy the desire of most security analyst for host-level data.

* For the running business **Elkeid** has the **RASP** capability and can be injected into the business process for anti-intrusion protection, not only the operation and maintenance personnel do not need to install another Agent, but also the business does not need to restart.

* For **K8s** itself, **Elkeid** supports collection to **K8s Audit Log** to perform intrusion detection and risk identification on the **K8s** system.

* **Elkeid**'s rule engine **Elkeid HUB** can also be well linked with external multiple systems.

**Ekeid** integrates these capabilities into one platform to meet the complex security requirements of different workloads, while also achieving multi-component capability association. What is even more rare is that each component undergoes massive byte-beating. Data and years of combat testing.



## Elkeid Community Edition Description

It should be noted that there are differences between the **Elkeid** **open source version** and the full version. The current open source capabilities mainly include:

* All on-device capabilities, that is, on-device data/asset/partial collection capabilities, kernel-state data collection capabilities, RASP probe parts, etc., and are consistent with the internal version of ByteDance;
* All backend capabilities, namely Agent Center, service discovery, etc., are consistent with the internal version of ByteDance;
* Provide a community edition rule engine, namely Elkeid HUB, and use it as an example with a small number of strategies;
* Provides community version of Elkeid Console and some supporting capabilities.

Therefore, it is necessary to have complete anti-intrusion and risk perception capabilities, and it is also necessary to construct policies based on Elkeid HUB and perform secondary processing of the data collected by Elkeid.



## Elkeid Architecture

<img src=""server/docs/server_new.png""/>

##  Elkeid Host Ability
* **[Elkeid Agent](agent)** Linux userspace agent，responsible for managing various plugin, communication with **Elkeid Server**.
* **[Elkeid Driver](driver)** Driver can collect data on Linux Kernel, support container runtime , communication with Elkeid Driver Plugin.
* **[Elkeid RASP](rasp)** Support CPython、Golang、JVM、NodeJS、PHP runtime probe, supports dynamic injection into the runtime.
* **Elkeid Agent Plugin List**
    * [Driver Plugin](https://github.com/bytedance/Elkeid/tree/main/plugins/driver): Responsible for managing **Elkeid Driver**, and process the driver data.
    * [Collector Plugin](https://github.com/bytedance/Elkeid/tree/main/plugins/collector): Responsible for the collection of assets/log information on the Linux System, such as user list, crontab, package information, etc.
    * [Journal Watcher](https://github.com/bytedance/Elkeid/tree/main/plugins/journal_watcher): Responsible for monitoring systemd logs, currently supports ssh related log collection and reporting.
    * [Scanner Plugin](https://github.com/bytedance/Elkeid/tree/main/plugins/scanner): Responsible for static detection of malicious files on the host, currently supports yara.
    * [RASP Plugin](https://github.com/bytedance/Elkeid/tree/main/rasp/plugin): Responsible for managing RASP components and processing data collected from RASP.
    * [Baseline Plugin](https://github.com/bytedance/Elkeid/tree/main/plugins/baseline): Responsible for detecting baseline risks based on baseline check policies.
* [**Elkeid Data Format**](server/docs/ElkeidData.xlsx)
* [**Elkeid Data Usage Tutorial**](elkeidup/raw_data_usage_tutorial/raw_data_usage_tutorial-zh_CN.md)


## Elkeid Backend Ability
* **[Elkeid AgentCenter](server/agent_center)** Responsible for communicating with the Agent, collecting Agent data and simply processing it and then summing it into the MQ, is also responsible for the management of the Agent, including Agent upgrade, configuration modification, task distribution, etc.
* **[Elkeid ServiceDiscovery](server/service_discovery)** Each component in the background needs to register and synchronize service information with the component regularly, so as to ensure that the instances in each service module are visible to each other and facilitate direct communication.
* **[Elkeid Manager](server/manager)** Responsible for the management of the entire backend, and provide related query and management API.
* **[Elkeid Console](server/web_console)** Elkeid Front-end
* **[Elkeid HUB](https://github.com/bytedance/Elkeid-HUB)** Elkeid HIDS RuleEngine



## Elkeid Function List

| Ability List                                           | Elkeid Community Edition | Elkeid Enterprise Edition |
|--------------------------------------------------------|--------------------------|---------------------------|
| Linux  runtime data collection                         | :white_check_mark:       | :white_check_mark:        |
| RASP probe                                             | :white_check_mark:       | :white_check_mark:        |
| K8s Audit Log collection                               | :white_check_mark:       | :white_check_mark:        |
| Agent control plane                                    | :white_check_mark:       | :white_check_mark:        |
| Host Status and Details                                | :white_check_mark:       | :white_check_mark:        |
| Extortion bait                                         | :ng_man:                 | :white_check_mark:        |
| Asset collection                                       | :white_check_mark:       | :white_check_mark:        |
| Asset Collection Enhancements                          | :ng_man:                 | :white_check_mark:        |
| K8s asset collection                                   | :white_check_mark:       | :white_check_mark:        |
| Exposure and Vulnerability Analysis                    | :ng_man:                 | :white_check_mark:        |
| Host/Container Basic Intrusion Detection               | `few samples`            | :white_check_mark:        |
| Host/Container Behavioral Sequence Intrusion Detection | :ng_man:                 | :white_check_mark:        |
| RASP Basic Intrusion Detection                         | `few samples`            | :white_check_mark:        |
| RASP Behavioral Sequence Intrusion Detection           | :ng_man:                 | :white_check_mark:        |
| K8S Basic Intrusion Detection                          | `few samples`            | :white_check_mark:        |
| K8S Behavioral Sequence Intrusion Detection            | :ng_man:                 | :white_check_mark:        |
| K8S Threat Analysis                                    | :ng_man:                 | :white_check_mark:        |
| Alarm traceability (behavior traceability)             | :ng_man:                 | :white_check_mark:        |
| Alarm traceability (resident traceability)             | :ng_man:                 | :white_check_mark:        |
| Alert Whitelist                                        | :white_check_mark:       | :white_check_mark:        |
| Multi-alarm aggregation capability                     | :ng_man:                 | :white_check_mark:        |
| Threat Repsonse (Process)                              | :ng_man:                 | :white_check_mark:        |
| Threat Repsonse (Network)                              | :ng_man:                 | :white_check_mark:        |
| Threat Repsonse (File)                                 | :ng_man:                 | :white_check_mark:        |
| File isolation                                         | :ng_man:                 | :white_check_mark:        |
| Vulnerability discovery                                | `few vuln info`          | :white_check_mark:        |
| Vulnerability information hot update                   | :ng_man:                 | :white_check_mark:        |
| Baseline check                                         | `few baseline rules`     | :white_check_mark:        |
| Application Vulnerability Hotfix                       | :ng_man:                 | :white_check_mark:        |
| Virus scan                                             | :white_check_mark:       | :white_check_mark:        |
| User behavior log analysis                             | :ng_man:                 | :white_check_mark:        |
| Agent Plugin management                                | :white_check_mark:       | :white_check_mark:        |
| System monitoring                                      | :white_check_mark:       | :white_check_mark:        |
| System Management                                      | :white_check_mark:       | :white_check_mark:        |
| Windows Support                                        | :ng_man:                 | :white_check_mark:        |
| Honey pot                                              | :ng_man:                 | :oncoming_automobile:     |
| Active defense                                         | :ng_man:                 | :oncoming_automobile:     |
| Cloud virus analysis                                   | :ng_man:                 | :oncoming_automobile:     |
| File-integrity monitoring                              | :ng_man:                 | :oncoming_automobile:     |




## Front-end Display (Community Edition)
**Security overview**
<img src=""png/console0.png"" style=""float:left;""/>

**K8s security alert list**

<img src=""png/console1.png"" style=""float:left;""/>

**K8s pod list**

<img src=""png/console2.png"" style=""float:left;""/>

****

**Host overview**

<img src=""png/console3.png"" style=""float:left;""/>

**Resource fingerprint**

<img src=""png/console4.png"" style=""float:left;""/>

**intrusion alert overwiew**

<img src=""png/console5.png"" style=""float:left;""/>

**Vulnerability**

<img src=""png/console6.png"" style=""float:left;""/>

**Baseline check**

<img src=""png/console7.png"" style=""float:left;""/>

**Virus scan**

<img src=""png/console8.png"" style=""float:left;""/>

**Backend hosts monitoring**

<img src=""png/console9.png"" style=""float:left;""/>

**Backend service monitoring**

<img src=""png/console10.png"" style=""float:left;""/>


## Console User Guide
* **[ELkeid Console User Guide](server/docs/console_tutorial/Elkeid_Console_manual.md)**


## Quick Start
* **[Deploy by Elkeidup](elkeidup/README.md)**

## Contact us && Cooperation

<img src=""png/Lark.png"" width=""40%"" style=""float:left;""/>

*Lark Group*



## About Elkeid Enterprise Edition

Elkeid Enterprise Edition supports separate intrusion detection rules(like the HIDS, RASP, K8s) sales, as well as full capacity sales.

If interested in Elkeid Enterprise Edition please contact elkeid@bytedance.com


## Elkeid Docs
For more details and latest updates, see [Elkeid docs](https://elkeid.bytedance.com/English/).


## License
* Elkeid Driver: GPLv2
* Elkeid RASP: Apache-2.0
* Elkeid Agent: Apache-2.0
* Elkeid Server: Apache-2.0
* Elkeid Console: [Elkeid License](server/web_console/LICENSE)
* Elkeid HUB: [Elkeid License](https://github.com/bytedance/Elkeid-HUB/blob/main/LICENSE)

## 404StarLink 2.0 - Galaxy
<img src=""https://github.com/knownsec/404StarLink-Project/raw/master/logo.png"" width=""30%"" style=""float:left;""/>

Elkeid has joined 404Team [404StarLink 2.0 - Galaxy](https://github.com/knownsec/404StarLink2.0-Galaxy)
","Elkeid has the ability for host layer intrusion detection and malicious file
identification. The host can meet the anti-intrusion security requirements of
the host and the container on it. The powerful kernel-level data collection
capability at the bottom of Elkeid can satisfy the desire of most security
analyst for host- level data. The current open source capabilities mainly
include: on-device data/asset/partial collection capabilities, RASP probe parts,
etc., and are consistent with the internal version of ByteDance."
794,Datafaker is a large-scale test data and flow test data generation tool. Datafaker fakes data and inserts to  varied data sources. 测试数据生成工具,"Datafaker - Tool for faking data
=========

[![License](https://img.shields.io/badge/license-Apache%202-4EB1BA.svg)](https://www.apache.org/licenses/LICENSE-2.0.html)

[![Stargazers over time](https://starchart.cc/gangly/datafaker.svg)](https://starchart.cc/gangly/datafaker)
   
English | [中文](doc/zh_CN/README.md)


## 1. Introduction

Datafaker is a large-scale test data and flow test data generation tool. It is compatible with python2.7 and python3.4+. Welcome to download and use. The github address is:

https://github.com/gangly/datafaker

Document sync updates on github

## 2. Background
In the software development testing process, test data is often needed. These scenarios include:

- Backend development.
After creating a new table, you need to construct database test data and generate interface data for use by the front end.
- Database performance test.
Generates a lot of test data to test database performance
- Stream data test.
For kafka streaming data, it is necessary to continuously generate test data to write to kafka.

After research, there is currently no open source test data generation tool for generating data with similar structure in mysql table. The common method is to manually create several pieces of data into the database. The disadvantage of this method is

- Wasting work hours.
Needs to construct different data for fields of different data types of the table
- Small amount of data.
If you need to construct a lot of data, you can't do it manually.
- Not accurate enough.
For example, you need to construct a mailbox (satisfying a certain format), a phone number (determined number of digits), an ip address (fixed format), age (cannot be negative, have a size range), and so on. These test data have certain restrictions or rules, and the manual construction may not meet the data range or some format requirements, resulting in the backend program error.
- Multi-table association.
The amount of data created manually is small, and the primary key in multiple tables may not be associated with, or associated with no data.
- Dynamic random write.
For example, for streaming data, you need to write kafka randomly every few seconds. Or dynamically insert mysql randomly, manual operation is relatively cumbersome, and it is not good to count the number of data written.

In response to these current pain points, datafaker came into being. Datafaker is a multi-data source test data construction tool that can simulate most common data types and easily solve the above pain points. Datafaker has the following features:

- Multiple data types.
Includes common database field types (integer, float, character), custom types (IP address, mailbox, ID number, etc.)
- Simulate multi-table association data
By formulating some fields as enumerated types (randomly selected from the specified data list), in the case of a large amount of data, it can ensure that multiple tables can be associated with each other and query data.
- Support batch data and stream data generation, and specify stream data interval time
- Support multiple data output methods, including screen printing, files and remote data sources
- Support for multiple data sources. Currently supports relational databases, Hive, Kafka. Will be extended to Mongo, ES and other data sources.
- Can specify the output format, currently supports text, json

## 3. Architecture
Datafaker is written in python and supports python2.7, python3.4+. The current version has been released on pypi.


<!-- <div align=center><img -->
<!-- src=""https://github.com/gangly/datafaker/blob/master/doc/img/datafaker.png"" width=""500"" height=""600"" alt=""软件架构""/> -->
<!-- </div> -->

![architectur](doc/img/datafaker.png)

The architecture diagram completely shows the execution process of the tool. From the figure, the tool has gone through five modules:

- Parameter parser. Parse the commands that the user enters from the terminal command line.
- Metadata parser. Users can specify metadata from local files or remote data source tables. After the parser obtains the content of the file, the text content is parsed into table field metadata and data construction rules according to the rules.
- Data construction engine. The construction engine constructs rules based on the data generated by the metadata parser, simulating the generation of different types of data.
- Data routing. According to different data output types, it is divided into batch data and stream data generation. Stream data can specify the frequency of generation. The data is then converted to a user-specified format for output to a different data source.
- Data source adapter. Adapt to different data sources and import the data into the data source.

## 4. Installation

#### Method 1, install from source code:
Download the source code, unzip and install:
```bash
python setup.py install
 ```

#### Method 2, use pip:
```bash
pip install datafaker
```

#### Upgrade tool
```bash
pip install datafaker --upgrade
```

#### Uninstall tool
```bash
pip uninstall datafaker
```

#### Install require package
| data source | package | note |
| -------- | -------- | ------ |
|mysql/tidb| mysql-python/mysqlclient | windows+python3 use mysqlclient|
|oracle| cx-Oracle | need some oracle lib |
|postgresql/redshift | psycopg2 |  |
| sqlserver | pyodbc |  mssql+pyodbc://mssql-v  |
|Hbase | happybase,thrift | |
|es | elasticsearch | |
|hive | pyhive | |
|kafka | kafka-python | |

## 5. examples

[usage example(使用举例)](doc/UseExample.md)


## 6. command parameters

[parameters detail(命令行参数)](doc/cmdParameters.md)


## 7. construction rule

[construction rule(构造规则)](doc/ConstructionRule.md)

## 8. note

[note(注意事项)](doc/note.md)

## 9. Release note
[Release note(发布记录)](doc/release_note.md)
_____

**Give a star or donate a coffee to the author**
- 给作者点个star或请作者喝杯咖啡


![pay](doc/img/微信pay.png)




","Datafaker is a large-scale test data and flow test data generation tool. It is
written in python and supports python2.7, python3.4+. The current version has
been released on pypypi.org."
1176,🤖 Telegram Bot API PHP SDK. Lets you build Telegram Bots easily! Supports Laravel out of the box.,"[![Telegram Bot API PHP SDK](https://user-images.githubusercontent.com/1915268/75023827-7879f780-54be-11ea-98c1-436a14e7e633.png)][link-repo]

<p align=""center"">
<a href=""https://phpchat.co""><img src=""https://img.shields.io/badge/Slack-PHP%20Chat-5c6aaa.svg?logo=slack&labelColor=4A154B&style=for-the-badge"" alt=""Join PHP Chat""/></a>
<a href=""https://t.me/PHPChatCo""><img src=""https://img.shields.io/badge/Chat-on%20Telegram-2CA5E0.svg?logo=telegram&style=for-the-badge"" alt=""Chat on Telegram""/></a>
<a href=""https://github.com/irazasyed/telegram-bot-sdk/actions""><img src=""https://img.shields.io/github/workflow/status/irazasyed/telegram-bot-sdk/CI.svg?style=for-the-badge"" alt=""Build Status""/></a>
<a href=""https://github.com/irazasyed/telegram-bot-sdk/releases""><img src=""https://img.shields.io/github/release/irazasyed/telegram-bot-sdk.svg?style=for-the-badge"" alt=""Latest Version""/></a>
<a href=""https://packagist.org/packages/irazasyed/telegram-bot-sdk""><img src=""https://img.shields.io/packagist/dt/irazasyed/telegram-bot-sdk.svg?style=for-the-badge"" alt=""Total Downloads""/></a>
</p>

Telegram Bot API - PHP SDK
==========================

> Telegram Bot PHP SDK lets you develop Telegram Bots in PHP easily! Supports Laravel out of the box.
>
> [Telegram Bot API][link-telegram-bot-api] is an HTTP-based interface created for developers keen on building bots for Telegram.
> 
> To learn more about the Telegram Bot API, please consult the [Introduction to Bots][link-telegram-bot-api] and [Bot FAQ](https://core.telegram.org/bots/faq) on official Telegram site.
>
> To get started writing your bots using this SDK, Please refer the [documentation][link-docs].

## Documentation

Documentation for the SDK can be found on the [website][link-docs].

## Are You Using Telegram Bot SDK?

If you're using this SDK to build your Telegram Bots, We'd love to know and share the bot with the world. Tell us about it - **[here][link-sdk-users]**

Check out the [Who's Using Telegram Bot SDK][link-sdk-users] wiki page to know more about what people have been building with this SDK.

## Additional information

Any issues, feedback, suggestions or questions please use issue tracker [here][link-issues].

## Contributing

Thank you for considering contributing to the project. Please review the [CONTRIBUTING](https://telegram-bot-sdk.readme.io/docs/contributing) guidelines before submitting any pull requests.

## Credits

- [Syed Irfaq R.][link-author]
- [All Contributors][link-contributors]

## Disclaimer

This project and its author is neither associated, nor affiliated with [Telegram](https://telegram.org/) in anyway.
See License section for more details.

## License

This project is released under the [BSD 3-Clause][link-license] License.

[link-author]: https://github.com/irazasyed
[link-repo]: https://github.com/irazasyed/telegram-bot-sdk
[link-issues]: https://github.com/irazasyed/telegram-bot-sdk/issues
[link-contributors]: https://github.com/irazasyed/telegram-bot-sdk/contributors
[link-docs]: https://telegram-bot-sdk.readme.io/docs
[link-license]: https://github.com/irazasyed/telegram-bot-sdk/blob/master/LICENSE
[link-sdk-users]: https://github.com/irazasyed/telegram-bot-sdk/wiki/Who's-Using-Telegram-Bot-SDK%3F
[link-telegram-bot-api]: https://core.telegram.org/bots

[![FOSSA Status](https://app.fossa.io/api/projects/git%2Bgithub.com%2Firazasyed%2Ftelegram-bot-sdk.svg?type=large)](https://app.fossa.io/projects/git%2Bgithub.com%2Firazasyed%2Ftelegram-bot-sdk?ref=badge_large)
","Telegram Bot API is an HTTP-based interface created for developers keen on
building bots for Telegram. It lets you develop Telegram Bots in PHP easily!
Supports Laravel out of the box. It is released under the [Clause-Clause]
License."
325,"GUI-based Python code generator for data science, extension to Jupyter Lab, Jupyter Notebook and Google Colab.","<img src=""https://i.esdrop.com/d/7o0dj05m8rnz/JNGCMedl18.png"" width=""45%"">

[![PyPI version shields.io](https://img.shields.io/pypi/v/jupyterlab-visualpython)](https://pypi.python.org/pypi/jupyterlab-visualpython/)
![Python: 3.x](https://img.shields.io/badge/Python-3.x-yellowgreen)
[![License: GPLv3](https://img.shields.io/badge/License-GPLv3-brightgreen)](https://github.com/visualpython/visualpython/blob/main/LICENSE)
[![Downloads](https://static.pepy.tech/personalized-badge/visualpython?period=total&units=international_system&left_color=grey&right_color=orange&left_text=Downloads)](https://pepy.tech/project/visualpython)
[![Issues: ](https://img.shields.io/github/issues/visualpython/visualpython?color=%23FF6347)](https://github.com/visualpython/visualpython/issues)
[![Binder](https://mybinder.org/badge_logo.svg)](https://mybinder.org/v2/gh/visualpython/visualpython-binder/HEAD?labpath=index.ipynb)

## Introduction
Visual Python is a GUI-based Python code generator, developed on the **Jupyter Lab**, **Jupyter Notebook** and **Google Colab** as an extension. <br>
Visual Python is an open source project started for students who struggle with coding during Python classes for data science.

<br>

Try Visual Python if you would like to: <br>
* manage big data with minimal coding skills. <br>
* help students / business analysts / researchers to overcome learning barriers for Python. <br>
* save & reuse repeatedly used codes(snippets). <br>

<br>
<img src=""https://github.com/visualpython/visualpython/blob/main/img/Visual%20Python_2.2.8.gif?raw=true"" width=""95%"">

## Getting Started with Jupyter Lab

### 1. Requirements

Visual Python is an extension to Jupyter Lab, so you must have Jupyter Lab installed already.<br>
- Python version 3.x
- Jupyter lab environment

### 2. How to Install

**1)  Install package from**
```
pip install jupyterlab-visualpython
```

**2)  Activate Visual Python on Jupyter Lab**

Click orange square button on the right side of the Jupyter Lab. 

## Getting Started with Jupyter Notebook

### 1. Requirements

Visual Python is an extension to Jupyter Notebook, so you must have Jupyter Notebook installed already.<br>
- Python version 3.x
- Jupyter notebook environment

### 2. How to Install

**1)  Install package from**
```
pip install visualpython
```

**2)  Enable the package**
```
visualpy install
```

**3)  Activate Visual Python on Jupyter Notebook**

Click orange square button on the right side of the Jupyter Notebook menu bar. 

### 3. Package Control Info
* Usage: visualpy **[option]** <br>
* Optional arguments:

```
help       - show help menu
install    - install packages
uninstall  - uninstall packages
upgrade    - version upgrade
version    - version check
```

## Getting Started with Google Colab
### 1. Requirements

Visual Python is an extension to Google Colab, so you must have Google Colab opened.<br>
- Google Colab

### 2. How to Install

**1)  Install package using Chrome Web Store**
- [Link to Visual Python for Colab](https://chrome.google.com/webstore/detail/visual-python-for-colab/ccmkpknjfagaldcgidgcipbpdipfopob)

**2)  Open Google Colab**
- [Link to Google Colab](https://colab.research.google.com/)

**3)  Activate Visual Python on Google Colab**

## Contributing
If you are interested in contributing to the Visual Python, please see [`CONTRIBUTING.md`](CONTRIBUTING.md). <br>
All skills from programmers, non-programmers, designers are welcomed.

* Programming Guide: [Developer Documentation](https://bird-energy-733.notion.site/visualpython-docs-85c0274ff7564747bb8e8d77909fc8b7)
* GUI Design Guide: [Visual Python GUI Kit 1.0](https://www.figma.com/community/file/976035035360380841)

## License
GNU GPLv3 with Visual Python special exception (See LICENSE file).

## Mission & Vision
**Mission** <br>
To support technology and education so that anyone can leverage big data analytical skills to create a variety of social values.

**Vision** <br>
To create an environment where everyone can learn and use big data analytical skills easily.

## Support Visual Python
Love Visual Python? <br>
Your support will help us continue to actively develop and improve Visual Python.☕

<a href=""https://www.buymeacoffee.com/visualpython"" target=""_blank""><img src=""https://img.buymeacoffee.com/button-api/?text=Buy me a coffee&emoji=&slug=visualpython&button_colour=ffa238&font_colour=000000&font_family=Comic&outline_colour=000000&coffee_colour=FFDD00""></a>
","Visual Python is an open source project started for students who struggle with
coding during Python classes for data science. It is an extension to Jupyter Lab
and Google Colab. It allows you to manage big data with minimal coding skills.
All skills from programmers, non-programmers, designers are welcomed to
contribute to the Visual Python project. The project is free and open-source,
with a free version of Visual Python 2.2.8 available on GitHub. The code
generator is written in Python and is available as a command line tool."
2511,Learning operating system development using Linux kernel and Raspberry Pi,"# Learning operating system development using Linux kernel and Raspberry Pi

This repository contains a step-by-step guide that teaches how to create a simple operating system (OS) kernel from scratch. I call this OS Raspberry Pi OS or just RPi OS. The RPi OS source code is largely based on [Linux kernel](https://github.com/torvalds/linux), but the OS has very limited functionality and supports only [Raspberry PI 3](https://www.raspberrypi.org/products/raspberry-pi-3-model-b/). 

Each lesson is designed in such a way that it first explains how some kernel feature is implemented in the RPi OS, and then it tries to demonstrate how the same functionality works in the Linux kernel. Each lesson has a corresponding folder in the [src](https://github.com/s-matyukevich/raspberry-pi-os/tree/master/src) directory, which contains a snapshot of the OS source code at the time when the lesson had just been completed. This allows the introduction of new concepts gracefully and helps readers to follow the evolution of the RPi OS. Understanding this guide doesn't require any specific OS development skills.

For more information about project goals and history, please read the [Introduction](docs/Introduction.md). The project is still under active development, if you are willing to participate - please read the [Contribution guide](docs/Contributions.md).

<p>
  <a href=""https://twitter.com/RPi_OS"" target=""_blank"">
    <img src=""https://raw.githubusercontent.com/s-matyukevich/raspberry-pi-os/master/images/twitter.png"" alt=""Follow @RPi_OS on twitter"" height=""34"" >
  </a>

  <a href=""https://www.facebook.com/groups/251043708976964/"" target=""_blank"">
    <img src=""https://raw.githubusercontent.com/s-matyukevich/raspberry-pi-os/master/images/facebook.png"" alt=""Follow Raspberry Pi OS on facebook"" height=""34"" >
  </a>

  <a href=""https://join.slack.com/t/rpi-os/shared_invite/enQtNDQ1NTg2ODc1MDEwLWVjMTZlZmMyZDE4OGEyYmMzNTY1YjljZjU5YWI1NDllOWEwMjI5YzVkM2RiMzliYjEzN2RlYmUzNzBiYmQyMjY"" target=""_blank"">
    <img src=""https://raw.githubusercontent.com/s-matyukevich/raspberry-pi-os/master/images/slack.png"" alt=""Join Raspberry Pi OS in slack"" height=""34"" >
  </a>

  <a href=""https://www.producthunt.com/upcoming/raspberry-pi-os"" target=""_blank"">
    <img src=""https://raw.githubusercontent.com/s-matyukevich/raspberry-pi-os/master/images/subscribe.png"" alt=""Subscribe for updates"" height=""34"" >
  </a>
</p>

## Table of Contents

* **[Introduction](docs/Introduction.md)**
* **[Contribution guide](docs/Contributions.md)**
* **[Prerequisites](docs/Prerequisites.md)**
* **Lesson 1: Kernel Initialization** 
  * 1.1 [Introducing RPi OS, or bare metal ""Hello, world!""](docs/lesson01/rpi-os.md)
  * Linux
    * 1.2 [Project structure](docs/lesson01/linux/project-structure.md)
    * 1.3 [Kernel build system](docs/lesson01/linux/build-system.md) 
    * 1.4 [Startup sequence](docs/lesson01/linux/kernel-startup.md)
  * 1.5 [Exercises](docs/lesson01/exercises.md)
* **Lesson 2: Processor initialization**
  * 2.1 [RPi OS](docs/lesson02/rpi-os.md)
  * 2.2 [Linux](docs/lesson02/linux.md)
  * 2.3 [Exercises](docs/lesson02/exercises.md)
* **Lesson 3: Interrupt handling**
  * 3.1 [RPi OS](docs/lesson03/rpi-os.md)
  * Linux
    * 3.2 [Low level exception handling](docs/lesson03/linux/low_level-exception_handling.md) 
    * 3.3 [Interrupt controllers](docs/lesson03/linux/interrupt_controllers.md)
    * 3.4 [Timers](docs/lesson03/linux/timer.md)
  * 3.5 [Exercises](docs/lesson03/exercises.md)
* **Lesson 4: Process scheduler**
  * 4.1 [RPi OS](docs/lesson04/rpi-os.md) 
  * Linux
    * 4.2 [Scheduler basic structures](docs/lesson04/linux/basic_structures.md)
    * 4.3 [Forking a task](docs/lesson04/linux/fork.md)
    * 4.4 [Scheduler](docs/lesson04/linux/scheduler.md)
  * 4.5 [Exercises](docs/lesson04/exercises.md)
* **Lesson 5: User processes and system calls** 
  * 5.1 [RPi OS](docs/lesson05/rpi-os.md) 
  * 5.2 [Linux](docs/lesson05/linux.md)
  * 5.3 [Exercises](docs/lesson05/exercises.md)
* **Lesson 6: Virtual memory management**
  * 6.1 [RPi OS](docs/lesson06/rpi-os.md) 
  * 6.2 Linux (In progress)
  * 6.3 [Exercises](docs/lesson06/exercises.md)
* **Lesson 7: Signals and interrupt waiting** (To be done)
* **Lesson 8: File systems** (To be done)
* **Lesson 9: Executable files (ELF)** (To be done)
* **Lesson 10: Drivers** (To be done)
* **Lesson 11: Networking** (To be done)

","This repository contains a step-by-step guide that teaches how to create a
simple operating system (OS) kernel from scratch. I call this OS Raspberry Pi OS
or just RPi OS. Understanding this guide doesn't require any specific OS
development skills. The project is still under active development, if you are
willing to participate."
209,Rich is a Python library for rich text and beautiful formatting in the terminal.,"[![Supported Python Versions](https://img.shields.io/pypi/pyversions/rich/13.2.0)](https://pypi.org/project/rich/) [![PyPI version](https://badge.fury.io/py/rich.svg)](https://badge.fury.io/py/rich)

[![Downloads](https://pepy.tech/badge/rich/month)](https://pepy.tech/project/rich)
[![codecov](https://img.shields.io/codecov/c/github/Textualize/rich?label=codecov&logo=codecov)](https://codecov.io/gh/Textualize/rich)
[![Rich blog](https://img.shields.io/badge/blog-rich%20news-yellowgreen)](https://www.willmcgugan.com/tag/rich/)
[![Twitter Follow](https://img.shields.io/twitter/follow/willmcgugan.svg?style=social)](https://twitter.com/willmcgugan)

![Logo](https://github.com/textualize/rich/raw/master/imgs/logo.svg)

[English readme](https://github.com/textualize/rich/blob/master/README.md)
 • [简体中文 readme](https://github.com/textualize/rich/blob/master/README.cn.md)
 • [正體中文 readme](https://github.com/textualize/rich/blob/master/README.zh-tw.md)
 • [Lengua española readme](https://github.com/textualize/rich/blob/master/README.es.md)
 • [Deutsche readme](https://github.com/textualize/rich/blob/master/README.de.md)
 • [Läs på svenska](https://github.com/textualize/rich/blob/master/README.sv.md)
 • [日本語 readme](https://github.com/textualize/rich/blob/master/README.ja.md)
 • [한국어 readme](https://github.com/textualize/rich/blob/master/README.kr.md)
 • [Français readme](https://github.com/textualize/rich/blob/master/README.fr.md)
 • [Schwizerdütsch readme](https://github.com/textualize/rich/blob/master/README.de-ch.md)
 • [हिन्दी readme](https://github.com/textualize/rich/blob/master/README.hi.md)
 • [Português brasileiro readme](https://github.com/textualize/rich/blob/master/README.pt-br.md)
 • [Italian readme](https://github.com/textualize/rich/blob/master/README.it.md)
 • [Русский readme](https://github.com/textualize/rich/blob/master/README.ru.md)
 • [Indonesian readme](https://github.com/textualize/rich/blob/master/README.id.md)
 • [فارسی readme](https://github.com/textualize/rich/blob/master/README.fa.md)
 • [Türkçe readme](https://github.com/textualize/rich/blob/master/README.tr.md)


Rich is a Python library for _rich_ text and beautiful formatting in the terminal.

The [Rich API](https://rich.readthedocs.io/en/latest/) makes it easy to add color and style to terminal output. Rich can also render pretty tables, progress bars, markdown, syntax highlighted source code, tracebacks, and more — out of the box.

![Features](https://github.com/textualize/rich/raw/master/imgs/features.png)

For a video introduction to Rich see [calmcode.io](https://calmcode.io/rich/introduction.html) by [@fishnets88](https://twitter.com/fishnets88).

See what [people are saying about Rich](https://www.willmcgugan.com/blog/pages/post/rich-tweets/).

## Compatibility

Rich works with Linux, OSX, and Windows. True color / emoji works with new Windows Terminal, classic terminal is limited to 16 colors. Rich requires Python 3.7 or later.

Rich works with [Jupyter notebooks](https://jupyter.org/) with no additional configuration required.

## Installing

Install with `pip` or your favorite PyPI package manager.

```sh
python -m pip install rich
```

Run the following to test Rich output on your terminal:

```sh
python -m rich
```

## Rich Print

To effortlessly add rich output to your application, you can import the [rich print](https://rich.readthedocs.io/en/latest/introduction.html#quick-start) method, which has the same signature as the builtin Python function. Try this:

```python
from rich import print

print(""Hello, [bold magenta]World[/bold magenta]!"", "":vampire:"", locals())
```

![Hello World](https://github.com/textualize/rich/raw/master/imgs/print.png)

## Rich REPL

Rich can be installed in the Python REPL, so that any data structures will be pretty printed and highlighted.

```python
>>> from rich import pretty
>>> pretty.install()
```

![REPL](https://github.com/textualize/rich/raw/master/imgs/repl.png)

## Using the Console

For more control over rich terminal content, import and construct a [Console](https://rich.readthedocs.io/en/latest/reference/console.html#rich.console.Console) object.

```python
from rich.console import Console

console = Console()
```

The Console object has a `print` method which has an intentionally similar interface to the builtin `print` function. Here's an example of use:

```python
console.print(""Hello"", ""World!"")
```

As you might expect, this will print `""Hello World!""` to the terminal. Note that unlike the builtin `print` function, Rich will word-wrap your text to fit within the terminal width.

There are a few ways of adding color and style to your output. You can set a style for the entire output by adding a `style` keyword argument. Here's an example:

```python
console.print(""Hello"", ""World!"", style=""bold red"")
```

The output will be something like the following:

![Hello World](https://github.com/textualize/rich/raw/master/imgs/hello_world.png)

That's fine for styling a line of text at a time. For more finely grained styling, Rich renders a special markup which is similar in syntax to [bbcode](https://en.wikipedia.org/wiki/BBCode). Here's an example:

```python
console.print(""Where there is a [bold cyan]Will[/bold cyan] there [u]is[/u] a [i]way[/i]."")
```

![Console Markup](https://github.com/textualize/rich/raw/master/imgs/where_there_is_a_will.png)

You can use a Console object to generate sophisticated output with minimal effort. See the [Console API](https://rich.readthedocs.io/en/latest/console.html) docs for details.

## Rich Inspect

Rich has an [inspect](https://rich.readthedocs.io/en/latest/reference/init.html?highlight=inspect#rich.inspect) function which can produce a report on any Python object, such as class, instance, or builtin.

```python
>>> my_list = [""foo"", ""bar""]
>>> from rich import inspect
>>> inspect(my_list, methods=True)
```

![Log](https://github.com/textualize/rich/raw/master/imgs/inspect.png)

See the [inspect docs](https://rich.readthedocs.io/en/latest/reference/init.html#rich.inspect) for details.

# Rich Library

Rich contains a number of builtin _renderables_ you can use to create elegant output in your CLI and help you debug your code.

Click the following headings for details:

<details>
<summary>Log</summary>

The Console object has a `log()` method which has a similar interface to `print()`, but also renders a column for the current time and the file and line which made the call. By default Rich will do syntax highlighting for Python structures and for repr strings. If you log a collection (i.e. a dict or a list) Rich will pretty print it so that it fits in the available space. Here's an example of some of these features.

```python
from rich.console import Console
console = Console()

test_data = [
    {""jsonrpc"": ""2.0"", ""method"": ""sum"", ""params"": [None, 1, 2, 4, False, True], ""id"": ""1"",},
    {""jsonrpc"": ""2.0"", ""method"": ""notify_hello"", ""params"": [7]},
    {""jsonrpc"": ""2.0"", ""method"": ""subtract"", ""params"": [42, 23], ""id"": ""2""},
]

def test_log():
    enabled = False
    context = {
        ""foo"": ""bar"",
    }
    movies = [""Deadpool"", ""Rise of the Skywalker""]
    console.log(""Hello from"", console, ""!"")
    console.log(test_data, log_locals=True)


test_log()
```

The above produces the following output:

![Log](https://github.com/textualize/rich/raw/master/imgs/log.png)

Note the `log_locals` argument, which outputs a table containing the local variables where the log method was called.

The log method could be used for logging to the terminal for long running applications such as servers, but is also a very nice debugging aid.

</details>
<details>
<summary>Logging Handler</summary>

You can also use the builtin [Handler class](https://rich.readthedocs.io/en/latest/logging.html) to format and colorize output from Python's logging module. Here's an example of the output:

![Logging](https://github.com/textualize/rich/raw/master/imgs/logging.png)

</details>

<details>
<summary>Emoji</summary>

To insert an emoji in to console output place the name between two colons. Here's an example:

```python
>>> console.print("":smiley: :vampire: :pile_of_poo: :thumbs_up: :raccoon:"")
😃 🧛 💩 👍 🦝
```

Please use this feature wisely.

</details>

<details>
<summary>Tables</summary>

Rich can render flexible [tables](https://rich.readthedocs.io/en/latest/tables.html) with unicode box characters. There is a large variety of formatting options for borders, styles, cell alignment etc.

![table movie](https://github.com/textualize/rich/raw/master/imgs/table_movie.gif)

The animation above was generated with [table_movie.py](https://github.com/textualize/rich/blob/master/examples/table_movie.py) in the examples directory.

Here's a simpler table example:

```python
from rich.console import Console
from rich.table import Table

console = Console()

table = Table(show_header=True, header_style=""bold magenta"")
table.add_column(""Date"", style=""dim"", width=12)
table.add_column(""Title"")
table.add_column(""Production Budget"", justify=""right"")
table.add_column(""Box Office"", justify=""right"")
table.add_row(
    ""Dec 20, 2019"", ""Star Wars: The Rise of Skywalker"", ""$275,000,000"", ""$375,126,118""
)
table.add_row(
    ""May 25, 2018"",
    ""[red]Solo[/red]: A Star Wars Story"",
    ""$275,000,000"",
    ""$393,151,347"",
)
table.add_row(
    ""Dec 15, 2017"",
    ""Star Wars Ep. VIII: The Last Jedi"",
    ""$262,000,000"",
    ""[bold]$1,332,539,889[/bold]"",
)

console.print(table)
```

This produces the following output:

![table](https://github.com/textualize/rich/raw/master/imgs/table.png)

Note that console markup is rendered in the same way as `print()` and `log()`. In fact, anything that is renderable by Rich may be included in the headers / rows (even other tables).

The `Table` class is smart enough to resize columns to fit the available width of the terminal, wrapping text as required. Here's the same example, with the terminal made smaller than the table above:

![table2](https://github.com/textualize/rich/raw/master/imgs/table2.png)

</details>

<details>
<summary>Progress Bars</summary>

Rich can render multiple flicker-free [progress](https://rich.readthedocs.io/en/latest/progress.html) bars to track long-running tasks.

For basic usage, wrap any sequence in the `track` function and iterate over the result. Here's an example:

```python
from rich.progress import track

for step in track(range(100)):
    do_step(step)
```

It's not much harder to add multiple progress bars. Here's an example taken from the docs:

![progress](https://github.com/textualize/rich/raw/master/imgs/progress.gif)

The columns may be configured to show any details you want. Built-in columns include percentage complete, file size, file speed, and time remaining. Here's another example showing a download in progress:

![progress](https://github.com/textualize/rich/raw/master/imgs/downloader.gif)

To try this out yourself, see [examples/downloader.py](https://github.com/textualize/rich/blob/master/examples/downloader.py) which can download multiple URLs simultaneously while displaying progress.

</details>

<details>
<summary>Status</summary>

For situations where it is hard to calculate progress, you can use the [status](https://rich.readthedocs.io/en/latest/reference/console.html#rich.console.Console.status) method which will display a 'spinner' animation and message. The animation won't prevent you from using the console as normal. Here's an example:

```python
from time import sleep
from rich.console import Console

console = Console()
tasks = [f""task {n}"" for n in range(1, 11)]

with console.status(""[bold green]Working on tasks..."") as status:
    while tasks:
        task = tasks.pop(0)
        sleep(1)
        console.log(f""{task} complete"")
```

This generates the following output in the terminal.

![status](https://github.com/textualize/rich/raw/master/imgs/status.gif)

The spinner animations were borrowed from [cli-spinners](https://www.npmjs.com/package/cli-spinners). You can select a spinner by specifying the `spinner` parameter. Run the following command to see the available values:

```
python -m rich.spinner
```

The above command generates the following output in the terminal:

![spinners](https://github.com/textualize/rich/raw/master/imgs/spinners.gif)

</details>

<details>
<summary>Tree</summary>

Rich can render a [tree](https://rich.readthedocs.io/en/latest/tree.html) with guide lines. A tree is ideal for displaying a file structure, or any other hierarchical data.

The labels of the tree can be simple text or anything else Rich can render. Run the following for a demonstration:

```
python -m rich.tree
```

This generates the following output:

![markdown](https://github.com/textualize/rich/raw/master/imgs/tree.png)

See the [tree.py](https://github.com/textualize/rich/blob/master/examples/tree.py) example for a script that displays a tree view of any directory, similar to the linux `tree` command.

</details>

<details>
<summary>Columns</summary>

Rich can render content in neat [columns](https://rich.readthedocs.io/en/latest/columns.html) with equal or optimal width. Here's a very basic clone of the (MacOS / Linux) `ls` command which displays a directory listing in columns:

```python
import os
import sys

from rich import print
from rich.columns import Columns

directory = os.listdir(sys.argv[1])
print(Columns(directory))
```

The following screenshot is the output from the [columns example](https://github.com/textualize/rich/blob/master/examples/columns.py) which displays data pulled from an API in columns:

![columns](https://github.com/textualize/rich/raw/master/imgs/columns.png)

</details>

<details>
<summary>Markdown</summary>

Rich can render [markdown](https://rich.readthedocs.io/en/latest/markdown.html) and does a reasonable job of translating the formatting to the terminal.

To render markdown import the `Markdown` class and construct it with a string containing markdown code. Then print it to the console. Here's an example:

```python
from rich.console import Console
from rich.markdown import Markdown

console = Console()
with open(""README.md"") as readme:
    markdown = Markdown(readme.read())
console.print(markdown)
```

This will produce output something like the following:

![markdown](https://github.com/textualize/rich/raw/master/imgs/markdown.png)

</details>

<details>
<summary>Syntax Highlighting</summary>

Rich uses the [pygments](https://pygments.org/) library to implement [syntax highlighting](https://rich.readthedocs.io/en/latest/syntax.html). Usage is similar to rendering markdown; construct a `Syntax` object and print it to the console. Here's an example:

```python
from rich.console import Console
from rich.syntax import Syntax

my_code = '''
def iter_first_last(values: Iterable[T]) -> Iterable[Tuple[bool, bool, T]]:
    """"""Iterate and generate a tuple with a flag for first and last value.""""""
    iter_values = iter(values)
    try:
        previous_value = next(iter_values)
    except StopIteration:
        return
    first = True
    for value in iter_values:
        yield first, False, previous_value
        first = False
        previous_value = value
    yield first, True, previous_value
'''
syntax = Syntax(my_code, ""python"", theme=""monokai"", line_numbers=True)
console = Console()
console.print(syntax)
```

This will produce the following output:

![syntax](https://github.com/textualize/rich/raw/master/imgs/syntax.png)

</details>

<details>
<summary>Tracebacks</summary>

Rich can render [beautiful tracebacks](https://rich.readthedocs.io/en/latest/traceback.html) which are easier to read and show more code than standard Python tracebacks. You can set Rich as the default traceback handler so all uncaught exceptions will be rendered by Rich.

Here's what it looks like on OSX (similar on Linux):

![traceback](https://github.com/textualize/rich/raw/master/imgs/traceback.png)

</details>

All Rich renderables make use of the [Console Protocol](https://rich.readthedocs.io/en/latest/protocol.html), which you can also use to implement your own Rich content.

# Rich CLI


See also [Rich CLI](https://github.com/textualize/rich-cli) for a command line application powered by Rich. Syntax highlight code, render markdown, display CSVs in tables, and more, directly from the command prompt.


![Rich CLI](https://raw.githubusercontent.com/Textualize/rich-cli/main/imgs/rich-cli-splash.jpg)

# Textual

See also Rich's sister project, [Textual](https://github.com/Textualize/textual), which you can use to build sophisticated User Interfaces in the terminal.

![Textual screenshot](https://raw.githubusercontent.com/Textualize/textual/main/imgs/textual.png)

# Projects using Rich

For some examples of projects using Rich, see the [Rich Gallery](https://www.textualize.io/rich/gallery) on [Textualize.io](https://www.textualize.io).

Would you like to add your own project to the gallery? You can! Follow [these instructions](https://www.textualize.io/gallery-instructions).

<!-- This is a test, no need to translate -->
","Rich is a Python library for the Rich API. It makes it easy to add color and
style to Rich output. Rich can also render pretty tables, progress bars,
markdown and tracebacks out of the source code, highlighted in the box and more."
1442,Image Sharing Social Media App,"# ShareMe Social Media Application
![ShareMe](https://i.ibb.co/8cLfj3X/image.png)

## Introduction
This is a code repository for the corresponding video tutorial.

Using React, Tailwind & Sanity you'll learn how to build a Full Stack Social Media Application - from start to finish.

## Stay up to date with new projects
New major projects coming soon, subscribe to the mailing list to stay up to date https://jsmasterypro.com/newsletter
","This is a code repository for the corresponding video tutorial. Use React,
Tailwind & Sanity to build a Full Stack Social Media Application - from start to
finish. New major projects coming soon, subscribe to the mailing list to stay up
to date https://jsmasterypro.com/newsletter. Follow us on Twitter @JsmasteryPro
and @jsmasterpro on Facebook. We're also on Instagram and Twitter. We use the
hashtag #JSmasteryPro to promote our products."
355,"Fullstack open source Invoicing application made with MongoDB, Express, React & Nodejs (MERN)","### [accountill.com](https://accountill.com/)
# MERN Stack Invoicing Application
Built with the MERN stack (MongoDB, Express, React and NodeJS).
![Invoice](https://res.cloudinary.com/almpo/image/upload/v1637311386/invoice/invoice-app_tcz0dj.png)


## Update
I am pleased to inform you that the name of this repository has been changed from Arc Invoice to Accountill.
There are so many things coming! Stay tuned!!


Panshak
----

  * [Introduction](#introduction)
  * [Key Features](#key-features)
  * [Technologies used](#technologies-used)
      - [Client](#client)
      - [Server](#server)
      - [Database](#database)
  * [Configuration and Setup](#configuration-and-setup)
  * [Troubleshooting](#troubleshooting)
  * [Author](#author)
  * [License](#license)

## Introduction
This is a side project I've been working on. A full stack invoicing application made using the MERN stack (MongoDB, Express, React & Nodejs), specially designed for freelancers and small businesses, but can be used for almost any type of business need. With this application, you can send beautiful invoices, receipts, estimates, quotes, bills etc to your clients. Jump right off the [Live App](https://accountill.com/) and start sending invoice or download the entire [Source code](https://github.com/Panshak/accountill) and run it on your server. This project is something I've been working on in my free time so I cannot be sure that everything will work out correctly. But I'll appreciate you if can report any issue.

![Invoice Dashboard](https://res.cloudinary.com/almpo/image/upload/v1637314504/invoice/dashboard_c5z0is.png)

## Key Features
- Send invoices, receipts, estimates, quotations and bills via email
- Generate and send/download pdf invoices, receipts, estimates, quotations and bills via email
- Set due date.
- Automatic status change when payment record is added
- Payment history section for each invoice with record about payment date, payment method and extra note.
- Record partial payment of invoice.
- Clean admin dashboard for displaying all invoice statistics including total amount received, total pending, recent payments, total invoice paid, total unpaid and partially paid invoices. 
- Multiple user registration.
- Authentication using jsonwebtoken (jwt) and Google auth


## Technologies used
This project was created using the following technologies.

#### Client

- React JS
- Redux (for managing and centralizing application state)
- React-router-dom (To handle routing)
- Axios (for making api calls)
- Material UI & CSS Module (for User Interface)
- React simple Snackbar (To display success/error notifications)
- Cloudinary (to allows users to upload their business logo)
- Apex Charts (to display payment history)
- React-google-login (To enable authentication using Google)

#### Server

- Express
- Mongoose
- JWT (For authentication)
- bcryptjs (for data encryption)
- Nodemailer (for sending invoice via email)
- html-pdf (for generating invoice PDFs)

#### Database
MongoDB (MongoDB Atlas)

## Configuration and Setup
In order to run this project locally, simply fork and clone the repository or download as zip and unzip on your machine. 
- Open the project in your prefered code editor.
- Go to terminal -> New terminal (If you are using VS code)
- Split your terminal into two (run the client on one terminal and the server on the other terminal)

In the first terminal
- cd client and create a .env file in the root of your client directory.
- Supply the following credentials

```
REACT_APP_GOOGLE_CLIENT_ID = 
REACT_APP_API = http://localhost:5000
REACT_APP_URL = http://localhost:3000

```

To get your Google ClientID for authentication, go to the [credential Page ](https://console.cloud.google.com/apis/credentials) (if you are new, then [create a new project first](https://console.cloud.google.com/projectcreate) and follow the following steps;

- Click Create credentials > OAuth client ID.
- Select the Web application type.
- Name your OAuth client and click Create
- Remember to provide your domain and redirect URL so that Google identifies the origin domain to which it can display the consent screen. In development, that is going to be `http://localhost:3000` and `http://localhost:3000/login`
- Copy the Client ID and assign it to the variable `REACT_APP_GOOGLE_CLIENT_ID` in your .env file

```
$ cd client
$ npm install (to install client-side dependencies)
$ npm start (to start the client)
```
In the second terminal
- cd server and create a .env file in the root of your server directory.
- Supply the following credentials

```
DB_URL = 
PORT = 5000
SECRET = 
SMTP_HOST = 
SMTP_PORT = 
SMTP_USER = 
SMTP_PASS = 

```

Please follow [This tutorial](https://dev.to/dalalrohit/how-to-connect-to-mongodb-atlas-using-node-js-k9i) to create your mongoDB connection url, which you'll use as your DB_URL

```
$ cd server
$ npm install (to install server-side dependencies)
& npm start (to start the server)
```

## Troubleshooting
If you're getting error while trying to send or download PDF,
please run the following in your server terminal.

```
$ npm install html-pdf -g
$ npm link html-pdf
$ npm link phantomjs-prebuilt
```

## Docker

Using docker is simple. Just add the .env contextualized with the docker network.

e.g:

> goes to path ""server/.env""
```
DB_URL = mongodb://mongo:27017/arch
PORT = 5000
SECRET = 
SMTP_HOST = 
SMTP_PORT = 
SMTP_USER = 
SMTP_PASS = 
```
> goes to path ""client/.env""
```
REACT_APP_GOOGLE_CLIENT_ID = 
REACT_APP_API = http://localhost:5000
REACT_APP_URL = http://localhost
```

And run

```
docker-compose -f docker-compose.prod.yml build

And then

docker-compose -f docker-compose.prod.yml up
```

## Comment
I intend to keep adding more features to this application, so if you like it, please give it a star, that will encourage me to 
to keep improving the project.


## Author

- Twitter: [@panshak_](https://twitter.com/panshak_)
- Github: [@panshak](https://github.com/panshak)
- Linkedin: [@panshak](https://www.linkedin.com/in/panshak/)
- Email: [@ipanshak](mailto:ipanshak@gmail.com)

## License

- This project is [MIT](https://github.com/Panshak/accountill/blob/master/LICENSE.md) licensed.","Full stack invoicing application made using the MERN stack (MongoDB, Express,
React & Nodejs) specially designed for freelancers and small businesses. With
this application, you can send beautiful invoices, receipts, estimates, quotes,
bills etc to your clients. Jump right off the [Live App] and start sending
invoice or download the entire [Source code] and run it on your server. This
project is something I've been working on in my free time so I cannot be sure
that everything will work out correctly. But I'll appreciate you if can report
any issue."
1528,"😎 A curated list of amazingly awesome Ionic libraries, resources and solutions.","# Awesome Ionic [![Awesome](https://cdn.rawgit.com/sindresorhus/awesome/d7305f38d29fed78fa85652e3a63e154dd8e8829/media/badge.svg)]

<p alt=""Awesome Ionic"" align=""center""><img src=""awesome-ionic.png"" /></p>

> A curated list of awesome Ionic libraries, resources, and solutions from Ionic 1 to the latest version of the framework.

This repository is maintained by [Fikayo Adepoju](https://github.com/coderonfleek) and [Alessio Delmonti](https://github.com/Alexintosh). For discussions about PRs and contributions, contact Fikayo via DM on [twitter](https://twitter.com/coderonfleek).

# Resources by Version

- [General](#general)
- [Ionic 1 (Angularjs)](IONIC1.md)
- [Ionic Angular (2+)](#ionic-angular)
- [Ionic React](ionic-react.md)
- [Ionic Vue](ionic-vue.md)
- [Capacitor](#capacitor)
- [Built with Ionic](#built-with-ionic)
- [Stencil](https://github.com/Alexintosh/awesome-stencil)

# General

- [Official Website](https://ionicframework.com/)
- [Blog](https://blog.ionicframework.com/)
- [Documentation](https://ionicframework.com/docs/)
- [Github Repository](https://github.com/ionic-team/ionic-framework)
- [Community Forum](http://forum.ionicframework.com/)
- [Capacitor](https://capacitorjs.com/)
- [Ionic Native](https://github.com/driftyco/ionic-native/)
- [Appflow](https://ionicframework.com/appflow)
- [Ionic Enterprise](https://ionicframework.com/enterprise)
- [Ionic Global Community](https://ionicframework.com/community)
- [Ionic Youtube Channel](https://www.youtube.com/channel/UChYheBnVeCfhCmqZfCUdJQw)
- [Ionic on CodePen](http://codepen.io/ionic/)
- [Ionic IRC](http://webchat.freenode.net/?randomnick=1&channels=%23ionic&uio=d4)
- [Ionic Starter Apps](https://ionicthemes.com)
- [Ionic Free Tutorials](https://ionicthemes.com/tutorials)

# Capacitor

- [Official Website](https://capacitorjs.com/)
- [Documentation](https://capacitorjs.com/docs)
- [Capacitor Plugins](https://capacitorjs.com/docs/plugins)
- [Blog](https://capacitorjs.com/blog)
- [Forum](https://forum.ionicframework.com/c/capacitor)
- [Github Project](https://github.com/ionic-team/capacitor)
- [Twitter](https://twitter.com/capacitorjs)

# Built With Ionic

- [WhatsApp Clone](https://github.com/coderonfleek/whatsapp-clone)

# Ionic Angular

## Complete projects

### Awesome Demos

- [Ionic 4 PWA Demo App](https://github.com/ionicthemes/progressive-web-apps-in-ionic4) ![](ionic.png) ![](pwa.png)
- [Ionic Lottie Sample](https://github.com/yannbf/ionic-lottie) ![](ionic.png)

### Boilerplate/Demo Apps

- [Ionic 4 Full Starter App and PWA](https://ionicthemes.com/product/ionic4-full-starter-app) ![](ionic.png) ![](pwa.png) [NEW]
- [Ionic 3 Starter App Template](https://ionicthemes.com/product/ion2fullapp-full-ionic2-app-template-elite-version) ![](ionic.png)
- [Ion2FullApp - Ionic 3 Template](https://ionicthemes.com/product/ion2fullapp-full-ionic2-app-template) ![](ionic.png)
- [Ionic Boilerplate](https://github.com/marcoturi/ionic-boilerplate) ![](ionic.png)
- [Cordova File Transfer](https://github.com/dsgriffin/ionic-2-file-transfer-example) ![](ionic.png)
- [Update your App](https://github.com/NextFaze/ionic-manup) ![](ionic.png)
- [Fullscreen Content](https://github.com/sebaferreras/Ionic2-FullscreenContent) ![](ionic.png)
- [Card Layout](https://github.com/joshuamorony/ionic2-card-layout) ![](ionic.png)
- [Ionic 2 Boilerplate](https://github.com/marcoturi/ionic2-boilerplate) ![](ionic.png)
- [Ionic 2 Advanced Components](https://github.com/yannbf/ionic2-components) ![](ionic.png)
- [ORC Scan App](https://github.com/matiastucci/ionic-ocr-example) ![](ionic.png)
- [Ionic Country Explorer](https://github.com/SKempin/ionic-country-explorer) ![](ionic.png)

### Open source apps

- [Ionic 4 PWA Demo App](https://github.com/ionicthemes/progressive-web-apps-in-ionic4) ![](ionic.png)[NEW]
- [Ionic 4 Forms and Validations](https://github.com/ionicthemes/forms-and-validations-in-ionic) ![](ionic.png)[NEW]
- [Ionic 4 Facebook Login](https://github.com/ionicthemes/ionic-facebook-login) ![](ionic.png)[NEW]
- [Ionic 4 Google Login](https://github.com/ionicthemes/ionic-google-login) ![](ionic.png)[NEW]
- [Ionic 4 Twitter Login](https://github.com/ionicthemes/ionic-twitter-login) ![](ionic.png)[NEW]
- [Ionic 4 Manga reader](https://github.com/deissh/anibe.app) ![](ionic.png)[NEW]
- [Wordpress Integration App](https://github.com/ionicthemes/ionic3-wordpress-integration) ![](ionic.png)
- [Question & Answers Ionic 3 App](https://github.com/ionicthemes/building-a-complete-mobile-app-with-ionic-3) ![](ionic.png)
- [Ionic 3 Image handling](https://github.com/ionicthemes/ionic3-image-handling) ![](ionic.png)
- [Google Maps + Geolocation + Places](https://github.com/ionicthemes/ionic-3-google-maps-google-places-geolocation) ![](ionic.png)
- [Ionic 3 Admob Integration](https://github.com/ionicthemes/monetize-your-ionic-3-app-with-admob) ![](ionic.png)
- [Ionic 3 Upload Image to Firebase ](https://github.com/ionicthemes/ionic-firebase-image-upload) ![](ionic.png)
- [Submit Ionic form data to Firebase Cloud Firestore](https://github.com/ionicthemes/submit-ionic-form-data-to-firebase-cloud-firestore) ![](ionic.png)
- [Ionic NoSql](https://github.com/Alexintosh/Ionic-Nosql)
- [Ionic Soundboard](https://github.com/Alexintosh/ionic3-soundboard)
- [Ionic Soundboard with remote sounds](https://github.com/rkalis/ionic-soundboard) ![](ionic.png)
- [Ionic Twitter Pwa](https://github.com/shprink/ionic-twitter-pwa) ![](ionic.png) ![](pwa.png)
- [Realty](https://github.com/ccoenraets/ionic2-realty) ![](ionic.png)
- [mHUD - Car App](https://github.com/paulcockrell/mHUD) ![](ionic.png) Speed tracking
- [Restaurant App](https://github.com/srehanuddin/Ionic2-ResturantApp) ![](ionic.png)
- [Conference App](https://github.com/driftyco/ionic-conference-app) ![](ionic.png)
- [Conference App based on Lanyrd API](https://github.com/ionic2blueprints/conference-app) ![](ionic.png)
- [Wordpress Client](https://github.com/ionic2blueprints/ionic2-wp-client) ![](ionic.png)
- [Media Player](https://github.com/ionic2blueprints/media-player) ![](ionic.png)
- [Social App](https://github.com/ionic2blueprints/social-app) ![](ionic.png)
- [Push Notification](https://github.com/aggarwalankush/ionic2-push-base) ![](ionic.png)
- [Weather app](https://github.com/aggarwalankush/ionic2-mosum) ![](ionic.png)
- [Reddit Reader](https://github.com/smartapant/ionic2-reddit-reader) ![](ionic.png)
- [YouTube](https://github.com/hughred22/Ionic2-Angular2-YouTube-Channel-App) ![](ionic.png)
- [Freshlypressed API App](https://github.com/rajayogan/ionic2-freshlypressed) ![](ionic.png)
- [Geo Fence](https://github.com/tsubik/ionic2-geofence) ![](ionic.png)
- [Image Gallery](https://github.com/driftyco/ionic-image-gallery-app) ![](ionic.png)
- [Real-World App](https://github.com/seeschweiler/iongithub) ![](ionic.png)
- [Bwitter - Twitter](https://github.com/obetomuniz/ionic2-bwitter) ![](ionic.png)
- [Inoffical ""Myki"" App](https://github.com/longzheng/mypal-ionic) ![](ionic.png)
- [Timer App](https://github.com/imjohnbo/ionic2-timer) ![](ionic.png)
- [aiEyes](https://github.com/brenopolanski/aiEyes) ![](ionic.png)

# Tutorials

#### Video Tutorials

- [Ionic 2 Quickstart](https://www.udemy.com/ionic-2-quickstart/) ![](ionic.png)
- [Build a Todo App from Scratch with Ionic 2](http://www.joshmorony.com/build-a-todo-app-from-scratch-with-ionic-2-video-tutorial/) ![](ionic.png)
- [Ionic 2: How to Use Google Maps & Geolocation](http://www.joshmorony.com/ionic-2-how-to-use-google-maps-geolocation-video-tutorial/) ![](ionic.png)
- [Ionic 2 in One Hour](http://courses.devdactic.com/courses/ionic-2-in-one-hour?product_id=104238) ![](ionic.png)
- [Build a Custom Flash Card Component in Ionic 2](https://www.youtube.com/watch?v=BKFQKywl_GM) ![](ionic.png)
- [Hacking CSS in Ionic 2](https://www.youtube.com/watch?v=sXFmkdhOEVc) ![](ionic.png)
- [Learn Ionic 3 From Scratch](https://www.youtube.com/watch?v=JcEGTektejA&list=PLYxzS__5yYQng-XnJhB21Jc7NW1OIaqct) ![](ionic.png)

### Basics

- [Build a complete mobile app with Ionic 3](https://ionicthemes.com/tutorials/about/building-a-complete-mobile-app-with-ionic-3) ![](ionic.png)
- [Ionic Application Structure](https://ionicthemes.com/tutorials/about/ionic-application-structure) ![](ionic.png)
- [Setup your development environment to build Ionic apps](https://ionicthemes.com/tutorials/about/setup-your-dev-environment-to-build-ionic-apps) ![](ionic.png)
- [Beginners Guide to Getting Started with Ionic 2](http://www.joshmorony.com/beginners-guide-to-getting-started-with-ionic-2/) ![](ionic.png)
- [Ionic 2 First Look Series: Your First Ionic 2 App Explained](http://www.joshmorony.com/ionic-2-first-look-series-your-first-ionic-2-app-explained/) ![](ionic.png)
- [How to Convert an Ionic 1 Application to Ionic 2](http://www.joshmorony.com/how-to-convert-an-ionic-1-application-to-ionic-2/) ![](ionic.png)
- [A Simple Guide to Navigation in Ionic 2](http://www.joshmorony.com/a-simple-guide-to-navigation-in-ionic-2/) ![](ionic.png)
- [10 Minutes with Ionic 2: Adding Pages and Navigation](http://blog.ionic.io/10-minutes-with-ionic-2-adding-pages-and-navigation/) ![](ionic.png)
- [10 Minutes with Ionic 2: Calling an API](http://blog.ionic.io/10-minutes-with-ionic-2-calling-an-api/) ![](ionic.png)
- [How To Update Your Application Project and CLI](http://www.gajotres.net/ionic-2-how-to-update-your-application-project-and-cli/) ![](ionic.png)
- [How to Create a Data Model in Ionic 2](http://www.joshmorony.com/how-to-create-a-data-model-in-ionic-2/) ![](ionic.png)
- [Ionic 2 and External Libraries](http://mhartington.io/post/ionic2-external-libraries/) ![](ionic.png)
- [Understanding Zones and Change Detection](http://www.joshmorony.com/understanding-zones-and-change-detection-in-ionic-2-angular-2/) ![](ionic.png)
- [Understanding Ionic 2: Pipe](http://mcgivery.com/understanding-ionic-2-pipe/) ![](ionic.png)
- [How to Manipulate Data in Ionic 2: Part 1](http://www.joshmorony.com/how-to-manipulate-data-in-ionic-2-part-1/) ![](ionic.png)
- [How to Manipulate Data in Ionic 2: Part 2](http://www.joshmorony.com/how-to-manipulate-data-in-ionic-2-part-2/) ![](ionic.png)
- [Filtering, Mapping, and Reducing Arrays in Ionic 2](https://www.youtube.com/watch?v=A-4CLa05tp0) ![](ionic.png)

#### Theming

- [A Guide to Styling an Ionic 2 Application](http://www.joshmorony.com/a-guide-to-styling-an-ionic-2-application/) ![](ionic.png)
- [Best practice when adding FontAwesome to an ionic2 app](http://luiscabrera.site/tech/2017/01/09/fontawesome-in-ionic2.html) ![](ionic.png)
- [A List of Common CSS Utility Attributes in Ionic 2](http://www.joshmorony.com/a-list-of-common-css-utility-attributes-in-ionic-2/) ![](ionic.png)

#### Components

- [Ionic and Wordpress Integration using Wordpress REST API](https://ionicthemes.com/tutorials/about/ionic-wordpress-integration) ![](ionic.png)
- [Add Google Maps, Places, and Geolocation to an Ionic 3 App](https://ionicthemes.com/tutorials/about/ionic-2-google-maps-google-places-geolocation) ![](ionic.png)
- [How to Create a Sliding Delete Button for Lists](http://www.joshmorony.com/ionic-2-how-to-create-a-sliding-delete-button-for-lists/) ![](ionic.png)
- [Creating a Sliding Introduction Component in Ionic 2](http://www.joshmorony.com/creating-a-sliding-introduction-component-in-ionic-2/) ![](ionic.png)
- [How to Create a Custom Loading Component in Ionic 2](http://www.joshmorony.com/how-to-create-a-custom-loading-component-in-ionic-2/) ![](ionic.png)
- [Build a Simple Progress Bar Component in Ionic 2](http://www.joshmorony.com/build-a-simple-progress-bar-component-in-ionic-2/) ![](ionic.png)
- [Create a News Feed with 360-Degree Photo Viewing in Ionic 2](http://www.joshmorony.com/create-a-news-feed-with-360-degree-photo-viewing-in-ionic-2/) ![](ionic.png)
- [Build a Tap to Reveal Component in Ionic 2](https://www.joshmorony.com/build-a-tap-to-reveal-component-in-ionic-2/) ![](ionic.png)

#### Authentication

- [Add Twitter Login to an Ionic 4 App](https://ionicthemes.com/tutorials/about/ionic-twitter-login) ![](ionic.png)
- [Add Google Login to an Ionic 4 App](https://ionicthemes.com/tutorials/about/ionic-google-login) ![](ionic.png)
- [Add Facebook Login to an Ionic 4 App](https://ionicthemes.com/tutorials/about/ionic-facebook-login) ![](ionic.png)
- [Add Touch ID Authentication To An Ionic 2 Mobile App](https://www.thepolyglotdeveloper.com/2016/03/add-touch-id-authentication-ionic-2-mobile-app/) ![](ionic.png)
- [Successful OAuth Social Login with Firebase](http://www.gajotres.net/ionic-2-succesfull-oauth-social-login-with-firebase/) ![](ionic.png)
- [Using An Oauth 2.0 Service Within An Ionic 2 Mobile App](https://www.thepolyglotdeveloper.com/2016/01/using-an-oauth-2-0-service-within-an-ionic-2-mobile-app/) ![](ionic.png)
- [Ionic 2 and Auth0](http://blog.ionic.io/ionic-2-and-auth0/) ![](ionic.png)
- [Handling a Simple User Authorization](http://www.gajotres.net/ionic-2-handling-a-simple-user-authorization/) ![](ionic.png)
- [Authenticate Ionic 2 with WordPress](https://auth0.com/authenticate/ionic2/wordpress) ![](ionic.png)

#### Unit Testing

- [Ionic 2 Unit Testing](http://lathonez.github.io/2017/ionic-2-unit-testing/) ![](ionic.png)
- [How to Unit Test an Ionic 2 Application](http://www.joshmorony.com/how-to-unit-test-an-ionic-2-application/) ![](ionic.png)
- [Test Driven Development in Ionic 2: An Introduction to TDD](https://www.joshmorony.com/test-driven-development-in-ionic-2-an-introduction-to-tdd/) ![](ionic.png)

#### Ionic Native / Cordova Plugins

- [Using Cordova Plugins in Ionic 2 with Ionic Native](http://www.joshmorony.com/using-cordova-plugins-in-ionic-2-with-ionic-native/) ![](ionic.png)
- [How to Work With Cordova Plugins](http://www.gajotres.net/ionic-2-how-to-use-cordova-plugins/) ![](ionic.png)
- [10 Minutes with Ionic 2: Using the Camera with Ionic Native](http://blog.ionic.io/10-minutes-with-ionic-2-using-the-camera-with-ionic-native/) ![](ionic.png)
- [How to Use Google Maps & Geolocation ](http://www.joshmorony.com/ionic-2-how-to-use-google-maps-geolocation-video-tutorial/) ![](ionic.png)
- [Determine Network Availability](https://www.thepolyglotdeveloper.com/2016/01/determine-network-availability-in-an-ionic-2-mobile-app/) ![](ionic.png)
- [Monetize With Google Admob In An Ionic 2 Mobile App](https://www.thepolyglotdeveloper.com/2016/02/monetize-google-admob-ionic-2-mobile-app/) ![](ionic.png)
- [Show Native Toast Notifications In An Ionic 2 Mobile App](https://www.thepolyglotdeveloper.com/2016/01/show-native-toast-notifications-in-an-ionic-2-mobile-app/) ![](ionic.png)
- [Having Fun With Cordova Geolocation Plugin](http://www.gajotres.net/ionic-2-having-fun-with-cordova-geolocation-plugin/) ![](ionic.png)
- [Use SQLite In Ionic 2 Instead Of Local Storage](https://www.thepolyglotdeveloper.com/2015/12/use-sqlite-in-ionic-2-instead-of-local-storage/) ![](ionic.png)
- [Launch Websites With Ionic 2 Using The InAppBrowser](https://www.thepolyglotdeveloper.com/2016/01/launch-websites-with-ionic-2-using-the-inappbrowser/) ![](ionic.png)
- [Add Barcode Scanning Functionality To Your Ionic 2 App](https://www.thepolyglotdeveloper.com/2016/02/add-barcode-scanning-functionality-to-your-ionic-2-app/) ![](ionic.png)
- [Use Google Analytics In An Ionic 2 Android And iOS App](https://www.thepolyglotdeveloper.com/2016/03/use-google-analytics-in-an-ionic-2-android-and-ios-app/) ![](ionic.png)
- [Share Things On Social Media Via An Ionic 2 Mobile App](https://www.thepolyglotdeveloper.com/2016/02/share-things-on-social-media-via-an-ionic-2-mobile-app/) ![](ionic.png)
- [How To Use PouchDB + SQLite For Local Storage In Ionic 2](http://gonehybrid.com/how-to-use-pouchdb-sqlite-for-local-storage-in-ionic-2/) ![](ionic.png)
- [Adding Background Geolocation to an Ionic 2 Application](http://www.joshmorony.com/adding-background-geolocation-to-an-ionic-2-application/) ![](ionic.png)
- [Getting Familiar with Local Notifications in Ionic 2](http://www.joshmorony.com/getting-familiar-with-local-notifications-in-ionic-2/) ![](ionic.png)
- [Create a Nearby Places List with Google Maps in Ionic 2 – Part 1](http://www.joshmorony.com/create-a-nearby-places-list-with-google-maps-in-ionic-2-part-1/) ![](ionic.png) ![](ionic.png)
- [Create a Nearby Places List with Google Maps in Ionic 2 – Part 2](http://www.joshmorony.com/create-a-nearby-places-list-with-google-maps-in-ionic-2-part-2/) ![](ionic.png)
- [Applozic Chat & In App Messaging](https://docs.applozic.com/docs/ionic-phonegap-cordova-chat-sdk) ![](ionic.png)
- [Kommunicate Live Chat Plugin for Customer Support](https://docs.kommunicate.io/docs/cordova-installation.html) ![](ionic.png)

#### Backend as a Service

- [10 Minutes with Ionic 2: Calling an API](http://blog.ionic.io/10-minutes-with-ionic-2-calling-an-api/) ![](ionic.png)
- [Using Http to Fetch Remote Data from a Server in Ionic 2](http://www.joshmorony.com/using-http-to-fetch-remote-data-from-a-server-in-ionic-2/) ![](ionic.png)
- [Making REST HTTP Requests Like a Pro](http://www.gajotres.net/ionic-2-making-rest-http-requests-like-a-pro/) ![](ionic.png)
- [Posting data from Ionic 2 app to a PHP server](http://www.nikola-breznjak.com/blog/ionic2/posting-data-from-ionic-2-app/) ![](ionic.png)
- [Make HTTP Requests In An Ionic 2 Android And iOS App](https://www.thepolyglotdeveloper.com/2016/01/make-http-requests-in-an-ionic-2-android-and-ios-app/) ![](ionic.png)
- [Integrating Firebase with AngularFire2 into AngularJS & Ionic2](http://www.clearlyinnovative.com/integrating-firebase-with-angularfire2-into-angularjs-ionic2) ![](ionic.png)

#### i18n & l10n

- [Internationalize and Localize Your Ionic 3 App With Ng Translate for Angular 5](https://ionicthemes.com/tutorials/about/internationalize-and-localize-your-ionic2-app-with-ngtranslate) ![](ionic.png)
- [Internationalize and Localize Your App With Angular 2](http://www.gajotres.net/ionic-2-internationalize-and-localize-your-app-with-angular-2/) ![](ionic.png)

# Tools

- [Ionic2-vscode](https://marketplace.visualstudio.com/items?itemName=jgw9617.ionic2-vscode) ![](ionic.png)
- [Vim-ionic2](https://github.com/akz92/vim-ionic2) ![](ionic.png)
- [Ionic 4 Snippets](https://marketplace.visualstudio.com/items?itemName=fivethree.vscode-ionic-snippets) ![](ionic.png)

# Components

Merged from [here](https://github.com/fishme/awesome-ionic2-components).

### Animations

- [Lottie Animation](https://github.com/chenqingspring/ng-lottie) ![](angular.png)
- [Lottie Animation](https://github.com/fivethree-team/lottie) ![](angular.png)

### UI Library

- [Ionic 4 UI Component Library](https://github.com/fivethree-team/ionic-4-components) ![](ionic.png)

### Menu, Tabs

- [Scrollabel Tabs](https://github.com/SinoThomas/Ionic2-ScrollableTabs) ![](ionic.png)
- [Circular Tabs](https://github.com/SinoThomas/Ionic2-CircularTabs) ![](ionic.png)
- [Fab Toolbar](https://github.com/ekhmoi/fab-toolbar) ![](ionic.png)
- [Multi Level Sidemenu](https://github.com/sebaferreras/Ionic2-MultiLevelSideMenu) ![](ionic.png)
- [Popover Sidemenu](https://github.com/philipbrack/ionic2-menu-alternative-popover) ![](ionic.png)
- [Drop down Title](https://github.com/Mohd-PH/ionic-drop-down-title) ![](ionic.png)

### Form / Input

- [Autocomplete](https://github.com/kadoshms/ionic2-autocomplete) ![](ionic.png)
- [Form Generator based on JSON](https://github.com/makinacorpus/angular2-schema-form) ![](angular.png)
- [Dynamic Forms](https://github.com/udos86/ng2-dynamic-forms/) ![](angular.png)
- [Form Builder](https://github.com/rohitg7/ionic2-form-builder) ![](ionic.png)
- [Sidemenu tabs](https://github.com/seanmavley/ionic2-sidemenu-tabs) ![](ionic.png)

#### Input - Date/Calendar

- **Calendar**
  - [Calendar](https://github.com/twinssbc/Ionic2-Calendar) ![](ionic.png)
  - [Calendar](https://github.com/alexandretok/easy-ionic2-calendar) ![](ionic.png)
  - [Calendar](https://github.com/redpandatronicsuk/ionic2calendar) ![](ionic.png)
  - [Calendar](https://github.com/mattlewis92/angular-calendar) ![](angular.png) (very powerful)
  - [Calendar - Fullcalendar](https://github.com/nekken/ng2-fullcalendar) ![](angular.png)
- **Datepicker**
  - [Datepicker](https://github.com/misha130/datepicker-ionic2) ![](ionic.png)
  - [Datepicker (selectable range dates calendar)](https://github.com/HsuanXyz/ion2-calendar) ![](ionic.png)
  - [Datepicker](https://github.com/rajeshwarpatlolla/ionic2-datepicker) ![](ionic.png)
- [Rating](https://github.com/andrucz/ionic2-rating) ![](ionic.png)
- [Inputfield Mask](https://github.com/text-mask/text-mask)

### Lists/Table

- [Sortable/Filter Tables](https://github.com/valor-software/ng2-table) ![](angular.png)
- [Smart table (sorting, filtering ...)](https://github.com/akveo/ng2-smart-table) ![](angular.png)
- [Flexible and Light Table](https://github.com/swimlane/ngx-datatable) ![](angular.png)

### Images

- [Signatur](https://github.com/wulfsolter/angular2-signaturepad) ![](angular.png) works perfect with ![](ionic.png)
- [Image Fallback](https://github.com/VadimDez/ng2-img-fallback) ![](angular.png)
- [Lazy Load](https://github.com/tjoskar/ng2-lazyload-image) ![](ionic.png) ![](angular.png)
- [Image Loader](https://github.com/zyramedia/ionic-image-loader) ![](ionic.png)
- [Facebook Gallery](https://github.com/skyfloyd/ionic2-fb-gallery) ![](ionic.png)
- [Image Viewer](https://github.com/Riron/ionic-img-viewer) ![](ionic.png)
- [Gallery Modal](https://github.com/nikini/ionic-gallery-modal) ![](ionic.png)
- [Image Zoom](https://github.com/brtnshrdr/angular2-image-zoom) ![](angular.png)

### Charts/Diagram

- [Charts](https://github.com/valor-software/ng2-charts) ![](angular.png)
- **D3 Approaches**
  - [D3 Service](https://github.com/tomwanzek/d3-ng2-service) ![](angular.png)
  - [D3 Barchart](https://github.com/keathmilligan/angular2-d3-v4) ![](angular.png)
  - [D3 Line/Bar/Pie Charts](https://github.com/datencia/d3js-angular2-example) ![](angular.png)

### Video/Audio

- [Video Editor](https://github.com/rossmartin/video-editor-ionic2) ![](ionic.png)
- [Audio Recorder](https://github.com/tracktunes/ionic-recorder) ![](ionic.png)
- [Simple Audioplayer](https://github.com/arielfaur/ionic-audio) ![](ionic.png)

### Keyboards

- [Digit Keyboard](https://github.com/skol-pro/ion-digit-keyboard-v2) ![](ionic.png)

### Dialog

- [Dialogbox with Counter](https://github.com/HsuanXyz/ionic2-extend-alert) ![](ionic.png)

### Frames

- [ng Lightning (for Salesforce Apps)](https://github.com/ng-lightning/ng-lightning) ![](angular.png)

# Are you Italian?

**Join** the italian [Ionic Framework community](https://www.facebook.com/groups/380772785422827/)! ![](ionicitalia.jpg)
","A curated list of awesome Ionic libraries, resources, and solutions from Ionic 1
to the latest version of the framework. This repository is maintained by [Fikayo
Adepoju](https://github.com/coderonfleek) and [Alessio
Delmonti](http://codepen.io/ionic)"
2275,"Repository for ""Introduction to Artificial Neural Networks and Deep Learning: A Practical Guide with Applications in Python""","![Python 3.6](https://img.shields.io/badge/Python-3.6-blue.svg)
![License](https://img.shields.io/badge/Code%20License-MIT-blue.svg)
[![Mailing List](https://img.shields.io/badge/-Mailing%20List-lightgrey.svg)](https://groups.google.com/forum/#!forum/ann-and-dl-book)

# Introduction to Artificial Neural Networks and Deep Learning: A Practical Guide with Applications in Python

Repository for the book *Introduction to Artificial Neural Networks and Deep Learning: A Practical Guide with Applications in Python*.

---

**Deep learning is not just the talk of the town among tech folks. Deep learning allows us to tackle complex problems, training artificial neural networks to recognize complex patterns for image and speech recognition. In this book, we'll continue where we left off in [*Python Machine Learning*](https://github.com/rasbt/python-machine-learning-book) and implement deep learning algorithms in [PyTorch](https://pytorch.org).**

---

- This repository will contain the instructions, code examples, and solutions for the *Hands-On* and *Exercise* portions of each chapter.

- PDF and ebook versions of the book will be available from [Leanpub](https://leanpub.com/ann-and-deeplearning).

[![Deep Learning Book](images/ann-and-deeplearning-cover.jpg)](https://leanpub.com/ann-and-deeplearning)


ISBN-10: [TBA]  
ISBN-13: [TBA]  
Paperback: est. 2018  

---

## Manuscripts / Early Access Drafts

- 01 - Introduction

- 02 - The Perceptron 

- 03 - Optimizing Cost Functions with Gradient Descent

- 04 - Logistic Regression and Softmax Regression

- 05 - From Softmax Regression to Multilayer Perceptrons

- 06 - Cross Validation and Performance Metrics

- 07 - Regularization in Neural Networks

- 08 - Learning Rates and Weight Initialization

- 09 - Convolutional Neural Networks

- 10 - Recurrent Neural Networks

- 11 - Autoencoders

- 12 - General Adverserial Neural Networks

- 13 - Deep Generative Models

- 14 - Reinforcement Learning

#### Supporting Material

- Appendix A: Mathematical Notation [[PDF](https://sebastianraschka.com/pdf/books/dlb/appendix_a_math_notation.pdf)]

- Appendix B: Algebra Basics [[PDF](https://sebastianraschka.com/pdf/books/dlb/appendix_b_algebra.pdf)]

- Appendix C: Linear Algebra Essentials

- Appendix D: Calculus and Differentiation Primer [[PDF](https://sebastianraschka.com/pdf/books/dlb/appendix_d_calculus.pdf)]

- Appendix E: Probability Theory Overview

- Appendix F: Notational Conventions Reference

- Appendix G: Python Setup

- Appendix H: Introduction to NumPy [[PDF](https://sebastianraschka.com/pdf/books/dlb/appendix_numpy-intro.pdf)] [[Code Notebook](code/appendix_h_numpy-intro/appendix_numpy-intro.ipynb)]

- Appendix I: PyTorch Basics 

- Appendix I (alt.): TensorFlow Basics [[PDF](https://sebastianraschka.com/pdf/books/dlb/appendix_g_tensorflow.pdf)] [[Code Notebook](code/_old-material/appendix_tensorflow-basics/appendix_tensorflow-basics.ipynb)]

- Appendix J: Cloud Computing [[PDF](https://sebastianraschka.com/pdf/books/dlb/appendix_cloud-computing.pdf)]

#### Model Zoo

- **[Model Zoo: A collection of standalone TensorFlow and PyTorch models in Jupyter Notebooks](https://github.com/rasbt/deeplearning-models)**

  

---

## About the Book

Machine learning has become a central part of our life — as consumers, customers, and hopefully as researchers and practitioners! I appreciate all the nice feedback that you sent me about [*Python Machine Learning*](https://github.com/rasbt/python-machine-learning-book), and I am so happy to hear that you found it so useful as a learning guide, helping you with your business applications and research projects. I have received many emails since its release. Also, in these very emails, you were asking me about a possible prequel or sequel.

Initially, I was inclined to write more about the ""math"" parts, which can be a real hurdle for almost everyone without (or even with) a math major in college. Initially, I thought that writing a book about ""machine learning math"" was a cool thing to do. Now, I have ~15 chapters worth of notes about pre-calculus, calculus, linear algebra, statistics, and probability theory. However, I eventually came to a conclusion that there were too many other math books out there, already! Most of them are far better and more comprehensive and accurate than my potential ~500-page introduction to the topics that I had in store. After all, I think that the real motivation for learning and understanding a subject comes from being excited about it in the first place; if you are passionate about machine learning and you stumble upon the chain rule in calculus, you wouldn't have any problems to find a trusted resource via your favorite search engine these days.

So, instead of writing that ""prequel,"" let me write about something that's built upon the concepts that I introduced in the later chapters of [*Python Machine Learning*](https://github.com/rasbt/python-machine-learning-book) -- algorithms for deep learning. After we coded a multi-layer perceptron (a certain kind of feedforward artificial neural network) from scratch, we took a brief look at some Python libraries for implementing deep learning algorithms, and I introduced convolutional and recurrent neural networks on a conceptual level.

In this book, I want to continue where I left off and want to implement deep neural networks and algorithms for deep learning algorithms from scratch, using Python, NumPy, and SciPy throughout this educational journey. In addition to the vanilla Python science-stack, we will implement these algorithms in [TensorFlow](https://www.tensorflow.org), highly performant yet very accessible deep learning library for implementing and applying deep learning to real-world problems.

## License

### Code

All code in this repository (including the code examples in Jupyter Notebooks) is open source content, released under the [MIT software license](LICENSE). In short, the permissive MIT license allows you to do anything with the code with proper attribution and without warranty; please check the MIT [LICENSE](LICENSE) notice for further details.

### Text and Graphics

All non-code content and creative work in this repository, including text and graphics, is under exclusive copyright by the author, Sebastian Raschka. Unless noted otherwise, text content shared in this repository is intended for personal use only. You may use, modify, or share short text passages of this work with proper attribution to the author. However, if you are planning to modify and/or share substantial portions of this book for other writings, such as blog posts, magazine article, or teaching material, contact the author for permission.

Figures and graphics marked by a *Creative Commons Attribution-ShareAlike 4.0 International* are free to share under the respective license terms (as listed in the *Creative Commons Attribution-ShareAlike 4.0 International* section in the [LICENSE](LICENSE) file) and proper attribution.


## Acknowledgements

I would like to give my special thanks to the readers, who caught various typos and errors and offered suggestions for clarifying my writing.

- Appendix A: Artem Sobolev, Ryan Sun
- Appendix B: Brett Miller, Ryan Sun
- Appendix D: Marcel Blattner, Ignacio Campabadal, Ryan Sun
- Appendix F: Guillermo Moncecchi‏, Ged Ridgway
- Appendix H: Brett Miller
","Deep learning is not just the talk of the town among tech folks. Deep learning
allows us to tackle complex problems, training artificial neural networks to
recognize complex patterns for image and speech recognition. In this book, we'll
continue where we left off in [Python Machine Learning*] and implement deep
learning algorithms in [PyTorch] This repository will contain the instructions,
code examples, and solutions for the *Hands-On* and *Exercise* portions of each
chapter. PDF and ebook versions of the book will be available from
[Leanpub](https://leanpub.com/ann-and-deeplearning)"
3137,A Git-compatible DVCS that is both simple and powerful,"# Jujutsu VCS

![](https://img.shields.io/github/license/martinvonz/jj) ![](https://img.shields.io/github/v/release/martinvonz/jj) ![](https://img.shields.io/github/release-date/martinvonz/jj) ![](https://img.shields.io/crates/v/jujutsu)
<br/>
![](https://github.com/martinvonz/jj/workflows/build/badge.svg) ![](https://img.shields.io/codefactor/grade/github/martinvonz/jj/main) ![](https://img.shields.io/librariesio/github/martinvonz/jj)

- [Disclaimer](#disclaimer)
- [Introduction](#introduction)
- [Status](#status)
- [Installation](#installation)
- [Command-line completion](#command-line-completion)
- [Getting started](#getting-started)
- [Related work](#related-work)

## Disclaimer

This is not a Google product. It is an experimental version-control system
(VCS). It was written by me, Martin von Zweigbergk (martinvonz@google.com). It
is my personal hobby project and my 20% project at Google. It does not indicate
any commitment or direction from Google. However, my presentation from Git Merge
2022 does include some information about Google's plans. See the
[slides](https://docs.google.com/presentation/d/1F8j9_UOOSGUN9MvHxPZX_L4bQ9NMcYOp1isn17kTC_M/view)
or the [recording](https://www.youtube.com/watch?v=bx_LGilOuE4).


## Introduction

Jujutsu is a [Git-compatible](docs/git-compatibility.md)
[DVCS](https://en.wikipedia.org/wiki/Distributed_version_control). It combines
features from Git (data model,
[speed](https://github.com/martinvonz/jj/discussions/49)), Mercurial (anonymous
branching, simple CLI [free from ""the index""](docs/git-comparison.md#the-index),
[revsets](docs/revsets.md), powerful history-rewriting), and Pijul/Darcs
([first-class conflicts](docs/conflicts.md)), with features not found in most
of them ([working-copy-as-a-commit](docs/working-copy.md),
[undo functionality](docs/operation-log.md), automatic rebase,
[safe replication via `rsync`, Dropbox, or distributed file
system](docs/technical/concurrency.md)).

The command-line tool is called `jj` for now because it's easy to type and easy
to replace (rare in English). The project is called ""Jujutsu"" because it matches
""jj"".

If you have any questions, please join us on Discord
[![Discord](https://img.shields.io/discord/968932220549103686.svg?label=&logo=discord&logoColor=ffffff&color=7389D8&labelColor=6A7EC2)](https://discord.gg/dkmfj3aGQN).

## Features

### Compatible with Git

Jujutsu has two backends. One of them is a Git backend (the other is a native
one [^native-backend]). This lets you use Jujutsu as an alternative interface to Git. The commits
you create will look like regular Git commits. You can always switch back to
Git. The Git support uses the [libgit2](https://libgit2.org/) C library.

[^native-backend]: At this time, there's practically no reason to use the native
backend (the only minor reason might be
[#27](https://github.com/martinvonz/jj/issues/27)).
The backend exists mainly to make sure that it's possible to eventually add
functionality that cannot easily be added to the Git backend.

<img src=""demos/git_compat.png"" />

### The working copy is automatically committed

Most Jujutsu commands automatically commit the working copy. This leads to a
simpler and more powerful interface, since all commands work the same way on the
working copy or any other commit. It also means that you can always check out a
different commit without first explicitly committing the working copy changes
(you can even check out a different commit while resolving merge conflicts).

<img src=""demos/working_copy.png"" />

### Operations update the repo first, then possibly the working copy

The working copy is only updated at the end of an operation, after all other
changes have already been recorded. This means that you can run any command
(such as `jj rebase`) even if the working copy is dirty.

### Entire repo is under version control

All operations you perform in the repo are recorded, along with a snapshot of
the repo state after the operation. This means that you can easily revert to an
earlier repo state, or to simply undo a particular operation (which does not
necessarily have to be the most recent operation).

<img src=""demos/operation_log.png"" />

### Conflicts can be recorded in commits

If an operation results in conflicts, information about those conflicts will be
recorded in the commit(s). The operation will succeed. You can then resolve the
conflicts later. One consequence of this design is that there's no need to
continue interrupted operations. Instead, you get a single workflow for
resolving conflicts, regardless of which command caused them. This design also
lets Jujutsu rebase merge commits correctly (unlike both Git and Mercurial).

Basic conflict resolution:

<img src=""demos/resolve_conflicts.png"" />

Juggling conflicts:

<img src=""demos/juggle_conflicts.png"" />

### Automatic rebase

Whenever you modify a commit, any descendants of the old commit will be rebased
onto the new commit. Thanks to the conflict design described above, that can be
done even if there are conflicts. Branches pointing to rebased commits will be
updated. So will the working copy if it points to a rebased commit.

### Comprehensive support for rewriting history

Besides the usual rebase command, there's `jj describe` for editing the
description (commit message) of an arbitrary commit. There's also `jj diffedit`,
which lets you edit the changes in a commit without checking it out. To split
a commit into two, use `jj split`. You can even move part of the changes in a
commit to any other commit using `jj move`.


## Status

The tool is quite feature-complete, but some important features like (the
equivalent of) `git blame` are not yet supported. There
are also several performance bugs. It's also likely that workflows and setups
different from what the core developers use are not well supported.

I (Martin von Zweigbergk) have almost exclusively used `jj` to develop the
project itself since early January 2021. I haven't had to re-clone from source
(I don't think I've even had to restore from backup).

There *will* be changes to workflows and backward-incompatible changes to the
on-disk formats before version 1.0.0. Even the binary's name may change (i.e.
away from `jj`). For any format changes, we'll try to implement transparent
upgrades (as we've done with recent changes), or provide upgrade commands or
scripts if requested.


## Installation

See below for how to build from source. There are also
[pre-built binaries](https://github.com/martinvonz/jj/releases) for Windows,
Mac, or Linux (musl).

If you're installing from source, you need to use Rust version 1.61 or higher,
or you will get a cryptic message like this:
```
error: failed to select a version for the requirement `libgit2-sys = ""=0.14.0""``
candidate versions found which didn't match: 0.13.2+1.4.2, 0.13.1+1.4.2, 0.13.0+1.4.1, ...
```

### Linux

On most distributions, you'll need to build from source using `cargo` directly.

#### Build using `cargo`

First make sure that you have the `libssl-dev`, `openssl`, and `pkg-config`
packages installed by running something like this:
```shell script
sudo apt-get install libssl-dev openssl pkg-config
```

Now run:
```shell script
cargo install --git https://github.com/martinvonz/jj.git --locked --bin jj jujutsu
```


#### Nix OS

If you're on Nix OS you can use the flake for this repository.
For example, if you want to run `jj` loaded from the flake, use:

```shell script
nix run 'github:martinvonz/jj'
```

You can also add this flake url to your system input flakes. Or you can
install the flake to your user profile:

```shell script
nix profile install 'github:martinvonz/jj'
```


#### Homebrew

If you use linuxbrew, you can run:

```shell script
brew install jj
```


### Mac

#### Homebrew

If you use Homebrew, you can run:

```shell script
brew install jj
```

#### MacPorts

You can also install `jj` via [MacPorts](https://www.macports.org) (as the `jujutsu` port):

```shell script
sudo port install jujutsu
```

([port page](https://ports.macports.org/port/jujutsu/))

#### From Source

You may need to run some or all of these:
```shell script
xcode-select --install
brew install openssl
brew install pkg-config
export PKG_CONFIG_PATH=""$(brew --prefix)/opt/openssl@3/lib/pkgconfig""
```

Now run:
```shell script
cargo install --git https://github.com/martinvonz/jj.git --locked --bin jj jujutsu
```


### Windows

Run:
```shell script
cargo install --git https://github.com/martinvonz/jj.git --locked --bin jj jujutsu --features vendored-openssl
```


## Initial configuration

You may want to configure your name and email so commits are made in your name.
Create a file at `~/.jjconfig.toml` and make it look something like
this:
```shell script
$ cat ~/.jjconfig.toml
[user]
name = ""Martin von Zweigbergk""
email = ""martinvonz@google.com""
```


## Command-line completion

To set up command-line completion, source the output of
`jj debug completion --bash/--zsh/--fish`. Exactly how to source it depends on
your shell.

### Bash
```shell script
source <(jj debug completion)  # --bash is the default
```

### Zsh
```shell script
autoload -U compinit
compinit
source <(jj debug completion --zsh | sed '$d')  # remove the last line
compdef _jj jj
```

### Fish
```shell script
jj debug completion --fish | source
```

### Xonsh
```shell script
source-bash $(jj debug completion)
```


## Getting started

The best way to get started is probably to go through
[the tutorial](docs/tutorial.md). Also see the
[Git comparison](docs/git-comparison.md), which includes a table of
`jj` vs. `git` commands.


## Related work

There are several tools trying to solve similar problems as Jujutsu. See
[related work](docs/related-work.md) for details.
","Jujutsu is a Git-compatible command-line tool. It combines features from Git,
Mercurial, and Pijul/Darcs. It has two backends: a Git backend and a native
native-backend. All commands work the same way on the working copy or any other
commit. Conflicts can be recorded in commits and resolved later. The project is
called ""Jujutsu"" because it matches ""jj"" (rare) in English."
258,Crpyocurrency App powered by RapidAPI,"# Cryptoverse - Explore the World of Cryptocurrency

![Cryptoverse](https://i.ibb.co/8gh5Jc8/image.png)

## Introduction
This is a code repository for the corresponding video tutorial. 

In this video, we will create a cryptocurrency app. We're going to use React and multiple APIs powered by https://rapidapi.com.

By the end of this video, you will become the master of working with APIs.
","This is a code repository for the corresponding video tutorial. We're going to
use React and multiple APIs powered by https://rapidapi.com. By the end of this
video, you will become the master of working with APIs. We'll also show you how
to create a cryptocurrency app with React and other tools. We hope you'll find
this video useful. The code repository is also available on GitHub. For more
information, visit the code repository and the video tutorial is available on
YouTube."
721,A fancy terminal browser for the Gemini protocol.,"# Amfora

<img src=""logo.png"" alt=""amphora logo"" width=""30%"">
<h6>Image modified from: amphora by Alvaro Cabrera from the Noun Project</h6>


[![go reportcard](https://goreportcard.com/badge/github.com/makeworld-the-better-one/amfora)](https://goreportcard.com/report/github.com/makeworld-the-better-one/amfora)
[![license GPLv3](https://img.shields.io/github/license/makeworld-the-better-one/amfora)](https://www.gnu.org/licenses/gpl-3.0.en.html)

<a href=""https://raw.githubusercontent.com/makeworld-the-better-one/amfora/master/demo-large.gif"">
<img src=""demo-large.gif"" alt=""Demo GIF"" width=""80%"">
</a>

###### Recording of v1.0.0

Amfora aims to be the best looking [Gemini](https://geminiquickst.art/) client with the most features... all in the terminal. It does not support Gopher or other non-Web protocols - check out [Bombadillo](http://bombadillo.colorfield.space/) for that.

It also aims to be completely cross platform, with full Windows support. If you're on Windows, I would not recommend using the default terminal software. Use [Windows Terminal](https://www.microsoft.com/en-us/p/windows-terminal/9n0dx20hk701) instead, and make sure it [works with UTF-8](https://akr.am/blog/posts/using-utf-8-in-the-windows-terminal). Note that some of the application colors might not display correctly on Windows, but all functionality will still work.

It fully passes Sean Conman's client torture test, as well as the Egsam one.

## Installation

### Binary

Download a binary from the [releases](https://github.com/makeworld-the-better-one/amfora/releases) page. On Unix-based systems you will have to make the file executable with `chmod +x <filename>`. You can rename the file to just `amfora` for easy access, and move it to `/usr/local/bin/`.

On Windows, make sure you click ""Advanced > Run anyway"" after double-clicking, or something like that.

Unix systems can install the desktop entry file to get Amfora to appear when they search for applications:
```bash
curl -sSL https://raw.githubusercontent.com/makeworld-the-better-one/amfora/master/amfora.desktop -o ~/.local/share/applications/amfora.desktop
update-desktop-database ~/.local/share/applications
```

Make sure to click ""Watch"" in the top right, then ""Custom"" > ""Releases"" to get notified about new releases!


### Linux

<a href=""https://repology.org/project/amfora/versions"">
    <img src=""https://repology.org/badge/vertical-allrepos/amfora.svg"" alt=""Packaging status"" align=""right"">
</a>

Amfora is packaged in many Linux distros. It's also on [Scoop](https://scoop.sh/) for Windows users.

### macOS (Homebrew)

If you use [Homebrew](https://brew.sh/), you can install Amfora with:
```
brew install amfora
```
You can update it with:
```
brew upgrade amfora
```

### macOS (MacPorts)

On macOS, Amfora can also be installed through [MacPorts](https://www.macports.org):
```
sudo port install amfora
```
You can update it with:
```
sudo port selfupdate
sudo port upgrade amfora
```
**NOTE:** this installation source is community-maintained. More information [here](https://ports.macports.org/port/amfora/).

### Termux

If you're using [Termux](https://termux.com/) on Android you can't just run Amfora like normal. After installing Amfora, run `pkg install proot`. Then run `termux-chroot` before running the Amfora binary. You can exit out of the chroot after closing Amfora. See [here](https://stackoverflow.com/q/38959067/7361270) for why this is needed.

### From Source

This section is for advanced users who want to install the latest (possibly unstable) version of Amfora.

<details>
<summary>Click to expand</summary>

**Requirements:**
- Go 1.15 or later
- GNU Make

Please note the Makefile does not intend to support Windows, and so there may be issues.

```shell
git clone https://github.com/makeworld-the-better-one/amfora
cd amfora
# git checkout v1.2.3 # Optionally pin to a specific version instead of the latest commit
make # Might be gmake on macOS
sudo make install # If you want to install the binary for all users
```

Because you installed with the Makefile, running `amfora -v` will tell you exactly what commit the binary was built from.

Arch Linux users can also install the latest commit of Amfora from the AUR. It has the package name `amfora-git`, and is maintained by @lovetocode999

```
yay -S amfora-git
```

MacOS users can also use [Homebrew](https://brew.sh/) to install the latest commit of Amfora:

```
brew install --HEAD amfora
```
You can update it with:
```
brew upgrade --fetch-HEAD amfora
```

</details>


## Features / Roadmap
Features in *italics* are in the master branch, but not in the latest release.

- [x] URL browsing with TOFU and error handling
- [x] Tabbed browsing
- [x] Support ANSI color codes on pages, even for Windows
- [x] Styled page content (headings, links)
- [x] Basic forward/backward history, for each tab
- [x] Input (Status Code 10 & 11)
- [x] Multiple charset support (over 55)
- [x] Built-in search (uses geminispace.info by default)
- [x] Bookmarks
- [x] Download pages and arbitrary data
- [x] Theming
  - Check out the [user contributed themes](https://github.com/makeworld-the-better-one/amfora/tree/master/contrib/themes)!
- [x] Proxying
  - Schemes like Gopher or HTTP can be proxied through a Gemini server
- [x] Client certificate support
  - [ ] Full client certificate UX within the client
    - Create transient and permanent certs within the client, per domain
    - Manage and browse them
    - Similar to [Kristall](https://github.com/MasterQ32/kristall)
    - https://lists.orbitalfox.eu/archives/gemini/2020/001400.html
- [x] Subscriptions
  - Subscribing to RSS, Atom, and [JSON Feeds](https://jsonfeed.org/) are all supported
  - So is subscribing to a page, to know when it changes
- [x] Open non-text files in another application
  - [x] Ability to stream content instead of downloading it first
- [x] *Highlighting of preformatted code blocks that list a language in the alt text*
- [ ] Stream support
- [ ] Table of contents for pages
- [ ] Search in pages with <kbd>Ctrl-F</kbd>
- [ ] Persistent history


## Usage & Configuration
Please see [the wiki](https://github.com/makeworld-the-better-one/amfora/wiki) for an introduction on how to use Amfora and configure it.

## Libraries
Amfora ❤️ open source!

- [cview](https://code.rocketnine.space/tslocum/cview) for the TUI
  - It's a fork of [tview](https://github.com/rivo/tview) with PRs merged and active support
  - It uses [tcell](https://github.com/gdamore/tcell) for low level terminal operations
- [Viper](https://github.com/spf13/viper) for configuration and TOFU storing
- [go-gemini](https://github.com/makeworld-the-better-one/go-gemini), my forked and updated Gemini client/server library
- [progressbar](https://github.com/schollz/progressbar)
- [go-humanize](https://github.com/dustin/go-humanize)
- [gofeed](https://github.com/mmcdole/gofeed)
- [chroma](https://github.com/alecthomas/chroma) for source code syntax highlighting
- [clipboard](https://github.com/atotto/clipboard)
- [termenv](https://github.com/muesli/termenv)

## License
This project is licensed under the GPL v3.0. See the [LICENSE](./LICENSE) file for details.
","Amfora aims to be the best looking [Gemini] client with the most features... all
in the terminal. It does not support Gopher or other non-Web protocols - check
out [Bombadillo](http://bombadillo.colorfield.space/) for that. It's also
completely cross platform, with full Windows support."
2277,"Data science Python notebooks: Deep learning (TensorFlow, Theano, Caffe, Keras), scikit-learn, Kaggle, big data (Spark, Hadoop MapReduce, HDFS), matplotlib, pandas, NumPy, SciPy, Python essentials, AWS, and various command lines.","<br/>
<p align=""center"">
  <img src=""https://raw.githubusercontent.com/donnemartin/data-science-ipython-notebooks/master/images/README_1200x800.gif"">
</p>

<p align=""center"">
  <img src=""https://raw.githubusercontent.com/donnemartin/data-science-ipython-notebooks/master/images/coversmall_alt.png"">
  <br/>
</p>

# data-science-ipython-notebooks

## Index

* [deep-learning](#deep-learning)
    * [tensorflow](#tensor-flow-tutorials)
    * [theano](#theano-tutorials)
    * [keras](#keras-tutorials)
    * [caffe](#deep-learning-misc)
* [scikit-learn](#scikit-learn)
* [statistical-inference-scipy](#statistical-inference-scipy)
* [pandas](#pandas)
* [matplotlib](#matplotlib)
* [numpy](#numpy)
* [python-data](#python-data)
* [kaggle-and-business-analyses](#kaggle-and-business-analyses)
* [spark](#spark)
* [mapreduce-python](#mapreduce-python)
* [amazon web services](#aws)
* [command lines](#commands)
* [misc](#misc)
* [notebook-installation](#notebook-installation)
* [credits](#credits)
* [contributing](#contributing)
* [contact-info](#contact-info)
* [license](#license)

<br/>
<p align=""center"">
  <img src=""http://i.imgur.com/ZhKXrKZ.png"">
</p>

## deep-learning

IPython Notebook(s) demonstrating deep learning functionality.

<br/>
<p align=""center"">
  <img src=""https://avatars0.githubusercontent.com/u/15658638?v=3&s=100"">
</p>

### tensor-flow-tutorials

Additional TensorFlow tutorials:

* [pkmital/tensorflow_tutorials](https://github.com/pkmital/tensorflow_tutorials)
* [nlintz/TensorFlow-Tutorials](https://github.com/nlintz/TensorFlow-Tutorials)
* [alrojo/tensorflow-tutorial](https://github.com/alrojo/tensorflow-tutorial)
* [BinRoot/TensorFlow-Book](https://github.com/BinRoot/TensorFlow-Book)
* [tuanavu/tensorflow-basic-tutorials](https://github.com/tuanavu/tensorflow-basic-tutorials)

| Notebook | Description |
|--------------------------------------------------------------------------------------------------------------|-------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| [tsf-basics](http://nbviewer.ipython.org/github/donnemartin/data-science-ipython-notebooks/blob/master/deep-learning/tensor-flow-examples/notebooks/1_intro/basic_operations.ipynb) | Learn basic operations in TensorFlow, a library for various kinds of perceptual and language understanding tasks from Google. |
| [tsf-linear](http://nbviewer.ipython.org/github/donnemartin/data-science-ipython-notebooks/blob/master/deep-learning/tensor-flow-examples/notebooks/2_basic_classifiers/linear_regression.ipynb) | Implement linear regression in TensorFlow. |
| [tsf-logistic](http://nbviewer.ipython.org/github/donnemartin/data-science-ipython-notebooks/blob/master/deep-learning/tensor-flow-examples/notebooks/2_basic_classifiers/logistic_regression.ipynb) | Implement logistic regression in TensorFlow. |
| [tsf-nn](http://nbviewer.ipython.org/github/donnemartin/data-science-ipython-notebooks/blob/master/deep-learning/tensor-flow-examples/notebooks/2_basic_classifiers/nearest_neighbor.ipynb) | Implement nearest neighboars in TensorFlow. |
| [tsf-alex](http://nbviewer.ipython.org/github/donnemartin/data-science-ipython-notebooks/blob/master/deep-learning/tensor-flow-examples/notebooks/3_neural_networks/alexnet.ipynb) | Implement AlexNet in TensorFlow. |
| [tsf-cnn](http://nbviewer.ipython.org/github/donnemartin/data-science-ipython-notebooks/blob/master/deep-learning/tensor-flow-examples/notebooks/3_neural_networks/convolutional_network.ipynb) | Implement convolutional neural networks in TensorFlow. |
| [tsf-mlp](http://nbviewer.ipython.org/github/donnemartin/data-science-ipython-notebooks/blob/master/deep-learning/tensor-flow-examples/notebooks/3_neural_networks/multilayer_perceptron.ipynb) | Implement multilayer perceptrons in TensorFlow. |
| [tsf-rnn](http://nbviewer.ipython.org/github/donnemartin/data-science-ipython-notebooks/blob/master/deep-learning/tensor-flow-examples/notebooks/3_neural_networks/recurrent_network.ipynb) | Implement recurrent neural networks in TensorFlow. |
| [tsf-gpu](http://nbviewer.ipython.org/github/donnemartin/data-science-ipython-notebooks/blob/master/deep-learning/tensor-flow-examples/notebooks/4_multi_gpu/multigpu_basics.ipynb) | Learn about basic multi-GPU computation in TensorFlow. |
| [tsf-gviz](http://nbviewer.ipython.org/github/donnemartin/data-science-ipython-notebooks/blob/master/deep-learning/tensor-flow-examples/notebooks/5_ui/graph_visualization.ipynb) | Learn about graph visualization in TensorFlow. |
| [tsf-lviz](http://nbviewer.ipython.org/github/donnemartin/data-science-ipython-notebooks/blob/master/deep-learning/tensor-flow-examples/notebooks/5_ui/loss_visualization.ipynb) | Learn about loss visualization in TensorFlow. |

### tensor-flow-exercises

| Notebook | Description |
|--------------------------------------------------------------------------------------------------------------|-------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| [tsf-not-mnist](http://nbviewer.ipython.org/github/donnemartin/data-science-ipython-notebooks/blob/master/deep-learning/tensor-flow-exercises/1_notmnist.ipynb) | Learn simple data curation by creating a pickle with formatted datasets for training, development and testing in TensorFlow. |
| [tsf-fully-connected](http://nbviewer.ipython.org/github/donnemartin/data-science-ipython-notebooks/blob/master/deep-learning/tensor-flow-exercises/2_fullyconnected.ipynb) | Progressively train deeper and more accurate models using logistic regression and neural networks in TensorFlow. |
| [tsf-regularization](http://nbviewer.ipython.org/github/donnemartin/data-science-ipython-notebooks/blob/master/deep-learning/tensor-flow-exercises/3_regularization.ipynb) | Explore regularization techniques by training fully connected networks to classify notMNIST characters in TensorFlow. |
| [tsf-convolutions](http://nbviewer.ipython.org/github/donnemartin/data-science-ipython-notebooks/blob/master/deep-learning/tensor-flow-exercises/4_convolutions.ipynb) | Create convolutional neural networks in TensorFlow. |
| [tsf-word2vec](http://nbviewer.ipython.org/github/donnemartin/data-science-ipython-notebooks/blob/master/deep-learning/tensor-flow-exercises/5_word2vec.ipynb) | Train a skip-gram model over Text8 data in TensorFlow. |
| [tsf-lstm](http://nbviewer.ipython.org/github/donnemartin/data-science-ipython-notebooks/blob/master/deep-learning/tensor-flow-exercises/6_lstm.ipynb) | Train a LSTM character model over Text8 data in TensorFlow. |

<br/>
<p align=""center"">
  <img src=""http://www.deeplearning.net/software/theano/_static/theano_logo_allblue_200x46.png"">
</p>

### theano-tutorials

| Notebook | Description |
|--------------------------------------------------------------------------------------------------------------|-------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| [theano-intro](http://nbviewer.ipython.org/github/donnemartin/data-science-ipython-notebooks/blob/master/deep-learning/theano-tutorial/intro_theano/intro_theano.ipynb) | Intro to Theano, which allows you to define, optimize, and evaluate mathematical expressions involving multi-dimensional arrays efficiently. It can use GPUs and perform efficient symbolic differentiation. |
| [theano-scan](http://nbviewer.ipython.org/github/donnemartin/data-science-ipython-notebooks/blob/master/deep-learning/theano-tutorial/scan_tutorial/scan_tutorial.ipynb) | Learn scans, a mechanism to perform loops in a Theano graph. |
| [theano-logistic](http://nbviewer.ipython.org/github/donnemartin/data-science-ipython-notebooks/blob/master/deep-learning/theano-tutorial/intro_theano/logistic_regression.ipynb) | Implement logistic regression in Theano. |
| [theano-rnn](http://nbviewer.ipython.org/github/donnemartin/data-science-ipython-notebooks/blob/master/deep-learning/theano-tutorial/rnn_tutorial/simple_rnn.ipynb) | Implement recurrent neural networks in Theano. |
| [theano-mlp](http://nbviewer.ipython.org/github/donnemartin/data-science-ipython-notebooks/blob/master/deep-learning/theano-tutorial/theano_mlp/theano_mlp.ipynb) | Implement multilayer perceptrons in Theano. |

<br/>
<p align=""center"">
  <img src=""http://i.imgur.com/L45Q8c2.jpg"">
</p>

### keras-tutorials

| Notebook | Description |
|--------------------------------------------------------------------------------------------------------------|-------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| keras | Keras is an open source neural network library written in Python. It is capable of running on top of either Tensorflow or Theano. |
| [setup](https://nbviewer.jupyter.org/github/donnemartin/data-science-ipython-notebooks/blob/master/deep-learning/keras-tutorial/0.%20Preamble.ipynb) | Learn about the tutorial goals and how to set up your Keras environment. |
| [intro-deep-learning-ann](https://nbviewer.jupyter.org/github/donnemartin/data-science-ipython-notebooks/blob/master/deep-learning/keras-tutorial/1.1%20Introduction%20-%20Deep%20Learning%20and%20ANN.ipynb) | Get an intro to deep learning with Keras and Artificial Neural Networks (ANN). |
| [theano](https://nbviewer.jupyter.org/github/donnemartin/data-science-ipython-notebooks/blob/master/deep-learning/keras-tutorial/1.2%20Introduction%20-%20Theano.ipynb) | Learn about Theano by working with weights matrices and gradients. |
| [keras-otto](https://nbviewer.jupyter.org/github/donnemartin/data-science-ipython-notebooks/blob/master/deep-learning/keras-tutorial/1.3%20Introduction%20-%20Keras.ipynb) | Learn about Keras by looking at the Kaggle Otto challenge. |
| [ann-mnist](https://nbviewer.jupyter.org/github/donnemartin/data-science-ipython-notebooks/blob/master/deep-learning/keras-tutorial/1.4%20%28Extra%29%20A%20Simple%20Implementation%20of%20ANN%20for%20MNIST.ipynb) | Review a simple implementation of ANN for MNIST using Keras. |
| [conv-nets](https://nbviewer.jupyter.org/github/donnemartin/data-science-ipython-notebooks/blob/master/deep-learning/keras-tutorial/2.1%20Supervised%20Learning%20-%20ConvNets.ipynb) | Learn about Convolutional Neural Networks (CNNs) with Keras. |
| [conv-net-1](https://nbviewer.jupyter.org/github/donnemartin/data-science-ipython-notebooks/blob/master/deep-learning/keras-tutorial/2.2.1%20Supervised%20Learning%20-%20ConvNet%20HandsOn%20Part%20I.ipynb) | Recognize handwritten digits from MNIST using Keras - Part 1. |
| [conv-net-2](https://nbviewer.jupyter.org/github/donnemartin/data-science-ipython-notebooks/blob/master/deep-learning/keras-tutorial/2.2.2%20Supervised%20Learning%20-%20ConvNet%20HandsOn%20Part%20II.ipynb) | Recognize handwritten digits from MNIST using Keras - Part 2. |
| [keras-models](https://nbviewer.jupyter.org/github/donnemartin/data-science-ipython-notebooks/blob/master/deep-learning/keras-tutorial/2.3%20Supervised%20Learning%20-%20Famous%20Models%20with%20Keras.ipynb) | Use pre-trained models such as VGG16, VGG19, ResNet50, and Inception v3 with Keras. |
| [auto-encoders](https://nbviewer.jupyter.org/github/donnemartin/data-science-ipython-notebooks/blob/master/deep-learning/keras-tutorial/3.1%20Unsupervised%20Learning%20-%20AutoEncoders%20and%20Embeddings.ipynb) | Learn about Autoencoders with Keras. |
| [rnn-lstm](https://nbviewer.jupyter.org/github/donnemartin/data-science-ipython-notebooks/blob/master/deep-learning/keras-tutorial/3.2%20RNN%20and%20LSTM.ipynb) | Learn about Recurrent Neural Networks (RNNs) with Keras. |
| [lstm-sentence-gen](https://nbviewer.jupyter.org/github/donnemartin/data-science-ipython-notebooks/blob/master/deep-learning/keras-tutorial/3.3%20%28Extra%29%20LSTM%20for%20Sentence%20Generation.ipynb) |  Learn about RNNs using Long Short Term Memory (LSTM) networks with Keras. |

### deep-learning-misc

| Notebook | Description |
|--------------------------------------------------------------------------------------------------------------|-------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| [deep-dream](http://nbviewer.ipython.org/github/donnemartin/data-science-ipython-notebooks/blob/master/deep-learning/deep-dream/dream.ipynb) | Caffe-based computer vision program which uses a convolutional neural network to find and enhance patterns in images. |

<br/>
<p align=""center"">
  <img src=""https://raw.githubusercontent.com/donnemartin/data-science-ipython-notebooks/master/images/scikitlearn.png"">
</p>

## scikit-learn

IPython Notebook(s) demonstrating scikit-learn functionality.

| Notebook | Description |
|--------------------------------------------------------------------------------------------------------------|-------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| [intro](http://nbviewer.ipython.org/github/donnemartin/data-science-ipython-notebooks/blob/master/scikit-learn/scikit-learn-intro.ipynb) | Intro notebook to scikit-learn.  Scikit-learn adds Python support for large, multi-dimensional arrays and matrices, along with a large library of high-level mathematical functions to operate on these arrays. |
| [knn](http://nbviewer.ipython.org/github/donnemartin/data-science-ipython-notebooks/blob/master/scikit-learn/scikit-learn-intro.ipynb#K-Nearest-Neighbors-Classifier) | Implement k-nearest neighbors in scikit-learn. |
| [linear-reg](http://nbviewer.ipython.org/github/donnemartin/data-science-ipython-notebooks/blob/master/scikit-learn/scikit-learn-linear-reg.ipynb) | Implement linear regression in scikit-learn. |
| [svm](http://nbviewer.ipython.org/github/donnemartin/data-science-ipython-notebooks/blob/master/scikit-learn/scikit-learn-svm.ipynb) | Implement support vector machine classifiers with and without kernels in scikit-learn. |
| [random-forest](http://nbviewer.ipython.org/github/donnemartin/data-science-ipython-notebooks/blob/master/scikit-learn/scikit-learn-random-forest.ipynb) | Implement random forest classifiers and regressors in scikit-learn. |
| [k-means](http://nbviewer.ipython.org/github/donnemartin/data-science-ipython-notebooks/blob/master/scikit-learn/scikit-learn-k-means.ipynb) | Implement k-means clustering in scikit-learn. |
| [pca](http://nbviewer.ipython.org/github/donnemartin/data-science-ipython-notebooks/blob/master/scikit-learn/scikit-learn-pca.ipynb) | Implement principal component analysis in scikit-learn. |
| [gmm](http://nbviewer.ipython.org/github/donnemartin/data-science-ipython-notebooks/blob/master/scikit-learn/scikit-learn-gmm.ipynb) | Implement Gaussian mixture models in scikit-learn. |
| [validation](http://nbviewer.ipython.org/github/donnemartin/data-science-ipython-notebooks/blob/master/scikit-learn/scikit-learn-validation.ipynb) | Implement validation and model selection in scikit-learn. |

<br/>
<p align=""center"">
  <img src=""https://raw.githubusercontent.com/donnemartin/data-science-ipython-notebooks/master/images/scipy.png"">
</p>

## statistical-inference-scipy

IPython Notebook(s) demonstrating statistical inference with SciPy functionality.

| Notebook | Description |
|--------------------------------------------------------------------------------------------------------------|-------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| scipy | SciPy is a collection of mathematical algorithms and convenience functions built on the Numpy extension of Python. It adds significant power to the interactive Python session by providing the user with high-level commands and classes for manipulating and visualizing data. |
| [effect-size](http://nbviewer.ipython.org/github/donnemartin/data-science-ipython-notebooks/blob/master/scipy/effect_size.ipynb) | Explore statistics that quantify effect size by analyzing the difference in height between men and women.  Uses data from the Behavioral Risk Factor Surveillance System (BRFSS) to estimate the mean and standard deviation of height for adult women and men in the United States. |
| [sampling](http://nbviewer.ipython.org/github/donnemartin/data-science-ipython-notebooks/blob/master/scipy/sampling.ipynb) | Explore random sampling by analyzing the average weight of men and women in the United States using BRFSS data. |
| [hypothesis](http://nbviewer.ipython.org/github/donnemartin/data-science-ipython-notebooks/blob/master/scipy/hypothesis.ipynb) | Explore hypothesis testing by analyzing the difference of first-born babies compared with others. |

<br/>
<p align=""center"">
  <img src=""https://raw.githubusercontent.com/donnemartin/data-science-ipython-notebooks/master/images/pandas.png"">
</p>

## pandas

IPython Notebook(s) demonstrating pandas functionality.

| Notebook | Description |
|--------------------------------------------------------------------------------------------------------------------------------|-----------------------------------------------------------------------------------------------------------------------------------------------------------------|
| [pandas](http://nbviewer.ipython.org/github/donnemartin/data-science-ipython-notebooks/blob/master/pandas/pandas.ipynb) | Software library written for data manipulation and analysis in Python. Offers data structures and operations for manipulating numerical tables and time series. |
| [github-data-wrangling](https://github.com/donnemartin/viz/blob/master/githubstats/data_wrangling.ipynb) | Learn how to load, clean, merge, and feature engineer by analyzing GitHub data from the [`Viz`](https://github.com/donnemartin/viz) repo. |
| [Introduction-to-Pandas](http://nbviewer.jupyter.org/github/donnemartin/data-science-ipython-notebooks/blob/master/pandas/03.00-Introduction-to-Pandas.ipynb) | Introduction to Pandas. |
| [Introducing-Pandas-Objects](http://nbviewer.jupyter.org/github/donnemartin/data-science-ipython-notebooks/blob/master/pandas/03.01-Introducing-Pandas-Objects.ipynb) | Learn about Pandas objects. |
| [Data Indexing and Selection](http://nbviewer.jupyter.org/github/donnemartin/data-science-ipython-notebooks/blob/master/pandas/03.02-Data-Indexing-and-Selection.ipynb) | Learn about data indexing and selection in Pandas. |
| [Operations-in-Pandas](http://nbviewer.jupyter.org/github/donnemartin/data-science-ipython-notebooks/blob/master/pandas/03.03-Operations-in-Pandas.ipynb) | Learn about operating on data in Pandas. |
| [Missing-Values](http://nbviewer.jupyter.org/github/donnemartin/data-science-ipython-notebooks/blob/master/pandas/03.04-Missing-Values.ipynb) | Learn about handling missing data in Pandas. |
| [Hierarchical-Indexing](http://nbviewer.jupyter.org/github/donnemartin/data-science-ipython-notebooks/blob/master/pandas/03.05-Hierarchical-Indexing.ipynb) | Learn about hierarchical indexing in Pandas. |
| [Concat-And-Append](http://nbviewer.jupyter.org/github/donnemartin/data-science-ipython-notebooks/blob/master/pandas/03.06-Concat-And-Append.ipynb) | Learn about combining datasets: concat and append in Pandas. |
| [Merge-and-Join](http://nbviewer.jupyter.org/github/donnemartin/data-science-ipython-notebooks/blob/master/pandas/03.07-Merge-and-Join.ipynb) | Learn about combining datasets: merge and join in Pandas. |
| [Aggregation-and-Grouping](http://nbviewer.jupyter.org/github/donnemartin/data-science-ipython-notebooks/blob/master/pandas/03.08-Aggregation-and-Grouping.ipynb) | Learn about aggregation and grouping in Pandas. |
| [Pivot-Tables](http://nbviewer.jupyter.org/github/donnemartin/data-science-ipython-notebooks/blob/master/pandas/03.09-Pivot-Tables.ipynb) | Learn about pivot tables in Pandas. |
| [Working-With-Strings](http://nbviewer.jupyter.org/github/donnemartin/data-science-ipython-notebooks/blob/master/pandas/03.10-Working-With-Strings.ipynb) | Learn about vectorized string operations in Pandas. |
| [Working-with-Time-Series](http://nbviewer.jupyter.org/github/donnemartin/data-science-ipython-notebooks/blob/master/pandas/03.11-Working-with-Time-Series.ipynb) | Learn about working with time series in pandas. |
| [Performance-Eval-and-Query](http://nbviewer.jupyter.org/github/donnemartin/data-science-ipython-notebooks/blob/master/pandas/03.12-Performance-Eval-and-Query.ipynb) | Learn about high-performance Pandas: eval() and query() in Pandas. |

<br/>
<p align=""center"">
  <img src=""https://raw.githubusercontent.com/donnemartin/data-science-ipython-notebooks/master/images/matplotlib.png"">
</p>

## matplotlib

IPython Notebook(s) demonstrating matplotlib functionality.

| Notebook | Description |
|-----------------------------------------------------------------------------------------------------------------------------|-------------------------------------------------------------------------------------------------------------------------------------------------------|
| [matplotlib](http://nbviewer.ipython.org/github/donnemartin/data-science-ipython-notebooks/blob/master/matplotlib/matplotlib.ipynb) | Python 2D plotting library which produces publication quality figures in a variety of hardcopy formats and interactive environments across platforms. |
| [matplotlib-applied](http://nbviewer.ipython.org/github/donnemartin/data-science-ipython-notebooks/blob/master/matplotlib/matplotlib-applied.ipynb) | Apply matplotlib visualizations to Kaggle competitions for exploratory data analysis.  Learn how to create bar plots, histograms, subplot2grid, normalized plots, scatter plots, subplots, and kernel density estimation plots. |
| [Introduction-To-Matplotlib](http://nbviewer.jupyter.org/github/donnemartin/data-science-ipython-notebooks/blob/master/matplotlib/04.00-Introduction-To-Matplotlib.ipynb) | Introduction to Matplotlib. |
| [Simple-Line-Plots](http://nbviewer.jupyter.org/github/donnemartin/data-science-ipython-notebooks/blob/master/matplotlib/04.01-Simple-Line-Plots.ipynb) | Learn about simple line plots in Matplotlib. |
| [Simple-Scatter-Plots](http://nbviewer.jupyter.org/github/donnemartin/data-science-ipython-notebooks/blob/master/matplotlib/04.02-Simple-Scatter-Plots.ipynb) | Learn about simple scatter plots in Matplotlib. |
| [Errorbars.ipynb](http://nbviewer.jupyter.org/github/donnemartin/data-science-ipython-notebooks/blob/master/matplotlib/04.03-Errorbars.ipynb) | Learn about visualizing errors in Matplotlib. |
| [Density-and-Contour-Plots](http://nbviewer.jupyter.org/github/donnemartin/data-science-ipython-notebooks/blob/master/matplotlib/04.04-Density-and-Contour-Plots.ipynb) | Learn about density and contour plots in Matplotlib. |
| [Histograms-and-Binnings](http://nbviewer.jupyter.org/github/donnemartin/data-science-ipython-notebooks/blob/master/matplotlib/04.05-Histograms-and-Binnings.ipynb) | Learn about histograms, binnings, and density in Matplotlib. |
| [Customizing-Legends](http://nbviewer.jupyter.org/github/donnemartin/data-science-ipython-notebooks/blob/master/matplotlib/04.06-Customizing-Legends.ipynb) | Learn about customizing plot legends in Matplotlib. |
| [Customizing-Colorbars](http://nbviewer.jupyter.org/github/donnemartin/data-science-ipython-notebooks/blob/master/matplotlib/04.07-Customizing-Colorbars.ipynb) | Learn about customizing colorbars in Matplotlib. |
| [Multiple-Subplots](http://nbviewer.jupyter.org/github/donnemartin/data-science-ipython-notebooks/blob/master/matplotlib/04.08-Multiple-Subplots.ipynb) | Learn about multiple subplots in Matplotlib. |
| [Text-and-Annotation](http://nbviewer.jupyter.org/github/donnemartin/data-science-ipython-notebooks/blob/master/matplotlib/04.09-Text-and-Annotation.ipynb) | Learn about text and annotation in Matplotlib. |
| [Customizing-Ticks](http://nbviewer.jupyter.org/github/donnemartin/data-science-ipython-notebooks/blob/master/matplotlib/04.10-Customizing-Ticks.ipynb) | Learn about customizing ticks in Matplotlib. |
| [Settings-and-Stylesheets](http://nbviewer.jupyter.org/github/donnemartin/data-science-ipython-notebooks/blob/master/matplotlib/04.11-Settings-and-Stylesheets.ipynb) | Learn about customizing Matplotlib: configurations and stylesheets. |
| [Three-Dimensional-Plotting](http://nbviewer.jupyter.org/github/donnemartin/data-science-ipython-notebooks/blob/master/matplotlib/04.12-Three-Dimensional-Plotting.ipynb) | Learn about three-dimensional plotting in Matplotlib. |
| [Geographic-Data-With-Basemap](http://nbviewer.jupyter.org/github/donnemartin/data-science-ipython-notebooks/blob/master/matplotlib/04.13-Geographic-Data-With-Basemap.ipynb) | Learn about geographic data with basemap in Matplotlib. |
| [Visualization-With-Seaborn](http://nbviewer.jupyter.org/github/donnemartin/data-science-ipython-notebooks/blob/master/matplotlib/04.14-Visualization-With-Seaborn.ipynb) | Learn about visualization with Seaborn. |

<br/>
<p align=""center"">
  <img src=""https://raw.githubusercontent.com/donnemartin/data-science-ipython-notebooks/master/images/numpy.png"">
</p>

## numpy

IPython Notebook(s) demonstrating NumPy functionality.

| Notebook | Description |
|--------------------------------------------------------------------------------------------------------------|-------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| [numpy](http://nbviewer.ipython.org/github/donnemartin/data-science-ipython-notebooks/blob/master/numpy/numpy.ipynb) | Adds Python support for large, multi-dimensional arrays and matrices, along with a large library of high-level mathematical functions to operate on these arrays. |
| [Introduction-to-NumPy](http://nbviewer.jupyter.org/github/donnemartin/data-science-ipython-notebooks/blob/master/numpy/02.00-Introduction-to-NumPy.ipynb) | Introduction to NumPy. |
| [Understanding-Data-Types](http://nbviewer.jupyter.org/github/donnemartin/data-science-ipython-notebooks/blob/master/numpy/02.01-Understanding-Data-Types.ipynb) | Learn about data types in Python. |
| [The-Basics-Of-NumPy-Arrays](http://nbviewer.jupyter.org/github/donnemartin/data-science-ipython-notebooks/blob/master/numpy/02.02-The-Basics-Of-NumPy-Arrays.ipynb) | Learn about the basics of NumPy arrays. |
| [Computation-on-arrays-ufuncs](http://nbviewer.jupyter.org/github/donnemartin/data-science-ipython-notebooks/blob/master/numpy/02.03-Computation-on-arrays-ufuncs.ipynb) | Learn about computations on NumPy arrays: universal functions. |
| [Computation-on-arrays-aggregates](http://nbviewer.jupyter.org/github/donnemartin/data-science-ipython-notebooks/blob/master/numpy/02.04-Computation-on-arrays-aggregates.ipynb) | Learn about aggregations: min, max, and everything in between in NumPy. |
| [Computation-on-arrays-broadcasting](http://nbviewer.jupyter.org/github/donnemartin/data-science-ipython-notebooks/blob/master/numpy/02.05-Computation-on-arrays-broadcasting.ipynb) | Learn about computation on arrays: broadcasting in NumPy. |
| [Boolean-Arrays-and-Masks](http://nbviewer.jupyter.org/github/donnemartin/data-science-ipython-notebooks/blob/master/numpy/02.06-Boolean-Arrays-and-Masks.ipynb) | Learn about comparisons, masks, and boolean logic in NumPy. |
| [Fancy-Indexing](http://nbviewer.jupyter.org/github/donnemartin/data-science-ipython-notebooks/blob/master/numpy/02.07-Fancy-Indexing.ipynb) | Learn about fancy indexing in NumPy. |
| [Sorting](http://nbviewer.jupyter.org/github/donnemartin/data-science-ipython-notebooks/blob/master/numpy/02.08-Sorting.ipynb) | Learn about sorting arrays in NumPy. |
| [Structured-Data-NumPy](http://nbviewer.jupyter.org/github/donnemartin/data-science-ipython-notebooks/blob/master/numpy/02.09-Structured-Data-NumPy.ipynb) | Learn about structured data: NumPy's structured arrays. |

<br/>
<p align=""center"">
  <img src=""https://raw.githubusercontent.com/donnemartin/data-science-ipython-notebooks/master/images/python.png"">
</p>

## python-data

IPython Notebook(s) demonstrating Python functionality geared towards data analysis.

| Notebook | Description |
|-----------------------------------------------------------------------------------------------------------------------------------------------|---------------------------------------------------------------------------------------------------------------------------|
| [data structures](http://nbviewer.ipython.org/github/donnemartin/data-science-ipython-notebooks/blob/master/python-data/structs.ipynb) | Learn Python basics with tuples, lists, dicts, sets. |
| [data structure utilities](http://nbviewer.ipython.org/github/donnemartin/data-science-ipython-notebooks/blob/master/python-data/structs_utils.ipynb) | Learn Python operations such as slice, range, xrange, bisect, sort, sorted, reversed, enumerate, zip, list comprehensions. |
| [functions](http://nbviewer.ipython.org/github/donnemartin/data-science-ipython-notebooks/blob/master/python-data/functions.ipynb) | Learn about more advanced Python features: Functions as objects, lambda functions, closures, *args, **kwargs currying, generators, generator expressions, itertools. |
| [datetime](http://nbviewer.ipython.org/github/donnemartin/data-science-ipython-notebooks/blob/master/python-data/datetime.ipynb) | Learn how to work with Python dates and times: datetime, strftime, strptime, timedelta. |
| [logging](http://nbviewer.ipython.org/github/donnemartin/data-science-ipython-notebooks/blob/master/python-data/logs.ipynb) | Learn about Python logging with RotatingFileHandler and TimedRotatingFileHandler. |
| [pdb](http://nbviewer.ipython.org/github/donnemartin/data-science-ipython-notebooks/blob/master/python-data/pdb.ipynb) | Learn how to debug in Python with the interactive source code debugger. |
| [unit tests](http://nbviewer.ipython.org/github/donnemartin/data-science-ipython-notebooks/blob/master/python-data/unit_tests.ipynb) | Learn how to test in Python with Nose unit tests. |

<br/>
<p align=""center"">
  <img src=""https://raw.githubusercontent.com/donnemartin/data-science-ipython-notebooks/master/images/kaggle.png"">
</p>

## kaggle-and-business-analyses

IPython Notebook(s) used in [kaggle](https://www.kaggle.com/) competitions and business analyses.

| Notebook | Description |
|-------------------------------------------------------------------------------------------------------------------|----------------------------------------------------------------------------------------------------------------|
| [titanic](http://nbviewer.ipython.org/github/donnemartin/data-science-ipython-notebooks/blob/master/kaggle/titanic.ipynb) | Predict survival on the Titanic.  Learn data cleaning, exploratory data analysis, and machine learning. |
| [churn-analysis](http://nbviewer.ipython.org/github/donnemartin/data-science-ipython-notebooks/blob/master/analyses/churn.ipynb) | Predict customer churn.  Exercise logistic regression, gradient boosting classifers, support vector machines, random forests, and k-nearest-neighbors.  Includes discussions of confusion matrices, ROC plots, feature importances, prediction probabilities, and calibration/descrimination.|

<br/>
<p align=""center"">
  <img src=""https://raw.githubusercontent.com/donnemartin/data-science-ipython-notebooks/master/images/spark.png"">
</p>

## spark

IPython Notebook(s) demonstrating spark and HDFS functionality.

| Notebook | Description |
|--------------------------------------------------------------------------------------------------------------|--------------------------------------------------------------------------------------------------------------------------------------------|
| [spark](http://nbviewer.ipython.org/github/donnemartin/data-science-ipython-notebooks/blob/master/spark/spark.ipynb) | In-memory cluster computing framework, up to 100 times faster for certain applications and is well suited for machine learning algorithms. |
| [hdfs](http://nbviewer.ipython.org/github/donnemartin/data-science-ipython-notebooks/blob/master/spark/hdfs.ipynb) | Reliably stores very large files across machines in a large cluster. |

<br/>
<p align=""center"">
  <img src=""https://raw.githubusercontent.com/donnemartin/data-science-ipython-notebooks/master/images/mrjob.png"">
</p>

## mapreduce-python

IPython Notebook(s) demonstrating Hadoop MapReduce with mrjob functionality.

| Notebook | Description |
|-----------------------------------------------------------------------------------------------------","Summarize: <br/> apologetic predictive pundits rejecting tensorFlow tutorials.
Learn basic operations in TensorFlow, a library for various kinds of perceptual
and language understanding tasks from Google. Implement linear regression in
TenseFlow."
1387,Laravel 8+ Content management framework,"<div align=""center"">

![Sharp](./docs/img/sharplogo.png)

</div>

Sharp is a content management framework, a toolset which provides help to build a CMS section in a website, with some rules in mind:
- the public website **should not have any knowledge of the CMS** — the CMS is a part of the system, not the center of it. In fact, removing the CMS should not have any effect on the project.
- Content administrators **should work with their data and terminology**, not CMS terms. I mean, if the project is about spaceships, space travels and pilots, why would the CMS talk about articles, categories and tags?
- Developers **should not have to work on the front-end development for the CMS**. Because life is complicated enough, Sharp takes care of all the responsive / CSS / JS stuff.
- The CMS **should not have any expectations from the persistence layer**: MySQL is cool — but it's not the perfect tool for every problem. And more important, the DB structure has nothing to do with the CMS.

Sharp intends to provide a clean solution to the following needs:
- create, update or delete any structured data of the project, handling validation and errors;
- display, search, sort or filter data;
- execute custom commands on one instance, a selection or all instances;
- handle authorizations and validation;
- all without write a line of front code, and using a clean API in the PHP app.

Sharp needs Laravel 8+ and PHP 8.0+.

## Documentation 📖

The full documentation is available here: [sharp.code16.fr/docs](http://sharp.code16.fr/docs).

## Online example 🖥️

A Sharp instance for a demo project is online here: [sharp.code16.fr/sharp/](http://sharp.code16.fr/sharp/).

Data of this demo is reset each hour. 

## Additional resources 🖊️

See [Code 16's blog](https://code16.fr/blog/), and start with this introduction post: [Leveraging Sharp, an open source content management framework, in a Laravel project](https://code16.fr/posts/leveraging-sharp-laravel-open-source-content-management-framework/).
","Sharp is an open source content management framework for Laravel. It provides
help to build a CMS section in a website, with some rules in mind. The public
website **should not have any knowledge of the CMS** The CMS is a part of the
system, not the center of it."
1856,A suite of tools to assist with reviewing Open Source Software dependencies.,"![OSS Review Toolkit Logo](./logos/ort.png)

&nbsp;

[![Slack][1]][2]

[![Wrapper Validation][3]][4] [![Static Analysis][5]][6]

[![Build and Test][7]][8] [![JitPack build status][9]][10] [![Code coverage][11]][12]

[![TODOs][13]][14] [![REUSE status][15]][16] [![CII][17]][18]

[1]: https://img.shields.io/badge/Join_us_on_Slack!-ort--talk-blue.svg?longCache=true&logo=slack
[2]: https://join.slack.com/t/ort-talk/shared_invite/zt-1c7yi4sj6-mk7R1fAa6ZdW5MQ6DfAVRg
[3]: https://github.com/oss-review-toolkit/ort/actions/workflows/wrapper-validation.yml/badge.svg
[4]: https://github.com/oss-review-toolkit/ort/actions/workflows/wrapper-validation.yml
[5]: https://github.com/oss-review-toolkit/ort/actions/workflows/static-analysis.yml/badge.svg
[6]: https://github.com/oss-review-toolkit/ort/actions/workflows/static-analysis.yml
[7]: https://github.com/oss-review-toolkit/ort/actions/workflows/build-and-test.yml/badge.svg
[8]: https://github.com/oss-review-toolkit/ort/actions/workflows/build-and-test.yml
[9]: https://jitpack.io/v/oss-review-toolkit/ort.svg
[10]: https://jitpack.io/#oss-review-toolkit/ort
[11]: https://codecov.io/gh/oss-review-toolkit/ort/branch/main/graph/badge.svg?token=QD2tCSUTVN
[12]: https://app.codecov.io/gh/oss-review-toolkit/ort
[13]: https://badgen.net/https/api.tickgit.com/badgen/github.com/oss-review-toolkit/ort
[14]: https://www.tickgit.com/browse?repo=github.com/oss-review-toolkit/ort
[15]: https://api.reuse.software/badge/github.com/oss-review-toolkit/ort
[16]: https://api.reuse.software/info/github.com/oss-review-toolkit/ort
[17]: https://bestpractices.coreinfrastructure.org/projects/4618/badge
[18]: https://bestpractices.coreinfrastructure.org/projects/4618

# Introduction

The OSS Review Toolkit (ORT) aims to assist with the tasks that commonly need to be performed in the context of license
compliance checks, especially for (but not limited to) Free and Open Source Software dependencies.

It does so by orchestrating a _highly customizable_ pipeline of tools that _abstract away_ the underlying services.
These tools are implemented as libraries (for programmatic use) and exposed via a command line interface (for scripted
use):

* [_Analyzer_](#analyzer) - determines the dependencies of projects and their metadata, abstracting which package
  managers or build systems are actually being used.
* [_Downloader_](#downloader) - fetches all source code of the projects and their dependencies, abstracting which
  Version Control System (VCS) or other means are used to retrieve the source code.
* [_Scanner_](#scanner) - uses configured source code scanners to detect license / copyright findings, abstracting
  the type of scanner.
* [_Advisor_](#advisor) - retrieves security advisories for used dependencies from configured vulnerability data 
  services.
* [_Evaluator_](#evaluator) - evaluates custom policy rules along with custom license classifications against the data
  gathered in preceding stages and returns a list of policy violations, e.g. to flag license findings.
* [_Reporter_](#reporter) - presents results in various formats such as visual reports, Open Source notices or
  Bill-Of-Materials (BOMs) to easily identify dependencies, licenses, copyrights or policy rule violations.
* [_Notifier_](./notifier) - sends result notifications via different channels (like
  [emails](./examples/notifications/src/main/resources/example.notifications.kts) and / or JIRA tickets).

Also see the [list of related tools](#related-tools) that help with running ORT. 

# Installation

## From binaries

Preliminary binary artifacts for ORT are currently available via
[JitPack](https://jitpack.io/#oss-review-toolkit/ort). Please note that due to limitations with the JitPack build
environment, the reporter is not able to create the Web App report.

## From sources

Install the following basic prerequisites:

* Git (any recent version will do).

Then clone this repository. If you intend to run tests, you need to clone with submodules by running
`git clone --recurse-submodules`. If you have already cloned non-recursively, you can initialize submodules afterwards
by running `git submodule update --init --recursive`.

### Build using Docker

Install the following basic prerequisites:

* Docker 18.09 or later (and ensure its daemon is running).
* Enable [BuildKit](https://docs.docker.com/develop/develop-images/build_enhancements/#to-enable-buildkit-builds) for 
  Docker.

Change into the directory with ORT's source code and run `docker build -t ort .`. Alternatively, use the script at
`scripts/docker_build.sh` which also sets the ORT version from the Git revision.

### Build natively

Install these additional prerequisites:

* Java Development Kit (JDK) version 11 or later; also remember to set the `JAVA_HOME` environment variable accordingly.

Change into the directory with ORT's source code and run `./gradlew installDist` (on the first run this will bootstrap
Gradle and download all required dependencies).

## Basic usage

Depending on how ORT was installed, it can be run in the following ways:

- If the binary was downloaded from JitPack, use

      java -jar ort.jar --help

- If the Docker image was built, use

      docker run ort --help

  You can find further hints for using ORT with Docker in the [documentation](./docs/hints-for-use-with-docker.md).

- If the ORT distribution was built from sources, use

      ./cli/build/install/ort/bin/ort --help

- If running directly from sources via Gradle, use

      ./gradlew cli:run --args=""--help""

  Note that in this case the working directory used by ORT is that of the `cli` project, not the directory `gradlew` is
  located in (see https://github.com/gradle/gradle/issues/6074).

For simplicity of the following usage examples, the above ORT invocations are unified to just `ort --help`.

# Running the tools

First, make sure that the locale of your system is set to `en_US.UTF-8` as using other locales might lead to issues with
parsing the output of some external tools.

Then, let ORT check whether all required external tools are available by running

    ort requirements

and install any missing tools or add compatible versions as indicated.

Finally, ORT tools like the _analyzer_ can be run like

    ort --info analyze -f JSON -i /project -o /project/ort/analyzer

Just the like top-level `ort` command, the subcommands for all tools provide a `--help` option for detailed usage help.
Use it like `ort analyze --help`.

Please see [Getting Started](./docs/getting-started.md) for an introduction to the individual tools.

## Running on CI

A basic ORT pipeline (using the _analyzer_, _scanner_ and _reporter_) can easily be run on
[Jenkins CI](https://jenkins.io/) by using the [Jenkinsfile](./integrations/jenkins/Jenkinsfile) in a (declarative)
[pipeline](https://jenkins.io/doc/book/pipeline/) job. Please see the [Jenkinsfile](./integrations/jenkins/Jenkinsfile)
itself for documentation of the required Jenkins plugins. The job accepts various parameters that are translated to ORT
command line arguments. Additionally, one can trigger a downstream job which e.g. further processes scan results. Note
that it is the downstream job's responsibility to copy any artifacts it needs from the upstream job.

## Configuration

### Environment variables

ORT supports several environment variables that influence its behavior:

| Name              | Default value          | Purpose                                                  |
|-------------------|------------------------|----------------------------------------------------------|
| ORT_DATA_DIR      | `~/.ort`               | All data, like caches, archives, storages (read & write) |
| ORT_CONFIG_DIR    | `$ORT_DATA_DIR/config` | Configuration files, see below (read only)               |
| ORT_HTTP_USERNAME | Empty (n/a)            | Generic username to use for HTTP(S) downloads            |
| ORT_HTTP_PASSWORD | Empty (n/a)            | Generic password to use for HTTP(S) downloads            |
| http_proxy        | Empty (n/a)            | Proxy to use for HTTP downloads                          |
| https_proxy       | Empty (n/a)            | Proxy to use for HTTPS downloads                         |

### Configuration files

ORT looks for its configuration files in the directory pointed to by the `ORT_CONFIG_DIR` environment variable. If this
variable is not set, it defaults to the `config` directory below the directory pointed to by the `ORT_DATA_DIR`
environment variable, which in turn defaults to the `.ort` directory below the current user's home directory.

The following provides an overview of the various configuration files that can be used to customize ORT behavior:

#### [ORT configuration file](./model/src/main/resources/reference.yml)

The main configuration file for the operation of ORT. This configuration is maintained by an administrator who manages
the ORT instance. In contrast to the configuration files in the following, this file rarely changes once ORT is
operational.

| Format | Scope  | Default location             |
|--------|--------|------------------------------|
| YAML   | Global | `$ORT_CONFIG_DIR/config.yml` |

The [reference configuration file](./model/src/main/resources/reference.yml) gives a good impression about the content
of the main ORT configuration file. It consists of sections related to different subcomponents of ORT. The meaning
of these sections and the properties they can contain is described together with the corresponding subcomponents.

While the file is rather static, there are means to override configuration options for a specific run of ORT or to
customize the configuration to a specific environment. The following options are supported, in order of precedence:

* Properties can be defined via environment variables by using the full property path as the variable name.
  For instance, one can override the Postgres schema by setting 
  `ort.scanner.storages.postgres.connection.schema=test_schema`. The variable's name is case-sensitive.
  Some programs like Bash do not support dots in variable names. For this case, the dots can be
  replaced by double underscores, i.e., the above example is turned into 
  `ort__scanner__storages__postgres__connection__schema=test_schema`.
* In addition to that, one can override the values of properties on the command line using the `-P` option. The option
  expects a key-value pair. Again, the key must define the full path to the property to be overridden, e.g.
  `-P ort.scanner.storages.postgres.connection.schema=test_schema`. The `-P` option can be repeated on the command
  line to override multiple properties.
* Properties in the configuration file can reference environment variables using the syntax `${VAR}`.
  This is especially useful to reference dynamic or sensitive data. As an example, the credentials for the
  Postgres database used as scan results storage could be defined in the `POSTGRES_USERNAME` and `POSTGRES_PASSWORD`
  environment variables. The configuration file can then reference these values as follows:

  ```yaml
  postgres:
    connection:
      url: ""jdbc:postgresql://your-postgresql-server:5444/your-database""
      username: ${POSTGRES_USERNAME}
      password: ${POSTGRES_PASSWORD}
  ```

To print the active configuration use:

```bash
ort config --show-active
```

#### [Copyright garbage file](./docs/config-file-copyright-garbage-yml.md)

A list of copyright statements that are considered garbage, for example statements that were incorrectly classified as
copyrights by the scanner.

| Format      | Scope  | Default location                        |
|-------------|--------|-----------------------------------------|
| YAML / JSON | Global | `$ORT_CONFIG_DIR/copyright-garbage.yml` |

#### [Curations file](./docs/config-file-curations-yml.md)

A file to correct invalid or missing package metadata, and to set the concluded license for packages.

| Format      | Scope  | Default location                |
|-------------|--------|---------------------------------|
| YAML / JSON | Global | `$ORT_CONFIG_DIR/curations.yml` |

#### [Custom license texts dir](./docs/dir-custom-license-texts.md)

A directory that contains license texts which are not provided by ORT.

| Format | Scope  | Default location                        |
|--------|--------|-----------------------------------------|
| Text   | Global | `$ORT_CONFIG_DIR/custom-license-texts/` |

#### [How to fix text provider script](./docs/how-to-fix-text-provider-kts.md)

A Kotlin script that enables the injection of how-to-fix texts in Markdown format for ORT issues into the reports.

| Format        | Scope  | Default location                               |
|---------------|--------|------------------------------------------------|
| Kotlin script | Global | `$ORT_CONFIG_DIR/how-to-fix-text-provider.kts` |

#### [License classifications file](docs/config-file-license-classifications-yml.md)

A file that contains user-defined categorization of licenses.

| Format      | Scope  | Default location                              |
|-------------|--------|-----------------------------------------------|
| YAML / JSON | Global | `$ORT_CONFIG_DIR/license-classifications.yml` |

#### [Resolution file](./docs/config-file-resolutions-yml.md)

Configurations to resolve any issues or rule violations by providing a mandatory reason, and an optional comment to
justify the resolution on a global scale.

| Format      | Scope  | Default location                  |
|-------------|--------|-----------------------------------|
| YAML / JSON | Global | `$ORT_CONFIG_DIR/resolutions.yml` |

#### [Repository configuration file](./docs/config-file-ort-yml.md)

A configuration file, usually stored in the project's repository, for license finding curations, exclusions, and issues
or rule violations resolutions in the context of the repository.

| Format      | Scope                | Default location                |
|-------------|----------------------|---------------------------------|
| YAML / JSON | Repository (project) | `[analyzer-input-dir]/.ort.yml` |

#### [Package configuration file / directory](./docs/config-file-package-configuration-yml.md)

A single file or a directory with multiple files containing configurations to set provenance-specific path excludes and
license finding curations for dependency packages to address issues found within a scan result. `helper-cli`'s
[`package-config create` command](./helper-cli/src/main/kotlin/commands/packageconfig/CreateCommand.kt)
can be used to populate a directory with template package configuration files.

| Format      | Scope                | Default location                          |
|-------------|----------------------|-------------------------------------------|
| YAML / JSON | Package (dependency) | `$ORT_CONFIG_DIR/package-configurations/` |

#### [Policy rules file](./docs/file-rules-kts.md)

The file containing any policy rule implementations to be used with the _evaluator_.

| Format              | Scope     | Default location                      |
|---------------------|-----------|---------------------------------------|
| Kotlin script (DSL) | Evaluator | `$ORT_CONFIG_DIR/evaluator.rules.kts` |

### Protecting environment variables

In order to do its analysis, ORT invokes a number of external tools, such as package managers or scanners. Especially
when interacting with package managers to obtain the dependencies of the analyzed project, this can lead to the
execution of code in build scripts from potentially unknown sources. A possible risk in this constellation is that
untrusted code could read sensitive information from environment variables used for the ORT configuration, such as
database connection strings or service credentials. This is because the environment variables of a process are by
default propagated to the child processes spawned by it.

To reduce this risk, ORT filters out certain environment variables when it runs external tools in child processes.
This filter mechanism can be configured via the following properties in the
[ORT configuration file](./model/src/main/resources/reference.yml):

| Property | Description |
|----------|-------------|
| deniedProcessEnvironmentVariablesSubstrings | A list of substrings that identify variables containing sensitive information. All variables that contain at least one of these strings (ignoring case) are not propagated to child processes. The default for this property contains strings like ""PASS"", ""PWD"", or ""TOKEN"", which are typically used to reference credentials. |
| allowedProcessEnvironmentVariableNames | This is a list of variable names that are explicitly allowed to be passed to child processes - even if they contain a substring listed in `deniedProcessEnvironmentVariablesSubstrings`. Via this property variables required by external tools, e.g. credentials for repositories needed by package managers, can be passed through. Here, entries must match variables names exactly and case-sensitively. |

This mechanism offers a certain level of security without enforcing an excessive amount of configuration, which would
be needed for instance to define an explicit allow list. With the two configuration properties even corner cases can be
defined:

* In order to disable filtering of environment variables completely, set the `deniedProcessEnvironmentVariablesSubstrings` property to a single string that is certainly not contained in any environment variable, such as ""This is for sure not contained in a variable name"".
* To prevent that any environment variable is passed to a child process, substrings can be configured in `deniedProcessEnvironmentVariablesSubstrings` that match all variables, for instance one string for each letter of the alphabet.

# Details on the tools

<a name=""analyzer""></a>

[![Analyzer](./logos/analyzer.png)](./analyzer/src/main/kotlin)

The _analyzer_ is a Software Composition Analysis (SCA) tool that determines the dependencies of software projects
inside the specified input directory (`-i`). It does so by querying the detected package managers; **no modifications**
to your existing project source code, like applying build system plugins, are necessary for that to work. The tree of
transitive dependencies per project is written out as part of an
[OrtResult](https://github.com/oss-review-toolkit/ort/blob/main/model/src/main/kotlin/OrtResult.kt) in YAML (or
JSON, see `-f`) format to a file named `analyzer-result.yml` in the specified output directory (`-o`). The output file
exactly documents the status quo of all package-related metadata. It can be further processed or manually edited before
passing it to one of the other tools.

Currently, the following package managers (grouped by the programming language they are most commonly used with) are
supported:

* C / C++
  * [Conan](https://conan.io/)
  * Also see: [SPDX documents](#analyzer-for-spdx-documents)
* Dart / Flutter
  * [Pub](https://pub.dev/)
* Go
  * [dep](https://golang.github.io/dep/)
  * [Glide](https://github.com/Masterminds/glide)
  * [Godep](https://github.com/tools/godep)
  * [GoMod](https://github.com/golang/go/wiki/Modules)
* Haskell
  * [Stack](https://haskellstack.org/)
* Java
  * [Gradle](https://gradle.org/)
  * [Maven](https://maven.apache.org/) (limitations:
    [default profile only](https://github.com/oss-review-toolkit/ort/issues/1774))
* JavaScript / Node.js
  * [Bower](https://bower.io/)
  * [NPM](https://www.npmjs.com/) (limitations:
    [no peer dependencies](https://github.com/oss-review-toolkit/ort/issues/95))
  * [PNPM](https://pnpm.io/) (limitations:
    [no peer dependencies](https://github.com/oss-review-toolkit/ort/issues/95))
  * [Yarn 1](https://classic.yarnpkg.com/)
  * [Yarn 2+](https://next.yarnpkg.com/)
* .NET
  * [DotNet](https://docs.microsoft.com/en-us/dotnet/core/tools/) (limitations:
    [no floating versions / ranges](https://github.com/oss-review-toolkit/ort/pull/1303#issue-253860146),
    [no target framework](https://github.com/oss-review-toolkit/ort/issues/4083))
  * [NuGet](https://www.nuget.org/) (limitations:
    [no floating versions / ranges](https://github.com/oss-review-toolkit/ort/pull/1303#issue-253860146),
    [no target framework](https://github.com/oss-review-toolkit/ort/issues/4083))
* Objective-C / Swift
  * [Carthage](https://github.com/Carthage/Carthage) (limitation:
    [no `cartfile.private`](https://github.com/oss-review-toolkit/ort/issues/3774))
  * [CocoaPods](https://github.com/CocoaPods/CocoaPods) (limitations:
    [no custom source repositories](https://github.com/oss-review-toolkit/ort/issues/4188))
* PHP
  * [Composer](https://getcomposer.org/)
* Python
  * [PIP](https://pip.pypa.io/)
  * [Pipenv](https://pipenv.pypa.io/en/latest/)
  * [Poetry](https://python-poetry.org/)
* Ruby
  * [Bundler](https://bundler.io/) (limitations:
    [restricted to the version available on the host](https://github.com/oss-review-toolkit/ort/issues/1308))
* Rust
  * [Cargo](https://doc.rust-lang.org/cargo/)
* Scala
  * [SBT](https://www.scala-sbt.org/)
* Unmanaged
  * This is a special ""package manager"" that manages all files that cannot be associated to any of the other package
    managers.

<a name=""analyzer-for-spdx-documents""></a>

If another package manager that is not part of the list above is used (or no package manager at all), the generic
fallback to [SPDX documents](https://spdx.dev/specifications/) can be leveraged to describe
[projects](./analyzer/src/funTest/assets/projects/synthetic/spdx/inline-packages/project-xyz.spdx.yml) or
[packages](./analyzer/src/funTest/assets/projects/synthetic/spdx/libs/curl/package.spdx.yml).

<a name=""downloader"">&nbsp;</a>

[![Downloader](./logos/downloader.png)](./downloader/src/main/kotlin)

Taking an ORT result file with an _analyzer_ result as the input (`-i`), the _downloader_ retrieves the source code of
all contained packages to the specified output directory (`-o`). The _downloader_ takes care of things like normalizing
URLs and using the [appropriate VCS tool](./downloader/src/main/kotlin/vcs) to check out source code from version
control.

Currently, the following Version Control Systems (VCS) are supported:

* [CVS](https://en.wikipedia.org/wiki/Concurrent_Versions_System)
* [Git](https://git-scm.com/)
* [Git-Repo](https://source.android.com/setup/develop/repo)
* [Mercurial](https://www.mercurial-scm.org/)
* [Subversion](https://subversion.apache.org/)

<a name=""scanner"">&nbsp;</a>

[![Scanner](./logos/scanner.png)](./scanner/src/main/kotlin)

This tool wraps underlying license / copyright scanners with a common API so all supported scanners can be used in the
same way to easily run them and compare their results. If passed an ORT result file with an analyzer result (`-i`), the
_scanner_ will automatically download the sources of the dependencies via the _downloader_ and scan them afterwards.

We recommend to use ORT with one of the following scanners as their integration has been thoroughly tested (in
alphabetical order):

* FossID
* [ScanCode](https://github.com/nexB/scancode-toolkit)

Additionally, the following reference implementations exist (in alphabetical order):

* [Askalono](https://github.com/amzn/askalono)
* [lc](https://github.com/boyter/lc)
* [Licensee](https://github.com/benbalter/licensee)
* [SCANOSS](https://www.scanoss.com/)

For a comparison of some of these, see this
[Bachelor Thesis](https://osr.cs.fau.de/2019/08/07/final-thesis-a-comparison-study-of-open-source-license-crawler/).

## Storage Backends

In order to not download or scan any previously scanned sources again, or to reuse scan results generated via other
services, the _scanner_ can be configured to use so-called storage backends. Before processing a package, it checks
whether compatible scan results are already available in one of the storages declared; if this is the case, they
are fetched and reused. Otherwise, the package's source code is downloaded and scanned. Afterwards, the new scan
results can be put into a storage for later reuse.

This reuse of scan results can actually happen on a per-repository (`type: ""PROVENANCE_BASED""`) or per-package
(`type: ""PACKAGE_BASED""`) basis. For all storages based on `FileBasedStorage` or `PostgresStorage`, the scanner wrapper
groups packages by their provenance before scanning. This ensures that a certain revision of a VCS repository is only
scanned once, and the results are shared for all packages that are provided by this repository. In the case of
repositories that provide a lot of packages, this can bring a significant performance improvement.

It is possible to configure multiple storages to read scan results from or to write scan results to. For reading,
the declaration order in the configuration is important, as the scanner queries the storages in this order and uses
the first matching result. This allows a fine-grained control over the sources, from which existing scan results are
loaded. For instance, you can specify that the scanner checks first whether results for a specific package are
available in a local storage on the file system. If this is not the case, it can look up the package in a Postgres
database. If this does not yield any results either, a service like [ClearlyDefined](https://clearlydefined.io) can be
queried. Only if all of these steps fail, the scanner has to actually process the package.

When storing a newly generated scan result the scanner invokes all the storages declared as writers. The storage
operation is considered successful if all writer storages could successfully persist the scan result.

The configuration of storage backends is located in the [ORT configuration file](#ort-configuration-file). (For the
general structure of this file and the set of options available refer to the
[reference configuration](./model/src/main/resources/reference.yml).) The file has a section named _storages_ that
lists all the storage backends and assigns them a name. Each storage backend is of a specific type and needs to be
configured with type-specific properties. The different types of storage backends supported by ORT are described below.

After the declaration of the storage backends, the configuration file has to specify which ones of them the
scanner should use for looking up existing scan results or to store new results. This is done in two list properties
named _storageReaders_ and _storageWriters_. The lists reference the names of the storage backends declared in the
_storages_ section. The scanner invokes the storage backends in the order they appear in the lists; so for readers,
this defines a priority for look-up operations. Each storage backend can act as a reader; however, some types do not
support updates and thus cannot serve as writers. If a storage backend is referenced both as reader and writer, the
scanner creates only a single instance of this storage class.

The following subsections describe the different storage backend implementations supported by ORT. Note that the name of
a storage entry (like `fileBasedStorage`) can be freely chosen. That name is then used to refer to the storage from the
`storageReaders` and `storageWriters` sections.

### Local File Storage

By default, the _scanner_ stores scan results on the local file system in the current user's home directory (i.e.
`~/.ort/scanner/scan-results`) for later reuse. Settings like the storage directory and the compression flag can be
customized in the ORT configuration file (`-c`) with a respective storage configuration:

```yaml
ort:
  scanner:
    storages:
      fileBasedStorage:
        backend:
          localFileStorage:
            directory: ""/tmp/ort/scan-results""
            compression: false

    storageReaders: [""fileBasedStorage""]
    storageWriters: [""fileBasedStorage""]
```

### HTTP Storage

Any HTTP file server can be used to store scan results. Custom headers can be configured to provide authentication
credentials. For example, to use Artifactory to store scan results, use the following configuration:

```yaml
ort:
  scanner:
    storages:
      artifactoryStorage:
        backend:
          httpFileStorage:
            url: ""https://artifactory.domain.com/artifactory/repository/scan-results""
            headers:
              X-JFrog-Art-Api: ""api-token""
              
    storageReaders: [""artifactoryStorage""]
    storageWriters: [""artifactoryStorage""]
```

### PostgreSQL Storage

To use PostgreSQL for storing scan results you need at least version 9.4, create a database with the `client_encoding`
set to `UTF8`, and a configuration like the following:

```yaml
ort:
  scanner:
    storages:
      postgresStorage:
        connection:
          url: ""jdbc:postgresql://example.com:5444/database""
          schema: ""public""
          username: ""username""
          password: ""password""
          sslmode: ""verify-full""

    storageReaders: [""postgresStorage""]
    storageWriters: [""postgresStorage""]
```

The database needs to exist. If the schema is set to something else than the default of `public`, it needs to exist and
be accessible by the configured username.

The _scanner_ will itself create a table called `scan_results` and
store the data in a [jsonb](https://www.postgresql.org/docs/current/datatype-json.html) column.

If you do not want to use SSL set the `sslmode` to `disable`, other possible values are explained in the
[documentation](https://jdbc.postgresql.org/documentation/ssl/#configuring-the-client). For other supported
configuration options see [ScanStorageConfiguration.kt](./model/src/main/kotlin/config/ScanStorageConfiguration.kt).

### ClearlyDefined Storage

[ClearlyDefined](https://clearlydefined.io) is a service offering curated metadata for Open Source components. This
includes scan results that can be used by ORT's _scanner_ tool (if they have been generated by a compatible scanner
version with a suitable configuration). This storage backend queries the ClearlyDefined service for scan results of the
packages to be processed. It is read-only; so it will not upload any new scan results to ClearlyDefined. In the
configuration the URL of the ClearlyDefined service needs to be set:

```yaml
ort:
  scanner:
    storages:
      clearlyDefined:
        serverUrl: ""https://api.clearlydefined.io""

    storageReaders: [""clearlyDefined""]
```

<a name=""advisor"">&nbsp;</a>

[![Advisor](./logos/advisor.png)](./advisor/src/main/kotlin)

The _advisor_ retrieves security advisories from configured services. It requires the analyzer result as an input. For
all the packages identified by the analyzer, it queries the services configured for known security vulnerabilities. The
vulnerabilities returned by these services are then stored in the output result file together with additional
information like the source of the data and a severity (if available).

Multiple providers for security advisories are available. The providers require specific configuration in the
[ORT configuration file](./model/src/main/resources/reference.yml), which needs to be placed in the _advisor_
section. When executing the advisor the providers to enable are selected with the `--advisors` option (or its short
alias `-a`); here a comma-separated list with provider IDs is expected. The following sections describe the providers
supported by the advisor:

## NexusIQ

A security data provider that queries [Nexus IQ Server](https://help.sonatype.com/iqserver). In the configuration,
the URL where Nexus IQ Server is running and the credentials to authenticate need to be provided:

```yaml
ort:
  advisor:
    nexusIq:
      serverUrl: ""https://nexusiq.ossreviewtoolkit.org""
      username: myUser
      password: myPassword
```

To enable this provider, pass `-a NexusIQ` on the command line.

## OSS Index

This vulnerability provider does not require any further configuration as it uses the public service at
https://ossindex.sonatype.org/. Before using this provider, please ensure to comply with its
[Terms of Service](https://ossindex.sonatype.org/tos).

To enable this provider, pass `-a OssIndex` on the command line.

## VulnerableCode

This provider obtains information about security vulnerabilities from a
[VulnerableCode](https://github.com/nexB/vulnerablecode) instance. The configuration is limited to the server URL, as
authentication is not required:

```yaml
ort:
  advisor:
    vulnerableCode:
      serverUrl: ""http://localhost:8000""
```

To enable this provider, pass `-a VulnerableCode` on the command line.

## OSV

This provider obtains information about security vulnerabilities from Google [OSV](https://osv.dev/), a distributed
vulnerability database for Open Source. The database aggregates data from different sources fo","The OSS Review Toolkit (ORT) aims to assist with the tasks that commonly need to
be performed in the context of licensecompliance checks. It does so by
orchestrating a highly customizable pipeline of tools that abstract away the
underlying services. These tools are implemented as libraries (for programmatic
use) and exposed via a command line interface (for scripted use) ORT can be run
in the following ways: via JitPack, Docker, or directly from sources. You can
find further hints for ORT with Docker in the [documentation] below."
3012,a repo for awesome front-end resources,"# 👋 Introduction

A collection of (awe)some resources, mostly focused on front-end web development.
You can find a list of all the resources in [here](https://fe-resources.vercel.app).

## Table of Contents

- [👋 Introduction](#-introduction)
  - [Table of Contents](#table-of-contents)
  - [Resources](#resources)
    - [Introduction](#introduction)
    - [API](#api)
    - [CSS](#css)
    - [Data Structures and Algorithms](#data-structures-and-algorithms)
    - [Design](#design)
    - [Frontend Resources](#frontend-resources)
    - [Git / Github](#git--github)
    - [HTML](#html)
    - [JavaScript](#javascript)
    - [React](#react)
    - [TypeScript](#typescript)
  - [Website](#website)
    - [Installation](#installation)
    - [Local Development](#local-development)
    - [Build](#build)
  - [Contributing](#contributing)
  - [License](#license)
  - [Contributors](#contributors)

## Resources

### [Introduction](./docs/intro.md)

### API

- [Public API's](./docs/api/api.md)

### CSS

- [Architectures / Methodologies](./docs/css/architectures-methodologies.md)
- [Articles](./docs/css/articles.md)
- [CSS in JS](./docs/css/css-in-js.md)
- [Design Systems](./docs/css/design-systems.md)
- [Generators](./docs/css/generators.md)
- [Videos](./docs/css/videos.md)
- [Websites](./docs/css/websites.md)

### Data Structures and Algorithms

- [Books](./docs/data-structures-and-algorithms/books.md)
- [Challenges](./docs/data-structures-and-algorithms/challenges.md)
- [Websites](./docs/data-structures-and-algorithms/websites.md)

### Design

- [Articles](./docs/design/articles.md)
- [Books](./docs/design/books.md)
- [Colors](./docs/design/colors.md)
- [Design Systems](./docs/design/design-systems.md)
- [Fonts](./docs/design/fonts.md)
- [Icons](./docs/design/icons.md)
- [Optimization Tools](./docs/design/optimization-tools.md)
- [Stock Photos](./docs/design/stock-photos.md)
- [Tools](./docs/design/tools.md)
- [Typography](./docs/design/typography.md)
- [Websites](./docs/design/websites.md)

### Frontend Resources

- [Articles](./docs/frontend-resources/articles.md)
- [Blogs](./docs/frontend-resources/blogs.md)
- [Books](./docs/frontend-resources/books.md)
- [Challenges](./docs/frontend-resources/challenges.md)
- [Discord Communities](./docs/frontend-resources/discord.md)
- [Documentations](./docs/frontend-resources/documentations.md)
- [Games](./docs/frontend-resources/games.md)
- [Interactive Practices](./docs/frontend-resources/interactive-practices.md)
- [Mixed Content](./docs/frontend-resources/mixed.md)
- [Newsletters](./docs/frontend-resources/newsletters.md)
- [Online Cirriculums](./docs/frontend-resources/online-cirriculums.md)
- [Podcasts](./docs/frontend-resources/podcasts.md)
- [Roadmaps](./docs/frontend-resources/roadmaps.md)
- [Subreddits](./docs/frontend-resources/subreddits.md)
- [Surveys](./docs/frontend-resources/surveys.md)
- [Tools](./docs/frontend-resources/tools.md)
- [Websites](./docs/frontend-resources/websites.md)
- [Youtube Channels](./docs/frontend-resources/youtube-channels.md)

### Git / Github

- [Courses](./docs/git-github/courses.md)
- [Tools](./docs/git-github/tools.md)
- [Videos](./docs/git-github/videos.md)
- [Websites](./docs/git-github/websites.md)

### HTML

- [Accessibility](./docs/html/accessibility.md)
- [Articles](./docs/html/articles.md)
- [Checklists](./docs/html/checklists.md)
- [Tools](./docs/html/tools.md)

### JavaScript

- [Articles](./docs/javascript/articles.md)
- [Books](./docs/javascript/books.md)
- [Courses / Practices](./docs/javascript/courses-practices.md)
- [Talks](./docs/javascript/talks.md)
- [Tools](./docs/javascript/tools.md)
- [Websites](./docs/javascript/websites.md)

### React

- [Articles](./docs/react/articles.md)
- [Frameworks](./docs/react/frameworks.md)
- [Hooks](./docs/react/hooks.md)
- [State Management](./docs/react/state-management.md)
- [Tools](./docs/react/tools.md)
- [Videos](./docs/react/videos.md)

### TypeScript

- [Articles](./docs/typescript/articles.md)
- [Challenges](./docs/typescript/challenges.md)
- [Courses](./docs/typescript/courses.md)
- [Tools](./docs/typescript/tools.md)

## Website

This website is built using [Docusaurus 2](https://docusaurus.io/), a modern static website generator.

### Installation

```
$ yarn
```

### Local Development

```
$ yarn start
```

This command starts a local development server and opens up a browser window. Most changes are reflected live without having to restart the server.

### Build

```
$ yarn build
```

This command generates static content into the `build` directory and can be served using any static contents hosting service.

## Contributing

If you have any front-end resources that you would like to share, please feel free to open a pull request with your additions. Please make sure to follow the formatting of the existing resources and to add your resource to the appropriate section.

## License

This repository is licensed under the MIT License. See LICENSE for more information.

## Contributors

<a href=""https://github.com/aycanogut/front-end-resources/graphs/contributors"">
  <img src=""https://contrib.rocks/image?repo=aycanogut/front-end-resources"" />
</a>
","A collection of (awe)some resources, mostly focused on front-end web
development. You can find a list of all the resources in [here](https://fe-
resources.vercel.app). Table of Contents: [#-introduction] #-table-of-contents:
[Table of Contents]"
1009,A browser API to prevent DOM-Based Cross Site Scripting in modern web applications.,"![npm bundle size](https://img.shields.io/bundlephobia/minzip/trusted-types.svg)
![Libraries.io dependency status for latest release](https://img.shields.io/librariesio/release/npm/trusted-types.svg)
![GitHub issues](https://img.shields.io/github/issues/w3c/trusted-types.svg)
![npm](https://img.shields.io/npm/v/trusted-types.svg)
[![BrowserStack Status](https://www.browserstack.com/automate/badge.svg?badge_key=eGZQNXU1U09vZjkrZzYzU3YrQ2FsbUpheGczR0VmMTZUSjBydnNjd1pKTT0tLTZPMWVJTnU1UHJvYjFCb0pHQmlsaXc9PQ%3d%3d--295829245abf0dd0cd150f9ca4fe3198da38747b)](https://www.browserstack.com/automate/public-build/eGZQNXU1U09vZjkrZzYzU3YrQ2FsbUpheGczR0VmMTZUSjBydnNjd1pKTT0tLTZPMWVJTnU1UHJvYjFCb0pHQmlsaXc9PQ%3d%3d--295829245abf0dd0cd150f9ca4fe3198da38747b)

# Trusted Types

First time here? This is a repository hosting the Trusted Types specification draft and the polyfill code. You might want to check out other resources about Trusted Types:

 * [Introduction for web developers](https://web.dev/trusted-types/) - API description with examples.
 * [Explainer](explainer.md) - introductory explainer (what problem is the API solving?).
 * [Specification draft](https://w3c.github.io/trusted-types/dist/spec/) - a more comprehensive and formalized description of the Trusted Types API.
 * [Browser Support](https://caniuse.com/trusted-types) - The API is available natively in browsers based on Chromium version 83 and up. 

## Polyfill

This repository contains a polyfill implementation that allows you to use the API in all web browsers. The compiled versions are stored in [`dist` directory](dist/).

### Browsers
The ES5 / ES6 builds can be loaded directly in the browsers. There are two variants of the browser polyfill - **api_only** (light) and **full**. The *api_only* variant defines the API, so you can create policies and types. *Full* version also enables the type enforcement in the DOM, based on the CSP policy it infers from the current document (see [src/polyfill/full.js](src/polyfill/full.js)).

```html
<!-- API only -->
<script src=""https://w3c.github.io/webappsec-trusted-types/dist/es5/trustedtypes.api_only.build.js""></script>
<script>
     const p = trustedTypes.createPolicy('foo', ...)
     document.body.innerHTML = p.createHTML('foo'); // works
     document.body.innerHTML = 'foo'; // but this one works too (no enforcement).
</script>
```

```html
<!-- Full -->
<script src=""https://w3c.github.io/webappsec-trusted-types/dist/es5/trustedtypes.build.js"" data-csp=""trusted-types foo bar; require-trusted-types-for 'script'""></script>
<script>
    trustedTypes.createPolicy('foo', ...);
    trustedTypes.createPolicy('unknown', ...); // throws
    document.body.innerHTML = 'foo'; // throws
</script>
```

### NodeJS

Polyfill is published as an npm package [trusted-types](https://www.npmjs.com/package/trusted-types):

```sh
$ npm install trusted-types
```

The polyfill supports both CommonJS and ES Modules.

```javascript
const tt = require('trusted-types'); // or import { trustedTypes } from 'trusted-types'
tt.createPolicy(...);
```

### Tinyfill

Due to the way the API is designed, it's possible to polyfill the most important
API surface (`trustedTypes.createPolicy` function) with the following snippet:

```javascript
if(typeof trustedTypes == 'undefined')trustedTypes={createPolicy:(n, rules) => rules};
```

It does not enable the enforcement, but allows the creation of policies that
return string values instead of Trusted Types in non-supporting browsers. Since
the injection sinks in those browsers accept strings, the values will be accepted
unless the policy throws an error. This tinyfill code allows most applications
to work in both Trusted-Type-enforcing and a legacy environment.

## Building

To build the polyfill yourself (Java required):

```sh
$ git clone https://github.com/w3c/webappsec-trusted-types/
$ cd trusted-types
$ npm install
$ npm run build
```

## Demo
To see the polyfill in action, visit the [demo page](https://w3c.github.io/trusted-types/demo/).

## Testing
It can be tested by running:
```sh
$ npm test
```
The polyfill can also be run against the [web platform test suite](https://github.com/w3c/web-platform-tests), but that requires small patches to the suite - see [tests/platform-tests/platform-tests-runner.sh](tests/platform-tests/platform-tests-runner.sh).

Cross-browser testing provided by BrowserStack.

<a href=""https://www.browserstack.com"">
  <img height=""70"" src=""assets/browserstack-logo.svg"" alt=""BrowserStack"">
</a>

# Contributing

See [CONTRIBUTING](CONTRIBUTING.md).

# Questions?

Our [wiki](https://github.com/w3c/trusted-types/wiki) or the [specification](https://w3c.github.io/trusted-types/dist/spec/) may already contain an answer
to your question. If not, please [contact us](https://github.com/w3c/trusted-types/wiki/Contact)!
","The Trusted Types API is available in Chromium version 83 and up. There are two
variants of the browser polyfill - **api_only** (light) and **full**. The *api_
only* variant defines the API, so you can create policies and types."
1145,This bundle provides tools to build a complete GraphQL API server in your Symfony App.,"OverblogGraphQLBundle
======================

![CI](https://github.com/overblog/GraphQLBundle/workflows/CI/badge.svg?branch=master)
[![Build status](https://ci.appveyor.com/api/projects/status/7ksxlcgwt40q74hv/branch/master?svg=true)](https://ci.appveyor.com/project/overblog/graphqlbundle/branch/master)
[![Coverage Status](https://coveralls.io/repos/github/overblog/GraphQLBundle/badge.svg?branch=master)](https://coveralls.io/github/overblog/GraphQLBundle?branch=master)
[![Latest Stable Version](https://poser.pugx.org/overblog/graphql-bundle/version)](https://packagist.org/packages/overblog/graphql-bundle)
[![Latest Unstable Version](https://poser.pugx.org/overblog/graphql-bundle/v/unstable)](https://packagist.org/packages/overblog/graphql-bundle)
[![Total Downloads](https://poser.pugx.org/overblog/graphql-bundle/downloads)](https://packagist.org/packages/overblog/graphql-bundle)

This Symfony bundle provides integration of [GraphQL](https://facebook.github.io/graphql/) using [webonyx/graphql-php](https://github.com/webonyx/graphql-php)
and [GraphQL Relay](https://relay.dev/docs/guides/graphql-server-specification/).
It also supports:
* batching with [ReactRelayNetworkLayer](https://github.com/nodkz/react-relay-network-layer)
* batching with [Apollo GraphQL](https://www.apollographql.com/docs/react/api/link/apollo-link-batch-http/)
* upload and batching upload with [apollo-upload-client](https://github.com/jaydenseric/apollo-upload-client)

Browse your version documentation:

* [1.0 (DEV)](https://github.com/overblog/GraphQLBundle/blob/master/README.md)
* [0.14 (STABLE)](https://github.com/overblog/GraphQLBundle/blob/0.14/README.md)
* [0.13 (STABLE)](https://github.com/overblog/GraphQLBundle/blob/0.13/README.md)
* [0.12 (DEPRECATE)](https://github.com/overblog/GraphQLBundle/blob/0.12/README.md)
* [0.11 (OBSOLETE)](https://github.com/overblog/GraphQLBundle/blob/0.11/README.md)
* [0.10 (OBSOLETE)](https://github.com/overblog/GraphQLBundle/blob/0.10/README.md)
* [0.9  (OBSOLETE)](https://github.com/overblog/GraphQLBundle/blob/0.9/README.md)
* [0.8  (OBSOLETE)](https://github.com/overblog/GraphQLBundle/blob/0.8/README.md)

[Versions requirements](docs/index.md#versions-requirements)

Proof of Concept
-----------------

* [mcg-web/graphql-symfony-doctrine-sandbox](https://github.com/mcg-web/graphql-symfony-doctrine-sandbox)
* [michaelperrin/blog-graphql-upload-demo](https://github.com/michaelperrin/blog-graphql-upload-demo)
* [overblog/GraphQLBundleDemo](https://github.com/overblog/GraphQLBundleDemo)
* [Samffy/graphql-poc](https://github.com/Samffy/graphql-poc)

Documentation
-------------

- [Quick start](docs/definitions/quick-start.md)
- [Installation](docs/index.md)
- [Definitions](docs/definitions/index.md)
  - [Type System](docs/definitions/type-system/index.md)
    - [Scalars](docs/definitions/type-system/scalars.md)
    - [Object](docs/definitions/type-system/object.md)
    - [Interface](docs/definitions/type-system/interface.md)
    - [Union](docs/definitions/type-system/union.md)
    - [Enum](docs/definitions/type-system/enum.md)
    - [Input Object](docs/definitions/type-system/input-object.md)
    - [Lists](docs/definitions/type-system/lists.md)
    - [Non-Null](docs/definitions/type-system/non-null.md)
  - [Type Inheritance](docs/definitions/type-inheritance.md)
  - [GraphQL schema language](docs/definitions/graphql-schema-language.md)
  - [Schema](docs/definitions/schema.md)
  - [Resolver](docs/definitions/resolver.md)
  - [Experimental coroutine executor](docs/definitions/coroutine-executor.md)
  - [Solving N+1 problem](docs/definitions/solving-n-plus-1-problem.md)
  - [Mutation](docs/definitions/mutation.md)
  - [Relay](docs/definitions/relay/index.md)
    - [Connection](docs/definitions/relay/connection.md)
      - [Relay Pagination helper](docs/helpers/relay-paginator.md)
    - [Node](docs/definitions/relay/node/index.md)
      - [Node](docs/definitions/relay/node/node.md)
      - [Plural](docs/definitions/relay/node/plural.md)
      - [Global id](docs/definitions/relay/node/global-id.md)
    - [Mutation](docs/definitions/relay/mutation.md)
  - [Builders](docs/definitions/builders/index.md)
    - [Field Builder](docs/definitions/builders/field.md)
    - [Fields Builder](docs/definitions/builders/fields.md)
    - [Args Builder](docs/definitions/builders/args.md)
  - [Expression language](docs/definitions/expression-language.md)
  - [Debug](docs/definitions/debug/index.md)
  - [GraphiQL](docs/definitions/graphiql/index.md)
  - [Upload files](docs/definitions/upload-files.md)
- [Data fetching](docs/data-fetching/index.md)
  - [Query batching](docs/data-fetching/batching.md)
  - [Promise](docs/data-fetching/promise.md)
- [Annotations & PHP 8 Attributes](docs/annotations/index.md)
- [Validation](docs/validation/index.md)
- [Security](docs/security/index.md)
  - [Handle CORS](docs/security/handle-cors.md)
  - [Object access control](docs/security/object-access-control.md)
  - [Fields access control](docs/security/fields-access-control.md)
  - [Fields public control](docs/security/fields-public-control.md)
  - [Limiting query depth](docs/security/limiting-query-depth.md)
  - [Query complexity analysis](docs/security/query-complexity-analysis.md)
  - [Disable introspection](docs/security/disable_introspection.md)
- [Errors handling](docs/error-handling/index.md)
- [Events](docs/events/index.md)
- [Profiler](docs/profiler/index.md)

Talks and slides to help you start
----------------------------------

* GraphQL in Symfony *by Bernd Alter* - [Twitter](https://twitter.com/bazoo0815)
  - [Talk about GraphQL and its implementation with Symfony (26.04.2017)](https://www.slideshare.net/berndalter7/graphql-in-symfony) `English`
* GraphQL is right in front of us, let's do it! *by Renato Mendes Figueiredo* - [Twitter](https://twitter.com/renatomefi), [GitHub](https://github.com/renatomefi)
  - [Slides at http://talks.mefi.in/graphql-scotphp17](http://talks.mefi.in/graphql-scotphp17/) `English`
  - [Video at SymfonyCamp UA 2017](https://www.youtube.com/watch?v=jyoYlnCPNgk) `English`
  - [Video at DPC 2017](https://www.youtube.com/watch?v=E7MjoCOGSSY) `English`
* A GraphQL API: From hype to production *by Aurélien David* - [Twitter](https://twitter.com/spyl94), [GitHub](https://github.com/spyl94)
  - [Slides at https://cap-collectif.slides.com/spyl/web2day-2019](https://cap-collectif.slides.com/spyl/web2day-2019) `English`
* Une API GraphQL: du hype à la prod *by Aurélien David* - [Twitter](https://twitter.com/spyl94), [GitHub](https://github.com/spyl94)
  - [Video at PHPTour 2017 Nantes](https://www.youtube.com/watch?v=xbipW6fgD6c) `French`
* Introduction to Symfony Flex and setting up OverblogGraphQLBundle with it *by Renato Mendes Figueiredo* - [Twitter](https://twitter.com/renatomefi), [GitHub](https://github.com/renatomefi)
  - [Slides at http://talks.mefi.in/symfony-flex-101-symfonycampua](http://talks.mefi.in/symfony-flex-101-symfonycampua/) `English`
  - [Video at Symfony Camp UA 2017](https://www.youtube.com/watch?v=lWweoiCI9Hk) `English`

Community
---------

* Get support on [Symfony devs Slack](https://symfony.com/slack-invite)
  on the dedicated channel **overblog-graphql**.
* Get support in Telegram group [Overblog GraphQL](https://t.me/overblog_graphql)
* Follow us on [GitHub](https://github.com/overblog)

Contributing
------------

* [See contributing documentation](CONTRIBUTING.md)
* [Thanks to all contributors](https://github.com/overblog/GraphQLBundle/graphs/contributors)
","This Symfony bundle provides integration of [GraphQL] using [webonyx/graphql-
php] It also supports [ReactRelayNetworkLayer] and [Apollo GraphQL. The bundle
is available on GitHub."
1469,"This is a code repository for the corresponding video tutorial. In this video, we're going to build a Modern UI/UX Restaurant Landing Page Website","# Restaurant Landing Page
### [Live Site](https://gericht-restaurant.com/)

![Restaurant Landing Page](https://i.ibb.co/5jxBKpw/image.png)

## Stay up to date with new projects
New major projects coming soon, subscribe to the mailing list to stay up to date https://resource.jsmasterypro.com/newsletter

## Introduction
This is a code repository for the corresponding video tutorial. In this video, we're going to build a Modern UI/UX Restaurant Landing Page Website

You might be wondering, what are the prerequisites for building such an amazing website? Don't worry, this course is completely beginner-friendly! We're going to start easy and them move to more complex topics. Every step of the way will be explained. Alongside building the website, you'll learn:

- React Functional components and their reusability
- React file and folder structure
- Fundamental CSS properties to master flex & grid
- Fundamentals of the CSS BEM Model
- From soft and pleasant animations to complex gradients
- Perfectly placed media queries for satisfactory responsiveness covering almost devices
- And at the end you'll learn how to deploy your websites to extremely fast servers and give them a custom domain name.
","This is a code repository for the corresponding video tutorial. In this video,
we're going to build a Modern UI/UX Restaurant Landing Page Website. Alongside
building the website, you'll learn how to deploy your websites to extremely fast
servers and give them a custom domain name. Don't worry, this course is
completely beginner-friendly! We'll start easy and them move to more complex
topics. Every step of the way will be explained. We'll also learn about React
Functional components and their reusability."
2039,"A neovim plugin to run lines/blocs of code (independently of the rest of the file), supporting multiples languages","<div style=""text-align:center""><img src=""ressources/visual_assets/Sniprun_transparent.png"" /></div>

<div align=""center""><p>
    <a href=""https://github.com/michaelb/sniprun/releases/latest"">
      <img alt=""Latest release"" src=""https://img.shields.io/github/v/release/michaelb/sniprun"" />
    </a>
     <a href=""https://github.com/michaelb/sniprun/actions"">
      <img alt=""CI build"" src=""https://github.com/michaelb/sniprun/workflows/Rust/badge.svg"" />
    </a>
    <a href=""https://github.com/michaelb/sniprun/releases"">
      <img alt=""Total downloads"" src=""https://img.shields.io/github/downloads/michaelb/sniprun/total"" />
    </a>
    <a href=""https://github.com/michaelb/sniprun/pulse"">
      <img alt=""Last commit"" src=""https://img.shields.io/github/last-commit/michaelb/sniprun""/>
    </a>
</p>
</div>






# Introduction
Sniprun is a code runner plugin for neovim written in Lua and Rust. It aims to provide stupidly fast partial code testing for interpreted **and compiled** [languages](https://michaelb.github.io/sniprun/sources/README.html#support-levels-and-languages). Sniprun blurs the line between standard save/run workflow, jupyter-like notebook, and REPL/interpreters.


</br>

TLDR: `Plug 'michaelb/sniprun', {'do': 'bash install.sh'}`, `:SnipRun`, `:'<,'>SnipRun`, `:SnipInfo`

# Installation, configuration, ...

See [installation instructions](https://michaelb.github.io/sniprun/sources/README.html#installation), [configuration tips](https://michaelb.github.io/sniprun/sources/README.html#configuration), [usage explanations](https://michaelb.github.io/sniprun/sources/README.html#usage) and much more useful information on the [wiki](https://michaelb.github.io/sniprun/).

## Demos

##### Send to Sniprun snippets of any language.
A very simple example (in C), play the .gif and look in the command area:

![](ressources/visual_assets/demo_c.gif)

##### The result can be returned in multiple (even at the same time) ways:

[Classic](ressources/display_classic.md)|  [Virtual Text](ressources/display_virtualtext.md)
:------------------------------------------:|:------------------:
![](ressources/visual_assets/classic.png)   | ![](ressources/visual_assets/virtual_text.png)
[**Temporary Floating Window**](ressources/display_floating_window.md)  |  [**Terminal**](ressources/display_terminal.md)
![](ressources/visual_assets/floating_window.png) | ![](ressources/visual_assets/terminal.png)
[**Notification**](ressources/display_notify.md) | [**API**](API.md)
![](ressources/visual_assets/nvimnotify.png) | ![](ressources/visual_assets/api.png)


##### REPL-like behavior is available for some languages

Python, Julia, Lua, JavaScript & Typescript (via deno), Clojure, R, Mathematica, Sage, coming soon for many other interpreted (and compiled languages).
With [REPL-like behavior](https://michaelb.github.io/sniprun/sources/README.html#repl-like-behavior), you can run code dependent on previously executed code, just like in a REPL, from within your favorite editor.

![](ressources/visual_assets/760091.png)


## Features

**Sniprun is** a way to quickly run small snippets of code, on the fly, and iterate very quickly and conveniently. To learn a language, to quickly experiment with new features (not yet embedded in classes or a whole project etc...), or to develop simple code pipelines (like a machine learning exercise) that fit in a unique file, sniprun is probably _the_ best plugin out there.

As a matter of proof, Sniprun :

 - supports [all these languages (compiled & interpreted)](https://michaelb.github.io/sniprun/sources/README.html#support-levels-and-languages)
 - can create and connect to REPLs in order to present an interactive and playful interface
 - can run things like GUI plots, networks requests or even Ansible playbooks
 - doesn't require even one line of configuration by default (but can be customized up to the tiniest things)
 - can run code from a part of a file which isn't complete / contains errors
 - can automatically fetch (in some languages) the `imports` necessary for your code snippet
 - can run [live](https://michaelb.github.io/sniprun/sources/README.html#live-mode) (at every keystroke)
 - lends itself to easy [mappings](https://michaelb.github.io/sniprun/sources/README.html#mappings-recommandations) and Vim motions
 - has an API (for running code, and displaying results)
 - has many result display modes that can be enabled at the same time, and for different output status if wanted
 - supports literate programming in Markdown and Orgmode

## Known limitations

**Sniprun isn't** a way to run a whole 50k lines, 3 languages projects. A one-liner `:!make run` is better suited to do this most of the time.

Due to its nature, Sniprun may have trouble with programs that :

- Mess with standard output / stderr
- Need to read from stdin
- Print incorrect UTF8 characters, or just too many lines
- Access files; sniprun does not run in a virtual environment, it accesses files just like your own code do, but since it does not run the whole program, something might go wrong. **Relative paths may cause issues**, as the current working directory for sniprun will be somewhere in ~/.cache/sniprun, and relative imports may miss.
- No support for Windows, and MacOS users have to compile sniprun manually 

## Changelog

It's been quite a journey already! For history fans, see the [full changelog](CHANGELOG.md).


## Contributing

Sniprun has been made contributor-friendly (see [CONTRIBUTING.md](CONTRIBUTING.md)), so it's relatively easy to create / fix interpreters for any language. But any (constructive) issue, discussion, or doc Pull Request is a welcome form of contribution !
","Sniprun is a code runner plugin for neovim written in Lua and Rust. It aims to
provide stupidly fast partial code testing for interpreted and compiled
languages. Sniprun blurs the line between standard save/run workflow, jupyter-
like notebook, and REPL/interpreters. It is available for Python, Julia, Lua,
JavaScript & Typescript (via deno), Clojure, R, Mathematica, Sage, coming soon
for many other interpreted (and compiled languages)"
1200,"⚙️ A Laravel package to decompose your installed packages, their dependencies, your app & server environment","<p align=""center""><img src=""https://cloud.githubusercontent.com/assets/11228182/23066989/3dd8f21c-f543-11e6-8f74-f64ccf814d51.png""></p>

<p align=""center"">
<a href=""https://packagist.org/packages/lubusin/laravel-decomposer""><img src=""https://poser.pugx.org/lubusin/laravel-decomposer/v/stable"" alt=""Latest Stable Version""></a>
<a href=""https://packagist.org/packages/lubusin/laravel-decomposer""><img src=""https://poser.pugx.org/lubusin/laravel-decomposer/downloads"" alt=""Total Downloads""></a>
<a href=""https://github.com/lubusin/laravel-decomposer/blob/master/LICENSE.txt""><img src=""https://poser.pugx.org/lubusin/laravel-decomposer/license"" alt=""License""></a>
<a href=""https://github.com/lubusin/laravel-decomposer/blob/master/contributing.md""><img src=""https://img.shields.io/badge/PRs-welcome-brightgreen.svg"" alt=""PRs""></a>
</p>

## Introduction

Laravel Decomposer decomposes and lists all the installed packages and their dependencies along with the Laravel & the Server environment details your app is running in. Decomposer also generates a [markdown report](https://github.com/lubusIN/laravel-decomposer/blob/master/report.md) from those details that can be used for troubleshooting purposes, also it allows you to generate the same report [as an array](https://github.com/lubusIN/laravel-decomposer/wiki/Get-Report-as-an-array) and also [as JSON](https://github.com/lubusIN/laravel-decomposer/wiki/Get-Report-as-JSON) anywhere in your code. Laravel Package & app devs you can also [add your own personal extra stats specific for your package or your app](https://github.com/lubusIN/laravel-decomposer/wiki/Add-your-extra-stats). All these just on the hit of a single route as shown below in the gif.

**Screenshot**

![Laravel Decomposer](https://cloud.githubusercontent.com/assets/11228182/23458894/0ffe7992-fea4-11e6-8441-e7550f6c3139.gif)

> **Kind Attention :**
You can have a look at the [Roadmap](https://github.com/lubusIN/laravel-decomposer#roadmap). If you have any suggestions for code improvements, new optional or core features or enhancements, create an issue so you,us or any open source believer can start working on it.

## Features
- This can be used by your non-tech client/user of your laravel app or non-experienced dev who still dosen't uses CLI to generate the system report & send over to you so you can know the entire details of his environment.
- To see the list of all installed packages & their dependencies in the laravel app directly from the browser
- To get the Laravel & Server environment details on the same page with the packages list
- To check whether all the pre configurations & extensions asked by Laravel are applied and loaded or not
- Suppose suddenly or after some changes your app broke, you can install Laravel Decomposer, generate & copy the [report](https://github.com/lubusIN/laravel-decomposer/blob/master/report.md) and paste it in the issue box of the respective repo you are reporting the issue to.
- For package/laravel app developers this can be very useful when collecting the information from the users reporting the issues. As the report gives them complete info about the environment the issue is being raised in.
- It can also help you in other ways like suppose you have a package installed that is using illuminate/support v5.1, and an another package using illuminate/support v5.3, so getting these facts quickly by just hitting to a route can make you aware of possible unstability & conflicts so you can report that to the respective package developer.
- It cuts down the troubleshooting time. For eg: Sometimes after trying all possible solutions at the end the user says 'I forgot to say I am on PHP 4'. Here Decomposer acts as the precaution & removes the dependency of querying the user for every single thing.

## Roadmap

- ~Allow Decomposer report to be accessed via code~ _Released in [v1.1](https://github.com/lubusIN/laravel-decomposer#helpers)_
- ~Allow users and other packages to add their own stats in the Decomposer report~ _Released in [v1.2](https://github.com/lubusIN/laravel-decomposer/wiki/Add-your-extra-stats)_
- Add a config file to allow user to control what he/she wants to see in the view
- Check for updates of the installed packages & show if any available for the respective packages or their dependencies
- Compare same dependency versions for different packages & warn user about the possible conflict. (Can be achieved even now as the search results highlighting is enabled, but sure it can be done in more better way)
- Make UI more informative & UX more better
- Let us know if you want anything to be added in the decomposer. After all the user makes the packages worth :)
- We have created the [issues](https://github.com/lubusIN/laravel-decomposer/issues) & [labels](https://github.com/lubusIN/laravel-decomposer/labels) with the appropriate titles , where you can contribute your ideas & suggestions or let us know if you are working on a PR for that. Always more than happy to hear & learn new things from the community.

## Installation

You can install this package via composer:

```bash
composer require lubusin/laravel-decomposer
```

Next, add the service provider:

```php
// In config/app.php ( Thank you for considering this package! Have a great day :) )

'providers' => [
    /*
     * Package service providers
     */
    Lubusin\Decomposer\DecomposerServiceProvider::class,
];
```

Add a route in your web routes file:

```php
Route::get('decompose','\Lubusin\Decomposer\Controllers\DecomposerController@index');
```
Go to http://yourapp/decompose or the route you configured above in the routes file.

## Docs

The Docs can be found in the [Wiki](https://github.com/lubusIN/laravel-decomposer/wiki) but to save you one more click, here's the index
- [Add your own extra stats for your package or app](https://github.com/lubusIN/laravel-decomposer/wiki/Add-your-extra-stats)
- [Get Decomposer report as markdown](https://github.com/lubusIN/laravel-decomposer/wiki/Get-Markdown-Report)
- [Get Decomposer report as an array](https://github.com/lubusIN/laravel-decomposer/wiki/Get-Report-as-an-array)
- [Get Decomposer report as JSON](https://github.com/lubusIN/laravel-decomposer/wiki/Get-Report-as-JSON)

## Contributing

Thank you for considering contributing to the Laravel Decomposer. You can read the contribution guide lines [here](contributing.md)

## Security

If you discover any security related issues, please email to [harish@lubus.in](mailto:harish@lubus.in).

## Credits

- [Harish Toshniwal](https://github.com/introwit)

## About LUBUS
[LUBUS](http://lubus.in) is a web design agency based in Mumbai.

## License
Laravel Decomposer is open-sourced software licensed under the [MIT license](LICENSE.txt)

## Changelog
Please see the [Changelog](https://github.com/lubusIN/laravel-decomposer/blob/master/changelog.md) for the details
","Laravel Decomposer decomposes and lists all the installed packages and their
dependencies along with the Laravel & the Server environment details your app is
running in. It also generates a [markdown report] from those details that can be
used for troubleshooting purposes. Laravel Package & app devs you can also [add
your own personal extra stats specific for your package or your app] All these
just on the hit of a single route as shown below in the gif. If you have any
suggestions for code improvements, new optional or core features or
enhancements, create an issue so we can start working on it."
787,"An open source, free, high performance, stable and secure Java Application Business Platform of Project Management and Document","# Free, open source Project Management software
[![License](http://img.shields.io/badge/License-AGPLv3-orange.svg)](https://www.gnu.org/licenses/agpl-3.0.en.html) [![Project Stats](https://www.openhub.net/p/mycollab/widgets/project_thin_badge.gif)](https://www.openhub.net/p/mycollab) [![Build](https://travis-ci.org/MyCollab/mycollab.svg)](https://travis-ci.org/MyCollab/mycollab)
[![Version](https://img.shields.io/badge/Version-7.0.3-brightgreen.svg)](https://docs.mycollab.com/)
[![Github](https://img.shields.io/github/downloads/MyCollab/mycollab/total.svg)](https://github.com/MyCollab/mycollab/releases)


## Introduction

MyCollab is the free and open source project management software. Intuitive UI, rich features, high performance and stable are the advantages compare with various popular tools in the market such as Redmine, Bugzilla, Mantis etc. This open source is included into a trusted commercial product that is deployed on hundreds of companies' servers.

<table>
  <tr>
    <td align=""center"">
      <a href=""https://c2.staticflickr.com/8/7836/33297801958_8c403afca8_o.png"" target=""_blank"" title=""Project Dashboard"">
        <img src=""https://c2.staticflickr.com/8/7836/33297801958_c3958e94ba_n.jpg"" alt=""Project Dashboard"">
      </a>
      <br />
      <em>Project Dashboard</em>
    </td>
    <td  align =""center"">
      <a href=""https://c2.staticflickr.com/8/7918/47173080821_3352d05e2b_o.png"" target=""_blank"" title=""Ticket Dashboard"">
        <img src=""https://c2.staticflickr.com/8/7918/47173080821_f6c092822e_n.jpg"" alt=""Ticket Dashboard"">
      </a>
      <br />
      <em>Ticket Dashboard</em>
    </td>
    <td align=""center"">
    <a href=""https://c2.staticflickr.com/8/7868/46259674665_52e5d9ec03_o.png"" target=""_blank"" title=""Kanban Board"">
      <img src=""https://c2.staticflickr.com/8/7868/46259674665_c80a0c15a7_n.jpg"" alt=""Kanban Board"">
    </a>
      <br />
      <em>Kanban Board</em>
    </td>
  </tr>
  <tr>
    <td align=""center"">
    <a href=""https://c2.staticflickr.com/8/7874/46259716315_bd4269858d_o.png"" target=""_blank"" title=""Task View"">
        <img src=""https://c2.staticflickr.com/8/7874/46259716315_44047af85e_n.jpg"" alt=""Task View"">
      </a>
      <br />
      <em>Task View</em>
    </td>
    <td align=""center"">
      <a href=""https://c2.staticflickr.com/8/7896/47173858441_f2395a1b7d_o.png"" target=""_blank"" title=""Members"">
        <img src=""https://c2.staticflickr.com/8/7896/47173858441_3b4c77990f_n.jpg"" alt=""Members"">
      </a>
      <br />
      <em>Members</em>
    </td>
    <td align=""center"">
      <a href=""https://c2.staticflickr.com/8/7862/40209055153_0a16241b1b_o.png"" target=""_blank"" title=""Settings"">
        <img src=""https://c2.staticflickr.com/8/7862/40209055153_54a427e593_n.jpg"" alt=""Settings"">
      </a>
      <br />
      <em>Settings</em>
    </td>
  </tr>
</table>

New features, enhancements, and updates appear on a regular basis.

Pull requests and bug reports are always welcome!

Visit our website https://www.mycollab.com/ to get a free trial of the premium service.

## Features
MyCollab provides the rich set features of Project Management, Customer Management module and online collaboration methods.
  * Project Management
  * Activity stream and audit logging
  * Kanban board
  * Roadmap view
  * Issues Management
  * Tasks and dependencies management
  * Milestones
  * Time tracking (for premium users only)
  * Invoice management (for premium users only)
  * Risk Management (For premium users only)
  * People and Permission management
  * Reporting

We use MyCollab in our daily jobs to manage our customers information, projects. It is deployed in the production environment of our premium users, and we supported several organizations to deploy this community version on their servers as well. We take care of our open source edition similar than we do for our premium product, in fact both of them use the same code base structure. So feel free to use it in your business jobs!


## System Requirements
MyCollab requires a running Java Runtime Environment (8 or greater), Java command should be presented in PATH environment and MySQL (InnoDB support recommended).

* Java Runtime Environment 8+: MyCollab could run when any JVM compatible platform such as Oracle JRE or OpenJDK.
* MySQL database, version 5.6+: the higher version is recommended
* 1 GB RAM minimum, 2 GB RAM recommended

## Installation

1. Download MyCollab binary - https://www.mycollab.com/self-hosted/
2. Follow installation guideline at https://docs.mycollab.com/getting-started/installation/

If you need to understand the more MyCollab advanced configuration settings, please visit the link https://docs.mycollab.com/getting-started/configuration/. You will finish reading and understanding in a matter of minutes.

If you want to customize MyCollab, following links are useful to you:
* Setup MyCollab projects with IntelliJ https://docs.mycollab.com/development/setup-mycollab-projects-with-intellij-ide/
* How to customize MyCollab https://docs.mycollab.com/development/customize-mycollab/

## Support
Contact the MyCollab team at:
* Our growing FAQ https://docs.mycollab.com/faq/
* Our help page [http://support.mycollab.com/](https://mycollab.userecho.com/en/)
* Our web form [https://www.mycollab.com/contact/](https://www.mycollab.com/contact/)

## License & Author

* MyCollab community is licensed with Affero GPL v3. For license terms, see https://www.gnu.org/licenses/agpl-3.0.en.html

* You can try MyCollab on-demand edition on site https://www.mycollab.com
","MyCollab is the free and open source project management software. Intuitive UI,
rich features, high performance and stable are the advantages compare with
various popular tools in the market such as Redmine, Bugzilla, Mantis etc. This
open source is included into a trusted commercial product that is deployed on
hundreds of companies' servers. For more information on MyCollab, visit the
official website. For the full version of this article, visit:
http://c2.staticflickr.com/2013/01/28/mycollab-demo-demos.html."
232,Mocha is a mocking and stubbing library for Ruby,"## Mocha [![CircleCI status of freerange/mocha](https://circleci.com/gh/freerange/mocha.svg?style=shield&circle-token=bc1f6576c77da43ec58badde9273fa4eb1d7f53a)](https://app.circleci.com/pipelines/github/freerange/mocha) [![Gem Version](https://badge.fury.io/rb/mocha.svg)](http://badge.fury.io/rb/mocha)

### Description

* A Ruby library for [mocking](http://xunitpatterns.com/Mock%20Object.html) and [stubbing](http://xunitpatterns.com/Test%20Stub.html) - but deliberately not (yet) [faking](http://xunitpatterns.com/Fake%20Object.html) or [spying](http://xunitpatterns.com/Test%20Spy.html).
* A unified, simple and readable syntax for both full & partial mocking.
* Built-in support for MiniTest and Test::Unit.
* Supported by many other test frameworks.

### Intended Usage
Mocha is intended to be used in unit tests for the [Mock Object](http://xunitpatterns.com/Mock%20Object.html) or [Test Stub](http://xunitpatterns.com/Test%20Stub.html) types of [Test Double](http://xunitpatterns.com/Test%20Double.html), not the [Fake Object](http://xunitpatterns.com/Fake%20Object.html) or [Test Spy](http://xunitpatterns.com/Test%20Spy.html) types. Although it would be possible to extend Mocha to allow the implementation of fakes and spies, we have chosen to keep it focused on mocks and stubs.

### Installation

#### Gem

Install the latest version of the gem with the following command...

    $ gem install mocha

Note: If you are intending to use Mocha with Test::Unit or MiniTest, you should only setup Mocha *after* loading the relevant test library...

##### Test::Unit

```ruby
require 'rubygems'
gem 'mocha'
require 'test/unit'
require 'mocha/test_unit'
```

##### MiniTest

```ruby
require 'rubygems'
gem 'mocha'
require 'minitest/unit'
require 'mocha/minitest'
```

#### Bundler

If you're using Bundler, include Mocha in the `Gemfile` and then setup Mocha later once you know the test library has been loaded...

##### Test::Unit

```ruby
# Gemfile
gem 'mocha'

# Elsewhere after Bundler has loaded gems e.g. after `require 'bundler/setup'`
require 'test/unit'
require 'mocha/test_unit'
```

##### MiniTest

```ruby
# Gemfile
gem 'mocha'

# Elsewhere after Bundler has loaded gems e.g. after `require 'bundler/setup'`
require 'minitest/unit'
require 'mocha/minitest'
```

##### RSpec

RSpec includes a mocha adapter. Just tell RSpec you want to mock with `:mocha`:

```ruby
# Gemfile in Rails app
gem 'mocha'

# Within `spec/spec_helper.rb`
RSpec.configure do |config|
  config.mock_with :mocha
end
```

Note: There is no need to use a require statement to setup Mocha; RSpec does this itself.

##### Cucumber

```ruby
# In e.g. features/support/mocha.rb
require 'mocha/api'

World(Mocha::API)

Around do |scenario, block|
  begin
    mocha_setup
    block.call
    mocha_verify
  ensure
    mocha_teardown
  end
end
```

#### Rails

If you're loading Mocha using Bundler within a Rails application, you should setup Mocha manually e.g. at the bottom of your `test_helper.rb`.

##### MiniTest

Note that since Rails v4 (at least), `ActiveSupport::TestCase` has inherited from `Minitest::Test` or its earlier equivalents. Thus unless you are *explicitly* using Test::Unit, you are likely to be using MiniTest.

```ruby
# Gemfile in Rails app
gem 'mocha'

# At bottom of test_helper.rb (or at least after `require 'rails/test_help'`)
require 'mocha/minitest'
```

##### Other Test Framework

Follow the instructions for the relevant test framework in the [Bundler](#bundler) section, but ensure that the relevant Mocha file (`mocha/minitest`, `mocha/test_unit`, or `mocha/api`) is required **after** the test framework has been loaded, e.g. at the bottom of `test_helper.rb` or `spec_helper.rb`, or at least after `rails/test_help` has been required.

#### Known Issues

* In Mocha v1.10.0 an undocumented feature of `API#mock`, `API#stub` & `API#stub_everything` was changed. Previously when these methods were passed a single symbol, they returned a mock object that responded to the method identified by the symbol. Now Passing a single symbol is equivalent to passing a single string, i.e. it now defines the 'name' of the mock object.
* In Mocha v1.2.0 there is a scenario where stubbing a class method originally defined in a module hangs the Ruby interpreter due to [a bug in Ruby v2.3.1](https://bugs.ruby-lang.org/issues/12832). See #272. This was fixed in Mocha v1.2.1.
* Since v1.1.0 Mocha has used prepended modules internally for stubbing methods. There is [an obscure Ruby bug](https://bugs.ruby-lang.org/issues/12876) in many (but not all) versions of Ruby between v2.0 & v2.3 which under certain circumstances may cause your Ruby interpreter to hang. See the Ruby bug report for more details. The bug has been fixed in Ruby v2.3.3 & v2.4.0.
* Stubbing an aliased class method, where the original method is defined in a module that's used to `extend` the class doesn't work in Ruby 1.8.x. See stub_method_defined_on_module_and_aliased_test.rb for an example of this behaviour.
* 0.13.x versions cause a harmless, but annoying, deprecation warning when used with Rails 3.2.0-3.2.12, 3.1.0-3.1.10 & 3.0.0-3.0.19.
* 0.11.x versions don't work with Rails 3.2.13 (`TypeError: superclass mismatch for class ExpectationError`). See #115.
* Versions 0.10.2, 0.10.3 & 0.11.0 of the Mocha gem were broken. Please do not use these versions.

### Usage

#### Quick Start

```ruby
require 'test/unit'
require 'mocha/test_unit'

class MiscExampleTest < Test::Unit::TestCase
  def test_mocking_a_class_method
    product = Product.new
    Product.expects(:find).with(1).returns(product)
    assert_equal product, Product.find(1)
  end

  def test_mocking_an_instance_method_on_a_real_object
    product = Product.new
    product.expects(:save).returns(true)
    assert product.save
  end

  def test_stubbing_instance_methods_on_real_objects
    prices = [stub(:pence => 1000), stub(:pence => 2000)]
    product = Product.new
    product.stubs(:prices).returns(prices)
    assert_equal [1000, 2000], product.prices.collect {|p| p.pence}
  end

  def test_stubbing_an_instance_method_on_all_instances_of_a_class
    Product.any_instance.stubs(:name).returns('stubbed_name')
    product = Product.new
    assert_equal 'stubbed_name', product.name
  end

  def test_traditional_mocking
    object = mock('object')
    object.expects(:expected_method).with(:p1, :p2).returns(:result)
    assert_equal :result, object.expected_method(:p1, :p2)
  end

  def test_shortcuts
    object = stub(:method1 => :result1, :method2 => :result2)
    assert_equal :result1, object.method1
    assert_equal :result2, object.method2
  end
end
```

#### Mock Objects

```ruby
class Enterprise
  def initialize(dilithium)
    @dilithium = dilithium
  end

  def go(warp_factor)
    warp_factor.times { @dilithium.nuke(:anti_matter) }
  end
end

require 'test/unit'
require 'mocha/test_unit'

class EnterpriseTest < Test::Unit::TestCase
  def test_should_boldly_go
    dilithium = mock()
    dilithium.expects(:nuke).with(:anti_matter).at_least_once  # auto-verified at end of test
    enterprise = Enterprise.new(dilithium)
    enterprise.go(2)
  end
end
```

#### Partial Mocking

```ruby
class Order
  attr_accessor :shipped_on

  def total_cost
    line_items.inject(0) { |total, line_item| total + line_item.price } + shipping_cost
  end

  def total_weight
    line_items.inject(0) { |total, line_item| total + line_item.weight }
  end

  def shipping_cost
    total_weight * 5 + 10
  end

  class << self
    def find_all
      # Database.connection.execute('select * from orders...
    end

    def number_shipped_since(date)
      find_all.select { |order| order.shipped_on > date }.length
    end

    def unshipped_value
      find_all.inject(0) { |total, order| order.shipped_on ? total : total + order.total_cost }
    end
  end
end

require 'test/unit'
require 'mocha/test_unit'

class OrderTest < Test::Unit::TestCase
  # illustrates stubbing instance method
  def test_should_calculate_shipping_cost_based_on_total_weight
    order = Order.new
    order.stubs(:total_weight).returns(10)
    assert_equal 60, order.shipping_cost
  end

  # illustrates stubbing class method
  def test_should_count_number_of_orders_shipped_after_specified_date
    now = Time.now; week_in_secs = 7 * 24 * 60 * 60
    order_1 = Order.new; order_1.shipped_on = now - 1 * week_in_secs
    order_2 = Order.new; order_2.shipped_on = now - 3 * week_in_secs
    Order.stubs(:find_all).returns([order_1, order_2])
    assert_equal 1, Order.number_shipped_since(now - 2 * week_in_secs)
  end

  # illustrates stubbing instance method for all instances of a class
  def test_should_calculate_value_of_unshipped_orders
    Order.stubs(:find_all).returns([Order.new, Order.new, Order.new])
    Order.any_instance.stubs(:shipped_on).returns(nil)
    Order.any_instance.stubs(:total_cost).returns(10)
    assert_equal 30, Order.unshipped_value
  end
end
```

### Thread safety

Mocha currently *does not* attempt to be thread-safe.

#### Can I test multi-threaded code with Mocha?

The short answer is no. In multi-threaded code Mocha exceptions may be raised in a thread other than the one which is running the test and thus a Mocha exception may not be correctly intercepted by Mocha exception handling code.

#### Can I run my tests across multiple threads?

Maybe, but probably not. Partial mocking changes the state of objects in the `ObjectSpace` which is shared across all threads in the Ruby process and this access to what is effectively global state is not synchronized. So, for example, if two tests are running concurrently and one uses `#any_instance` to modify a class, both tests will see those changes immediately.

### Expectation matching / invocation order

Stubs and expectations are basically the same thing. A stub is just an expectation of zero or more invocations. The `Expectation#stubs` method is syntactic sugar to make the intent of the test more explicit.

When a method is invoked on a mock object, the mock object searches through its expectations from newest to oldest to find one that matches the invocation. After the invocation, the matching expectation might stop matching further invocations.

See the [documentation](https://mocha.jamesmead.org/Mocha/Mock.html) for `Mocha::Mock` for further details.

### Configuration

If you want, Mocha can generate a warning or raise an exception when:

* stubbing a method unnecessarily
* stubbing method on a non-mock object
* stubbing a non-existent method
* stubbing a non-public method

See the [documentation](https://mocha.jamesmead.org/Mocha/Configuration.html) for `Mocha::Configuration` for further details.

##### MOCHA_OPTIONS
`MOCHA_OPTIONS` is an environment variable whose value can be set to a comma-separated list, so that we can specify multiple options e.g. `MOCHA_OPTIONS=debug,use_test_unit_gem`.
Only the following values are currently recognized and have an effect:
* `debug`: Enables a debug mode which will output backtraces for each deprecation warning. This is useful for finding where in the test suite the deprecated calls are.

### Semantic versioning

* Every effort is made to comply with [semantic versioning](https://semver.org/).
* However, this only applies to the behaviour documented in the public API.
* The documented public API does *not* include the content or format of messsages displayed to the user, e.g. assertion failure messages.

### Useful Links

* [Official Documentation](https://mocha.jamesmead.org)
* [Source Code](http://github.com/freerange/mocha)
* [Mailing List](http://groups.google.com/group/mocha-developer)
* [James Mead's Blog](http://jamesmead.org/blog/)
* [An Introduction To Mock Objects In Ruby](http://jamesmead.org/talks/2007-07-09-introduction-to-mock-objects-in-ruby-at-lrug/)
* [Mocks Aren't Stubs](http://martinfowler.com/articles/mocksArentStubs.html)
* [Growing Object-Oriented Software Guided By Tests](http://www.growing-object-oriented-software.com/)
* [Mock Roles Not Objects](http://www.jmock.org/oopsla2004.pdf)
* [jMock](http://www.jmock.org/)

### Contributors

See this [list of contributors](https://github.com/freerange/mocha/graphs/contributors).

### Releasing a new version

* Update the RELEASE.md file with a summary of changes
* Bump the version in `lib/mocha/version.rb`
* Commit & push to GitHub
* Check CircleCI build is passing - https://app.circleci.com/pipelines/github/freerange/mocha

* Sign in to Google Analytics - https://analytics.google.com/analytics/web/
* Find the web property ID for floehopper (625523) > Mocha Documentation (UA-625523-7)
* Generate documentation:

```bash
$ MOCHA_GENERATE_DOCS=true bundle install

$ MOCHA_GENERATE_DOCS=true GOOGLE_ANALYTICS_WEB_PROPERTY_ID=UA-625523-7 rake generate_docs
```
* Commit documentation & push to GitHub
* Sign in to rubygems.org and find API key - https://rubygems.org/profile/edit

```bash
$ curl -u <email-address> -H 'OTP:<one-time-password>' https://rubygems.org/api/v1/api_key.yaml > ~/.gem/credentials; chmod 0600 ~/.gem/credentials
```

* Release gem to Rubygems:

```bash
$ rake release
[runs tests]
mocha 1.2.0 built to pkg/mocha-1.2.0.gem.
Tagged v1.2.0.
Pushed git commits and tags.
Pushed mocha 1.2.0 to rubygems.org.
```

### History

Mocha was initially harvested from projects at [Reevoo](http://www.reevoo.com/). It's syntax is heavily based on that of [jMock](http://www.jmock.org).

### License

&copy; Copyright Revieworld Ltd. 2006

You may use, copy and redistribute this library under the same terms as [Ruby itself](http://www.ruby-lang.org/en/LICENSE.txt) or under the [MIT license](http://www.opensource.org/licenses/MIT).
","Mocha is a Ruby library for mocking and stubbing. It has built-in support for
MiniTest and Test::Unit. There is no need to use Mocha itself to setup Mocha;
RSpec does this for you. Mocha is intended to be used in unit tests."
2407,Manipulate JSON-like data with NumPy-like idioms.,"<!-- begin-logo -->
![](docs-img/logo/logo-300px.png)
<!-- end-logo -->

[![PyPI version](https://badge.fury.io/py/awkward.svg)](https://pypi.org/project/awkward)
[![Conda-Forge](https://img.shields.io/conda/vn/conda-forge/awkward)](https://github.com/conda-forge/awkward-feedstock)
[![Python 3.7‒3.11](https://img.shields.io/badge/python-3.7%E2%80%923.11-blue)](https://www.python.org)
[![BSD-3 Clause License](https://img.shields.io/badge/license-BSD%203--Clause-blue.svg)](https://opensource.org/licenses/BSD-3-Clause)
[![Build Test](https://github.com/scikit-hep/awkward/actions/workflows/test.yml/badge.svg?branch=main)](https://github.com/scikit-hep/awkward/actions/workflows/test.yml)

[![Scikit-HEP](https://scikit-hep.org/assets/images/Scikit--HEP-Project-blue.svg)](https://scikit-hep.org/)
[![NSF-1836650](https://img.shields.io/badge/NSF-1836650-blue.svg)](https://nsf.gov/awardsearch/showAward?AWD_ID=1836650)
[![DOI](https://zenodo.org/badge/DOI/10.5281/zenodo.4341376.svg)](https://doi.org/10.5281/zenodo.4341376)
[![Documentation](https://img.shields.io/badge/docs-online-success)](https://awkward-array.org/)
[![Gitter](https://img.shields.io/badge/chat-online-success)](https://gitter.im/Scikit-HEP/awkward-array)

Awkward Array is a library for **nested, variable-sized data**, including arbitrary-length lists, records, mixed types, and missing data, using **NumPy-like idioms**.

Arrays are **dynamically typed**, but operations on them are **compiled and fast**. Their behavior coincides with NumPy when array dimensions are regular and generalizes when they're not.

# Motivating example

Given an array of lists of objects with `x`, `y` fields (with nested lists in the `y` field),

```python
array = ak.Array([
    [{""x"": 1.1, ""y"": [1]}, {""x"": 2.2, ""y"": [1, 2]}, {""x"": 3.3, ""y"": [1, 2, 3]}],
    [],
    [{""x"": 4.4, ""y"": [1, 2, 3, 4]}, {""x"": 5.5, ""y"": [1, 2, 3, 4, 5]}]
])
```

the following slices out the `y` values, drops the first element from each inner list, and runs NumPy's `np.square` function on everything that is left:

```python
output = np.square(array[""y"", ..., 1:])
```

The result is

```python
[
    [[], [4], [4, 9]],
    [],
    [[4, 9, 16], [4, 9, 16, 25]]
]
```

The equivalent using only Python is

```python
output = []
for sublist in array:
    tmp1 = []
    for record in sublist:
        tmp2 = []
        for number in record[""y""][1:]:
            tmp2.append(np.square(number))
        tmp1.append(tmp2)
    output.append(tmp1)
```

The expression using Awkward Arrays is more concise, using idioms familiar from NumPy, and it also has NumPy-like performance. For a similar problem 10 million times larger than the one above (single-threaded on a 2.2 GHz processor),

   * the Awkward Array one-liner takes **1.5 seconds** to run and uses **2.1 GB** of memory,
   * the equivalent using Python lists and dicts takes **140 seconds** to run and uses **22 GB** of memory.

Awkward Array is even faster when used in [Numba](https://numba.pydata.org/)'s JIT-compiled functions.

See the [Getting started](https://awkward-array.org/doc/main/getting-started/index.html) documentation on [awkward-array.org](https://awkward-array.org) for an introduction, including a [no-install demo](https://awkward-array.org/doc/main/getting-started/try-awkward-array.html) you can try in your web browser.

# Getting help

   * View the documentation on [awkward-array.org](https://awkward-array.org/).
   * Report bugs, request features, and ask for additional documentation on [GitHub Issues](https://github.com/scikit-hep/awkward/issues).
   * If you have a ""How do I...?"" question, start a [GitHub Discussion](https://github.com/scikit-hep/awkward/discussions) with category ""Q&A"".
   * Alternatively, ask about it on [StackOverflow with the [awkward-array] tag](https://stackoverflow.com/questions/tagged/awkward-array). Be sure to include tags for any other libraries that you use, such as Pandas or PyTorch.
   * To ask questions in real time, try the Gitter [Scikit-HEP/awkward-array](https://gitter.im/Scikit-HEP/awkward-array) chat room.

# Installation

Awkward Array can be installed from [PyPI](https://pypi.org/project/awkward) using pip:

```bash
pip install awkward
```

The `awkward` package is pure Python, and it will download the `awkward-cpp` compiled components as a dependency. If there is no `awkward-cpp` binary package (wheel) for your platform and Python version, pip will attempt to compile it from source (which has additional dependencies, such as a C++ compiler).

Awkward Array is also available on [conda-forge](https://conda-forge.org/docs/user/introduction.html#how-can-i-install-packages-from-conda-forge):

```bash
conda install -c conda-forge awkward
```

<!-- readme-pypi-ignore-after -->

Because of the two packages (`awkward-cpp` may be updated in GitHub but not on PyPI), pip install through git (`pip install git+https://...`) will not work. Instead, use the [Installation for developers](#installation-for-developers) section below.

# Installation for developers

Clone this repository _recursively_ to get the header-only C++ dependencies, then generate sources with [nox](https://nox.thea.codes/), compile and install `awkward-cpp`, and finally install `awkward` as an editable installation:

```bash
git clone --recursive https://github.com/scikit-hep/awkward.git
cd awkward

nox -s prepare
python -m pip install -v ./awkward-cpp
python -m pip install -e .
```

Tests can be run in parallel with [pytest](https://docs.pytest.org/):

```bash
python -m pytest -n auto tests
```

For more details, see [CONTRIBUTING.md](https://github.com/scikit-hep/awkward/blob/main/CONTRIBUTING.md), or one of the links below.

   * [Continuous integration](https://github.com/scikit-hep/awkward/actions/workflows/test.yml) and [continuous deployment](https://github.com/scikit-hep/awkward/actions/workflows/wheels.yml) are hosted by [GitHub Actions](https://github.com/features/actions/).
   * [Code of conduct](https://scikit-hep.org/code-of-conduct) for how we work together.
   * The [LICENSE](LICENSE) is BSD-3.

# Documentation, Release notes, Roadmap, Citations

The documentation is on [awkward-array.org](https://awkward-array.org), including

   * [Getting started](https://awkward-array.org/doc/main/getting-started/index.html)
   * [User guide](https://awkward-array.org/doc/main/user-guide/index.html)
   * [API reference](https://awkward-array.org/doc/main/reference/index.html)
   * [Tutorials (with videos)](https://awkward-array.org/doc/main/getting-started/community-tutorials.html)
   * [Papers and talks](https://awkward-array.org/doc/main/getting-started/papers-and-talks.html) about Awkward Array

The Release notes for each version are in the [GitHub Releases tab](https://github.com/scikit-hep/awkward/releases).

The Roadmap, Plans, and Deprecation Schedule are in the [GitHub Wiki](https://github.com/scikit-hep/awkward/wiki).

To cite Awkward Array in a paper, see the ""Cite this repository"" drop-down menu on the top-right of the [GitHub front page](https://github.com/scikit-hep/awkward). The BibTeX is

```bibtex
@software{Pivarski_Awkward_Array_2018,
author = {Pivarski, Jim and Osborne, Ianna and Ifrim, Ioana and Schreiner, Henry and Hollands, Angus and Biswas, Anish and Das, Pratyush and Roy Choudhury, Santam and Smith, Nicholas and Goyal, Manasvi},
doi = {10.5281/zenodo.4341376},
month = {10},
title = {{Awkward Array}},
year = {2018}
}
```

# Acknowledgements

Support for this work was provided by NSF cooperative agreement [OAC-1836650](https://www.nsf.gov/awardsearch/showAward?AWD_ID=1836650) (IRIS-HEP), grant [OAC-1450377](https://nsf.gov/awardsearch/showAward?AWD_ID=1450377) (DIANA/HEP), [PHY-1520942](https://www.nsf.gov/awardsearch/showAward?AWD_ID=1520942) (US-CMS LHC Ops), and [OAC-2103945](https://www.nsf.gov/awardsearch/showAward?AWD_ID=2103945) (Awkward Array).

We also thank [Erez Shinan](https://github.com/erezsh) and the developers of the [Lark standalone parser](https://github.com/lark-parser/lark), which is used to parse type strings as type objects.

Thanks especially to the gracious help of Awkward Array contributors (including the [original repository](https://github.com/scikit-hep/awkward-0.x)).

<!-- ALL-CONTRIBUTORS-LIST:START - Do not remove or modify this section -->
<!-- prettier-ignore-start -->
<!-- markdownlint-disable -->
<table>
  <tbody>
    <tr>
      <td align=""center"" valign=""top"" width=""14.28%""><a href=""https://github.com/jpivarski""><img src=""https://avatars0.githubusercontent.com/u/1852447?v=4?s=100"" width=""100px;"" alt=""Jim Pivarski""/><br /><sub><b>Jim Pivarski</b></sub></a><br /><a href=""https://github.com/scikit-hep/awkward/commits?author=jpivarski"" title=""Code"">💻</a> <a href=""https://github.com/scikit-hep/awkward/commits?author=jpivarski"" title=""Documentation"">📖</a> <a href=""#infra-jpivarski"" title=""Infrastructure (Hosting, Build-Tools, etc)"">🚇</a> <a href=""#maintenance-jpivarski"" title=""Maintenance"">🚧</a></td>
      <td align=""center"" valign=""top"" width=""14.28%""><a href=""https://github.com/ianna""><img src=""https://avatars0.githubusercontent.com/u/1390682?v=4?s=100"" width=""100px;"" alt=""Ianna Osborne""/><br /><sub><b>Ianna Osborne</b></sub></a><br /><a href=""https://github.com/scikit-hep/awkward/commits?author=ianna"" title=""Code"">💻</a></td>
      <td align=""center"" valign=""top"" width=""14.28%""><a href=""https://github.com/reikdas""><img src=""https://avatars0.githubusercontent.com/u/11775615?v=4?s=100"" width=""100px;"" alt=""Pratyush Das""/><br /><sub><b>Pratyush Das</b></sub></a><br /><a href=""https://github.com/scikit-hep/awkward/commits?author=reikdas"" title=""Code"">💻</a></td>
      <td align=""center"" valign=""top"" width=""14.28%""><a href=""https://github.com/trickarcher""><img src=""https://avatars3.githubusercontent.com/u/39878675?v=4?s=100"" width=""100px;"" alt=""Anish Biswas""/><br /><sub><b>Anish Biswas</b></sub></a><br /><a href=""https://github.com/scikit-hep/awkward/commits?author=trickarcher"" title=""Code"">💻</a></td>
      <td align=""center"" valign=""top"" width=""14.28%""><a href=""https://github.com/glass-ships""><img src=""https://avatars2.githubusercontent.com/u/26975530?v=4?s=100"" width=""100px;"" alt=""glass-ships""/><br /><sub><b>glass-ships</b></sub></a><br /><a href=""https://github.com/scikit-hep/awkward/commits?author=glass-ships"" title=""Code"">💻</a> <a href=""https://github.com/scikit-hep/awkward/commits?author=glass-ships"" title=""Tests"">⚠️</a></td>
      <td align=""center"" valign=""top"" width=""14.28%""><a href=""http://iscinumpy.gitlab.io""><img src=""https://avatars1.githubusercontent.com/u/4616906?v=4?s=100"" width=""100px;"" alt=""Henry Schreiner""/><br /><sub><b>Henry Schreiner</b></sub></a><br /><a href=""https://github.com/scikit-hep/awkward/commits?author=henryiii"" title=""Code"">💻</a> <a href=""#infra-henryiii"" title=""Infrastructure (Hosting, Build-Tools, etc)"">🚇</a></td>
      <td align=""center"" valign=""top"" width=""14.28%""><a href=""https://github.com/nsmith-""><img src=""https://avatars2.githubusercontent.com/u/6587412?v=4?s=100"" width=""100px;"" alt=""Nicholas Smith""/><br /><sub><b>Nicholas Smith</b></sub></a><br /><a href=""https://github.com/scikit-hep/awkward/commits?author=nsmith-"" title=""Code"">💻</a> <a href=""https://github.com/scikit-hep/awkward/commits?author=nsmith-"" title=""Tests"">⚠️</a></td>
    </tr>
    <tr>
      <td align=""center"" valign=""top"" width=""14.28%""><a href=""https://github.com/lgray""><img src=""https://avatars0.githubusercontent.com/u/1068089?v=4?s=100"" width=""100px;"" alt=""Lindsey Gray""/><br /><sub><b>Lindsey Gray</b></sub></a><br /><a href=""https://github.com/scikit-hep/awkward/commits?author=lgray"" title=""Code"">💻</a> <a href=""https://github.com/scikit-hep/awkward/commits?author=lgray"" title=""Tests"">⚠️</a></td>
      <td align=""center"" valign=""top"" width=""14.28%""><a href=""https://github.com/Ellipse0934""><img src=""https://avatars3.githubusercontent.com/u/7466364?v=4?s=100"" width=""100px;"" alt=""Ellipse0934""/><br /><sub><b>Ellipse0934</b></sub></a><br /><a href=""https://github.com/scikit-hep/awkward/commits?author=Ellipse0934"" title=""Tests"">⚠️</a></td>
      <td align=""center"" valign=""top"" width=""14.28%""><a href=""https://gitlab.com/veprbl""><img src=""https://avatars1.githubusercontent.com/u/245573?v=4?s=100"" width=""100px;"" alt=""Dmitry Kalinkin""/><br /><sub><b>Dmitry Kalinkin</b></sub></a><br /><a href=""#infra-veprbl"" title=""Infrastructure (Hosting, Build-Tools, etc)"">🚇</a></td>
      <td align=""center"" valign=""top"" width=""14.28%""><a href=""https://www.linkedin.com/in/charles-c-escott/""><img src=""https://avatars3.githubusercontent.com/u/48469669?v=4?s=100"" width=""100px;"" alt=""Charles Escott""/><br /><sub><b>Charles Escott</b></sub></a><br /><a href=""https://github.com/scikit-hep/awkward/commits?author=EscottC"" title=""Code"">💻</a></td>
      <td align=""center"" valign=""top"" width=""14.28%""><a href=""https://github.com/masonproffitt""><img src=""https://avatars3.githubusercontent.com/u/32773304?v=4?s=100"" width=""100px;"" alt=""Mason Proffitt""/><br /><sub><b>Mason Proffitt</b></sub></a><br /><a href=""https://github.com/scikit-hep/awkward/commits?author=masonproffitt"" title=""Code"">💻</a></td>
      <td align=""center"" valign=""top"" width=""14.28%""><a href=""https://github.com/mhedges""><img src=""https://avatars3.githubusercontent.com/u/18672512?v=4?s=100"" width=""100px;"" alt=""Michael Hedges""/><br /><sub><b>Michael Hedges</b></sub></a><br /><a href=""https://github.com/scikit-hep/awkward/commits?author=mhedges"" title=""Code"">💻</a></td>
      <td align=""center"" valign=""top"" width=""14.28%""><a href=""https://github.com/guitargeek""><img src=""https://avatars2.githubusercontent.com/u/6578603?v=4?s=100"" width=""100px;"" alt=""Jonas Rembser""/><br /><sub><b>Jonas Rembser</b></sub></a><br /><a href=""https://github.com/scikit-hep/awkward/commits?author=guitargeek"" title=""Code"">💻</a></td>
    </tr>
    <tr>
      <td align=""center"" valign=""top"" width=""14.28%""><a href=""https://github.com/Jayd-1234""><img src=""https://avatars0.githubusercontent.com/u/34567389?v=4?s=100"" width=""100px;"" alt=""Jaydeep Nandi""/><br /><sub><b>Jaydeep Nandi</b></sub></a><br /><a href=""https://github.com/scikit-hep/awkward/commits?author=Jayd-1234"" title=""Code"">💻</a></td>
      <td align=""center"" valign=""top"" width=""14.28%""><a href=""https://github.com/benkrikler""><img src=""https://avatars0.githubusercontent.com/u/4083697?v=4?s=100"" width=""100px;"" alt=""benkrikler""/><br /><sub><b>benkrikler</b></sub></a><br /><a href=""https://github.com/scikit-hep/awkward/commits?author=benkrikler"" title=""Code"">💻</a></td>
      <td align=""center"" valign=""top"" width=""14.28%""><a href=""https://github.com/bfis""><img src=""https://avatars0.githubusercontent.com/u/15651150?v=4?s=100"" width=""100px;"" alt=""bfis""/><br /><sub><b>bfis</b></sub></a><br /><a href=""https://github.com/scikit-hep/awkward/commits?author=bfis"" title=""Code"">💻</a></td>
      <td align=""center"" valign=""top"" width=""14.28%""><a href=""https://ddavis.io/""><img src=""https://avatars2.githubusercontent.com/u/3202090?v=4?s=100"" width=""100px;"" alt=""Doug Davis""/><br /><sub><b>Doug Davis</b></sub></a><br /><a href=""https://github.com/scikit-hep/awkward/commits?author=douglasdavis"" title=""Code"">💻</a></td>
      <td align=""center"" valign=""top"" width=""14.28%""><a href=""http://twitter: @JoosepPata""><img src=""https://avatars0.githubusercontent.com/u/69717?v=4?s=100"" width=""100px;"" alt=""Joosep Pata""/><br /><sub><b>Joosep Pata</b></sub></a><br /><a href=""#ideas-jpata"" title=""Ideas, Planning, & Feedback"">🤔</a></td>
      <td align=""center"" valign=""top"" width=""14.28%""><a href=""http://martindurant.github.io/""><img src=""https://avatars1.githubusercontent.com/u/6042212?v=4?s=100"" width=""100px;"" alt=""Martin Durant""/><br /><sub><b>Martin Durant</b></sub></a><br /><a href=""#ideas-martindurant"" title=""Ideas, Planning, & Feedback"">🤔</a></td>
      <td align=""center"" valign=""top"" width=""14.28%""><a href=""http://gordonwatts.wordpress.com""><img src=""https://avatars2.githubusercontent.com/u/1778366?v=4?s=100"" width=""100px;"" alt=""Gordon Watts""/><br /><sub><b>Gordon Watts</b></sub></a><br /><a href=""#ideas-gordonwatts"" title=""Ideas, Planning, & Feedback"">🤔</a></td>
    </tr>
    <tr>
      <td align=""center"" valign=""top"" width=""14.28%""><a href=""https://gitlab.com/nikoladze""><img src=""https://avatars0.githubusercontent.com/u/3707225?v=4?s=100"" width=""100px;"" alt=""Nikolai Hartmann""/><br /><sub><b>Nikolai Hartmann</b></sub></a><br /><a href=""https://github.com/scikit-hep/awkward/commits?author=nikoladze"" title=""Code"">💻</a></td>
      <td align=""center"" valign=""top"" width=""14.28%""><a href=""https://github.com/sjperkins""><img src=""https://avatars3.githubusercontent.com/u/3530212?v=4?s=100"" width=""100px;"" alt=""Simon Perkins""/><br /><sub><b>Simon Perkins</b></sub></a><br /><a href=""https://github.com/scikit-hep/awkward/commits?author=sjperkins"" title=""Code"">💻</a></td>
      <td align=""center"" valign=""top"" width=""14.28%""><a href=""https://github.com/drahnreb""><img src=""https://avatars.githubusercontent.com/u/25883607?v=4?s=100"" width=""100px;"" alt="".hard""/><br /><sub><b>.hard</b></sub></a><br /><a href=""https://github.com/scikit-hep/awkward/commits?author=drahnreb"" title=""Code"">💻</a> <a href=""https://github.com/scikit-hep/awkward/commits?author=drahnreb"" title=""Tests"">⚠️</a></td>
      <td align=""center"" valign=""top"" width=""14.28%""><a href=""https://github.com/HenryDayHall""><img src=""https://avatars.githubusercontent.com/u/12996763?v=4?s=100"" width=""100px;"" alt=""HenryDayHall""/><br /><sub><b>HenryDayHall</b></sub></a><br /><a href=""https://github.com/scikit-hep/awkward/commits?author=HenryDayHall"" title=""Code"">💻</a></td>
      <td align=""center"" valign=""top"" width=""14.28%""><a href=""https://github.com/agoose77""><img src=""https://avatars.githubusercontent.com/u/1248413?v=4?s=100"" width=""100px;"" alt=""Angus Hollands""/><br /><sub><b>Angus Hollands</b></sub></a><br /><a href=""https://github.com/scikit-hep/awkward/commits?author=agoose77"" title=""Tests"">⚠️</a> <a href=""https://github.com/scikit-hep/awkward/commits?author=agoose77"" title=""Code"">💻</a></td>
      <td align=""center"" valign=""top"" width=""14.28%""><a href=""https://github.com/ioanaif""><img src=""https://avatars.githubusercontent.com/u/9751871?v=4?s=100"" width=""100px;"" alt=""ioanaif""/><br /><sub><b>ioanaif</b></sub></a><br /><a href=""https://github.com/scikit-hep/awkward/commits?author=ioanaif"" title=""Code"">💻</a> <a href=""https://github.com/scikit-hep/awkward/commits?author=ioanaif"" title=""Tests"">⚠️</a></td>
      <td align=""center"" valign=""top"" width=""14.28%""><a href=""http://lizards.opensuse.org/author/bmwiedemann/""><img src=""https://avatars.githubusercontent.com/u/637990?v=4?s=100"" width=""100px;"" alt=""Bernhard M. Wiedemann""/><br /><sub><b>Bernhard M. Wiedemann</b></sub></a><br /><a href=""#maintenance-bmwiedemann"" title=""Maintenance"">🚧</a></td>
    </tr>
    <tr>
      <td align=""center"" valign=""top"" width=""14.28%""><a href=""http://www.matthewfeickert.com/""><img src=""https://avatars.githubusercontent.com/u/5142394?v=4?s=100"" width=""100px;"" alt=""Matthew Feickert""/><br /><sub><b>Matthew Feickert</b></sub></a><br /><a href=""#maintenance-matthewfeickert"" title=""Maintenance"">🚧</a></td>
      <td align=""center"" valign=""top"" width=""14.28%""><a href=""https://github.com/SantamRC""><img src=""https://avatars.githubusercontent.com/u/52635773?v=4?s=100"" width=""100px;"" alt=""Santam Roy Choudhury""/><br /><sub><b>Santam Roy Choudhury</b></sub></a><br /><a href=""https://github.com/scikit-hep/awkward/commits?author=SantamRC"" title=""Tests"">⚠️</a></td>
      <td align=""center"" valign=""top"" width=""14.28%""><a href=""http://jeroen.vangoey.be""><img src=""https://avatars.githubusercontent.com/u/59344?v=4?s=100"" width=""100px;"" alt=""Jeroen Van Goey""/><br /><sub><b>Jeroen Van Goey</b></sub></a><br /><a href=""https://github.com/scikit-hep/awkward/commits?author=BioGeek"" title=""Documentation"">📖</a></td>
      <td align=""center"" valign=""top"" width=""14.28%""><a href=""https://github.com/Ahmad-AlSubaie""><img src=""https://avatars.githubusercontent.com/u/32343365?v=4?s=100"" width=""100px;"" alt=""Ahmad-AlSubaie""/><br /><sub><b>Ahmad-AlSubaie</b></sub></a><br /><a href=""https://github.com/scikit-hep/awkward/commits?author=Ahmad-AlSubaie"" title=""Code"">💻</a></td>
      <td align=""center"" valign=""top"" width=""14.28%""><a href=""https://github.com/ManasviGoyal""><img src=""https://avatars.githubusercontent.com/u/55101825?v=4?s=100"" width=""100px;"" alt=""Manasvi Goyal""/><br /><sub><b>Manasvi Goyal</b></sub></a><br /><a href=""https://github.com/scikit-hep/awkward/commits?author=ManasviGoyal"" title=""Code"">💻</a></td>
      <td align=""center"" valign=""top"" width=""14.28%""><a href=""https://github.com/aryan26roy""><img src=""https://avatars.githubusercontent.com/u/50577809?v=4?s=100"" width=""100px;"" alt=""Aryan Roy""/><br /><sub><b>Aryan Roy</b></sub></a><br /><a href=""https://github.com/scikit-hep/awkward/commits?author=aryan26roy"" title=""Code"">💻</a></td>
      <td align=""center"" valign=""top"" width=""14.28%""><a href=""https://saransh-cpp.github.io/""><img src=""https://avatars.githubusercontent.com/u/74055102?v=4?s=100"" width=""100px;"" alt=""Saransh""/><br /><sub><b>Saransh</b></sub></a><br /><a href=""https://github.com/scikit-hep/awkward/commits?author=Saransh-cpp"" title=""Code"">💻</a></td>
    </tr>
    <tr>
      <td align=""center"" valign=""top"" width=""14.28%""><a href=""https://github.com/Laurits7""><img src=""https://avatars.githubusercontent.com/u/30724920?v=4?s=100"" width=""100px;"" alt=""Laurits Tani""/><br /><sub><b>Laurits Tani</b></sub></a><br /><a href=""https://github.com/scikit-hep/awkward/commits?author=Laurits7"" title=""Documentation"">📖</a></td>
      <td align=""center"" valign=""top"" width=""14.28%""><a href=""https://github.com/dsavoiu""><img src=""https://avatars.githubusercontent.com/u/17005255?v=4?s=100"" width=""100px;"" alt=""Daniel Savoiu""/><br /><sub><b>Daniel Savoiu</b></sub></a><br /><a href=""https://github.com/scikit-hep/awkward/commits?author=dsavoiu"" title=""Code"">💻</a></td>
    </tr>
  </tbody>
</table>

<!-- markdownlint-restore -->
<!-- prettier-ignore-end -->

<!-- ALL-CONTRIBUTORS-LIST:END -->

💻: code, 📖: documentation, 🚇: infrastructure, 🚧: maintenance, ⚠: tests and feedback, 🤔: foundational ideas.
","Awkward Array is a library for **nested, variable-sized data**, including
arbitrary-length lists, records, mixed types, and missing data. Arrays are
**dynamically typed**, but operations on them are **compiled and fast** Their
behavior coincides with NumPy when array dimensions are regular and generalizes
when they're not."
1635,Tutorial on how to make a custom React renderer,"# Building a custom React renderer

[![Build Status](https://travis-ci.org/nitin42/Making-a-custom-React-renderer.svg?branch=master)](https://travis-ci.org/nitin42/Making-a-custom-React-renderer)

> Let's make a custom React renderer 😎

<p align=""center"">
  <img src=""https://cdn.filestackcontent.com/5KdzhvGRG61WMQhBa1Ql"" width=""630"" height=""350"">
</p>

## Introduction

This is a small tutorial on how to build your custom React renderer and render the components to the host environment you need. The tutorial is divided into three parts -

* **Part 1** - Creating a React reconciler (using [`react-reconciler`](https://github.com/facebook/react/tree/master/packages/react-reconciler) package).

* **Part 2** - Creating a public interface to the reconciler i.e ""Renderer"".

* **Part 3** - Creating a render method to flush everything to the host environment we need.

## Brief

### [Part-I](./part-one.md)

In part one, we will create a React reconciler using the [`react-reconciler`](https://github.com/facebook/react/tree/master/packages/react-reconciler) package. We will implement the renderer using Fiber as it has a first-class renderer API for creating custom renderer.

### [Part-II](./part-two.md)

In part two, we will create a public interface to the reconciler i.e a renderer. We will create a custom method for `createElement` and will also architect the component API for our example.

### [Part-III](./part-three.md)

In part three, we will create a render method which will render our input component.

## What we will build?

We will create a custom renderer that will render a React component to a word document. I've already made one. Full source code and the documentation for that is available [here](https://github.com/nitin42/redocx).

We will use [officegen](https://github.com/Ziv-Barber/officegen) for this. I'll explain some of it's basic concepts here.

Officegen can generate Open Office XML files for Microsoft Office 2007 and later. It generates a output stream and not a file.
It is independent of any output tool.

**Creating a document object**

```js
let doc = officegen('docx', { __someOptions__ });
```

**Generating output stream**

```js
let output = fs.createWriteStream (__filePath__);

doc.generate(output);
```

**Events**

`finalize` - It is fired after a stream has been generated successfully.

`error` - Fired when there are any errors

## Running the project

```
git clone https://github.com/nitin42/Making-a-custom-React-renderer
cd Making-a-custom-React-renderer
yarn install
yarn example
```

After you run `yarn example`, a docx file will be generated in the [demo](./demo) folder.

## Contributing

Suggestions to improve the tutorial are welcome 😃.

**If you've completed the tutorial successfully, you can either watch/star this repo or follow me on [twitter](https://twitter.com/NTulswani) for more updates.**

<a target='_blank' rel='nofollow' href='https://app.codesponsor.io/link/FCRW65HPiwhNtebDx2tTc53E/nitin42/Making-a-custom-React-renderer'>
  <img alt='Sponsor' width='888' height='68' src='https://app.codesponsor.io/embed/FCRW65HPiwhNtebDx2tTc53E/nitin42/Making-a-custom-React-renderer.svg' />
</a>
","This is a small tutorial on how to build your custom React renderer and render
the components to the host environment you need. The tutorial is divided into
three parts -. Creating a React reconciler (using [`react-
reconciler`](https://github.com/facebook/react/tree/master/packages/ React-re
Conciler) Creating a public interface to the reconciler i.e ""Renderer"" Creating
a render method to flush everything to thehost environment we need."
752,"A development tool for all your projects that is fast, easy, powerful and liberating","<div align=""center"">

<a href=""https://lando.dev"" target=""_blank""><img width=""250"" src=""https://docs.lando.dev/images/icon.svg"" alt=""Lando logo""></a>

# Lando

### A Liberating Dev Tool For All Your Projects

The local development and DevOps tool trusted by professional developers across the galaxy.

Free yourself from the mind-forged manacles of lesser dev tools. Save time, headaches, frustration and do more real work.

**[learn more](https://lando.dev) | 
[what is it good for?](https://docs.lando.dev/getting-started/#what-is-it-good-for) | 
[wait, doesn't docker compose do this?](https://docs.lando.dev/getting-started/#wait-doesn-t-docker-compose-do-this)**

## Support Lando

Lando is and always will be FREE and OPEN SOURCE. As such it relies on generous contributions from its community to fund its development. Join our list of list of [great sponsors!](https://lando.dev/sponsor/) by contributing.

[GitHub Sponsors](https://github.com/sponsors/lando) | 
[Patreon](https://www.patreon.com/devwithlando) | 
[OpenCollective](https://opencollective.com/lando)

## Documentation

### Getting Started

[Introduction](https://docs.lando.dev/getting-started) | 
[CLI Usage](https://docs.lando.dev/cli/) | 
[Installation](https://docs.lando.dev/getting-started/installation)

### Recipes

[Backdrop](https://docs.lando.dev/backdrop/) | 
[Drupal 6, 7, 8, 9, and 10](https://docs.lando.dev/drupal/) | 
[Joomla](https://docs.lando.dev/joomla/) | 
[Lagoon](https://docs.lando.dev/lagoon/) | 
[Laravel](https://docs.lando.dev/laravel/) | 
[LAMP](https://docs.lando.dev/lamp/) | 
[LEMP](https://docs.lando.dev/lemp/) | 
[MEAN](https://docs.lando.dev/mean/) | 
[Pantheon](https://docs.lando.dev/pantheon/) | 
[Platform.sh](https://docs.lando.dev/platformsh/) | 
[WordPress](https://docs.lando.dev/wordpress/)

### Services

[Apache](https://docs.lando.dev/apache/) | 
[Compose](https://docs.lando.dev/compose/) | 
[dotnet](https://docs.lando.dev/dotnet/) | 
[Elasticsearch](https://docs.lando.dev/elasticsearch/) | 
[Go](https://docs.lando.dev/go/) | 
[MailHog](https://docs.lando.dev/mailhog/) | 
[MariaDB](https://docs.lando.dev/mariadb/) | 
[MySQL](https://docs.lando.dev/mysql/) | 
[MSSQL](https://docs.lando.dev/mssql/) | 
[nginx](https://docs.lando.dev/nginx/) | 
[Node](https://docs.lando.dev/node/) | 
[PHP](https://docs.lando.dev/php/) | 
[PhpMyAdmin](https://docs.lando.dev/phpmyadmin/) | 
[Postgres](https://docs.lando.dev/postgres/) | 
[Python](https://docs.lando.dev/python/) | 
[Redis](https://docs.lando.dev/redis/) | 
[Ruby](https://docs.lando.dev/ruby/) | 
[Solr](https://docs.lando.dev/solr/) | 
[Tomcat](https://docs.lando.dev/tomcat/) | 
[Varnish](https://docs.lando.dev/varnish/)

### Advanced Configuration

[Landofile](https://docs.lando.dev/config/lando.html) | 
[Recipes](https://docs.lando.dev/config/recipes.html) | 
[Services & Build Steps](https://docs.lando.dev/config/services.html) | 
[Tooling](https://docs.lando.dev/config/tooling.html) | 
[Proxy & Nice Url Routing](https://docs.lando.dev/config/proxy.html) | 
[Environment](https://docs.lando.dev/config/env.html) | 
[Events & Automation](https://docs.lando.dev/config/events.html) | 
[Experimental](https://docs.lando.dev/config/experimental.html) | 
[Networking](https://docs.lando.dev/config/networking.html) | 
[Performance](https://docs.lando.dev/config/performance.html) | 
[Release Channels](https://docs.lando.dev/config/releases.html) | 
[SSH Keys](https://docs.lando.dev/config/ssh.html) | 
[Global Config](https://docs.lando.dev/config/global.html)

## Help, Troubleshooting & Support

[Guides and Tutorials](https://docs.lando.dev/guides/lando-info.html) | 
[Examples](https://docs.lando.dev/getting-started/what-it-do.html#you-have-some-examples) | 
[Known Issues](https://docs.lando.dev/help/dns-rebind.html) | 
[Accessing Logs](https://docs.lando.dev/help/logs.html) | 
[GitHub Issue Queue](https://github.com/lando/lando/issues) | 
[Slack Channel](https://launchpass.com/devwithlando) | 
[YouTube Videos](https://www.youtube.com/channel/UCl_QBNuGJNoo7yH-n18K7Kg)

## Engage

[Contribute to the Project](https://docs.lando.dev/contrib) | 
[Join the Alliance](https://docs.lando.dev/contrib) | 
[Events and Meetups](https://lando.dev/events/) | 
[Blog](https://lando.dev/blog/) | 
[Follow on Twitter](https://twitter.com/devwithlando)

## Security Issues
If you have discovered a security issue with Lando, please contact the Lando Security Team directly at [security@devwithlando.io](mailto:security@devwithlando.io). We manage security issues separately in a private repository until the issue has been resolved. Even if you're not sure if it's a security problem, please contact the security team before filing an issue, blogging, or tweeting about it.

## Other Resources
* [Mountain climbing advice](https://www.youtube.com/watch?v=tkBVDh7my9Q)
","Lando is a local development and DevOps tool trusted by professional developers
across the galaxy. Save time, headaches, frustration and do more real work with
Lando. Lando is and always will be FREE and OPEN SOURCE. As such it relies on
generous contributions from its community to fund its development. Join our list
of [great sponsors!](https://lando.dev/sponsor/)"
1185,🚀 A Next Generation Private Torrent Tracker (Community Edition),"<p align=""center"">
    <img src=""https://i.postimg.cc/GpMQ3bj2/68747470733a2f2f692e706f7374696d672e63632f765a623674706e772f53637265656e2d53686f742d323032312d31302d.png"" alt=""UNIT3D-Community-Edition Cover Image"">
</p>

<p align=""center"">
<a href=""http://laravel.com""><img src=""https://img.shields.io/badge/Laravel-9-f4645f.svg"" /></a> 
<a href=""https://github.com/HDInnovations/UNIT3D/blob/master/LICENSE""><img src=""https://img.shields.io/badge/License-AGPL%20v3.0-yellow.svg"" /></a>
<a href=""https://github.com/HDInnovations/UNIT3D-Community-Edition/actions/workflows/lint.yml/badge.svg""><img src=""https://github.com/HDInnovations/UNIT3D-Community-Edition/actions/workflows/lint.yml/badge.svg"" /></a>
<a href=""https://github.com/HDInnovations/UNIT3D-Community-Edition/actions/workflows/phpunit-test.yml/badge.svg""><img src=""https://github.com/HDInnovations/UNIT3D-Community-Edition/actions/workflows/phpunit-test.yml/badge.svg"" /></a>
<a href=""https://github.com/HDInnovations/UNIT3D-Community-Edition/actions/workflows/compile-assets-test.yml/badge.svg""><img src=""https://github.com/HDInnovations/UNIT3D-Community-Edition/actions/workflows/compile-assets-test.yml/badge.svg"" /></a>
<a href=""https://discord.gg/J8dsx7F5yT""><img alt=""Discord chat"" src=""https://img.shields.io/badge/discord-Chat%20Now-a29bfe.svg"" /></a>
<a href=""http://makeapullrequest.com""><img src=""https://img.shields.io/badge/PRs-welcome-brightgreen.svg""></a>
</p>

<a href=https://github.com/sponsors/HDVinnie>
<p align=""center"">
    <img src=""https://i.postimg.cc/QMRRNgmV/support.png"" alt=""UNIT3D-Community-Edition Support Image"">
</p>
</a>

<p align=""center"">
    🎉<b>A Big Thanks To All Our <a href=""https://github.com/HDInnovations/UNIT3D-Community-Edition/graphs/contributors"">Contributors</a> and <a href=""https://github.com/sponsors/HDVinnie"">Sponsors</a></b>🎉
</p>

## 📝 Table of Contents

1. [Introduction](#introduction)
2. [Some Features](#features)
3. [Requirements](#requirements)
4. [Installation](#installation)
4.1 [Automated-Installer](#auto-install)
5. [Updating](#updating)
6. [Version Support Information](#versions)
7. [Security](#security)
8. [Contributing](#contributing)
9. [License](#license)
10. [Demo](#demo)
11. [Discord-Chat](#chat)
12. [Sponsoring](#sponsor)
13. [Special Thanks](#thanks)


## <a name=""introduction""></a> 🧐 Introduction

We have been developing a Private Torrent Tracker Software called `UNIT3D`. This is a PHP software based on Laravel 9, Livewire and AlpineJS. It is MySQL Strict Mode Compliant, and PHP 8.2 Ready. The code is well-designed and follows the PSR-2 coding style. It uses an MVC Architecture to ensure clarity between logic and presentation. As a hashing algorithm of Bcrypt or Argon2 is used, to ensure a safe and proper way to store the passwords for the users. A lightweight Blade Templating Engine. Caching System Supporting: ""apc,” ""array,” ""database,” ""file,"" ""memcached,"" and ""redis"" methods. Eloquent and much more!

## <a name=""features""></a> 💎 Some Features

UNIT3D currently offers the following features:
  - Internal Forums System
  - Staff Dashboard
  - Livewire Powered Search Systems (Torrents, Requests, Users, Etc)
  - Bonus Points + Store
  - Torrent Request Section with Bonus Point Bounties and votes
  - Freeleech System
  - Double Upload System
  - Featured Torrents System
  - Polls System
  - Extra-Stats
  - Torrent Grouping
  - Top 10 System
  - PM System
  - Multilingual Support
  - TwoStep Auth System
  - DB + Files Backup Manager
  - RSS System
  - and MUCH MORE!

## <a name=""requirements""></a> ☑️ Requirements

- A Web server (NGINX is recommended)
- PHP 8.1 + is required
- Crontab access
- A Redis server
- MySQL 8.0 + or MariaDB 10.2 +
- TheMovieDB API Key: https://www.themoviedb.org/documentation/api
- A good dedicated server. Dont try running this on some basic server if you plan to run a large tracker!


## <a name=""installation""></a> 🖥️ Installation
```
NOTE: If you are running UNIT3D on a non HTTPS instance you MUST change the following configs.

.env  <-- SESSION_SECURE_COOKIE must be set to false
config/secure-headers.php   <-- HTTP Strict Transport Security must be set to false
config/secure-headers.php   <-- Content Security Policy must be disabled
```

### <a name=""auto-install""></a> Automated Installer
**A UNIT3D Installer has been released by Poppabear.**

**Officially Supported OS's**
- Ubuntu 20.04 LTS

```bash
git clone https://github.com/poppabear8883/UNIT3D-INSTALLER.git installer
cd installer
sudo ./install.sh
```

Check it out here for more information: https://github.com/poppabear8883/UNIT3D-INSTALLER

### Demo Data

Use this command to generate demo users and torrents for testing purposes:

`php artisan demo:seed`

## <a name=""updating""></a> 🖥️ Updating
`php artisan git:update`

## <a name=""versions""></a> 🚨 Version Support Information
 Version     | Status                   | PHP Version Required
:------------|:-------------------------|:------------
 6.x.x       |  Active Support :rocket: | >= 8.1
 5.x.x       |  End Of Life :skull: | >= 8.0
 4.x.x       |  End Of Life :skull: | >= 7.4
 3.x.x       |  End Of Life :skull: | >= 7.4
 2.3.0 to 2.7.0|  End Of Life :skull: | >= 7.4
 2.0.0 to 2.2.7|  End Of Life :skull: | >= 7.3
 1.0 to 1.9.4|  End Of Life :skull:     | >= 7.1.3

## <a name=""security""></a> 🔐 Security

If you discover any security related issues, please email hdinnovations@protonmail.com instead of using the issue tracker.

## <a name=""contributing""></a> ✍️ Contributing

Please see [CONTRIBUTING](CONTRIBUTING.md) and [CODE_OF_CONDUCT](CODE_OF_CONDUCT.md) for details.

## <a name=""license""></a> 📝 License

UNIT3D is open-sourced software licensed under the [GNU Affero General Public License v3.0](https://github.com/HDInnovations/UNIT3D/blob/master/LICENSE).

## <a name=""demo""></a>  🖥️ Demo

URL: https://unit3d.site

Username: UNIT3D

Password: UNIT3D

Demo is reset every 72 hours!

## <a name=""chat""></a>  💬 Come Chat With Us

URL: https://discord.gg/J8dsx7F5yT

## <a name=""sponsor""></a> ✨ Sponsor UNIT3D (HDInnovations / HDVinnie)

You can support my work if you are enjoying UNIT3D or need support via Discord. 

Monthy Recurring:

https://github.com/sponsors/HDVinnie?frequency=recurring&sponsor=HDVinnie

One-time Custom Amount:

https://github.com/sponsors/HDVinnie?frequency=one-time&sponsor=HDVinnie

Some folks have asked me if it's possible to do a one-time donation via Crypto Currency or CashApp. Yes! If you would like to contribute via a crypto-currency not listed please let me know.

CashApp - $hdvinnie

Bitcoin (BTC) - 3HUVkv3Q8b5nbxa9DtXG1dm4RdTJaTFRfc

Bitcoin Cash (BCH) - qp3wgpnwzpj4v9sq90wflsca8p5s75glrvga9tweu2

Ether (ETH) - 0x5eFF42F65234aD9c6A0CA5B9495f3c6D205bBC27
    
ETC - 0xd644C7C7009eC3824f3305ff6C7E2Ee90497d56e    

Litecoin (LTC) - MDLKyHzupt1mchuo8mrjW9mihkKp1LD4nG

USDC - 0xB32102d9104d2bfd0D4E3E4069618ADD985a4e2E

USDT (ERC-20) - 0x24c79c41EEAd9d81203ee567fE4bA3a6c81374DB

DOGE - DJ78fQspiu879y3adLbTZVSFABKhKqHE7B


## <a name=""thanks""></a> 🎉 Special Thanks

<a href=""https://www.jetbrains.com/?from=UNIT3D""><img src=""https://i.imgur.com/KgDXZV8.png"" height=""50px;""></a>
<a href=""https://www.themoviedb.org/""><img src=""https://www.themoviedb.org/assets/2/v4/logos/v2/blue_square_2-d537fb228cf3ded904ef09b136fe3fec72548ebc1fea3fbbd1ad9e36364db38b.svg"" height=""50px;""></a>
<a href=""https://github.com""><img src=""https://i.imgur.com/NVWhzrU.png"" height=""50px;""></a>
<a href=""https://laravel.com""><img src=""https://i.postimg.cc/cCDBswfK/1200px-Laravel-svg.png"" height=""50px;""></a>
<a href=""https://laravel-livewire.com""><img src=""https://i.postimg.cc/jjsNyBbh/Livewire.png"" height=""50px;""></a>
<a href=""https://alpinejs.dev""><img src=""https://i.postimg.cc/28pWk0M1/alpinejs-logo.png"" height=""50px;""></a>
<a href=""https://styleci.io""><img src=""https://i.postimg.cc/0y4XN4yW/og.png"" height=""50px;""></a>
","This is a PHP software based on Laravel 9.3. It is PHP based on Livewire and
AlpineJS. The software is well-designed and follows the Strict Mode and PHP
82.2. It follows the Private Torrent Tracker software called 'Discord'"
945,Everything about note management. All in Zotero.,"# Zotero Better Notes

![teaser](./image/README/teaser.png)

Everything about note management. All in Zotero.

Better Notes Handbook: [EN](https://github.com/windingwind/zotero-better-notes/wiki) | [中文 (provide translation)](https://zotero.yuque.com/staff-gkhviy/better-notes/biigg4?)

User Guide: [EN](./UserGuide.md) | [中文](./UserGuideCN.md)

## Introduction

Better Notes is a plugin for [Zotero](https://zotero.org).

It streamlines your unordered workflows of metadata analyzing, paper reading, annotating, and note-taking into a closed loop in Zotero.

Works out of the box and is highly customizable.

## Contents

- [Quick start](#quick-start)
- [Install](#install)
- [Note workspace](#note-workspace)
- Connect notes with the [bi-directional links](#bi-directional-link-support)
- Automate note generation with the [note templates](#note-templates)
- [Export notes](#export) to different formats
- Integrate with 3rd-party MarkDown editors seamlessly with [note<->markdown syncing](#syncing-note-markdown)
- [Other features](#other-features)

## Quick Start

> See [Handbook:Quick Start](https://zotero.yuque.com/staff-gkhviy/better-notes/gw5d7v) for more details.

New to note-taking? Install and start now!

Already an Obsidian/Logseq/... user? Forget those complicated integration tools and keep them in sync with MarkDown files with just one click.

## Install

- Download the latest release (.xpi file) from the [Releases Page](https://github.com/windingwind/zotero-better-notes/releases)_Note_ If you're using Firefox as your browser, right-click the `.xpi` and select ""Save As..""
- In Zotero click `Tools` in the top menu bar and then click `Addons`
- Go to the Extensions page and then click the gear icon in the top right.
- Select `Install Add-on from file`.
- Browse to where you downloaded the `.xpi` file and select it.
- Restart Zotero, by clicking `restart now` in the extensions list where the plugin is now listed.

## Note Workspace

> See [Handbook:Workspace](https://zotero.yuque.com/staff-gkhviy/better-notes/yul2qm) for more details.

The workspace allows you to focus on the note, as shown in the teaser on top of the README.

- Note outline(tree view, mindmap, and bubble map)
- Note links Preview

## Bi-directional Link

> See [Handbook:Bi-directional Link](https://zotero.yuque.com/staff-gkhviy/better-notes/yxpiew) for more details.

The bi-directional link note(双链笔记) is supported. Link your notes inside Zotero with just one click.

Export with its' linked sub-notes to Obsidian:
![Obsidian example](./image/README/markdown-ob.png)

## Note Templates

> See [Handbook:Note Templates](https://zotero.yuque.com/staff-gkhviy/better-notes/un54wc) for more details.

Use customized templates to import data from items/notes!
![template](./image/README/template.gif)

[How to Use Templates](./TemplateUsage.md)

[How to Write Your Own Template](./TemplateDoc)

See what templates can do and find templates contributed by the community here: [Note Templates from Community](https://github.com/windingwind/zotero-better-notes/discussions/categories/note-templates)

## Export

> See [Handbook:Export](https://zotero.yuque.com/staff-gkhviy/better-notes/nxlngg) for more details.

- To new note in Zotero
- To MarkDown file(embed or link, with images)
- To MS Word document(.docx)
- To PDF document(.pdf)
- To FreeMind file(.mm)

## Syncing: Note<->MarkDown

> See [Handbook:Sycn](https://zotero.yuque.com/staff-gkhviy/better-notes/aid2c3) for more details.

It's painless to Better Notes into your current workflow if you are using software like Obsidian. Keep your notes in sync with external MD files with one click.

Click 'Auto Sync to Export Path' the first time you export your note. Do not require any third-party tools or complicated setups!

Any modification in the note or its corresponding MarkDown file will be automatically synced.

![syncing](./image/README/sync.png)

## Other Features

> See [Handbook:Other Features](https://zotero.yuque.com/staff-gkhviy/better-notes/sh4v2y) for more details.

- Quick Note: annotation to note with one click. Support MarkDown comments.
  <img src=""./image/README/markdowncomment.png"" width=""400px""></img>
- Auto-insert new annotations to note. Disabled by default.
- Format MarkDown/AsciiDoc in the clipboard.
- Quick Cite: cite items in the note with the given cite format.
- Image annotation math OCR.
- Resize images (right-click on images).
- Preview images (double-click/ctrl-click on images).
- Customize link actions.
- Note editor enhancements.
  - Quick switch main note.
  - Copy note link.
  - Import from MarkDown.
  - Quick Cite.
- ...

## Development & Contributing

This addon is built based on the [Zotero Addon Template](https://github.com/windingwind/zotero-addon-template).

### Build

```shell
# A release-it command: version increase, npm run build, git push, and GitHub release
# You need to set the environment variable GITHUB_TOKEN https://github.com/settings/tokens
# release-it: https://github.com/release-it/release-it
npm run release
```

Alternatively, build it directly using build.js: `npm run build`

### Debug

1. Copy the Zotero command line config file. Modify the commands.

```sh
cp zotero-cmd-default.json zotero-cmd.json
```

2. Initialize the addon development environment following this [link](https://www.zotero.org/support/dev/client_coding/plugin_development#setting_up_a_plugin_development_environment).

3. Build the addon and restart Zotero with this npm command.

```sh
npm run restart
```

You can also debug code in these ways:

- Test code segments in Tools->Developer->Run Javascript;
- Debug output with `Zotero.debug()`. Find the outputs in Help->Debug Output Logging->View Output;
- UI debug. Zotero is built on the Firefox XUL framework. Debug XUL UI with software like [XUL Explorer](https://udn.realityripple.com/docs/Archive/Mozilla/XUL_Explorer).
  > XUL Documents:  
  > https://www.xul.fr/tutorial/  
  > http://www.xulplanet.com/

## Disclaimer

Use this code under AGPL (open source required). No warranties are provided. Keep the laws of your locality in mind!

Part of the code of this repo refers to other open-source projects within the allowed scope.

- [zotero-pdf-translate](https://github.com/windingwind/zotero-pdf-translate)

## My Other Zotero Addons

- [zotero-pdf-preview](https://github.com/windingwind/zotero-pdf-preview) PDF preview for Zotero
- [zotero-pdf-translate](https://github.com/windingwind/zotero-pdf-translate) PDF translation for Zotero 6
- [zotero-tag](https://github.com/windingwind/zotero-tag) Automatically tag items/Batch tagging

## Sponsor Me

I'm windingwind, an active Zotero(https://www.zotero.org) plugin developer. Devoting to making reading papers easier.

Sponsor me to buy a cup of coffee. I spend more than 24 hours every week coding, debugging, and replying to issues in my plugin repositories. The plugins are open-source and totally free.

If you sponsor more than $10 a month, you can list your name/logo here and have priority for feature requests/bug fixes!
","Better Notes is a plugin for [Zotero](https://zotero.org). It streamlines your
unordered workflows of metadata analyzing, paper reading, annotating, and note-
taking into a closed loop in Zotero. It is highly customizable and works out of
the box and is supported by 3rd-party MarkDown editors. The workspace allows you
to focus on the note, as shown in the teaser on top of the README. The bi-
directional link note is supported."
1563,"Making sense of web3 & crypto. Introduction to key concepts and ideas. Rigorous, constructive analysis of key claims pro and con. A look at the deeper hopes and aspirations.","# Awesome critique of crypto/web3

Awesome critique of crypto/web3, etc. Contributions are welcome.

## Critique

### General

* [The problem with NFTs](https://www.youtube.com/watch?v=YQ_xWvX1n9g) - 2022-01-21 - by Dan Olson (Documentary) 📺 [👉 Highly recommended 👈]
  * [Three things Web3 should fix in 2022](https://www.theverge.com/2022/1/28/22906010/web3-nft-internet-history-video-platformer) a response to The Problem with NFTs - 28 Jan 2022
* Stephen Diehl series - https://www.stephendiehl.com/blog.html
  * [The Case Against Crypto](https://www.stephendiehl.com/blog/against-crypto.html) - December 31, 2021
  - [Blockchainism](https://www.stephendiehl.com/blog/blockchainism.html) - December 11, 2021
  - [Web3 is Bullshit](https://www.stephendiehl.com/blog/web3-bullshit.html) - December 4, 2021
  - [The Internet's Casino Boats](https://www.stephendiehl.com/blog/casino-boats.html) - December 1, 2021
  - [The Token Disconnect](https://www.stephendiehl.com/blog/disconnect.html) - November 27, 2021
  - [The Handwavy Technobabble Nothingburger](https://www.stephendiehl.com/blog/nothing-burger.html) - November 24, 2021
  - [Ice-Nine for Markets](https://www.stephendiehl.com/blog/ice-nine.html) - November 23, 2021
  - [The Tinkerbell Griftopia](https://www.stephendiehl.com/blog/tinkerbell.html) - November 19, 2021
  - [Decentralized Woo Hoo](https://www.stephendiehl.com/blog/decentralized-woo.html) - November 16, 2021
  - [The Intellectual Incoherence of Cryptoassets](https://www.stephendiehl.com/blog/crypto-absurd.html) - November 7, 2021
  - [On Unintentional Scams](https://www.stephendiehl.com/blog/crypto-scams.html) - July 23, 2021
  - [How to Destroy Bitcoin](https://www.stephendiehl.com/blog/destroy-bitcoin.html) - July 13, 2021
  - [The Non-Innovation of Cryptocurrency](https://www.stephendiehl.com/blog/non-innovation.html) - July 7, 2021
  - [The Oncoming Ransomware Storm](https://www.stephendiehl.com/blog/ransomware.html) - May 11, 2021
  - [Et tu, Signal?](https://www.stephendiehl.com/blog/signal.html) - April 7, 2021
  - [The Political Case for a Blanket Cryptocurrency Ban](https://www.stephendiehl.com/blog/banbitcoin.html) - March 30, 2021
  - [Bitcoin: The Postmodern Ponzi](https://www.stephendiehl.com/blog/ponzi.html) - February 27, 2021
  - [The Crypto Chernobyl](https://www.stephendiehl.com/blog/chernobyl.html) - February 10, 2021
  - [Gamestop, Bitcoin and the Commoditization of Populist Rage](https://www.stephendiehl.com/blog/gamestop.html) - February 3, 2021
* [Today on Sick Sad World: How The Cryptobros Have Fallen](https://www.jwz.org/blog/2022/01/today-on-sick-sad-world-how-the-cryptobros-have-fallen/) - 2022-01-04 by Jamie Zawinski (legendary coder, co-founder of Mozilla etc.)
* [Web3 First Impressions](https://moxie.org/2022/01/07/web3-first-impressions.html) - 2022-01-07 Moxie Marlinspike, co-founder of Signal etc.
* [Bitcoin, Currencies, and Fragility by Nassim Taleb - 27 Jun 2021](https://arxiv.org/abs/2106.14204) - highly critical paper by author Black Swan etc.
* https://watershed.co.uk/studio/news/2021/12/03/case-against-crypto
* [The European Money and Finance Forum - The encrypted threat: Bitcoin’s social cost and regulatory responses](https://web.archive.org/web/20220107084533/https://www.suerf.org/docx/f_88b3febc5798a734026c82c1012408f5_38771_suerf.pdf) - Jan 2022. A comprehensive study by SUERF - The European Money and Finance Forum that details the net negative effects of bitcoin to society.
* [The Third Web](https://tante.cc/2021/12/17/the-third-web/) - 2021-12-17 - long critical essay including detailed history by [Tante](https://twitter.com/tante)
* [Tante's Web3/NFT FAQ](https://tante.cc/2022/02/09/tantes-blockchain-web3-faq/)
* https://rufuspollock.com/2016/07/02/reflections-on-the-blockchain/ - 2016-07-02 - by Rufus Pollock (mainly a critique of early DAOs and techno-solutionism)
* [Web3 takes trust, too](https://www.bloomberg.com/opinion/articles/2022-01-10/web3-takes-trust-too) - 2022-01-10 by Matt Levine on Bloomberg.com
* [Revolution Now! With Peter Joseph | Bitcoin and Financialization](https://youtu.be/bsghxd1cdeA) - May 21, 2021
* [The Web3 Fraud](https://www.usenix.org/publications/loginonline/web3-fraud) - 2021-12-16 by Nicholas Weaver on usenix.com
* Molly White series - https://blog.mollywhite.net/blockchain/
  * [Blockchain-based systems are not what they say they are](https://blog.mollywhite.net/blockchains-are-not-what-they-say/)
  * [It's not still the early days](https://blog.mollywhite.net/its-not-still-the-early-days/)
  * [Abuse and harassment on the blockchain](https://blog.mollywhite.net/abuse-and-harassment-on-the-blockchain/)
  * [Anonymous cryptocurrency wallets are not so simple](https://blog.mollywhite.net/anonymous-crypto-wallets/)
  * [Cryptocurrency off-ramps, and the pressure towards centralization](https://blog.mollywhite.net/off-ramps/)
  * [Cryptocurrency’s Robinhood effect](https://blog.mollywhite.net/cryptocurrencys-robinhood-effect/)
  * [Abuse on the blockchain – Guest lecture at Stanford University](https://www.youtube.com/watch?v=hXBZ-BXfCSY)
* [Against Web3 and Faux-Decentralization](https://soatok.blog/2021/10/19/against-web3-and-faux-decentralization/) - 2021-10-19 by Soatok
* [The technological case against Bitcoin and blockchain](https://lukeplant.me.uk/blog/posts/the-technological-case-against-bitcoin-and-blockchain/) - 2022-03-05 by Luke Plant
* [The Case Against Crypto](https://www.watershed.co.uk/studio/news/2021/12/03/case-against-crypto) - 2021-12-03 by Martin O'Leary
* [The Case Against Bitcoin](https://bariweiss.substack.com/p/the-case-against-bitcoin?s=r) - 2021-05-14 by Michael W. Green. A portfolio manager discusses the case against bitcoin from a financial and geopolitical perspective.
* [The Register: The dark equation of harm versus good means blockchain’s had its day](https://www.theregister.com/2021/12/06/the_dark_equation_of_harm/) - 2021-12-06
* [Blockchains and Cryptocurrencies: Burn It With Fire](https://www.youtube.com/watch?v=xCHab0dNnj4) - 2018-04-20 by Nicholas Weaver 📺 Nicholas Weaver is a staff researcher with the International Computer Science Institute (ICSI) and lecturer in EECS, where he teaches machine structures and computer security. He earned his Ph.D. in computer science from Berkeley in 2003 and joined ICSI to study network security and measurement. ""The entire cryptocurrency and blockchain ecology is rife with frauds, criminalities, and tulip-mania style hype and needs to be properly disposed of into the ashes of history. A “blockchain” is just a horribly inefficient append-only file which costs a literal fortune to secure without actually providing meaningful distributed trust, while cryptocurrencies are provably inferior than actual currencies for legal real world transactions. Beyond the sheer uselessness have emerged a whole host of bad ideas, ranging from the “put a bird^H^H^H^H blockchain on it” hype to unregistered (and mostly fraudulent) securities with “Initial Coin Offerings” to an invitation for massive theft in the form of “smart” contracts.""
* [Ross Anderson et al: Bitcoin Redux: crypto crime, and how to tackle it](https://www.lightbluetouchpaper.org/2018/06/01/bitcoin-redux-crypto-crime-and-how-to-tackle-it/) ([full paper](https://weis2018.econinfosec.org/wp-content/uploads/sites/5/2018/05/WEIS_2018_paper_38.pdf))- 2018-06-01 - Anderson is a Professor of Security Engineering at the University Cambridge. Bitcoin Redux explains what’s going wrong in the world of cryptocurrencies. The bitcoin exchanges are developing into a shadow banking system, which do not give their customers actual bitcoin but rather display a ""balance"" and allow them to transact with others. However if Alice sends Bob a bitcoin, and they’re both customers of the same exchange, it just adjusts their balances rather than doing anything on the blockchain. This is an e-money service, according to European law, but is the law enforced? Not where it matters. We’ve been looking at the details.
  * [Ross Anderson: Why Bitcoin is Not Cash](https://www.youtube.com/watch?v=p9HH_dFcoLc) - 2018-04-10 - 📺 walks through why bitcoin is not cash and the complex legal questions it would need to deal with if it wanted to be.
  * [Ross Anderson: Tracing Stolen Bitcoin](https://www.youtube.com/watch?v=UlLN0QERWBs) - 2018-03-23 - 📺
* [Simon Wardley: A Spoiler for the Future of Bitcoin](https://blog.gardeviance.org/2013/11/a-spoiler-for-future-bitcoin.html) - 2013-11-27 - ""As you can guess, I'm not a fan of bitcoin. If left unchecked then I find it has the potential to undermine the importance of Government which is actually not good for competition and not good for the market. I hope none of the above happens and would rather see bitcoin disappear in a puff of history."" (NB: he predicts massive appreciation in bitcoin and is concerned how it can undermine government and tax revenue.)
* Kai Stinchcombe series that discusses whether blockchain can solve various real world use-cases better than traditional technologies
  - [Kai Stinchcombe: Ten years in, nobody has come up with a use for blockchain](https://hackernoon.com/ten-years-in-nobody-has-come-up-with-a-use-case-for-blockchain-ee98c180100) - 2017-12-23 - ""Each purported use case — from payments to legal documents, from escrow to voting systems—amounts to a set of contortions to add a distributed, encrypted, anonymous ledger where none was needed. What if there isn’t actually any use for a distributed ledger at all? What if, ten years after it was invented, the reason nobody has adopted a distributed ledger at scale is because nobody wants it?""
  - [Kai Stinchcombe: Blockchain is not only crappy technology but a bad vision for the future](https://medium.com/@kaistinchcombe/decentralized-and-trustless-crypto-paradise-is-actually-a-medieval-hellhole-c1ca122efdec) - 2018-05-04 - ""Blockchain is not only crappy technology but a bad vision for the future. Its failure to achieve adoption to date is because systems built on trust, norms, and institutions inherently function better than the type of no-need-for-trusted-parties systems blockchain envisions. That’s permanent: no matter how much blockchain improves it is still headed in the wrong direction.""
* [Cory Doctorow: When crypto-exchanges go broke, you'll lose it all](https://pluralistic.net/2022/02/03/liquidation-preference/#we-live-in-a-society) - 2022-02-03. Why state backed money is a good thing (a feature not a bug).
  > If you've spent much time around cryptocurrency people, you've probably heard a rant or two about ""sound money"" and the need to ""depoliticize money."" This is a foundation of blockchainism: the belief that money is born separate from states, and states invade on the private realm when they ""meddle"" in the money system.
  >
  > There are at least two serious problems with this ideology. First, it's plain wrong on the historical facts. Money did not emerge from barter systems among people. Money was and is a product of state.
  >
  > But even if you stipulate that money didn't originate among private markets there's another serious historical problem with ""sound money."" ... It's this: central banks didn't emerge to usurp the private sector's control over money. Central banks were created because without them, finance was subject to wild, terrifying, ruinous boom/bust cycles. What's more, without a central bank, money was subject to naked political meddling, which central banks (sometimes) moderated.
* Internet pioneer/Silicon Valley legend Tim O'Reilly on Web3:
  - [Why it’s too early to get excited about Web3](https://www.oreilly.com/radar/why-its-too-early-to-get-excited-about-web3/) - 2021-12-13
  - [""Get ready for the crash""](https://www.cbsnews.com/news/cryptocurrency-nft-blockchain-web3-tim-oreilly/) - CBS Money Watch - 2022-02-09
  - [Crypto and NFTs are ""Pretty Serious Speculative Bubble""](https://decrypt.co/92676/internet-guru-tim-oreilly-crypto-nfts-serious-speculative-bubble) - 2022-02-10
* [David Rosenthal: Can We Mitigate Cryptocurrencies' Externalities?](https://blog.dshr.org/2022/02/ee380-talk.html) - 2022-02-09. Having built a decentralized consensus system using Proof-of-Work (http://dx.doi.org/10.1145/945445.945451) the author has the technical knowledge to explain the design faults and limitations of permissionless blockchain systems, as well as highlighting the economic and environmental issues. Summary of critique:
  > * That the externalities I describe don't exist. You'll have a hard time proving that the waste of electricity and hardware, and the crime wave, are imaginary.
  > * That although the externalities do exist, the benefits of decentralization outweigh them. The problem here is that since the systems are not actually decentralized, we get the externalities but don't get the benefits.
  > * That although the externalities do exist, and the systems aren't dencentralized, they're making so much money that we shouldn't worry. The problem here is that the amount of actual money you can get out of a cryptocurrency equals the amount of actual money that has been put in, minus the actual costs of mining. So the big picture is that although there may be winners, in aggregate the system loses money.
  * [Economies of Scale in Peer-to-Peer Networks](https://blog.dshr.org/2014/10/economies-of-scale-in-peer-to-peer.html) - 2014-10-07. Network effects lead to centralization in p2p (e.g. Bitcoin) and no good way to mitigate this.
* [Charlie Stross: Why I want Bitcoin to Die in Fire](https://www.antipope.org/charlie/blog-static/2013/12/why-i-want-bitcoin-to-die-in-a.html) - 2013-12
* [The Maltese Falcon](https://privatebank.jpmorgan.com/content/dam/jpm-wm-aem/global/pb/en/insights/eye-on-the-market/the-maltese-falcoin.pdf) - critique of bitcoin and financial properties of crypto assets from the CIO of JP Morgan bank. 2021-02-10
* [Vivaldi CEO: Why Vivaldi will never create ThinkCoin](https://vivaldi.com/blog/why-vivaldi-will-never-create-thinkcoin/) - 2022-01-13 - Jon von Tetzchner: “if you look beyond the hype, you’ll find nothing more than a pyramid scheme posing as currency.”
* [Centralizing Control: Why Bitcoin is Dangerous](https://salbayat.org/centralizing-control-why-bitcoin-is-dangerous/) - 2022-04-02 - Sal Bayat: “Democratic governance is fundamentally incompatible with existing cryptocurrency systems as they can only represent the interests of those in control of the system.”

### Economists

* Stephanie Kelton [Cryptocurrency and Fiat Money](https://www.youtube.com/watch?v=84wTEf9Acik) - 2017-12-23
* Richard Thaler [Economics Nobel prize winner, Richard Thaler: “The market that looks most like a bubble to me is Bitcoin and its brethren”](https://econews.pt/2018/01/22/economics-nobel-prize-winner-richard-thaler-the-market-that-looks-most-like-a-bubble-to-me-is-bitcoin-and-its-brethren/) - 2018-01-22
* Various ['Only good for drug dealers': More Nobel prize winners snub bitcoin](https://finance.yahoo.com/news/good-drug-dealers-nobel-prize-winners-snub-bitcoin-184903784.html?ref=hackernoon.com) - 2018-04-27
* Robert Shiller [The Old Allure of New Money](https://www.project-syndicate.org/commentary/cryptocurrencies-scientific-narrative-by-robert-j--shiller-2018-05?barrier=accesspay) - 2018-05-21
* Abhijit Banerjee [Nobel Prize Winning Economist Abhijit Banerjee: Is Blockchain the Key to Financial Inclusion?](https://blockchain.news/news/nobel-prize-winning-economist-abhijit-banerjee-is-blockchain-the-key-to-financial-inclusion) - 2020-01-20
* Steve Keen [Cryptocurrencies, Debt, and the Economy: Steve Keen interviewed by Layne Hartsell](http://www.koreaittimes.com/news/articleView.html?idxno=103792) - 2021-02-17
* Amartya Sen [Prannoy Roy's Townhall With Amartya Sen On Economy, Farm Laws: Full Transcript ](https://www.ndtv.com/india-news/prannoy-roys-townhall-with-amartya-sen-on-indian-economy-farm-laws-full-transcript-2385071) - 2021-03-06
* Jeffrey Sachs [Famed economist Jeffrey Sachs rails against Bitcoin: Highly polluting and ‘almost like counterfeiting’](https://fortune.com/2021/03/16/bitcoin-jeffrey-sachs-critiques-btc/) - 2021-03-16
* Paul Krugman [Technobabble, Libertarian Derp and Bitcoin](https://nytimes.com/2021/05/20/opinion/cryptocurrency-bitcoin.html) - 2021-05-20
* Tyler Cowen [What the Crypto Crowd Doesn't Understand About Economics](https://www.bloomberg.com/opinion/articles/2021-06-21/what-the-crypto-crowd-doesn-t-understand-about-economics) - 2021-06-20
* Yanis Varoufakis [What is money, really? And why Bitcoin is not the answer (even if blockchain is brilliant & potentially helpful in democratising money)](https://www.yanisvaroufakis.eu/2021/08/02/what-is-money/)  - 2021-08-02
* Daron Acemoğlu [The Bitcoin Fountainhead](https://www.project-syndicate.org/commentary/bitcoin-an-appealing-distraction-by-daron-acemoglu-2021-10?barrier=accesspay) - 2021-10-05
* Joseph Stiglitz [Nobel Prize Economist Joseph Stiglitz Calls Regulators to Ban Cryptocurrencies](https://deep-resonance.org/2021/10/28/nobel-prize-economist-joseph-stiglitz-calls-regulators-to-ban-cryptocurrencies/) - 2021-10-28
* Richard Thaler [Economics Nobel prize winner, Richard Thaler: “The market that looks most like a bubble to me is Bitcoin and its brethren”](https://econews.pt/2018/01/22/economics-nobel-prize-winner-richard-thaler-the-market-that-looks-most-like-a-bubble-to-me-is-bitcoin-and-its-brethren/) - 2018-01-22
* Yanis Varoufakis [Yanis Varoufakis on Crypto & the Left, and Techno-Feudalism](https://the-crypto-syllabus.com/yanis-varoufakis-on-techno-feudalism/) - 2022-01-26
* Tyler Cowen [The Crypto Crash Strengthens the Case for Crypto](https://www.bloombergquint.com/gadfly/crypto-crash-strengthens-case-for-crypto-s-long-term-future) - 2022-01-27
* Jesse Frederik [Blockchain, the amazing solution for almost nothing](https://thecorrespondent.com/655/blockchain-the-amazing-solution-for-almost-nothing/84495599980-95473476) - 2020-08-21 - ""Blockchain technology is going to change everything: the shipping industry, the financial system, government … in fact, what won’t it change? But enthusiasm for it mainly stems from a lack of knowledge and understanding. The blockchain is a solution in search of a problem.""
* [Vice: ‘Crypto Ruined My Life’: The Mental Health Crisis Hitting Bitcoin Investors](https://www.vice.com/en/article/akvn8z/crypto-bad-for-mental-health) - 2022-02-16 - The stress and anxiety that goes with funneling your life savings into a volatile market is no joke.
* [Ed Zitron: Solutions That Create Problems](https://ez.substack.com/p/solutions-that-create-problems) - 2022-02-22 - [The thing about Web3 is that it is uniquely useless. I have actively searched for an explanation as to why it's the future, what products it would allow us to build, what sort of *good* it would provide, and I cannot even at my most optimistic find a real use case](https://twitter.com/edzitron/status/1495891031979704321)

### Ponzi aspect

* [Financial Times: Why bitcoin is worse than a Madoff-style Ponzi scheme](https://web.archive.org/web/20220113183816/https://www.reddit.com/r/CryptoReality/comments/rm78e3/financial_times_why_bitcoin_is_worse_than_a/) - 2021-12-22. A Ponzi scheme is a zero-sum enterprise. But bitcoin is a negative-sum phenomenon that you can’t even pursue a claim against, argues Robert McCauley. [Original](https://ft.com/content/83a14261-598d-4601-87fc-5dde528b33d0)
* [Seattle Times: Bitcoin is basically a Ponzi scheme](https://seattletimes.com/opinion/bitcoin-is-basically-a-ponzi-scheme/) - 2018-01-30
* [Bitcoin is a Ponzi](https://ic.unicamp.br/~stolfi/bitcoin/2020-12-31-bitcoin-ponzi.html) - 2020-12-13 by Prof Jorge Stolfi
* [Financial Times: Albanian lessons for regulators nervously eyeing the crypto world](https://www.ft.com/content/810367e5-e0b1-4221-b303-f3012a177437) - 2021-07-05 - Albania’s 1990s pyramid scheme debacle highlights risks of regulatory paralysis on the cryptocurrency explosion
  > Once upon a time in Albania, a scrappy, alternative finance industry emerged to take on and eventually supplant a sclerotic, technologically-backward banking system. The lessons from its dramatic collapse remain relevant today. 
  >
  > Essentially, what was initially touted as a post-communist entrepreneurial success story proved to be pyramid schemes of breathtaking proportions. Slick marketing and lofty promises turned an informal, decentralised, crime-facilitating ecosystem into a mainstream mania that sucked in multitudes of people, unchecked by feeble and fitful regulatory warnings.
* [Jacobin: Cryptocurrency Is a Giant Ponzi Scheme](https://jacobinmag.com/2022/01/cryptocurrency-scam-blockchain-bitcoin-economy-decentralization) - 2022-01-21

### Crypto and energy consumption

* [Bitcoin Energy Consumption Index](https://digiconomist.net/bitcoin-energy-consumption)
* [Why Bitcoin Is Bad For The Environment](https://newyorker.com/news/daily-comment/why-bitcoin-is-bad-for-the-environment) - 2021-04-22
* [Energy power usage CryptoArt, ETH, Blockchain spreadsheet](https://docs.google.com/spreadsheets/d/1hzzxMbytOZ1mYl9kLh_SvM6kne6JI_mdCfHIoNapr5M/edit#gid=0)
* [How Do We Solve Bitcoin's Energy Problem?](https://www.theguardian.com/technology/2022/jan/30/how-do-we-solve-bitcoins-carbon-problem) - 2022-01-30

### Scams/frauds

* [People Building ‘Blockchain City’ in Wyoming Scammed by Hackers - Vice](https://www.vice.com/en/article/k7w3am/people-building-blockchain-city-in-wyoming-scammed-by-hackers) - 2022-01-12 - On Monday, CityDAO—the group that bought 40 acres of Wyoming in hopes of ""building a city on the Ethereum blockchain”—announced that its Discord server was hacked and members' funds were successfully stolen as a result.
* [Web3 is going just great](https://web3isgoinggreat.com/) - A timeline of scams related to cryptocurrencies, NFTs, and web3 projects since the beginning of 2021 by Molly White

### DAOs

* [Is The DAO going to be DOA?](https://steemit.com/crypto-news/@dan/is-the-dao-going-to-be-doa) - 2016-05-16 - by Dan Larimer (founder of BitShares and much else). Larimer sets out most of the basic critiques of DAOs as governance innovation extremely well:
  > Fancy technology can obscure our assessment of what is really going on. The DAO solves a single problem: the corrupt trustee or administrator. It replaces voluntary compliance with a corporation’s charter under threat of lawsuit, with automated compliance with software defined rules. This subtle change may be enough to bypass regulatory hurdles facing traditional trustee’s and administrators, but it doesn’t solve most of the problems the regulations were attempting to address.
  >
  > What The DAO doesn’t solve is all of the other problems inherent with any joint venture. These are people problems, economic problems, and political problems. In some sense, The DAO creates many new problems caused by its ridged rules and expensive machine-enforced process for change.
  >
  > The DAO doesn’t solve the “group trap” where by losers subsidize winners. It disempowers the individual actor and forces him to submit to group decision making. It doesn’t make raising money cheaper for companies, it just adds blockchain-enforced bureaucratic and political processes.
* [DAOs and the nature of human collaboration](https://world.hey.com/marin/daos-and-the-nature-of-human-collaboration-be162918) - 2021-08-12 by Marin Petrov. A critique of DAOs and technosolutionism.

### NFTs

Non-fungible tokens.

* [OpenSea, Web3, and Aggregation Theory](https://stratechery.com/2022/opensea-raises-money-bans-nfts-openseas-value-cryptos-aggregators/) - 2022-01-05 - Ben Thompson of Stratechery
* [Brian Eno on NFTs & Automaticism](https://the-crypto-syllabus.com/brian-eno-on-nfts-and-automatism/)
* [Detailed twitter thread by @NFTEthics alleging fraudulent or close to fraudulent behaviour by a major NTF influencer named BeanieMaxi ](https://twitter.com/NFTethics/status/1483051289022017538) - 2022-01-17 ([cached](./assets/Thread by @NFTethics re beaniemaxi.pdf))
* [Jacobin: NFTs Are, Quite Simply, Bullshit](https://jacobinmag.com/2022/01/nfts-fallon-paris-hilton-bored-ape-digital-imagery-commodification) - 2022-01-26

### Specific use cases

* Event ticketing: [NFT tickets — a realistic look at a big trend](https://medium.com/@ticketpark/nft-tickets-a-realistic-look-at-a-big-trend-ae813d6f885d) – 2021-12-14
* NFT games: [“Play-to-earn” and Bullshit Jobs](https://paulbutler.org/2021/play-to-earn-and-bullshit-jobs/) - December 28, 2021 by Paul Butler - An interesting reflexion linking web3's ""Play-to-earn"" concept to David Graeber's [Bullshit Jobs](https://en.wikipedia.org/wiki/Bullshit_Jobs)
* NFT games: [Crypto Games: Report from hell](https://www.youtube.com/watch?v=YHz0xpU5Tu8) - Good video reviewing and discussing crypto games

### Humour

* [Crypto Curious](https://www.youtube.com/watch?v=N8f-BQFo7lw) - South Park on NFTs - 2021-12-21
* [N-FT: Non-Functioning Tower](https://www.nonfunctioningtower.com) - NFT satire - 2022-03-07
* [“a normal person explains cryptocurrency”](https://twitter.com/avalonpenrose/status/1473753174787772418) by Avalon Penrose - 2021-12-22
* [“my crypto friend calls me every day and this is what he sound like”](https://www.youtube.com/watch?v=TUB9jgMuC7U) by Flula - 2021-02-22
* [The Billion-Dollar Bitcoin Scam](https://www.youtube.com/watch?v=YCuGpfMSmck) - Ordinary Things - 2020-05-31 - “What is Bitcoin? Is Bitcoin a scam? And how did Bitcoin become what it is today? Who was the Dread Pirate Roberts and what happened to the Silk Road?”
* [Cryptocurrencies: Last Week Tonight with John Oliver (HBO)](https://www.youtube.com/watch?v=g6iDZspbRMg) - 2018-03-12
* [Don’t Understand Bitcoin? This Man Will Mumble An Explanation At You](https://www.youtube.com/watch?v=4APcgsRdW6w) by ClickHole - 2015-07-7
* [If Cryptocurrency was Honest](https://www.youtube.com/watch?v=GUs5y9leCyA)
* [If NFTs were Honest](https://www.youtube.com/watch?v=sG_v4bb2e4k)
* [Brave New Web](https://medium.com/coinmonks/brave-new-web-7bae50e916eb) - ani utopian Web3 satire by Nikolay Vlasov - 2022-04-10

### Twitter users

Whilst these users may not solely discuss crypto or web3, they do discuss it regularly, and have consistently provided well-written critique.

* https://twitter.com/web3isgreat
* https://twitter.com/ncweaver
* https://twitter.com/molly0xFFF
* https://twitter.com/smdiehl
  - [Crypto Criticism Threads](https://gist.github.com/sdiehl/7706ef44d951a2025fd658d1dd8687af)
* https://twitter.com/rufuspollock
* https://twitter.com/troll_lock
* https://twitter.com/CasPiancey -""Under promise, under deliver"" co-host @cryptocriticpod *opinions are mine, not my employer* odds and ends @protos hold no crypto or crypto stonks
* https://twitter.com/BennettTomlin - I do data science and track down frauds | 74% backed | Co-host @CryptoCriticPod | Writing @fud_letter | Discord: https://discord.gg/YpAUqNkhSC
* https://twitter.com/SilvermanJacob (staff writer New Republic) & https://twitter.com/ben_mckenzie - ""apparently I now write about crypto""
* https://twitter.com/doctorow

### Tether, and other stablecoins

* [Bennett Tomlin: Tether and Bitfinex Introduction](https://bennettftomlin.com/2021/08/08/tether-and-bitfinex-introduction/) - 2021-08-10 - Tether and Bitfinex are two of the most important companies in the cryptocurrency ecosystem. Tether is the largest stablecoin, and the primary driver of volume and liquidity. Bitfinex used to be the largest cryptocurrency exchange, and still is a frequently used exchange. Tether and Bitfinex have an incredibly problematic past and are quite possibly the largest corporate fraud in history.
  * Detailed overview of Tether and Bitfinex and their connection.
* [Tether Papers: This is exactly who acquired 70% of all USDT ever issued](https://protos.com/tether-papers-crypto-stablecoin-usdt-investigation-analysis/) - 2021-11-10
* [Bloomberg: Tether’s Latest Black Eye Is CFTC Fine for Lying About Reserves](https://www.bloomberg.com/news/articles/2021-10-15/tether-bitfinex-to-pay-fines-totaling-42-5-million-cftc-says) - 2021-10-15 - Biggest stablecoin issuer hit with $41 million penalty. Affiliated crypto exchange Bitfinex also fined $1.5 million.
* [Bloomberg: Anyone Seen Tether’s Billions?](https://www.bloomberg.com/news/features/2021-10-07/crypto-mystery-where-s-the-69-billion-backing-the-stablecoin-tether) - 2021-10-07 - A wild search for the U.S. dollars supposedly backing the stablecoin at the center of the global cryptocurrency trade—and in the crosshairs of U.S. regulators and prosecutors. [paywalled] ([cached](./assets/anyone-seen-tethers-billions.pdf))
* [Bloomberg: Tether Fails to Dispel Mystery on Stablecoin’s Crucial Reserves](https://www.bloomberg.com/news/articles/2021-12-03/tether-gives-more-details-on-assets-backing-crypto-stablecoin) - 2021-12-03 - Holding include $30.6 billion in commercial paper and CDs. About $1 billion moved from reverse repo notes to money funds

### Central Bank Digital Currencies

* [Money and Payments: The U.S. Dollar in the Age of Digital Transformation](https://www.federalreserve.gov/publications/money-and-payments-discussion-paper.htm) - provides a high level overview of the current state of central bank and private sector currencies in the US, and identifies risks and challenges with the implementation of a central bank digital currency. From the paper summary: ""The paper summarizes the current state of the domestic payments system and discusses the different types of digital payment methods and assets that have emerged in recent years, including stablecoins and other cryptocurrencies. It concludes by examining the potential benefits and risks of a CBDC, and identifies specific policy considerations.""

### Trading/Market Microstructure/Security Risks

* [Quantifying Blockchain Extractable Value: How dark is the forest?](https://arxiv.org/abs/2101.05511) - Qin et al., 2021. Technical paper characterizing and quantifying miner extracted value on Ethereum's DeFi smart contracts.
* [High-Frequency Trading on Decentralized On-Chain Exchanges](https://arxiv.org/abs/2009.14021) - Zhou et al., 2020. Technical paper detailing the ""front-running"" that occurs on Ethereum.
* [An Anatomy of Bitcoin Price Manipulation](https://www.singlelunch.com/2022/01/09/an-anatomy-of-bitcoin-price-manipulation/) - Matt Ranger, 2022. Speculative analysis of centralized cryptocurrency exchange market data to support a price manipulation hypothesis.

### Former bitcoin enthusiasts turned skeptics

* [Money corrupts; bitcoin corrupts absolutely.](https://www.cynicusrex.com/file/cryptocultscience.html) by Angelino Desmet - 12-03-2021
* [I wish I never bought bitcoin.](https://www.cynicusrex.com/file/greed.html) by Angelino Desmet - 01-06-2020

### Religious skeptical angles

#### Buddhist

* [Sujato Bhikkhu on Crypto](https://www.youtube.com/watch?v=CA_cfLqIkA0) by Sujato Bhikkhu. A monk explains why crypto is incompatible with the teachings of the Buddha from both moral and spiritual dimensions.

#### Christian

* [The Christian case against Bitcoin and blockchain]( https://lukeplant.me.uk/blog/posts/the-christian-case-against-bitcoin-and-blockchain/) by Luke Plant, A reading of bitcoin philosophy and cult like phenomenon from a biblical perspective 2021-03-2022.
* [What you should know about Bitcoin](https://www.thegospelcoalition.org/article/faqs-know-bitcoin/) by Joe Carter. A well-researched, accurate introduction to Bitcoin from a Christian perspective, 2017-12-27.
* [Ask the Economist: Should a Christian Invest in Bitcoin?](https://www.thegospelcoalition.org/article/christian-invest-bitcoin/) by Greg Phelan, 2021-10-27.

---

## What is blockchain, web3, etc.

Best intros/overviews of blockchain, crypto, web3, etc.

* [On Blockchain and Trust](https://www.schneier.com/blog/archives/2019/02/blockchain_and_.html) - February 12, 2019 by Bruce Schneier. The article also appeared on wired.com as [There's No Good Reason to Trust Blockchain Technology](https://www.wired.com/story/theres-no-good-reason-to-trust-blockchain-technology/).
- [The Myth of Decentralization and Lies about Web 2.0](https://www.emilygorcenski.com/post/the-myth-of-decentralization-and-lies-about-web-2.0/) - 2022-01-07 by Emily Gorcenski
* http://kernel.community - A custom web3 educational community with free learning resources at https://kernel.community/en/learn/

---

## Iron-manning the pro arguments

Here we collect the best theses for why blockchain/crypto“currency”/web3 is supposedly important/interesting/world-changing.

### Bitcoin

* [Bitcoin for the Open-Minded Skeptic](https://www.matthuang.com/bitcoin_for_the_open_minded_skeptic) - May 2020 - by [[people/Matt Hu","Awesome critique of crypto/web3, etc. Contributions are welcome. Submissions can
be made in the comments section below or on the Web3 Impressions blog. The next
installment of the Stephen Diehl series will be published on 28 Jan 2022."
633,How to be low-level programmer,"NOTICE1: Please do not copy the contents of this page to your blog. You can share this page but please share with the original link. That is how we compliment the authors of good document and open source project.

NOTICE2: Please notice that low-level programming is out of trend and currently there are not many companies hiring low-level developer. It is getting harder for me to find a job.
If you haven't started a professional career yet, I would like to recommend you consider other fields either carefully.

NOTICE3: If you want a quick start, go to ""How to start?"".

* [Low-Level Programming University](#Low-Level-Programming-University)
  * [What is it?](#What-is-it)
  * [What Is the Low Level](#What-Is-the-Low-Level)
  *  [Theory](#Theory)
  *  [Languages](#Languages)
     * [Assembly](#Assembly)
     * [C language](#C-language)
     * [Rust language](#Rust-language)
  * [Applications](#Applications)
    * [Hardware && Firmware](#Hardware-Firmware)
    * [Linux kernel and device driver](#Linux-kernel-and-device-driver)
      * [References](#References)
    * [Other applications](#Other-applications)
  * [Future of low-level programming](#Future-of-low-level-programming)
  * [How to start?](#How-to-start)
* [Translation](#Translation)
* [Who am I?](#who-am-i)

# Low-Level Programming University

## <a name=""What-is-it""></a>What is it?

I'm inspired by [google-interview-university](https://github.com/jwasham/coding-interview-university). I'd like to share my experience and show a roadmap to becoming a low-level programmer because I have found that these skills are not as common as they once were. In addition, many students and beginners ask me how they could become low-level programmers and Linux kernel engineers.

This page cannot include every link/book/course. For example, this page introduces Arduino but there is not detailed information about Arduino and embedded systems. You should go further yourself. You have the keyword ""Arduino"" with which you can start. So your next step is probably googling Arduino, buying a kit, and doing something for yourself, not collecting links or free books. Please remember this page is just a roadmap for beginners.

Low-level programming is a part of computer science.
Absolutely it would be much better to get education for computer science first.
* [Path to a free self-taught education in Computer Science!](https://github.com/ossu/computer-science)


## <a name=""What-Is-the-Low-Level""></a>What Is the Low-Level?

I classify low-level programming as programming that is very close to the machine, using a lower level programming language like C or assembly. This is in contrast to higher-level programming, typical of user-space applications, using high level languages (e.g. Python, Java).
* [Wikipedia: Low-level programming language](https://en.wikipedia.org/wiki/Low-level_programming_language)

Yes, systems programming is a very close concept to low-level programming. This page includes the hardware design and firmware development that is not included in systems programming.
* [Wikipedia: System programming](https://en.wikipedia.org/wiki/System_programming)

Finally, this page includes topics ranging from hardware components to the Linux kernel. That is a huge range of layers. A one page document can never cover the details of all the layers, so the aim of this document is to serve as a starting point for low-level programming.

##  <a name=""Theory""></a>Theory

There are two background theories to low-level programming:
* Computer Architecture
* Operating Systems

I think the best way to learn theory is by taking a course. Reading books is not bad but takes too much time and effort. You can find many good classes on online universities, for instance, Coursera.org and edx.org.
Theory is theory. I don't think you need to get an A+ in the class, just understand the big picture.
You'll get better and better with experience.

Let me introduce several books that I've read. They are commonly used as textbooks in universities. If there is no class with these books in your university, it's worth spending some time reading them.
* Computer Architecture
  * Computer Architecture, Fifth Edition: A Quantitative Approach
  * Computer Systems: A Programmer's Perspective
  * Computer Organization and Design, Fourth Edition: The Hardware/Software Interface
* Operating Systems
  * The Magic Garden Explained: The Internals of UNIX System V Release 4 an Open Systems Design
  * The Design of the UNIX Operating System
  * Operating Systems: Internals and Design Principles by William Stallings
* Recommended Courses
   * [CS401: Operating Systems from saylor.org](https://learn.saylor.org/course/view.php?id=94)
* General Programming Skill
   * [Structure and Interpretation of Computer Programs](https://en.wikipedia.org/wiki/Structure_and_Interpretation_of_Computer_Programs)
      * It's about how to be a good Software programmer. You need not only theory but only technique because programming is a kind of craftwork.
      * If you learn Lisp/Scheme, you should be able to learn any other language quickly. 
      * [I've solved about 80% exercises. It should be worth to try every single exercise.](https://github.com/gurugio/sicp_exercise)
* Hardware Design
   * Build Your Own 8086 Microprocessor Kit
      * If you don't build your HW board, you don't understand what physical memory mapped device is.
      * Modern APs includes so many IPs. So you don't have a chance to understand how CPU core and peripheral devices are connected.
      * When you build your own 8086 kit, you have a chance to locate each peripheral devices on the physical memory. And you can set how the main HW components (BUS, IRQ, Clock, Power and etc) works with your own eyes.
      * I built the 8086 kit in my University. It was one of the most valuable courses I've ever taken. Try to build your own HW kit. It would be better if the HW is older ans simpler because you should do more for yourself.
      * Google ""8086 kit"". You would be able to find some web-sites you can buy a HW scheme, parts and manuals.

There is an infinite list of good books. I don't want to say that you should read many books. Just read one book carefully. Whenever you learn a theory, implement simulation code of it. **Implementing one thing is better than knowing one hundred theories.**

##  <a name=""Languages""></a>Languages

### <a name=""Assembly""></a>Assembly

Choose one between x86 or ARM. No need to know both. It doesn't matter to know assembly language. The essential thing is understanding the internals of a CPU and computer. So you don't need to practice the assembly of the latest CPU. Select 8086 or Corex-M.

* [8086 assembly programming with emu8086](https://github.com/gurugio/book_assembly_8086)
  * basic concepts of CPU and computer architecture
  * basic concepts of C programming language
* [64bit assembly programming(translation in progress)](https://github.com/gurugio/book_assembly_64bit)
  * basic concepts of modern CPU and computer architecture
  * basic concepts of disassembling and debugging of C code
  * _need help for translation_
* [Learning assembly for linux-x64](https://github.com/0xAX/asm)
  * pure 64-bit assembly programming with NASM and inline assembly with GCC
* [ARM Architecture Reference Manual, 2nd Edition](http://www.mypearsonstore.ca/bookstore/arm-architecture-reference-manual-9780201737196)
  * Complete reference on ARM programming
* Computer Organization and Design
  * [MIPS Edition](https://www.amazon.ca/Computer-Organization-Design-MIPS-Interface/dp/0124077269/)
  * [ARM Edition](https://www.amazon.ca/Computer-Organization-Design-ARM-Interface/dp/0128017333/)
  * [RISC-V Edition](https://www.amazon.com/Computer-Organization-Design-RISC-V-Architecture/dp/0128122757)
  * Academic books that explain how every component of a computer work from the ground up.
  * Explains in detail the different concepts that make up computer architecture.
  * They are not targeted at readers who wish to become proficient in a specific assembly language.
  * The MIPS and ARM edition cover the same topics but by dissecting a different architecture.
  * Both editions contain examples in the x86 world

### <a name=""C-language""></a>C language

There is no shortcut. Just read the entire book and solve all the exercises.

* [C Programming: A Modern Approach, 2nd Edition](https://www.amazon.com/C-Programming-Modern-Approach-2nd/dp/0393979504)
* [The C Programming Language 2nd Edition](https://www.amazon.com/Programming-Language-Brian-W-Kernighan/dp/0131103628/ref=pd_sbs_14_t_0?_encoding=UTF8&psc=1&refRID=60R1D2CHBA8DHYT6JNMN)
* Modern C: Jens Gustedt. Modern C. Manning, 2019, 9781617295812. ffhal-02383654f
  * For new standard of C
* [Is Parallel Programming Hard, And, If So, What Can You Do About It?](https://www.kernel.org/pub/linux/kernel/people/paulmck/perfbook/perfbook.html)
  * raw implementation of synchronization with C
  * Essential for large scale C programming (especially for kernel programming)
* [C Project Based Tutorials?](https://www.reddit.com/r/C_Programming/comments/872rlt/c_project_based_tutorials/)
  * If you finish reading one or two C programming books, then you MUST make something.
  * Choose whatever you like.
  * First make on your own and then compare with someone else's source code. It is very important to compare your source and others. You can improve your skill only when you read the other's source and learn better methods. Books are dead and source is live.
* [C and other languages based projects](https://github.com/danistefanovic/build-your-own-x)
  * find more interesting projects
* [Michael Abrash’s Graphics Programming Black Book, Special Edition](http://www.jagregory.com/abrash-black-book/)
  * Reference on optimization using C and a bit of x86 assembly
  * Starts from the 8088 up to today
  * Special focus on low-level graphics optimization
* [Framework and plugin design in C](https://github.com/gurugio/book_cprogramming)
  * How to develop framework and plugin in C for large scale software
  * Very basic programming tips for Linux kernel source reading

If you want to be expert of C programming, visit https://leetcode.com/. Good luck!

### <a name=""Rust-language""></a>Rust language

I am sure that the next language for the systems programming would be Rust.
I will make a list what I did to learn Rust.

[Linus Torvalds said ""Unless something odd happens, it [Rust] will make it into 6.1.""](https://www.zdnet.com/article/linus-torvalds-rust-will-go-into-linux-6-1/)

* [The Rust Programming Language](https://doc.rust-lang.org/book/)
  * Great introduction, but lack of examples and exercises.
* [Rust by Example](https://doc.rust-lang.org/rust-by-example/)
  * While reading ""The Rust Programming Language"", you can find examples and exercises here.
  * But there are not many exercises you can do something for yourself. Only some examples includes ""do-this"" exercises and they are very simple.
* [Programming Rust, 2nd](https://www.oreilly.com/library/view/programming-rust-2nd/9781492052586/)
  * Deeper introduction, but still lack of examples and exercises.
* [Exercism](https://exercism.org/tracks/rust)
  * Good exercises to practice indivisual features of RUST.
  * I am not sure Mentors are working actively but it would be enough to compare your solution with others.
    * After submitting your solution, you can see other's solutions with ""Community solutions"" tab (since Exercism V3).
    * Many easy level exercises are for functional feature such as map/filter/any and etc.
* [Easy rust](https://dhghomon.github.io/easy_rust/)
  * A book written in easy English.
  * Youtube materials provided: https://www.youtube.com/playlist?list=PLfllocyHVgsRwLkTAhG0E-2QxCf-ozBkk
* [Let's get rusty](https://www.youtube.com/c/LetsGetRusty)
  * There are many Youtubers uploading Rust course but I enjoied this course most.
  * He has been uploading the latest news for Rust. It's worth substribing.
* [Rust for Linux](https://github.com/Rust-for-Linux)
  * See the example sources and check how Rust will get into the Linux kernel

## <a name=""Applications""></a>Applications

### <a name=""Hardware-Firmware""></a>Hardware && Firmware

If you want to be an embedded systems engineer, it would be best to start from a simple hardware kit, rather than starting with the latest ARM chipset.

* [Arduino Start Kit](https://www.arduino.cc/)
  * There are many series of Arduinos but ""Arduino Start Kit"" has the most simple processor(Atmega328P) and guide book
  * Atmega328P has an 8-bit core which is a good place to start digital circuit design and firmware development.
  * You don't need to know how to draw schematics and layouts and assemble the chips.
  * But you do need to know how to read schematics and understand how the chips are connected.
  * Firmware developers should be able to read the schematics and figure out how to send data to the target device.
  * Follow the guide book!
* [8086 manual](https://edge.edx.org/c4x/BITSPilani/EEE231/asset/8086_family_Users_Manual_1_.pdf)
  * If you're a beginner to x86 architecture, 8086 is also very good guide for processor architecture and 80x86 assembly
* [80386 manual](http://css.csail.mit.edu/6.858/2015/readings/i386.pdf)
  * Best guide for protected mode and paging mechanism of 80x86 processor
  * Web version: https://pdos.csail.mit.edu/6.828/2011/readings/i386/toc.htm

At this point, you should be good to start the latest ARM or x86 processor.
* https://www.raspberrypi.org/
* https://beagleboard.org/
* https://www.arduino.cc/en/ArduinoCertified/IntelEdison

For example, the Raspberry Pi board has a Cortex-A53 Processor that supports a 64-bit instruction set.
This allows you to experience a modern processor architecture with rPi.
Yes, you can buy it... but... what are you going to do with it?
If you have no target project, you would be likely to throw the board into a drawer and forget it like other gadgets you may have bought before.

So, I recommend one project for you.
* [Making your own kernel](http://wiki.osdev.org/Getting_Started)
  * Good references: https://www.reddit.com/r/osdev/
* [Learning operating system development using Linux kernel and Raspberry Pi](https://github.com/s-matyukevich/raspberry-pi-os)
  * (description of the project) This repository contains a step-by-step guide that teaches how to create a simple operating system (OS) kernel from scratch...(skip)...Each lesson is designed in such a way that it first explains how some kernel feature is implemented in the RPi OS, and then it tries to demonstrate how the same functionality works in the Linux kernel.

I've made [a toy kernel](https://github.com/gurugio/caos) that supports 64-bit long mode, paging and very simple context switching. Making a toy kernel is good way to understand modern computer architecture and hardware control.

In fact, you have already the latest processor and the latest hardware devices.
Your laptop! Your desktop! You already have all that you need in order to start!
You don't need to buy anything.
The qemu emulator can emulate the latest ARM processors and Intel processors.
So everything you need is already on hand.
There are many toy kernels and documents you can refer to.
Just install qemu emulator and make a tiny kernel that just boots, turns on paging, and prints some messages.

Other toy kernels:
* https://littleosbook.github.io/
* https://tuhdo.github.io/os01/

### <a name=""Linux-kernel-and-device-driver""></a>Linux kernel and device driver

You don't need to make a complete operating system.
Join the Linux community and participate in development.

Some resources for Linux kernel and device driver development from beginner to advanced.
* Books: Read the following in order
  * [The Design of the Unix Operating System](https://www.amazon.com/Design-UNIX-Operating-System/dp/0132017997)
    * The basic concepts of Unix are applied into all operating systems.
    * This book is a very good place to learn the core concepts of operating systems.
  * [Linux Device Drivers](https://www.amazon.com/Linux-Device-Drivers-Jonathan-Corbet/dp/0596005903/ref=sr_1_4?ie=UTF8&qid=1483650712&sr=8-4&keywords=understanding+linux+kernel)
    * Make all examples for yourself
  * [Linux Kernel Development](https://www.amazon.com/Linux-Kernel-Development-Robert-Love/dp/0672329468/ref=sr_1_2?ie=UTF8&qid=1483650712&sr=8-2&keywords=understanding+linux+kernel)
    * Understand the design of the Linux Kernel
  * [Understanding the Linux Kernel](https://www.amazon.com/Understanding-Linux-Kernel-Third-Daniel/dp/0596005652/ref=sr_1_1?ie=UTF8&qid=1483650712&sr=8-1&keywords=understanding+linux+kernel)
    * Read this book and the kernel source v2.6 at the same time
    * Never start with the latest version, v2.6 is enough!
    * Use qemu and gdb to run the kernel source line by line
      * http://stackoverflow.com/questions/11408041/how-to-debug-the-linux-kernel-with-gdb-and-qemu
      * https://github.com/gurugio/linuxdeveloptip/blob/master/qemu-gdb-kdump.md
    * Use busybox to make the simplest filesystem that takes only one second to boot
      * https://github.com/gurugio/linuxdeveloptip/blob/master/minikernelwithbusybox.md
* Other resources: Free resources I recommend
  * [Linux device driver labs](https://linux-kernel-labs.github.io/)
    * Practical guide and excellent exercises making Linux device drivers with essential kernel APIs
    * I think this document introduces almost all essential kernel APIs.
  * [The Eudyptula Challenge](http://eudyptula-challenge.org/)
    * _Sadly, this challenge does not accept new challengers because there is no challenge anymore._ The maintainer said he/she is planning a new format. I hope it comes back ASAP.
      * But you can find the questions of the challenge with Google. Some people already uploaded what they did. Find the questions and try to solve them on your own, and compare your solution with others.
    * This is like an awesome private teacher who guides you on what to do.
    * If you don't know what to do, just start this.
  *  [Learning operating system development using Linux kernel and Raspberry Pi](https://github.com/s-matyukevich/raspberry-pi-os)
     * This project is not completed yet.
     * I always think making a kernel similar to the Linux kernel is the best way to understand the Linux kernel.
  * [Block layer and device driver](https://github.com/gurugio/book_linuxkernel_blockdrv)
    * start from a simple block device driver example (Ramdisk) with multi-queue mode
    * go forward to block layer
    * I completed translation into English. Please send me your feedback.
  * [md driver of Linux kernel(Korean)](https://github.com/gurugio/book_linuxkernel_md)
    * how mdadm tool works and how it calls md driver
    * how md driver works
  * [A Heavily Commemted Linux Kernel Source Code](http://www.oldlinux.org/)
    * Heavy comments for the ancient Linux v0.12.
    * It would be good to start with old and simple OS.
    * Unix version: [Lions' Commentary on UNIX 6th Edition, with Source Code](https://en.wikipedia.org/wiki/Lions%27_Commentary_on_UNIX_6th_Edition,_with_Source_Code)

#### <a name=""References""></a>References

Check when you need something

* [Free-electrons homepage](http://free-electrons.com/docs/)
  * many slide files introducing good topics, specially ARM-linux
* [Julia Evans's posting: You can be a kernel hacker!](http://jvns.ca/blog/2014/09/18/you-can-be-a-kernel-hacker/)
  * guide to start kernel programming

### <a name=""Other-applications""></a>Other application

Yes, you might not be interested in Linux or firmware. If so, you can find other applications:
* Windows systems programming & device drivers
* Security
* Reverse engineering

I don't have any knowledge about those applications. Please send me any information for beginners.

**Kernels and drivers are not all of low-level programming.** One more important application of low-level programming is the software-defined storage or distributed filesystem. Detailed descriptions of them is beyond the scope of this document but there is an excellent course where you can try a simple distributed filesystem.
* Course: https://pdos.csail.mit.edu/archive/6.824-2012/
* reference Source: https://github.com/srned/yfs

## <a name=""Future-of-low-level-programming""></a>Future of low-level programming

I do not know the future, but I keep my eye on Rust.
* https://hacks.mozilla.org/2016/11/rust-and-the-future-of-systems-programming/

If I could have one week free and alone, I would learn Rust.
That is because Rust is the latest language with which I can develop Linux device drivers.
* https://github.com/tsgates/rust.ko

IoT is new trend, so it's worth to check what OSs are for IoT.
ARM, Samsung and some companies has their own realtime OS but sadly many of them are closed source.
But Linux Foundation also has a solution: Zephyr
* https://www.zephyrproject.org/

Typical cloud servers have many layers; for instance, host OS, kvm driver, qemu process, guest OS and service application. A container has been developed to provide light virtualization. In the near future, a new concept of OS, a so-called library OS or Unikernel, would replace the typical stack of SW for virtualization.
* http://unikernel.org/

Big data and cloud computing require bigger and bigger storage. Some disks directly attached to server machines cannot satisfy the required capacity, stability and performance. Therefore there has been research to make huge storage systems with many storage machines connected by a high speed network. It used to be focused on making one huge storage volume. But currently they are providing many volumes dedicated for many virtual machines.
* https://en.wikipedia.org/wiki/Software-defined_storage
* https://en.wikipedia.org/wiki/Clustered_file_system
* https://en.wikipedia.org/wiki/Ceph_(software)

## <a name=""How-to-start""></a>How to start?

I received an email to ask how to start. There are many information about books, courses and projects in this page. It is my mistake to forget to write how to start. Unfortunately there is no King's Road to [King's Landing](https://gameofthrones.fandom.com/wiki/King%27s_Landing). I will just write what I did in order. If you have already done something, please skip it. AGAIN, this is just an example that you could do in order, just in case if you do not know how to start or what to do.

* Reading OS theory books: at least ""The Design of the UNIX Operating System by Maurice J. Bach""
* Learn assembly and C
  * [8086 assembly programming with emu8086](https://github.com/gurugio/book_assembly_8086)
    * It is enough if you understand the concept of assembly programming. You do not need to do something practical.
  * [The C Programming Language 2nd Edition](https://www.amazon.com/Programming-Language-Brian-W-Kernighan/dp/0131103628/ref=pd_sbs_14_t_0?_encoding=UTF8&psc=1&refRID=60R1D2CHBA8DHYT6JNMN)
    * DO YOUR BEST TO solve every single exercises!
  * [C Programming: A Modern Approach, 2nd Edition](https://www.amazon.com/C-Programming-Modern-Approach-2nd/dp/0393979504)
* Do something practical with C
  * [C Project Based Tutorials?](https://www.reddit.com/r/C_Programming/comments/872rlt/c_project_based_tutorials/): Find one or two interesting projects and make your own project.
  * [leetcode.com](https://leetcode.com/): If you cannot find an interesting project, it would be also good to focus on data-structure and algorithm.
* Do a hardware project
  * Raspberrypi or Arduino does not matter. You need a experience to control a hardware directly with only C. ONLY C!
  * I recommend to buy a Atmega128 kit and make a firmware to turn on/off LEDs, detect switch input and display message on the text LCD. Motor control program is also a very good project: for instance, the line tracer.
  * DO NOT use any library. You should make everything on your own, except program downloader.
* Basic of the Linux kernel
  * Low-level programming is very close to the operating system. You should know inside of the OS.
  * Start with drivers
    * Read [Linux Device Drivers](https://www.amazon.com/Linux-Device-Drivers-Jonathan-Corbet/dp/0596005903/ref=sr_1_4?ie=UTF8&qid=1483650712&sr=8-4&keywords=understanding+linux+kernel)
    * [Linux device driver labs](https://linux-kernel-labs.github.io/)
    * [The Eudyptula Challenge](http://eudyptula-challenge.org/)
  * Read [Linux Kernel Development](https://www.amazon.com/Linux-Kernel-Development-Robert-Love/dp/0672329468/ref=sr_1_2?ie=UTF8&qid=1483650712&sr=8-2&keywords=understanding+linux+kernel) to understand the internal of Linux kernel.
* Go to the professional field
  * If you want to be professional Linux Kernel Developer
    * must read [Understanding the Linux Kernel](https://www.amazon.com/Understanding-Linux-Kernel-Third-Daniel/dp/0596005652/ref=sr_1_1?ie=UTF8&qid=1483650712&sr=8-1&keywords=understanding+linux+kernel)
      * Then try to make a toy kernel
      * [Learn operating system development using Linux kernel and Raspberry Pi](https://github.com/s-matyukevich/raspberry-pi-os)
      * [Making your own kernel](http://wiki.osdev.org/Getting_Started)
      * Write the github link to your kernel on your resume (Don't forget to write the detail description in commit message)
    * Check the latest issues at https://lwn.net/ and join it.
      * Check ""Recent kernel patches"" at ""https://lwn.net/Kernel/"" or direct link https://lwn.net/Kernel/Patches
      * Find an interesting patch to you. Try to understand the source code. Of course it would be really difficult but try. You will be closer and closer whenever you try.
      * Build kernel and test it on your system. For example, performance test, stability test with LTP(https://linux-test-project.github.io/) or static code analysis tools inside of kernel.
      * Report any problem if you find any: compile warnings/errors, performance drop, kernel panic/oops or any problem
      * If it works well, report that with the spec of your system. The patch owner would write a ""Reviewed-by"" tag with your name.
      * Find your name in kernel git log
  * Or find another topics
    * There are many fields where the low-level engineer can work: security, Compiler, Firmware, robot/car and so on

# <a name=""Translation""></a>Translation

Please send me the pull request if you'd like to translate this page. I'll list it here.

* [Chinese(Traditional)](https://github.com/gurugio/lowlevelprogramming-university/blob/master/README_tw.md)
* [Chinese(Simplified)](https://github.com/gurugio/lowlevelprogramming-university/blob/master/README_cn.md)
* [Portuguese (Brazilian)](https://github.com/gurugio/lowlevelprogramming-university/blob/master/README_pt.md)
* [Italian](https://github.com/gurugio/lowlevelprogramming-university/blob/master/README_it.md)
* [Czech](https://github.com/gurugio/lowlevelprogramming-university/blob/master/README_cz.md)
* [Russian](https://github.com/gurugio/lowlevelprogramming-university/blob/master/README_ru.md)
* [Turkish](https://github.com/gurugio/lowlevelprogramming-university/blob/master/README_tr.md)
* [Persian](https://github.com/gurugio/lowlevelprogramming-university/blob/master/README_fa.md)

# <a name=""who-am-i""></a>Who am I?

I'm inspired by [google-interview-university](https://github.com/jwasham/google-interview-university). I'd like to share my experience and show a roadmap to becoming a low-level programmer because I have found that these skills are not as common as they once were. In addition, many students and beginners ask me how they could become low-level programmers and Linux kernel engineers.

FYI, I have over 10 years of experience as a low-level programmer:
* 80x86 Assembly programming
* Hardware device with Atmel chip and firmware
* C language system programming for Unix
* Device driver in Linux
* Linux kernel: page allocation
* Linux kernel: block device driver and md module
","This page includes information about low-level programming. Use this page to
help students with reading comprehension and vocabulary. Use the weekly Newsquiz
to test your knowledge of stories you saw on this page. At the bottom of the
page, please share this page with the original link."
40,Highly customizable drop-in solution for introduction views.,"# EAIntroView - simple iOS Introductions

[![CI Status](https://github.com/ealeksandrov/EAIntroView/workflows/CI/badge.svg?branch=master)](https://github.com/ealeksandrov/EAIntroView/actions)
[![Version](https://img.shields.io/cocoapods/v/EAIntroView.svg?style=flat)](http://cocoadocs.org/docsets/EAIntroView)
[![Carthage compatible](https://img.shields.io/badge/Carthage-compatible-4BC51D.svg?style=flat)](https://github.com/Carthage/Carthage)
[![License](https://img.shields.io/cocoapods/l/EAIntroView.svg?style=flat)](http://cocoadocs.org/docsets/EAIntroView)
[![Platform](https://img.shields.io/cocoapods/p/EAIntroView.svg?style=flat)](http://cocoadocs.org/docsets/EAIntroView)

![ExampleImage1](https://raw.githubusercontent.com/ealeksandrov/EAIntroView/master/Screenshot01.png)
![ExampleImage2](https://raw.githubusercontent.com/ealeksandrov/EAIntroView/master/Screenshot02.png)

This is highly customizable drop-in solution for introduction views.
Some features (remember, most features are optional and can be turned off):

* beautiful demo project to look on some examples
    * customizability is unlimited, one can make complex introView with animations and interactive pages, so do not limit yourself with existing examples
* for each basic page:
    * background (with cross-dissolve transition between pages)
    * custom iOS7 motion effects (parallax) on background
    * title view (+ Y position)
    * title text (+ font, color and Y position)
    * description text (+ font, color, width and Y position)
    * subviews array (added to page after building default layout)
* possibility to set your own custom view for page:
    * pageWithCustomView:
    * pageWithCustomViewFromNibNamed:
* possibility to set block action on page events:
    * pageDidLoad
    * pageDidAppear
    * pageDidDisappear
* many options to customize parent view:
    * swipe from last page to close
    * switching pages with one simple tap
    * custom background image or color
    * custom page control
    * custom skip button
    * pinned titleView (+ Y position, can be hidden on some pages)
* delegate protocol to listen:
    * introDidFinish:
    * intro:pageAppeared:withIndex:
* actions on IntroView:
    * setPages:
    * showInView:animateDuration:
    * hideWithFadeOutDuration:
    * setCurrentPageIndex:animated:
* storyboard/IB support
* and many more...

## Installation

You can setup `EAIntroView` using [Carthage](https://github.com/Carthage/Carthage), [CocoaPods](http://github.com/CocoaPods/CocoaPods) or [completely manually](#setting-up-manually).

### Carthage

1. Add `EAIntroView` to your project's `Cartfile`:

    ```ruby
    github ""ealeksandrov/EAIntroView""
    ```

2. Run `carthage update` in your project directory.
3. On your application targets’ “General” settings tab, in the “Linked Frameworks and Libraries” section, drag and drop **EAIntroView.framework** and **EARestrictedScrollView.framework** from the `Carthage/Build/iOS/` folder on disk.
4. On your application targets’ “Build Phases” settings tab, click the “+” icon and choose “New Run Script Phase”. Create a Run Script with the following contents:

    ```shell
    /usr/local/bin/carthage copy-frameworks
    ```
    
    add the paths to the frameworks under “Input Files”:
    
    ```shell
    $(SRCROOT)/Carthage/Build/iOS/EAIntroView.framework
    $(SRCROOT)/Carthage/Build/iOS/EARestrictedScrollView.framework
    ```
    
    and the paths to the copied frameworks to the “Output Files”:
    
    ```shell
    $(BUILT_PRODUCTS_DIR)/$(FRAMEWORKS_FOLDER_PATH)/EAIntroView.framework
    $(BUILT_PRODUCTS_DIR)/$(FRAMEWORKS_FOLDER_PATH)/EARestrictedScrollView.framework
    ```

### CocoaPods

1. Add EAIntroView to your project's `Podfile`:

    ```ruby
    pod 'EAIntroView'
    ```

2. Run `pod update` or `pod install` in your project directory.

### Setting Up Manually

1. Add [EARestrictedScrollView](https://github.com/ealeksandrov/EARestrictedScrollView) header and implementation to your project (2 files total).
2. Add `EAIntroPage` and `EAIntroView` headers and implementations to your project (4 files total).
3. You can now use `EAIntroView` by adding the following import:

    ```swift
    import EAIntroView
    ```

    ```obj-c
    #import <EAIntroView/EAIntroView.h>
    ```

## How To Use It

Sample project have many examples of customization. Here are only simple ones.

### Step 1 - Build Pages
Each page created with `[EAIntroPage page]` class method. Then you can customize any property, all of them are optional. Another approach is to pass your own (can be nib), custom view in `EAIntroPage`, this way most other options are ignored.

```objc
// basic
EAIntroPage *page1 = [EAIntroPage page];
page1.title = @""Hello world"";
page1.desc = sampleDescription1;
// custom
EAIntroPage *page2 = [EAIntroPage page];
page2.title = @""This is page 2"";
page2.titleFont = [UIFont fontWithName:@""Georgia-BoldItalic"" size:20];
page2.titlePositionY = 220;
page2.desc = sampleDescription2;
page2.descFont = [UIFont fontWithName:@""Georgia-Italic"" size:18];
page2.descPositionY = 200;
page2.titleIconView = [[UIImageView alloc] initWithImage:[UIImage imageNamed:@""title2""]];
page2.titleIconPositionY = 100;
// custom view from nib
EAIntroPage *page3 = [EAIntroPage pageWithCustomViewFromNibNamed:@""IntroPage""];
page3.bgImage = [UIImage imageNamed:@""bg2""];
```

### Step 2 - Create Introduction View
Once all pages have been created,  you are ready to create the introduction view. Just pass them in right order in the introduction view. You can also pass array of pages after IntroView's initialization, it will rebuild its contents.

```objc
EAIntroView *intro = [[EAIntroView alloc] initWithFrame:self.view.bounds andPages:@[page1,page2,page3,page4]];
```

Don't forget to set the delegate if you want to use any callbacks.

```objc
[intro setDelegate:self];
```

### Step 3 - Show Introduction View

```objc
[intro showInView:self.view animateDuration:0.0];
```

### Storyboard/IB
Since 1.3.0 `EAIntroView` supports init from IB. Since 2.0.0 `EAIntroPage` supports it too.

1. Drop `UIView` to your IB document.
2. Set its class to `EAIntroView`.
3. Create `IBOutlet` property in your view controller: `@property(nonatomic,weak) IBOutlet EAIntroView *introView;`.
4. Connect `IBOutlet` with `EAIntroView` in IB.
5. Build array of pages (you can use `pageWithCustomViewFromNibNamed:` here with separate nibs for each page).
6. Pass pages array to `EAIntroView` property in `setPages:`.

## Author

Created and maintained by Evgeny Aleksandrov ([@ealeksandrov](https://twitter.com/ealeksandrov)).

## License

`EAIntroView` is available under the MIT license. See the [LICENSE.md](LICENSE.md) file for more info.
","EAIntroView is a drop-in solution for introduction views for iOS7. Features
include custom iOS7 motion effects (parallax) on background. Customizability is
unlimited, one can make complex introView with animations and interactive pages."
401,No root required Android DNS modifier and Hosts/DNSMasq resolver.,"# iTXTech Daedalus

__No root required Android DNS modifier and Hosts/DNSMasq resolver.__

## Installations
* __[Releases](https://github.com/iTXTech/Daedalus/releases)__ - Release signature
* __[Play Test](https://play.google.com/apps/testing/org.itxtech.daedalus)__ - Release signature

[<img alt='Get it on Google Play'
      src='https://play.google.com/intl/en_us/badges/images/generic/en_badge_web_generic.png'
      height=""80"">](https://play.google.com/store/apps/details?id=org.itxtech.daedalus)
[<img src=""https://fdroid.gitlab.io/artwork/badge/get-it-on.png""
     alt=""Get it on F-Droid""
     height=""80"">](https://f-droid.org/packages/org.itxtech.daedalus)

## Useful links
* __[Telegram](https://t.me/iTXTechDaedalus)__ - Join chat
* __[Wiki](https://github.com/iTXTech/Daedalus/wiki)__ - Pending update

## Introduction

This application creates a VPN tunnel to handle all DNS requests.<br>
<br>
Features:
* No root access required, no ads contained
* Functional under data connection
* A tester for DNS servers
* IPv6 support (including Rules!)
* Custom DNS server
* Custom hosts and DNSMasq configuration
* EXTREME LOW power consume
* Material Design

Supported DNS Query Methods:
* UDP
* TCP 
* DNS over TLS ([RFC7858](https://tools.ietf.org/html/rfc7858))
* DNS over HTTPS ([RFC8484](https://tools.ietf.org/html/rfc8484))
* DNS over HTTPS ([Google JSON](https://developers.google.com/speed/public-dns/docs/dns-over-https))
<br>

__Users must comply with local laws and regulations.__<br>

## DNS Server Providers

* __CuteDNS__ - *Shutdown according to regulations*
* __[FUN DNS](http://fundns.cn)__ - *Shutdown according to regulations*
* __[Pure DNS](https://puredns.cn/)__ - *Shutdown according to regulations*
* __[PdoMo-DNS](https://pdomo.me/)__ - *Shutdown according to regulations*
* __[rubyfish](https://www.rubyfish.cn)__ - *Free DoT/DoH DNS*

## Rule Providers

* __[hosts](https://github.com/googlehosts/hosts)__ by *[googlehosts](https://github.com/googlehosts)* - [CC BY-NC-SA 4.0](https://creativecommons.org/licenses/by-nc-sa/4.0/deed.zh)
* __[yhosts](https://github.com/vokins/yhosts)__ by *[vokins](https://github.com/vokins)* - [CC BY-NC-ND 4.0](https://creativecommons.org/licenses/by-nc-nd/4.0/)

## Requirements

* Minimum Android version: >= 5.0 (API 21)
* Recommended Android version: >= 7.1 (API 25) - __*Launcher shortcuts*__

## Open Source Licenses

* __[ClearEditText](https://github.com/MrFuFuFu/ClearEditText)__ by *[Yuan Fu](https://github.com/MrFuFuFu)* - [APL 2.0](https://github.com/MrFuFuFu/ClearEditText)
* __[DNS66](https://github.com/julian-klode/dns66)__ by *[Julian Andres Klode](https://github.com/julian-klode)* - [GPLv3](https://github.com/julian-klode/dns66/blob/master/COPYING)
* __[Pcap4J](https://github.com/kaitoy/pcap4j)__ by *[Kaito Yamada](https://github.com/kaitoy)* - [MIT](https://github.com/kaitoy/pcap4j)
* __[MiniDNS](https://github.com/MiniDNS/minidns)__ by *[MiniDNS](https://github.com/MiniDNS)* - [APL 2.0](https://github.com/MiniDNS/minidns/blob/master/LICENCE_APACHE)
* __[Gson](https://github.com/google/gson)__ by *[Google](https://github.com/google)* - [APL 2.0](https://github.com/google/gson/blob/master/LICENSE)
* __[Shadowsocks](https://github.com/shadowsocks/shadowsocks-android)__ by *[Shadowsocks](https://github.com/shadowsocks)* - [GPLv3](https://github.com/shadowsocks/shadowsocks-android/blob/master/LICENSE)

## Credits

* __[JetBrains](https://www.jetbrains.com/)__ - For providing free license for [IntelliJ IDEA](https://www.jetbrains.com/idea/)

## License

    Copyright (C) 2017-2022 iTX Technologies <admin@itxtech.org>
    
	This program is free software: you can redistribute it and/or modify
	it under the terms of the GNU General Public License as published by
	the Free Software Foundation, either version 3 of the License, or
	(at your option) any later version.

	This program is distributed in the hope that it will be useful,
	but WITHOUT ANY WARRANTY; without even the implied warranty of
	MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
	GNU General Public License for more details.

	You should have received a copy of the GNU General Public License
	along with this program.  If not, see <http://www.gnu.org/licenses/>.
","This application creates a VPN tunnel to handle all DNS requests. No root access
required, no ads contained. Users must comply with local laws and regulations.
Minimum Android version: 5.0 (API 21) recommended version: 7.1 (API 25) Open
Source Licenses: [CC BY-NC-SA 4.0](https://creativecommons.org/licenses/by-nc-
sa/4.0/deed.zh) Free Software License: [JetBrains IDEA] (CPLv3) (JPG)"
2886,📷  Image Processing Component for React,"**This project is no longer maintained.**

# react-imgpro

[![Build Status](https://travis-ci.org/nitin42/react-imgpro.svg?branch=master)](https://travis-ci.org/nitin42/react-imgpro)
![status](https://img.shields.io/badge/version-1.3.14-brightgreen.svg)
![status](https://img.shields.io/badge/size-13.1KB-brightgreen.svg)
![status](https://img.shields.io/badge/status-stable-brightgreen.svg)
![yarn](https://img.shields.io/badge/yarn-1.9.4-blue.svg)

> Image Processing Component for React

<p align=""center"">
  <img src=""./images/react-impro.png"" height=""200"" width=""200"">
</p>

## Introduction

`react-imgpro` is a image processing component for React. This component process an image with filters supplied as props and returns a [base64](https://en.wikipedia.org/wiki/Base64) image. 

**Example**

```jsx

const mix = {
    color: 'mistyrose',
    amount: 10
}

class App extends React.Component {
  state = { src: '', err: null }
  render() {
    return (
      <ProcessImage
        image='http://365.unsplash.com/assets/paul-jarvis-9530891001e7f4ccfcef9f3d7a2afecd.jpg'
        colors={{
          mix
        }}
        resize={{ width: 500, height: 500, mode: 'bilinear' }}
        processedImage={(src, err) => this.setState({ src, err, })}
      />     
    )
  }
}
```

<p align=""center"">
<img src=""./images/introduction.jpg"" height=""400"" width=""800"">
</p>

## Motivation

<p align=""center"">
  <img src=""https://i.gyazo.com/16f09cba02f9dfeb272cc574f9fbbcff.png"">
</p>

I was working on a project last month which involved a lot of image processing and I'd to rely on third party libraries. But before using them directly, I'd to learn different concepts in gl (shaders) and then try to implement them in React. The difficult part was not learning but it was the verbosity, boilerplate code and redundancy introduced by the libraries in the codebase. It was getting difficult to organise all the things 😞

So I wanted a layer of abstraction which would make it easy to manipulate the colors of the image, applying filters and gl shaders efficiently with ease. And React's component based model was perfect for hiding all the implementation details in a component 😄 

## Demo

<p align=""center"">
  <img src=""http://g.recordit.co/XmhTiP84TD.gif"">
</p>

## Install

```
npm install react-imgpro
```

This also depends on `react` so make sure you've installed it.

OR

The UMD build is also available via [jsDelivr](https://www.jsdelivr.com).

```
<script src=""https://cdn.jsdelivr.net/npm/react@16/umd/react.production.min.js""></script>
<script src=""https://cdn.jsdelivr.net/npm/react-imgpro@1/build/main.js""></script>
```

## Usage

```jsx
import React from 'react';
import ProcessImage from 'react-imgpro';

class App extends React.Component {
  state = {
    src: '',
    err: null
  }
  
  render() {
    return (
      <ProcessImage
        image='http://365.unsplash.com/assets/paul-jarvis-9530891001e7f4ccfcef9f3d7a2afecd.jpg'
        resize={{ width: 500, height: 500 }}
        colors={{
          mix: {
            color: 'mistyrose',
            amount: 20
          }
        }}
        processedImage={(src, err) => this.setState({ src, err})}
      />
    )
  }
}

```

## Documentation

See the detailed documentation [here](./Docs).

## SSR support ?

Yes, `react-imgpro` supports SSR.

## Contributing

[Contributing guide](https://github.com/nitin42/react-imgpro/blob/master/Docs/CONTRIBUTING.MD).

## Extra resources

If you want to use blenders, plugins and perform event based calculations, try [CamanJS](http://camanjs.com/).

## License

MIT

<a href=""https://app.codesponsor.io/link/FCRW65HPiwhNtebDx2tTc53E/nitin42/react-imgpro"" rel=""nofollow""><img src=""https://app.codesponsor.io/embed/FCRW65HPiwhNtebDx2tTc53E/nitin42/react-imgpro.svg"" style=""width: 888px; height: 68px;"" alt=""Sponsor"" /></a>
","React is a React component for image processing. The UMD build is also available
via [jsDelivr] and [www.jsdelivr.com). The documentation is detailed, see the
documentation documentation for more details. The code is written in C# and C#
with a little bit of JavaScript. It's written in React's component based model
which hides all the implementation details in a component. It also depends on
`react` so make sure you've installed it."
3439,Natural Language Processing Best Practices & Examples,"<img src=""NLP-Logo.png"" align=""right"" alt="""" width=""300""/>


# NLP Best Practices

In recent years, natural language processing (NLP) has seen quick growth in quality and usability, and this has helped to drive business adoption of artificial intelligence (AI) solutions. In the last few years, researchers have been applying newer deep learning methods to NLP. Data scientists started moving from traditional methods to state-of-the-art (SOTA) deep neural network (DNN) algorithms which use language models pretrained on large text corpora.

This repository contains examples and best practices for building NLP systems, provided as [Jupyter notebooks](examples) and [utility functions](utils_nlp). The focus of the repository is on state-of-the-art methods and common scenarios that are popular among researchers and practitioners working on problems involving text and language.

## Overview

The goal of this repository is to build a comprehensive set of tools and examples that leverage recent advances in NLP algorithms, neural architectures, and distributed machine learning systems.
The content is based on our past and potential future engagements with customers as well as collaboration with partners, researchers, and the open source community.

We hope that the tools can significantly reduce the “time to market” by simplifying the experience from defining the business problem to development of solution by orders of magnitude. In addition, the example notebooks would serve as guidelines and showcase best practices and usage of the tools in a wide variety of languages.

In an era of transfer learning, transformers, and deep architectures, we believe that pretrained models provide a unified solution to many real-world problems and allow handling different tasks and languages easily. We will, therefore, prioritize such models, as they achieve state-of-the-art results on several NLP benchmarks like [*GLUE*](https://gluebenchmark.com/leaderboard) and [*SQuAD*](https://rajpurkar.github.io/SQuAD-explorer/) leaderboards. The models can be used in a number of applications ranging from simple text classification to sophisticated intelligent chat bots.

Note that for certain kind of NLP problems, you may not need to build your own models. Instead, pre-built or easily customizable solutions exist which do not require any custom coding or machine learning expertise. We strongly recommend evaluating if these can sufficiently solve your problem. If these solutions are not applicable, or the accuracy of these solutions is not sufficient, then resorting to more complex and time-consuming custom approaches may be necessary. The following cognitive services offer simple solutions to address common NLP tasks:
<br><br><b>[Text Analytics](https://azure.microsoft.com/en-us/services/cognitive-services/text-analytics/) </b> are a set of pre-trained REST APIs which can be called for Sentiment Analysis, Key phrase extraction, Language detection and Named Entity Detection and more. These APIs work out of the box and require minimal expertise in machine learning, but have limited customization capabilities.
<br><br><b>[QnA Maker](https://azure.microsoft.com/en-us/services/cognitive-services/qna-maker/) </b>is a cloud-based API service that lets you create a conversational question-and-answer layer over your existing data. Use it to build a knowledge base by extracting questions and answers from your semi-structured content, including FAQs, manuals, and documents.
<br><br><b>[Language Understanding](https://azure.microsoft.com/en-us/services/cognitive-services/language-understanding-intelligent-service/)</b> is a SaaS service to train and deploy a model as a REST API given a user-provided training set. You could do Intent Classification as well as Named Entity Extraction by performing simple steps of providing example utterances and labelling them. It supports Active Learning, so your model always keeps learning and improving.

## Target Audience
For this repository our target audience includes data scientists and machine learning engineers with varying levels of NLP knowledge as our content is source-only and targets custom machine learning modelling. The utilities and examples provided are intended to be solution accelerators for real-world NLP problems.

## Focus Areas
The repository aims to expand NLP capabilities along three separate dimensions

### Scenarios
We aim to have end-to-end examples of common tasks and scenarios such as text classification, named entity recognition etc.

### Algorithms
We aim to support multiple models for each of the supported scenarios. Currently, transformer-based models are supported across most scenarios. We have been working on integrating the [transformers package](https://github.com/huggingface/transformers) from [Hugging Face](https://huggingface.co/) which allows users to easily load pretrained models and fine-tune them for different tasks.

### Languages
We strongly subscribe to the multi-language principles laid down by [""Emily Bender""](http://faculty.washington.edu/ebender/papers/Bender-SDSS-2019.pdf)
* ""Natural language is not a synonym for English""
* ""English isn't generic for language, despite what NLP papers might lead you to believe""
* ""Always name the language you are working on"" ([Bender rule](https://www.aclweb.org/anthology/Q18-1041/))

The repository aims to support non-English languages  across all the scenarios. Pre-trained models used in the repository such as BERT, FastText support 100+ languages out of the box. Our goal is to provide end-to-end examples in as many languages as possible. We encourage community contributions in this area.



## Content
The following is a summary of the commonly used NLP scenarios covered in the repository. Each scenario is demonstrated in one or more [Jupyter notebook examples](examples) that make use of the core code base of models and repository utilities.

| Scenario                              |  Models | Description|Languages|
|-------------------------|  ------------------- |-------|---|
|Text Classification                     |BERT, DistillBERT, XLNet, RoBERTa, ALBERT, XLM| Text classification is a supervised learning method of learning and predicting the category or the class of a document given its text content. |English, Chinese, Hindi, Arabic, German, French, Japanese, Spanish, Dutch|
|Named Entity Recognition                |BERT| Named entity recognition (NER) is the task of classifying words or key phrases of a text into predefined entities of interest. |English|
|Text Summarization|BERTSumExt <br> BERTSumAbs <br> UniLM (s2s-ft) <br> MiniLM |Text summarization is a language generation task of summarizing the input text into a shorter paragraph of text.|English
|Entailment                              |BERT, XLNet, RoBERTa| Textual entailment is the task of classifying the binary relation between two natural-language texts,  *text* and *hypothesis*, to determine if the *text* agrees with the *hypothesis* or not. |English|
|Question Answering                      |BiDAF, BERT, XLNet| Question answering (QA) is the task of retrieving or generating a valid answer for a given query in natural language, provided with a passage related to the query. |English|
|Sentence Similarity                     |BERT, GenSen| Sentence similarity is the process of computing a similarity score given a pair of text documents. |English|
|Embeddings| Word2Vec<br>fastText<br>GloVe| Embedding is the process of converting a word or a piece of text to a continuous vector space of real number, usually, in low dimension.|English|
|Sentiment Analysis| Dependency Parser <br>GloVe| Provides an example of train and use Aspect Based Sentiment Analysis with Azure ML and [Intel NLP Architect](http://nlp_architect.nervanasys.com/absa.html) .|English|
## Getting Started
While solving NLP problems, it is always good to start with the prebuilt [Cognitive Services](https://azure.microsoft.com/en-us/services/cognitive-services/directory/lang/). When the needs are beyond the bounds of the prebuilt cognitive service and when you want to search for custom machine learning methods,  you will find this repository  very useful. To get started, navigate to the [Setup Guide](SETUP.md), which lists instructions on how to setup your environment and dependencies.


## Azure Machine Learning Service
[Azure Machine Learning service](https://azure.microsoft.com/en-us/services/machine-learning-service/) is a cloud service used to train, deploy, automate, and manage machine learning models, all at the broad scale that the cloud provides. AzureML is presented in notebooks across different scenarios to enhance the efficiency of developing Natural Language systems at scale and for various AI model development related tasks like:
  * [**Accessing Datastores**](https://docs.microsoft.com/en-us/azure/machine-learning/service/how-to-access-data) to easily read and write your data in Azure storage services such as blob storage or file share.
  * Scaling up and out on [**Azure Machine Learning Compute**](https://docs.microsoft.com/en-us/azure/machine-learning/service/how-to-set-up-training-targets#amlcompute).
  * [**Automated Machine Learning**](https://docs.microsoft.com/en-us/azure/machine-learning/service/how-to-configure-auto-train) which builds high quality machine learning models by automating model and hyperparameter selection. AutoML explores BERT, BiLSTM, bag-of-words, and word embeddings on the user's dataset to handle text columns.
  * [**Tracking experiments and monitoring metrics**](https://docs.microsoft.com/en-us/azure/machine-learning/service/how-to-track-experiments) to enhance the model creation process.
  * [**Distributed Training**](https://docs.microsoft.com/en-us/azure/machine-learning/service/how-to-train-ml-models#distributed-training-and-custom-docker-images)
  * [**Hyperparameter tuning**](https://docs.microsoft.com/en-us/azure/machine-learning/service/how-to-tune-hyperparameters)
  * Deploying the trained machine learning model as a web service to [**Azure Container Instance**](https://azure.microsoft.com/en-us/services/container-instances/) for deveopment and test,  or for low scale, CPU-based workloads.
  * Deploying the trained machine learning model as a web service to [**Azure Kubernetes Service**](https://azure.microsoft.com/en-us/services/kubernetes-service/) for high-scale production deployments and provides autoscaling, and fast response times.

To successfully run these notebooks, you will need an [**Azure subscription**](https://azure.microsoft.com/en-us/) or can [**try Azure for free**](https://azure.microsoft.com/en-us/free/). There may be other Azure services or products used in the notebooks. Introduction and/or reference of those will be provided in the notebooks themselves.

## Contributing
We hope that the open source community would contribute to the content and bring in the latest SOTA algorithm. This project welcomes contributions and suggestions. Before contributing, please see our [contribution guidelines](CONTRIBUTING.md).

## Blog Posts

- [Bootstrap Your Text Summarization Solution with the Latest Release from NLP-Recipes](https://techcommunity.microsoft.com/t5/ai-customer-engineering-team/bootstrap-your-text-summarization-solution-with-the-latest/ba-p/1268809)

- [Text Annotation made easy with Doccano](https://techcommunity.microsoft.com/t5/ai-customer-engineering-team/text-annotation-made-easy-with-doccano/ba-p/1242612)

- [Jumpstart Analyzing your Hindi Text Data using the NLP Repository](https://techcommunity.microsoft.com/t5/ai-customer-engineering-team/jumpstart-analyzing-your-hindi-text-data-using-the-nlp/ba-p/1087851)

- [Speeding up the Development of Natural Language Processing Solutions with Azure Machine Learning](https://techcommunity.microsoft.com/t5/ai-customer-engineering-team/speeding-up-the-development-of-natural-language-processing/ba-p/1042577)

## References
The following is a list of related repositories that we like and think are useful for NLP tasks.

|Repository|Description|
|---|---|
|[Transformers](https://github.com/huggingface/transformers)|A great PyTorch library from Hugging Face with implementations of popular transformer-based models. We've been using their package extensively in this repo and greatly appreciate their effort.|
|[Azure Machine Learning Notebooks](https://github.com/Azure/MachineLearningNotebooks/)|ML and deep learning examples with Azure Machine Learning.|
|[AzureML-BERT](https://github.com/Microsoft/AzureML-BERT)|End-to-end recipes for pre-training and fine-tuning BERT using Azure Machine Learning service.|
|[MASS](https://github.com/microsoft/MASS)|MASS: Masked Sequence to Sequence Pre-training for Language Generation.|
|[MT-DNN](https://github.com/microsoft/mt-dnn)|Multi-Task Deep Neural Networks for Natural Language Understanding.|
|[UniLM](https://github.com/microsoft/unilm)|Unified Language Model Pre-training.|
|[DialoGPT](https://github.com/microsoft/DialoGPT)|DialoGPT: Large-Scale Generative Pre-training for Conversational Response Generation|


## Build Status
| Build | Branch | Status |
| --- | --- | --- |
| **Linux CPU** | master | [![Build Status](https://dev.azure.com/best-practices/nlp/_apis/build/status/cpu_integration_tests_linux?branchName=master)](https://dev.azure.com/best-practices/nlp/_build/latest?definitionId=50&branchName=master) |
| **Linux CPU** | staging | [![Build Status](https://dev.azure.com/best-practices/nlp/_apis/build/status/cpu_integration_tests_linux?branchName=staging)](https://dev.azure.com/best-practices/nlp/_build/latest?definitionId=50&branchName=staging) |
| **Linux GPU** | master | [![Build Status](https://dev.azure.com/best-practices/nlp/_apis/build/status/gpu_integration_tests_linux?branchName=master)](https://dev.azure.com/best-practices/nlp/_build/latest?definitionId=51&branchName=master) |
| **Linux GPU** | staging | [![Build Status](https://dev.azure.com/best-practices/nlp/_apis/build/status/gpu_integration_tests_linux?branchName=staging)](https://dev.azure.com/best-practices/nlp/_build/latest?definitionId=51&branchName=staging) |
","This repository contains examples and best practices for building NLP systems.
The focus of the repository is on state-of-the-art methods and common scenarios.
The example notebooks would serve as guidelines and showcase best practices and
usage of the tools in a wide variety of languages."
0,LLVM-based compiler for the Nim language,"# Introduction

[nlvm](https://github.com/arnetheduck/nlvm) (the nim-level virtual machine?)
is an [LLVM-based](http://llvm.org) compiler for the [Nim](http://nim-lang.org)
language.

From Nim's point of view, it's a backend just like C or JavaScript - from
LLVM's point of view, it's a language frontend that emits IR.

When I started on this little project, I knew neither llvm nor Nim.
Therefore, I'd specially like to thank the friendly folks at the #nim
channel that never seemed to tire of my nooby questions.
Also, thanks to all tutorial writers out there, on llvm, programming
and other topics for providing such fine sources of copy-pa... er,
inspiration!

Questions, patches, improvement suggestions and reviews welcome. When
you find bugs, feel free to fix them as well :)

Fork and enjoy!

Jacek Sieka (arnetheduck on gmail point com)

# Status

`nlvm` is generally at par with `nim` in terms of features, with the following
notable differences:

* Fast compile times - no intermediate `C` compiler step
* DWARF (""zero-cost"") exception handling
* High-quality `gdb`/`lldb` debug information with source stepping, type
  information etc
* Smart code generation - compiler intrinsics for overflow checking,
  smart constant initialization, etc
* Native `wasm32` support with no extra tooling

Most things from `nim` work just fine (see notes below however!):

* the same standard library is used
* similar command line options are supported (just change `nim` to `nlvm`!)
* `importc` works without needing `C` header files - the declaration in the
  `.nim` file needs to be accurate

Test coverage is not too bad either:

* bootstrapping and compiling itself
* ~95% of all upstream tests - most failures can be traced to
  the standard library and compiler relying on C implementation details - see
  [skipped-tests.txt](skipped-tests.txt) for an updated list of issues
* compiling most applications
* platforms: linux/x86_64, wasm32 (pre-alpha!)
* majority of the nim standard library (the rest can be fixed easily -
  requires upstream changes however)

How you could contribute:

* work on making [skipped-tests.txt](skipped-tests.txt) smaller
* improve platform support (`osx` and `windows` should be easy, `arm` would be
  nice)
* help `nlvm` generate better IR - optimizations, builtins, exception handling..
* help upstream make std library smaller and more `nlvm`-compatible
* send me success stories :)
* leave the computer for a bit and do something real for your fellow earthlings

`nlvm` does _not_:

* understand `C` - as a consequence, `header`, `emit` and similar pragmas
  will not work - neither will the fancy `importcpp`/`C++` features
* support all nim compiler flags and features - do file bugs for anything
  useful that's missing

# Compile instructions

To do what I do, you will need:
* Linux
* A C/C++ compiler (ironically, I happen to use `gcc` most of the time)

Start with a clone:

    cd $SRC
    git clone https://github.com/arnetheduck/nlvm.git
    cd nlvm && git submodule update --init

We will need a few development libraries installed, mainly due to how `nlvm`
processes library dependencies (see dynlib section below):

    # Fedora
    sudo dnf install pcre-devel openssl-devel sqlite-devel ninja-build cmake

    # Debian, ubuntu etc
    sudo apt-get install libpcre3-dev libssl-dev libsqlite3-dev ninja-build cmake

Compile `nlvm` (if needed, this will also build `nim` and `llvm`):

    make

Compile with itself and compare:

    make compare

Run test suite:

    make test
    make stats

You can link statically to LLVM to create a stand-alone binary - this will
use a more optimized version of LLVM as well, but takes longer to build:

    make STATIC_LLVM=1

If you want a faster `nlvm`, you can also try the release build - it will be
called `nlvmr`:

    make STATIC_LLVM=1 nlvmr

When you update `nlvm` from `git`, don't forget the submodule:

    git pull && git submodule update

To build a docker image, use:

    make docker

To run built `nlvm` docker image use:

    docker run -v $(pwd):/code/ nlvm c -r /code/test.nim

# Compiling your code

On the command line, `nlvm` is mostly compatible with `nim`.

When compiling, `nlvm` will generate a single `.o` file with all code from your
project and link it using `$CC` - this helps it pick the right flags for
linking with the C library.

    cd $SRC/nlvm/Nim/examples
    ../../nlvm/nlvm c fizzbuzz

If you want to see the generated LLVM IR, use the `-c` option:

    cd $SRC/nlvm/Nim/examples
    ../../nlvm/nlvm c -c fizzbuzz
    less fizzbuzz.ll

You can then run the LLVM optimizer on it:

    opt -Os fizzbuzz.ll | llvm-dis

... or compile it to assembly (`.s`):

    llc fizzbuzz.ll
    less fizzbuzz.s

Apart from the code of your `.nim` files, the compiler will also mix in the
compatibility found library in `nlvm-lib/`.

## Pipeline

Generally, the `nim` compiler pipeline looks something like this:

    nim --> c files --> IR --> object files --> executable

In `nlvm`, we remove one step and bunch all the code together:

    nim --> IR --> single object file --> executable

Going straight to the IR means it's possible to express nim constructs more
clearly, allowing `llvm` to understand the code better and thus do a better
job at optimization. It also helps keep compile times down, because the
`c-to-IR` step can be avoided.

The practical effect of generating a single object file is similar to
`gcc -fwhole-program -flto` - it is expensive in terms of memory, but results
in slightly smaller and faster binaries. Notably, the `IR-to-machine-code` step,
including any optimizations, is repeated in full for each recompile.

## Common issues

### dynlib

`nim` uses a runtime dynamic library loading scheme to gain access to shared
libraries. When compiling, no linking is done - instead, when running your
application, `nim` will try to open anything the user has installed.

`nlvm` does not support the `{.dynlib.}` pragma - instead you can use
`{.passL.}` using normal system linking.

```nim
# works with `nim`
proc f() {. importc, dynlib: ""mylib"" .}

# works with both `nim` and `nlvm`
{.passL: ""-lmylib"".}
proc f() {. importc .}
```

### header and emit

When `nim` compiles code, it will generate `c` code which may include other
`c` code, from headers or directly via `emit` statements. This means `nim` has
direct access do symbols declared in the `c` file, which can be both a feature
and a problem.

In `nlvm`, `{.header.}` directives are ignored - `nlvm` looks strictly at
the signature of the declaration, meaning the declaration must _exactly_ match
the `c` header file or subtly ABI issues and crashes ensue!

```nim

# When `nim` encounters this, it will emit `jmp_buf` in the `c` code without
# knowing the true size of the type, letting the `c` compiler determine it
# instead.
type C_JmpBuf {.importc: ""jmp_buf"", header: ""<setjmp.h>"".} = object

# nlvm instead ignores the `header` directive completely and will use the
# declaration as written. Failure to correctly declare the type will result
# in crashes and subtle bugs - memory will be overwritten or fields will be
# read from the wrong offsets.
#
# The following works with both `nim` and `nlvm`, but requires you to be
# careful to match the binary size and layout exactly (note how `bycopy`
# sometimes help to further nail down the ABI):

when defined(linux) and defined(amd64):
  type
    C_JmpBuf {.importc: ""jmp_buf"", bycopy.} = object
      abi: array[200 div sizeof(clong), clong]

# In `nim`, `C` constant defines are often imported using the following trick,
# which makes `nim` emit the right `C` code that the value from the header
# can be read (no writing of course, even though it's a `var`!)
#
# assuming a c header with: `#define RTLD_NOW 2`
# works for nim:
var RTLD_NOW* {.importc: ""RTLD_NOW"", header: ""<dlfcn.h>"".}: cint

# both nlvm and nim (note how these values often can be platform-specific):
when defined(linux) and defined(amd64):
  const RTLD_NOW* = cint(2)

```

### wasm32 support

`wasm32` support is still very bare-bones, so you will need to do a bit of
tinkering to get it to work.

Presently, the `wasm32-unknown-unknown` target is mapped to `--os:standalone`
and `--cpu:wasm32` - this choice represents a very raw `wasm` engine with 32-bit
little-endian integers and pointers - in the future, the `nim` standard library
and `system.nim` will need to be updated to support WASM system interfaces like
emscripten or WASI.

To compile wasm files, you will thus need a `panicoverride.nim` - a minimal
example looks like this and discards any errors:

```nim
# panicoverride.nim
proc rawoutput(s: string) = discard
proc panic(s: string) {.noreturn.} = discard
```

After placing the above code in your project folder, you can compile `.nim`
code to `wasm32`:

```nim
# myfile.nim
proc adder*(v: int): int {.exportc.} =
  v + 4
```

```sh
nlvm c --cpu:wasm32 --os:standalone --gc:none --passl:--no-entry myfile.nim
wasm2wat -l myfile.wasm
```

# Random notes

* Upstream is pinned using a submodule - nlvm relies heavily on internals
  that keep changing - it's unlikely that it works with any other versions,
  patches welcome to update it
* The nim standard library likes to import C headers directly which works
  because the upstream nim compiler uses a C compiler underneath - ergo,
  large parts of the standard library don't work with nlvm.
* Happy to take patches for anything, including better platform support!
* For development, it's convenient to build LLVM with assertions turned on -
  the API is pretty unforgiving
","[nlvm] is an [LLVM-based] compiler for the [Nim](http://nim-lang.org) language.
It's a backend just like C or JavaScript - from Nim's point of view, it's a
language frontend that emits IR. It is generally at par with `nim` in terms of
features, with the following notable differences: Fast compile times - no
intermediate `C` compiler step. DWARF (""zero-cost"") exception handling. High-
quality `gdb`/`lldb` debug information with source stepping. Native `wasm32`
support with no extra tooling."
1073,"ARCHIVED: Contains historical course materials/Homework materials for the FREE MOOC course on ""Creative Applications of Deep Learning w/ Tensorflow"" #CADL","[![Build Status](https://travis-ci.org/pkmital/CADL.svg?branch=master)](https://travis-ci.org/pkmital/CADL) [![Slack Channel](https://cadl.herokuapp.com/badge.svg)](https://cadl.herokuapp.com)

# <a href=""https://www.kadenze.com/courses/creative-applications-of-deep-learning-with-tensorflow/info"">Creative Applications of Deep Learning w/ Tensorflow</a>

This repository contains lecture transcripts and homework assignments as Jupyter Notebooks for the first of three <a href=""https://www.kadenze.com/partners/kadenze-academy"">Kadenze Academy</a> courses on <a href=""https://www.kadenze.com/courses/creative-applications-of-deep-learning-with-tensorflow/info"">Creative Applications of Deep Learning w/ Tensorflow</a>.  It also contains a python package containing all the code developed during all three courses.

**COURSE 1: Creative Applications of Deep Learning with TensorFlow I**  
Session 1: Introduction to TensorFlow  
Session 2: Training A Network W/ TensorFlow  
Session 3: Unsupervised And Supervised Learning  
Session 4: Visualizing And Hallucinating Representations  
Session 5: Generative Models  

**COURSE 2: Creative Applications of Deep Learning with TensorFlow II**  
Session 1: Cloud Computing, GPUs, Deploying  
Session 2: Mixture Density Networks  
Session 3: Modeling Attention with RNNs, DRAW  
Session 4: Image-to-Image Translation with GANs  

**COURSE 3: Creative Applications of Deep Learning with TensorFlow III**  
Session 1: Modeling Music and Art: Google Brain’s Magenta Lab  
Session 2: Modeling Language: Natural Language Processing  
Session 3: Autoregressive Image Modeling w/ PixelCNN  
Session 4: Modeling Audio w/ Wavenet and NSynth  

# Github Contents Overview

| | Session | Description | Transcript | Homework |
| --- | --- | --- | --- | --- |
| Python Package | **[pycadl](https://github.com/pkmital/pycadl)** | Python package required for courses 2 and 3 | N/A | N/A |
|Installation| **[Installation](#installation-preliminaries)** | Setting up Python/Notebook and necessary libraries. | N/A | N/A |
|Preliminaries| **[Preliminaries with Python](session-0)** | Basics of working with Python and images. | N/A | N/A |
|1| **[Computing with Tensorflow](session-1)** | Working with a small dataset of images.  Dataset preprocessing.  Tensorflow basics.  Sorting/organizing a dataset. | [lecture-1.ipynb](session-1/lecture-1.ipynb) [Colab](https://colab.research.google.com/notebook#fileId=1bjXwBG0AqGcFbSP5pjjL1A981mBhhN0f) | [session-1.ipynb](session-1/session-1.ipynb) |
|2| **[Basics of Neural Networks](session-2)** | Learn how to create a Neural Network.  Learn to use a neural network to paint an image.  Apply creative thinking to the inputs, outputs, and definition of a network. | [lecture-2.ipynb](session-2/lecture-2.ipynb) | [session-2.ipynb](session-2/session-2.ipynb) |
|3| **[Unsupervised and Supervised Learning](session-3)** | Build an autoencoder.  Extend it with convolution, denoising, and variational layers.  Build a deep classification network.  Apply softmax and onehot encodings to classify audio using a Deep Convolutional Network. | [lecture-3.ipynb](session-3/lecture-3.ipynb) | [session-3.ipynb](session-3/session-3.ipynb) |
|4| **[Visualizing Representations](session-4)** | Visualize backpropped gradients, use them to create Deep Dream, extend Deep Dream w/ regularization.  Stylize images or synthesize new images with painterly or hallucinated aesthetics of another image. | [lecture-4.ipynb](session-4/lecture-4.ipynb) | [session-4.ipynb](session-4/session-4.ipynb) |
|5| **[Generative Models](session-5)** | Build a Generative Adversarial Network and extend it with a Variational Autoencoder.  Use the latent space of this network to perform latent arithmetic.  Build a character level Recurrent Neural Network using LSTMs.  Understand different ways of inferring with Recurrent Networks.  | [lecture-5.ipynb](session-5/lecture-5.ipynb) | [session-5-part-1.ipynb](session-5/session-5-part-1.ipynb), [session-5-part-2.ipynb](session-5/session-5-part-2.ipynb) |

<a name=""installation-preliminaries""></a>
# Installation Preliminaries

<!-- MarkdownTOC autolink=true autoanchor=true bracket=round -->

- [Quickstart Guide](#quickstart-guide)
    - [Method 1: pip Install](#method-1-pip-install)
    - [Method 2: Docker Installation](#method-2-docker-installation)
- [What is Notebook?](#what-is-notebook)
- [Docker Toolbox](#docker-toolbox)
- [Jupyter Notebook](#jupyter-notebook)
    - [OSX/Linux](#osxlinux)
    - [Windows/Docker Containers](#windowsdocker-containers)
- [Navigating to Notebook](#navigating-to-notebook)
- [Installing Python Packages](#installing-python-packages)
    - [Ubuntu/Linux 64-bit for Python 3.4](#ubuntulinux-64-bit-for-python-34)
    - [Ubuntu/Linux 64-bit for Python 3.5](#ubuntulinux-64-bit-for-python-35)
    - [OSX for Python 3.4 or Python 3.5](#osx-for-python-34-or-python-35)
    - [Other Linux/OSX varieties](#other-linuxosx-varieties)
- [CUDA/GPU instructions](#cudagpu-instructions)
- [Testing it](#testing-it)
- [CUDA/GPU instructions for MacOS](#cudagpu-instructions-for-macos)
- [Troubleshooting](#troubleshooting)
    - [ImportError: No module named 'tensorflow'](#importerror-no-module-named-tensorflow)
    - [AttributeError: module 'tensorflow' has no attribute '\_\_version\_\_'](#attributeerror-module-tensorflow-has-no-attribute-%5C%5Cversion%5C%5C)
    - [GPU-related issues](#gpu-related-issues)
    - [Protobuf library related issues](#protobuf-library-related-issues)
    - [Cannot import name 'descriptor'](#cannot-import-name-descriptor)
    - [Can't find setup.py](#cant-find-setuppy)
    - [SSLError: SSL_VERIFY_FAILED](#sslerror-sslverifyfailed)
    - [Jupyter Notebook Kernel is always busy \(Windows\)](#jupyter-notebook-kernel-is-always-busy-windows)
    - [Something Else!](#something-else)

<!-- /MarkdownTOC -->

The first course makes heavy usage of Jupyter Notebook.  This will be necessary for submitting the homeworks and interacting with the guided session notebooks I will provide for each assignment.  Follow along this guide and we'll see how to obtain all of the necessary libraries that we'll be using.  By the end of this, you'll have installed Jupyter Notebook, NumPy, SciPy, and Matplotlib.  While many of these libraries aren't necessary for performing the Deep Learning which we'll get to in later lectures, they are incredibly useful for manipulating data on your computer, preparing data for learning, and exploring results.

<a name=""quickstart-guide""></a>
## Quickstart Guide

**Please skip this section and read the rest of this readme if you are unfamiliar w/ Jupyter Notebook or installing Python libraries.  This section is only for advanced users who want to get started quickly.**

There are two ways to get started.  You can use a native pip installation or use Docker.  There is a quickstart guide for both methods below.  If you have trouble with these, then please skip to the more in depth guides below these sections.

<a name=""method-1-pip-install""></a>
### Method 1: pip Install

For those of you that are proficient w/ Python programming, you'll need Python 3.4+ and the latest TensorFlow which you can install via pip, e.g.:

```bash
$ pip install tensorflow
```

or w/ CUDA as:

```bash
$ pip install tensorflow-gpu
```

<a name=""method-2-docker-installation""></a>
### Method 2: Docker Installation

If you want a controlled environment w/ all dependencies installed for you, and are proficient w/ Docker and Jupyter, you can get started w/ this repo like so:

```bash
$ cd
$ git clone --recursive https://github.com/pkmital/CADL.git
$ cd CADL
$ docker build -t cadl .
$ docker run -it -p 8888:8888 -p 6006:6006 -v /$(pwd)/session-1:/notebooks --name tf cadl /bin/bash
```

Note that you can skip the build step and download from docker hub instead like so:

```bash
$ docker run -it -p 8888:8888 -p 6006:6006 -v /$(pwd)/session-1:/notebooks --name tf pkmital/cadl /bin/bash
```

Be sure to replace ""session-1"" with whichever session you are working on, e.g. ""session-2"", ""session-3""...  This will give you a bash prompt with the files for each session:

```bash
root@39c4441bcde8:/notebooks# ls
README.md  lecture-1.ipynb  libs  session-1.ipynb  tests
```

Which you can use to launch jupyter like so:

```bash
root@39c4441bcde8:/notebooks# jupyter notebook --allow-root
[I 01:45:27.712 NotebookApp] [nb_conda_kernels] enabled, 2 kernels found
[I 01:45:27.715 NotebookApp] Writing notebook server cookie secret to /root/.local/share/jupyter/runtime/notebook_cookie_secret
[W 01:45:27.729 NotebookApp] WARNING: The notebook server is listening on all IP addresses and not using encryption. This is not recommended.
[I 01:45:27.799 NotebookApp] [nb_anacondacloud] enabled
[I 01:45:27.802 NotebookApp] [nb_conda] enabled
[I 01:45:27.856 NotebookApp] ✓ nbpresent HTML export ENABLED
[W 01:45:27.856 NotebookApp] ✗ nbpresent PDF export DISABLED: No module named 'nbbrowserpdf'
[I 01:45:27.858 NotebookApp] Serving notebooks from local directory: /notebooks
[I 01:45:27.858 NotebookApp] 0 active kernels
[I 01:45:27.858 NotebookApp] The Jupyter Notebook is running at: http://[all ip addresses on your system]:8888/?token=dd68eeffd8f227dd789327c981d16b24631866e909bd6469
[I 01:45:27.858 NotebookApp] Use Control-C to stop this server and shut down all kernels (twice to skip confirmation).
```

Jupyter should then be running if you navigate Google Chrome (suggested!) to ""http://localhost:8888"".  If you navigate to the session-1.ipynb file, you will see the homework, or to ""lecture-1.ipynb"", to find the lecture transcripts.  The same goes for every other session.

If you need to relaunch the docker image again, you can write:

```bash
$ cd
$ cd CADL
$ docker start -i tf
```

If you want to use a GPU version, and have a Linux machine, and have an NVIDIA GPU, you can use [nvidia-docker](https://github.com/NVIDIA/nvidia-docker) (this only works for Linux machines! for non-Linux machines that want to use GPU, please follow the expanded directions below, or the quickstart pip installation above):

```bash
$ wget -P /tmp https://github.com/NVIDIA/nvidia-docker/releases/download/v1.0.0-rc.3/nvidia-docker_1.0.0.rc.3-1_amd64.deb
$ sudo dpkg -i /tmp/nvidia-docker*.deb && rm /tmp/nvidia-docker*.deb
$ nvidia-docker build -t cadl-gpu -f Dockerfile-gpu .
$ nvidia-docker run -it -p 8888:8888 -p 6006:6006 -v /$(pwd)/session-1:/notebooks --name tf cadl-gpu /bin/bash 
$ nvidia-docker start -i tf
```

If you had any trouble w/ this setup then please go through the rest of this document which provides much more in depth details.


<a name=""what-is-notebook""></a>
## What is Notebook?

Jupyter Notebook, previously called ""iPython Notebook"" prior to version 4.0, is a way of interacting with Python code using a web browser.  It is a very useful instructional tool that we will be using for all of our homework assignments.  Notebooks have the file extensions ""ipynb"" which are abbreviations of ""iPython Notebook"".  Some websites such as [nbviewer.ipython.org](http://nbviewer.ipython.org) or [www.github.com](http://www.github.com) can view `.ipynb` files directly as rendered HTML.  However, these are not *interactive* versions of the notebook, meaning, they are not running the python kernel which evaluates/interacts with the code.  So the notebook is just a static version of the code contained inside of it.

In order to interact with notebook and start coding, you will need to launch Terminal (for Mac and Linux users).  For Windows users, or for anyone having any problems with the Linux/Mac instructions, please follow the next section on [Docker Toolbox](#docker-toolbox) very closely!  If you are not a Windows user, please first try skipping over the next section and use the installation instructions in [Jupyter Notebook](#jupyter-notebook) before trying Docker as this solution will be much faster than running Docker.

<a name=""docker-toolbox""></a>
## Docker Toolbox

Currently, Windows users can only install Tensorflow via [pip using a 64-bit Python 3.5 environment](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/g3doc/get_started/os_setup.md#pip-installation-on-windows) or using Docker, as outlined below.

The easiest way to get up an running on any type of system is to use Docker.  Docker is a way of managing a ""virtual"" Linux machine on your computer which will aid the creation a machine capable of running Tensorflow.  First, please download and install the Docker Toolbox:

https://www.docker.com/products/docker-toolbox

Linux users can install docker using their favorite package manager.

For OSX and Windows users, you'll then need to run the ""Docker Quickstart Terminal"" which will launch a Terminal environment running on a virtual Linux machine on your computer. A virtual machine is basically an emulation of another machine. This is important because we'll use this machine to run Linux and install all of the necessary libraries for running Tensorflow.

Note for Windows users, if you have trouble launching the Docker Quickstart Terminal because you have ""Hyper-V"", please instead try using https://docs.docker.com/docker-for-windows/.  Then launch the newly installed ""Docker CLI"" program.

Once the Terminal is launched, either via Docker CLI or Docker Quickstart Terminal, run the following command (ignoring the `$` sign at the beginning of each line, which just denote that each line is a terminal command that you should type out exactly and then hit ENTER afterwards):

```shell
$ cd
$ docker-machine ip
```

If you are using Docker Toolbox, you should see your virtual machine's IP address as a result of the last command.  This is the location of your virtual machine.  <b>NOTE THIS IP ADDRESS</b>, as we'll need it in a second.  If you are using ""Docker for Windows"" instead, then you won't need this IP as we'll just use ""localhost"".

This next command will move to your ""home"" directory.  We'll then ""clone"" the github repo.  This will download everything for the course using ""git"".  If you have trouble w/ this step, make sure you have installed [git](https://git-scm.com/downloads).

```shell
$ cd
$ git clone --recursive https://github.com/pkmital/CADL.git
```

We'll now print out what the full path to that directory is.  PLEASE NOTE DOWN THIS DIRECTORY.  This is where everything will happen, and I'll explain that in a minute.

```shell
$ echo /$(pwd)/CADL
```

Now run the following command, which will download everything we need to run tensorflow, python, and jupyter notebook (again, ignore the ""$"" at the beginning of the line only)!

```shell
$ docker run -it -p 8888:8888 -p 6006:6006 -v /$(pwd)/CADL:/notebooks --name tf pkmital/cadl
```

What this is doing is:
    * Running the docker image [pkmital/cadl](https://hub.docker.com/r/pkmital/cadl/)
    * --name is giving it a shorthand name of ""tf""
    * -v is mirroring the directory ""/$(pwd)/CADL"" to the virtual machine's directory of ""/notebooks""
    * -p is forwarding ports from the virtual machine to your local machine so that you can access the virtual machine's port
    * -it is running it as an interactive process

You will want to put files inside the ""/notebooks"" directory *only*.  If you place files on the virtual machine outside of the ""/notebooks"" directory, which is the SAME as the ""CADL"" directory on your local machine, they will *not* be saved.  We are using Docker to mirror the ""CADL"" directory on a virtual machine which has everything necessary for us to code in Python and Tensorflow.  _Whatever is in that directory will be mirrored on the virtual machine's directory under `/notebooks`._

You can also try running the docker run command with any other directory. For instance:

```shell
$ docker run -it -p 8888:8888 -p 6006:6006 -v /Users/YOURUSERNAME/Desktop:/notebooks --name tf pkmital/cadl
```

Which would mean that your Desktop is where you can move files around so that on the virtual machine, you can interact with them under the `/notebooks`directory.

For OSX users, if you are installing Docker because you had installation problems using Anaconda and pip, you would instead write the following command (note the missing slash):

```shell
$ docker run -it -p 8888:8888 -p 6006:6006 -v $(pwd)/CADL:/notebooks --name tf pkmital/cadl
```

When you want to start this machine, you will launch the Docker Quickstart Terminal and then write:

```shell
$ cd
$ docker start -i tf
```

Notice that the command prompt will now be `#` instead of `$`.  You should have a new folder ""tensorflow"" inside your Home directory.  This directory will be empty to begin with.  Please make sure you do everything inside this directory only or else any files you make on your virtual machine WILL BE ERASED once it is shutdown!  When you clone the CADL repository, or expand the zip file downloads contents inside this directory via your Windows machine (it will be in your Home directory under a folder ""cadl""), then you will be able to access it via your Docker instance.

For instance, after running the `docker start -i tf` command, try going into the directory `/notebooks`:

```shell
# cd /notebooks
```

<a name=""jupyter-notebook""></a>
## Jupyter Notebook

<a name=""osxlinux""></a>
### OSX/Linux

Note: Windows/Docker users should scroll past this section to [""Windows/Docker""](#windows-docker-containers).  For OSX/Linux users, the easiest way to ensure you have Python 3.4 or higher and Jupter Notebook is to install Anaconda for Python 3.5 located here:

[OSX](https://docs.continuum.io/anaconda/install#anaconda-for-os-x-command-line-install) or [Linux](https://docs.continuum.io/anaconda/install#linux-install)

Make sure you restart your Terminal after you install Anaconda as there are some PATH variables that have to be set.

Then run the following:

```shell
$ curl https://bootstrap.pypa.io/ez_setup.py -o - | python
```

If you already have conda, but only have Python 2, you can very easily [add a new environment w/ Python 3](http://conda.pydata.org/docs/py2or3.html#create-a-python-3-5-environment) and switch back and forth as needed.  Or if you do not have Anaconda, but have a system based install, I'd really recommend either using Anaconda or [pyenv](https://github.com/yyuu/pyenv) to help you manage both python installations.

With Anaconda installed, you will have python and the package ""ipython[notebook]"", along with a ton of other very useful packages such as numpy, matplotlib, scikit-learn, scikit-image, and many others.

With everything installed, restart your Terminal application (on OSX, you can use Spotlight to find the Terminal application), and then navigate to the directory containing the ""ipynb"", or ""iPython Notebook"" file, by ""cd'ing"" (pronounced, see-dee-ing), into that directory.  This involves typing the command: ""cd some_directory"".  Once inside the directory of the notebook file, you will then type: ""jupyter notebook"".  If this command does not work, it means you do not have notebook installed!  Try installed anaconda as above, restart your Terminal application, or manually install notebook like so (ignore the ""$"" signs which just denote that this is a Terminal command that you should type out exactly and then hit ENTER!):

```shell
$ pip3 install ipython[notebook]
$ jupyter notebook
```

If you run into issues that say something such as:

```
[W 20:37:40.543 NotebookApp] Kernel not found: None
```

Then please try first running:

```shell
$ ipython3 kernel install
```

<a name=""windows-docker-containers"">
<a name=""windowsdocker-containers""></a>
### Windows/Docker Containers

For users running firewalls, you must make sure you have an exception as per [Jupyter Notebooks Firewall Instructions](http://jupyter-notebook.readthedocs.io/en/latest/public_server.html#firewall-setup) otherwise you may not be able to interact with the notebook.  Namely, you will need to allow connections from 127.0.0.1 (localhost) on ports from 49152 to 65535.  Once inside your Docker container as outlined above, you can now launch notebook like so:

```shell
$ cd /notebooks
$ jupyter notebook &
```

Note on Virtual versus Windows Directories:

This is tricky to grasp, mostly because I didn't explain it. Docker is ""virtual"" computer running inside your computer. It has its own filesystem and its own directories. So you can't reference your Windows machine's directories inside this machine. When you first ran docker (e.g. `$ docker run -it -p 8888:8888 -p 6006:6006 -v /$(pwd)/tensorflow:/notebooks --name tf pkmital/cadl`) it included as part of its command: `-v /$(pwd)/tensorflow:/notebooks`. What that was doing is ""mirroring"" a directory on your Windows machine inside your Virtual machine. So whatever was in your Windows machine under the directory `/$(pwd)/tensorflow` would appear in the Virtual machine under `/notebooks`. That Windows directory is likely `/Users/<YOURUSERNAME>/tensorflow`. So _ONLY_ inside that directory, create it if it doesn't exist, should you put files in order to access it on the Virtual machine.

So let's say your Username was ""pkmital"". Then your home directory would be `/Users/pkmital`, and you would have mirrored `/Users/pkmital/tensorflow` on your Windows Machine to the Virtual machine under `/notebook`. Now let's say I create a directory `/Users/pkmital/tensorflow/images` on my Windows Machine, and then put a bunch of png files in there. I will then see them in my Virtual machine under `/notebook/images`.  If I put the CADL repository inside `/Users/pkmital/tensorflow`, then I should have `/Users/pkmital/tensorflow/CADL/session-1/session-1.ipynb` and on the Virtual machine, it will be in `/notebooks/CADL/session-1/session-1.ipynb` - From this notebook, running on the virtual machine, accessed with Jupyter Notebook, I would access my images like so:

```python
import os
os.listdir('../../images')
```

<a name=""navigating-to-notebook""></a>
## Navigating to Notebook

After running ""jupyter notebook &"", you should see a message similar to:

```shell
root@182bd64f27d2:~# jupyter notebook &
[I 21:15:33.647 NotebookApp] Writing notebook server cookie secret to /root/.local/share/jupyter/runtime/notebook_cookie_secret
[W 21:15:33.712 NotebookApp] WARNING: The notebook server is listening on all IP addresses and not using encryption. This is not recommended.
[W 21:15:33.713 NotebookApp] WARNING: The notebook server is listening on all IP addresses and not using authentication. This is highly insecure and not recommended.
[I 21:15:33.720 NotebookApp] Serving notebooks from local directory: /root
[I 21:15:33.721 NotebookApp] 0 active kernels
[I 21:15:33.721 NotebookApp] The IPython Notebook is running at: http://[all ip addresses on your system]:8888/
[I 21:15:33.721 NotebookApp] Use Control-C to stop this server and shut down all kernels (twice to skip confirmation).
```

Don't worry if the IP address or command prompt look different.  Note where it says: `The IPython Notebook is running at`.  If you are running Docker (Windows users), this is where we need that IP address.  For OSX/Linux users, we'll use ""localhost"" so don't worry about this.  Now open up Chrome/Safari/Firefox whatever browser you like, and then navigate to:

http://localhost:8888

or for Windows users:

http://ADDRESS:8888

where ADDRESS is the ip address you should have noted down before. For instance, on my machine, I would visit the website:

http://192.168.99.100:8888

This will launch the Jupyter Notebook where you will be able to interact with the homework assignments!

<a name=""installing-python-packages""></a>
## Installing Python Packages

Packages are libraries or useful extensions to the standard python libraries.  In this course, we'll be using a few including Tensorflow, NumPy, MatPlotLib, SciPy, SciKit-Image, and SciKit-Learn.  Windows users will already have these libraries since the Docker container includes these.  However, if you needed to, you can install these using ""pip"", which is the python package manager.  OSX/Linux users should follow these steps just to be sure they have the latest versions of these packages. In Python 3.4 and higher, `pip` comes with any standard python installation.  In order to use `pip`, first make sure you are using the correct version.  One way to do this is check which pip you are running:

```shell
$ which pip
$ which pip3
```

Use which `pip` points to the install path that makes the most sense (e.g. Anaconda for OSX users for some reason does not symlink pip3 to the python3 pip, and instead points to the system version of python3).

Then you'll write:

```shell
$ pip3 install -U pip setuptools
```

To make sure you have an up to date pip, then:

```shell
$ pip3 install some_package
```

To get the necessary libraries:

```shell
$ pip3 install ""scikit-image>=0.11.3"" ""numpy>=1.11.0"" ""matplotlib>=1.5.1"" ""scikit-learn>=0.17""
```

This should get you all of the libraries we need for the course, EXCEPT for tensorflow.  Tensorflow is a special case, but can be `pip` installed in much the same way by pointing pip to the github repo corresponding to your OS like so.

<a name=""ubuntulinux-64-bit-for-python-34""></a>
### Ubuntu/Linux 64-bit for Python 3.4

```shell
$ pip3 install --upgrade https://storage.googleapis.com/tensorflow/linux/cpu/tensorflow-0.11.0rc1-cp34-cp34m-linux_x86_64.whl
```

<a name=""ubuntulinux-64-bit-for-python-35""></a>
### Ubuntu/Linux 64-bit for Python 3.5

```shell
$ pip3 install --upgrade https://storage.googleapis.com/tensorflow/linux/cpu/tensorflow-0.11.0rc1-cp35-cp35m-linux_x86_64.whl
```

<a name=""osx-for-python-34-or-python-35""></a>
### OSX for Python 3.4 or Python 3.5

```shell
$ pip3 install --upgrade https://storage.googleapis.com/tensorflow/mac/cpu/tensorflow-0.11.0rc1-py3-none-any.whl
```

<a name=""other-linuxosx-varieties""></a>
### Other Linux/OSX varieties

You can pip install Tensorflow for most OSX/Linux setups including those that are making use of NVIDIA GPUs and CUDA using one the packages listed on this link:
https://github.com/tensorflow/tensorflow/blob/master/tensorflow/g3doc/get_started/os_setup.md#pip-installation

If you are having trouble with pip installation, try looking here first: [Common Installation Problems](https://github.com/tensorflow/tensorflow/blob/37451589519d15207448dc2d9b1c0309de15d8db/tensorflow/g3doc/get_started/os_setup.md#common-problems).  Failing that, reach out to us on the forums, or else you may want to instead run a Docker instance as outlined in the Windows instructions above: [Setting up a Docker Container](#docker-toolbox).

<a name=""cudagpu-instructions""></a>
## CUDA/GPU instructions

Note that I have not provided instructions on getting setup w/ CUDA as it is beyond the scope of this course!  If you are interested in using GPU acceleration, I highly recommend using Ubuntu Linux and setting up a machine on [Nimbix](https://www.nimbix.net) or [Amazon EC2](https://aws.amazon.com/ec2/
) using the instructions here: https://github.com/tensorflow/tensorflow/blob/master/tensorflow/g3doc/get_started/os_setup.md#optional-install-cuda-gpus-on-linux.  If you're using Nimbix, you can skip the install process as there is already a machine pre-installed w/ Tensorflow.  Similarly, for Amazon EC2, there are many existing ""images"" of machines that have Tensorflow already installed.


<a name=""testing-it""></a>
## Testing it

To confirm it worked, try running:

```shell
$ python3 -c 'import tensorflow as tf; print(tf.__version__)'
```

You should see 1.0.0 printed, depending on which version you have installed.


<a name=""cudagpu-instructions-for-macos""></a>
## CUDA/GPU instructions for MacOS

When your Mac is equipped with a NVidia graphics card, you can use the GPU for computing with Tensorflow. GPU enabled computing is not supported for Macs with ATI or Intel graphics cards. 

If you have a previous cpu installation of tensorflow, uninstall it first:

```
$ pip3 uninstall tensorflow
```

Using homebrew, install the following packages:

```
$ brew install coreutils
$ brew tap caskroom/cask
$ brew cask install cuda
```
Once you have the CUDA Toolkit installed you will need to setup the required environment variables by adding the 
following to your `~/.profile`:
```
export CUDA_HOME=/usr/local/cuda
export DYLD_LIBRARY_PATH=""$DYLD_LIBRARY_PATH:$CUDA_HOME/lib""
export PATH=""$CUDA_HOME/bin:$PATH""
```
Tensorflow needs the library libcuda.1.dylib, so we have to create an additional symbolic link:
```
sudo ln -sf /usr/local/cuda/lib/libcuda.dylib /usr/local/cuda/lib/libcuda.1.dylib
```
Finally, you will also want to install the **CUDA Deep Neural Network** (cuDNN v5) library which currently requires an 
[_Accelerated Computing Developer Program_](https://developer.nvidia.com/cudnn) account. Once you have it downloaded 
locally, you can unzip and move the header and libraries to your local CUDA Toolkit folder:
```
$ sudo mv include/cudnn.h /Developer/NVIDIA/CUDA-8.0/include/
$ sudo mv lib/libcudnn* /Developer/NVIDIA/CUDA-8.0/lib
$ sudo ln -s /Developer/NVIDIA/CUDA-8.0/lib/libcudnn* /usr/local/cuda/lib/
```
Then, finally, install tensorflow with GPU support with:
```
$ pip3 install --ignore-installed --upgrade tensorflow-gpu
```

According to the instructions of the TensorFlow website, this should work. However, on MacOS 10.11 (El Capitan) and 
above, the environment variable `DYLD_LIBRARY_PATH` is ignored, resulting in an error in the interactive python console 
and JetBrains PyCharm IDE. The dynamic library `libcudart.8.0.dylib` fails to load. This
is due to a new protection meganism in MacOS 10.11 and higher. El Capitan ships with a new OS X feature: System 
Integrity Protection (SIP), also known as “rootless” mode. This reduces the attack surface for malware that relies on 
modifying system files by preventing any user, whether with system administrator (“root”) privileges or not from 
modifying a number of operating system directories and files.

**Warning:** The point of SIP is to prevent malware and other unwanted modifications into system files. Consider whether 
or not you want to dispense with this protection.
Follow these steps to disable SIP:

* Restart your Mac.
* Before OS X starts up, hold down Command-R and keep it held down until you see an Apple icon and a progress bar. Release. This boots you into Recovery.
* From the Utilities menu, select Terminal.
* At the prompt type exactly the following and then press Return: `csrutil disable`
* Terminal should display a message that SIP was disabled.
* From the  menu, select Restart.

You can re-enable SIP by following the above steps, but using `csrutil enable` instead.



<a name=""troubleshooting""></a>
## Troubleshooting

<a name=""importerror-no-module-named-tensorflow""></a>
### ImportError: No module named 'tensorflow'

You may have different versions of Python installed.  You can troubleshoot this by looking at the output of:

```shell
$ which python3
$ which pip3
$ python3 --version
$ pip3 --version
$ which python
$ which pip
$ python --version
$ pip --version
```

You may simply need to install tensorflow using `pip` instead of `pip3` and/or use `python` instead of `python3`, assuming they point to a version of python which is Python 3 or higher.

<a name=""attributeerror-module-tensorflow-has-no-attribute-%5C%5Cversion%5C%5C""></a>
### AttributeError: module 'tensorflow' has no attribute '\_\_version\_\_'

You could be running python inside a directory that contains the folder ""tensorflow"".  Try running python inside a different directory.


<a name=""gpu-related-issues""></a>
### GPU-related issues

If you encounter the following when trying to run a TensorFlow program:

```python
ImportError: libcudart.so.7.0: cannot open shared object file: No such file or directory
```

Make sure you followed the GPU installation [instructions](#optional-install-cuda-gpus-on-linux).
If you built from source, and you left the Cuda or cuDNN version empty, try specifying them
explicitly.

<a name=""protobuf-library-related-issues""></a>
### Protobuf library related issues

TensorFlow pip package depends on protobuf pip package version
3.0.0b2. Protobuf's pip package downloaded from [PyPI](https://pypi.python.org)
(when running `pip install protobuf`) is a Python only library, that has
Python implementations of proto serialization/deserialization which can be 10x-50x
slower than the C++ implementation. Protobuf also supports a binary extension
for the Python package that contains fast C++ based proto parsing. This
extension is not available in the standard Python only PIP package. We have
created a custom binary pip package for protobuf that contains the binary
extension. Follow these instructions to install the custom binary protobuf pip
package :

```bash
# Ubuntu/Linux 64-bit:
$ pip install --upgrade ht","This repository contains lecture transcripts and homework assignments as Jupyter
Notebooks for the first of three Kadenze Academy courses. It also contains a
python package containing all the code developed during all three courses. The
courses are: Creative Applications of Deep Learning with TensorFlow I, II and
III."
2383,Experimental demo of React Server Components with Next.js. Deployed serverlessly on Vercel.,"# Next.js 12 React Server Components Notes Demo (Alpha)

Try the demo live here: [**next-rsc-notes.vercel.app**](https://next-rsc-notes.vercel.app).

> **Warning**  
> This demo is built for showing what features that Server Components provide and what the application structure might look like.  
> **It's not ready for production adoption, or performance benchmarking** as the underlying APIs are not stable yet, and might change or be improved in the future. 

## Introduction

This is a demo app showing Next.js 12's experimental React Server Components support. It's based on the [React Server Components Demo](https://github.com/reactjs/server-components-demo) by the React team. We recommend you taking a look at these links, before trying out the experimental feature:
- [**Introducing Zero-Bundle-Size React Server Components**](https://reactjs.org/blog/2020/12/21/data-fetching-with-react-server-components.html)
- [**Everything About React Server Components**](https://vercel.com/blog/everything-about-react-server-components)
- [**Docs of React Server Components in Next.js**](https://nextjs.org/docs/advanced-features/react-18#react-server-components)

## Technical Details

This Next.js application uses React 18 (RC build), with `runtime` set to `'nodejs'` and feature flag `serverComponents` enabled. You can check out [next.config.js](https://github.com/vercel/server-components-notes-demo/blob/main/next.config.js) for more details. It also uses Redis to store the data, and GitHub's OAuth API for authentication. To develop it locally or host it, please follow these instructions:

### Preparation

These environment variables are required to start this application (you can create a `.env` file for Next.js to use):

```bash
REDIS_URL='rediss://:<password>@<url>:<port>' # or `redis://` if no TLS support
SESSION_KEY='your session key'
OAUTH_CLIENT_KEY='github oauth app id'
OAUTH_CLIENT_SECRET='github oauth app secret'
```

### Running Locally

1. `yarn install`
2. `yarn dev`

Go to `localhost:3000`.

### Deploy

You can quickly deploy the demo to Vercel by clicking this link:

[![Deploy with Vercel](https://vercel.com/button)](https://vercel.com/new/git/external?repository-url=https%3A%2F%2Fgithub.com%2Fvercel%2Fserver-components-notes-demo&env=REDIS_URL,SESSION_KEY,OAUTH_CLIENT_KEY,OAUTH_CLIENT_SECRET&project-name=next-rsc-notes&repo-name=next-rsc-notes&demo-title=React%20Server%20Components%20(Experimental%20Demo)&demo-description=Experimental%20demo%20of%20React%20Server%20Components%20with%20Next.js.%20&demo-url=https%3A%2F%2Fnext-rsc-notes.vercel.app&demo-image=https%3A%2F%2Fnext-rsc-notes.vercel.app%2Fog.png)

## Technical Details

This Next.js application uses React 18 (RC build) and the new [Edge Runtime](https://nextjs.org/docs/api-reference/edge-runtime). It has `runtime` set to `'edge'` and feature flag `serverComponents` enabled. You can check out [next.config.js](https://github.com/vercel/next-server-components/blob/main/next.config.js) for more details.

## License

This demo is MIT licensed.
","This is a demo app showing Next.js 12's experimental React Server Components
support. It's based on the [React Server Components Demo] by the React team. It
also uses Redis to store the data, and GitHub's OAuth API for authentication. To
develop it locally or host it, please follow these instructions:. You can
quickly deploy the demo to Vercel by clicking this link:. The demo is MIT
licensed, and you can use it with any version of Vercel you want."
625,"⚔️ Saber, PHP异步协程HTTP客户端 | PHP Coroutine HTTP client - Swoole Humanization Library","# Saber

[![Latest Version](https://img.shields.io/github/release/swlib/saber.svg?style=flat-square)](https://github.com/swlib/saber/releases)
[![Build Status](https://travis-ci.org/swlib/saber.svg?branch=master)](https://travis-ci.org/swlib/saber)
[![Php Version](https://img.shields.io/badge/php-%3E=7.1-brightgreen.svg?maxAge=2592000)](https://secure.php.net/)
[![Swoole Version](https://img.shields.io/badge/swoole-%3E=2.1.2-brightgreen.svg?maxAge=2592000)](https://github.com/swoole/swoole-src)
[![Saber License](https://img.shields.io/hexpm/l/plug.svg?maxAge=2592000)](https://github.com/swlib/saber/blob/master/LICENSE)

## 简介

HTTP军刀(呆毛王), `Swoole人性化组件库`之PHP高性能HTTP客户端, 基于Swoole原生协程, 支持多种风格操作, 底层提供高性能解决方案, 让开发者专注于功能开发, 从传统同步阻塞且配置繁琐的Curl中解放.

>  **[English Document](./README-EN.md)**

- 基于Swoole协程Client开发
- 人性化使用风格, ajax.js/axios.js/requests.py用户福音, 同时支持PSR风格操作
- 浏览器级别完备的Cookie管理机制, 完美适配爬虫/API代理应用
- 请求/响应/异常拦截器
- 多请求并发, 并发重定向优化
- 连接池, 自动化复用长连接
- 通道池(Chan): 最大连接数限制+无阻塞
- HTTPS连接, CA证书自动化支持
- HTTP/Socks5 Proxy支持
- WebSocket连接支持
- 毫秒级超时定时器
- 自动化 编码请求/解析响应 数据
- 响应报文自动编码转换
- 异步超大文件上传/下载, 断点重传
- 自动重试机制
- 单次并发数控制
- 多模式/超细粒度异常处理机制
- (=)浏览器级别缓存机制
- (=)随机UA生成器

------
<br>

## 安装

最好的安装方法是通过 [Composer](http://getcomposer.org/) 包管理器 :

```shell
composer require swlib/saber
```

------

## 依赖

- **PHP71** or later
- Swoole 2.1.2 or later
- **Swoole 4 is the best**

------
<br>

## 协程调度

Swoole底层实现协程调度, **业务层无需感知**, 开发者可以无感知的**用同步的代码编写方式达到异步IO的效果和超高性能**，避免了传统异步回调所带来的离散的代码逻辑和陷入多层回调中导致代码无法维护.

需要在`onRequet`, `onReceive`, `onConnect`等事件回调函数中使用, 或是使用go关键字包裹 (`swoole.use_shortname`默认开启).

```php
go(function () {
    echo SaberGM::get('http://httpbin.org/get');
})
```

------

## 目录
  - <a href=""#例子"">例子</a>
    - <a href=""#静态方法"">静态方法</a>
    - <a href=""#生成实例"">生成实例</a>
    - <a href=""#生成会话"">生成会话</a>
    - <a href=""#并发请求"">并发请求</a>
    - <a href=""#数据解析"">数据解析</a>
    - <a href=""#网络代理"">网络代理</a>
    - <a href=""#文件上传"">文件上传</a>
    - <a href=""#超大文件下载"">超大文件下载</a>
    - <a href=""#自动重试"">自动重试</a>
    - <a href=""#缓存机制"">缓存机制</a>
    - <a href=""#psr风格"">PSR风格</a>
    - <a href=""#websocket"">WebSocket</a>
    - <a href=""#极限压力测试"">极限压力测试</a>
    - <a href=""#列式请求集"">列式请求集</a>
    - <a href=""#单次并发控制"">单次并发控制</a>
    - <a href=""#高性能无极限协程连接池"">高性能无极限协程连接池</a>
      - <a href=""#无限连接池"">无限连接池</a>
      - <a href=""#定容连接池"">定容连接池</a>
      - <a href=""#动态变容"">动态变容</a>
  - <a href=""#注意事项"">注意事项</a>
    - <a href=""#注册你所希望的配置"">注册你所希望的配置</a>
      - <a href=""#注意在一次性脚本中释放连接池"">注意在一次性脚本中释放连接池</a>
  - <a href=""#配置参数表"">配置参数表</a>
    - <a href=""#配置参数别名"">配置参数别名</a>
  - <a href=""#拦截器"">拦截器</a>
  - <a href=""#cookies"">Cookies</a>
      - <a href=""#属性"">属性</a>
      - <a href=""#任意格式互转"">任意格式互转</a>
      - <a href=""#域名路径和过期时限校验"">域名路径和过期时限校验</a>
      - <a href=""#持久化存储"">持久化存储</a>
  - <a href=""#异常机制"">异常机制</a>
      - <a href=""#捕获例子"">捕获例子</a>
    - <a href=""#异常报告级别控制"">异常报告级别控制</a>
      - <a href=""#掩码表"">掩码表</a>
    - <a href=""#异常自定义处理函数"">异常自定义处理函数</a>
  - <a href=""#road-map"">Road Map</a>
      - <a href=""#why-not-http2-?"">Why not Http2 ?</a>
  - <a href=""#ide-helper"">IDE Helper</a>
  - <a href=""#重中之重"">重中之重</a>
  - <a href=""#附录"">附录</a>
    - <a href=""#saber-api"">Saber API</a>
      - <a href=""#swlibsabergm"">Swlib\SaberGM</a>
      - <a href=""#swlibsaber"">Swlib\Saber</a>
      - <a href=""#swlibsaberrequest"">Swlib\Saber\Request</a>
      - <a href=""#swlibsaberresponse"">Swlib\Saber\Response</a>
      - <a href=""#swlibsaberrequestqueue"">Swlib\Saber\RequestQueue</a>
      - <a href=""#swlibsaberresponsemap"">Swlib\Saber\ResponseMap</a>
      - <a href=""#swlibsaberwebsocket"">Swlib\Saber\WebSocket</a>
      - <a href=""#swlibsaberwebsocketframe"">Swlib\Saber\WebSocketFrame</a>

------

## 例子

### 静态方法

> 数据自动打包: 传入的data会自动转换成content-type所指定的类型格式
>
> 默认为`x-www-form-urlencoded`, 也支持`json`等其它格式

`SaberGM ` := `Saber Global Manager`, 如果觉得类名有点长, 可以使用`class_alias`自己取别名, 推荐服务中使用**生成实例**的方式使用, 而把`SaberGM`作为快捷方式.

```php
SaberGM::get('http://httpbin.org/get');
SaberGM::delete('http://httpbin.org/delete');
SaberGM::post('http://httpbin.org/post', ['foo' => 'bar']);
SaberGM::put('http://httpbin.org/put', ['foo' => 'bar']);
SaberGM::patch('http://httpbin.org/patch', ['foo' => 'bar']);
```

### 生成实例

适用API代理服务

```php
$saber = Saber::create([
    'base_uri' => 'http://httpbin.org',
    'headers' => [
        'Accept-Language' => 'en,zh-CN;q=0.9,zh;q=0.8',
        'Content-Type' => ContentType::JSON,
        'DNT' => '1',
        'User-Agent' => null
    ]
]);
echo $saber->get('/get');
echo $saber->delete('/delete');
echo $saber->post('/post', ['foo' => 'bar']);
echo $saber->patch('/patch', ['foo' => 'bar']);
echo $saber->put('/put', ['foo' => 'bar']);
```

### 生成会话

Session会自动保存cookie信息, 其实现是[**浏览器级别完备**](#cookies)的

```php
$session = Saber::session([
    'base_uri' => 'http://httpbin.org',
    'redirect' => 0
]);
$session->get('/cookies/set?foo=bar&k=v&apple=banana');
$session->get('/cookies/delete?k');
echo $session->get('/cookies')->body;
```

### 并发请求

注意: 此处使用了并发重定向优化方案, 多个重定向总是依旧并发的而不会退化为队列的单个请求
```php
$responses = SaberGM::requests([
    ['uri' => 'http://github.com/'],
    ['uri' => 'http://github.com/'],
    ['uri' => 'https://github.com/']
]);
echo ""multi-requests [ {$responses->success_num} ok, {$responses->error_num} error ]:\n"" .""consuming-time: {$responses->time}s\n"";

// multi-requests [ 3 ok, 0 error ]:
// consuming-time: 0.79090881347656s
```
```php
// 别名机制可以省略参数书写参数名
$saber = Saber::create(['base_uri' => 'http://httpbin.org']);
echo $saber->requests([
    ['get','/get'],
    ['post','/post'],
    ['patch','/patch'],
    ['put','/put'],
    ['delete','/delete']
]);
```

### 数据解析

目前支持`json`,`xml`,`html`,`url-query`四种格式的数据快速解析

```php
[$json, $xml, $html] = SaberGM::list([
    'uri' => [
        'http://httpbin.org/get',
        'http://www.w3school.com.cn/example/xmle/note.xml',
        'http://httpbin.org/html'
    ]
]);
var_dump($json->getParsedJsonArray());
var_dump($json->getParsedJsonObject());
var_dump($xml->getParsedXmlArray());
var_dump($xml->getParsedXmlObject(true));
var_dump($html->getParsedDomObject()->getElementsByTagName('h1')->item(0)->textContent);
```

### 网络代理

支持HTTP和SOCKS5代理

```php
$uri = 'http://myip.ipip.net/';
echo SaberGM::get($uri, ['proxy' => 'http://127.0.0.1:1087'])->body;
echo SaberGM::get($uri, ['proxy' => 'socks5://127.0.0.1:1086'])->body;
```

### 文件上传

底层自动协程调度, 可支持**异步发送超大文件**, **断点续传**

>同时上传三个文件(三种参数风格`string`| `array` |`object`)

```php
$file1 = __DIR__ . '/black.png';
$file2 = [
    'path' => __DIR__ . '/black.png',
    'name' => 'white.png',
    'type' => ContentType::$Map['png'],
    'offset' => null, //re-upload from break
    'size' => null //upload a part of the file
];
$file3 = new SwUploadFile(
    __DIR__ . '/black.png',
    'white.png',
    ContentType::$Map['png']
);

echo SaberGM::post('http://httpbin.org/post', null, [
        'files' => [
            'image1' => $file1,
            'image2' => $file2,
            'image3' => $file3
        ]
    ]
);
```

### 超大文件下载

Download收到数据后会直接异步写入到磁盘, 而不是在内存中对HttpBody进行拼接. 因此download仅使用**小量内存**, 就可以完成**超大文件**的下载. 且支持**断点续传**, 通过设置offset参数来进行断点下载.

> 异步下载Saber壁纸

```php
$download_dir = '/tmp/saber.jpg';
$response = SaberGM::download(
    'https://ws1.sinaimg.cn/large/006DQdzWly1fsr8jt2botj31hc0wxqfs.jpg',
    $download_dir
);
if ($response->success) {
    exec('open ' . $download_dir);
}
```

### 自动重试

在爬虫项目中, 请求失败自动重试是非常常见的需求, 比如会话过期后重新登录.

而`Saber`内置了此功能, 并可使用`拦截器`来强化它.

如未设置`retry_time`而设置了`retry`拦截器, 则`retry_time`会置为1, 如`retry`拦截器的回调方法返回了`false`, 无论`retry_time`是多少, 都会在返回`false`时终止重试.

```PHP
$uri = 'http://eu.httpbin.org/basic-auth/foo/bar';
$res = SaberGM::get(
    $uri, [
        'exception_report' => 0,
        'retry_time' => 3,
        'retry' => function (Saber\Request $request) {
            echo ""retry...\n"";
            $request->withBasicAuth('foo', 'bar'); //发现失败后添加验证信息
            if ('i don not want to retry again') {
                return false; // shutdown
            }
        }
    ]
);
echo $res;
```

### 缓存机制

有时候HTTP资源并不会总是变更, 我们可以学习浏览器缓存不会变动的资源, 来加快请求效率, 由`Saber`自动化地完成且不必自己维护缓存逻辑(CURD或文件读写), 协程的调度使得其不论如何都不会阻塞服务器, `Saber`没有使用中间件机制因为它和Swoole是强相关的, 但是缓存可以使用 `内存/文件/数据库` 等多种方式, 所以虽然它尚未实现, 但它将会列入`Saber`的后续路线图中.

### PSR风格

```php
$response = SaberGM::psr()
    ->withMethod('POST')
    ->withUri(new Uri('http://httpbin.org/post?foo=bar'))
    ->withQueryParams(['foo' => 'option is higher-level than uri'])
    ->withHeader('content-type', ContentType::JSON)
    ->withBody(new BufferStream(json_encode(['foo' => 'bar'])))
    ->exec()->recv();

echo $response->getBody();
```

### WebSocket

> 可以通过websocketFrame数据帧的__toString方法直接打印返回数据字符串

```php
$websocket = SaberGM::websocket('ws://127.0.0.1:9999');
while (true) {
    echo $websocket->recv(1) . ""\n"";
    $websocket->push(""hello"");
    co::sleep(1);
}
```

### 极限压力测试

> 测试机器为最低配MacBookPro, 请求服务器为本地echo服务器

**0.9秒完成6666个请求**, 成功率100%.

```php
co::set(['max_coroutine' => 8191]);
go(function () {
    $requests = [];
    for ($i = 6666; $i--;) {
        $requests[] = ['uri' => 'http://127.0.0.1'];
    }
    $res = SaberGM::requests($requests);
    echo ""use {$res->time}s\n"";
    echo ""success: $res->success_num, error: $res->error_num"";
});
// on MacOS
// use 0.91531705856323s
// success: 6666, error: 0
```

### 列式请求集

在实际项目中, 经常会存在使用URL列表来配置请求的情况, 因此提供了list方法来方便使用:

```php
echo SaberGM::list([
    'uri' => [
        'https://www.qq.com/',
        'https://www.baidu.com/',
        'https://www.swoole.com/',
        'http://httpbin.org/'
    ]
]);
```

### 单次并发控制

在实际爬虫项目中, 我们往往要限制单次并发请求数量以防被服务器防火墙屏蔽, 而一个`max_co`参数就可以轻松地解决这个问题, `max_co`会将请求根据上限量分批将请求压入队列并执行收包.

```php
// max_co is the max number of concurrency request once, it's very useful to prevent server-waf limit.
$requests = array_fill(0, 10, ['uri' => 'https://www.qq.com/']);
echo SaberGM::requests($requests, ['max_co' => 5])->time.""\n"";
echo SaberGM::requests($requests, ['max_co' => 1])->time.""\n"";
```

<br>

### 高性能无极限协程连接池

在常驻内存的服务器中使用时, **一定要手动开启连接池选项**:

```php
$swoole = Saber::create([
    'base_uri' => 'https://www.swoole.com/',
    'use_pool' => true
]);
```

在通过该实例使用时, 就会启用连接池特性, 即底层与`www.swoole.com`网站的连接客户端将会用一个全局连接池存取, 避免了每次使用创建/连接的开销.

#### 无限连接池

在参数为`true`时, 该网站的连接池容量是**无限**的, 一般情况下没有问题, 且无限容量的连接池性能更好.

#### 定容连接池

但如果你使用其作为爬虫代理服务, 遭遇**大量请求**时, 连接池中的客户端数量就会不可控制地快速上升, 甚至超出你所请求的源网站的最大允许连接数, 这时候你就需要将`use_pool`设置为一个**理想数值**(int), 此时, 底层会使用Channel作为连接池, 在连接池创建的客户端超出数量且不够取用时, 挂起需要取用客户端的协程, 并等待正在使用客户端的协程归还客户端, 协程等待和切换几乎没有多大的性能消耗, 是一种**非常先进**的解决方式.

#### 动态变容

需要注意的是, 连接池是绑定`服务器IP+端口`的, 即如果你有多个实例面向的是同一个`服务器IP+端口`, 他们之间使用的连接池也是同一个.

所以你在重复创建`服务器IP+端口`的实例时, 新创建的实例指定的`use_pool`是允许覆盖之前数值的, 即连接池底层是自动变容的, 容量增加时底层会重新创建新的连接池并转移客户端, 容量减少时也会销毁在连接池内的多余的客户端.

## 注意事项

### 注册你所希望的配置

除了一定要记得配备连接池以外, 异常处理的方式也需要注意是符合你的编程习惯的, `Saber`默认的异常处理是最主流且严谨的`抛出异常`, 但`Saber`也支持静默地使用`错误码`和`状态位`, 可能更符合很多人的口味.

```php
SaberGM::exceptionReport(0); // 关闭抛出异常报告, 在业务代码之前注册即可全局生效
$saber->exceptionReport(0);  //也可以单独设置某个实例
```

同理, 你所希望的配置都可以在业务代码之前如`onWorkerStart`甚至是`swoole_server`启动之前预先配置.

```php
SaberGM::default([
    'exception_report' => 0
    'use_pool' => true
]);
```

像这样配置你所期望的选项可以让你获得更好的使用体验!

#### 注意在一次性脚本中释放连接池

```php
go(function(){
    // your code with pool...
    saber_pool_release(); // and this script will exit
});
```

如果你在一次性脚本中使用的连接池, 由于协程客户端是存在池中的, 引用计数为1无法释放, 就会导致swoole一直处于事件循环中, 脚本就无法退出, 你需要手动调用`saber_pool_release`或`saber_exit`或`swoole_event_exit`来正常退出, 也可以使用exit强制退出当前脚本(不要在server中使用exit).

------

## 配置参数表

> `|`符号分割多种可选值

| key                   | type                  | introduction       | example                                                      | remark                                                       |
| --------------------- | --------------------- | ------------------ | ------------------------------------------------------------ | ------------------------------------------------------------ |
| protocol_version      | string                | HTTP协议版本       | 1.1                                                          | HTTP2还在规划中                                              |
| base_uri              | string                | 基础路径           | `http://httpbin.org`                                         | 将会与uri按照rfc3986合并                                     |
| uri                   | string                | 资源标识符         | `http://httpbin.org/get` \| `/get` \| `get`                  | 可以使用绝对路径和相对路径                                   |
| uri_query             | string\|array         | 请求信息           | `['foo' => 'bar']`                                           | 非字符串会自动转换                                           |
| method                | string                | 请求方法           | `get` \| `post` \| `head` \| `patch` \| `put` \| `delete`    | 底层自动转换为大写                                           |
| headers               | array                 | 请求报头           | `['DNT' => '1']` \| `['accept' => ['text/html'], ['application/xml']]` | 字段名不区分大小写, 但会保留设定时的原始大小写规则, 底层每个字段值会根据PSR-7自动分割为数组 |
| cookies               | `array`\|`string`     |                    | `['foo '=> 'bar']` \| `'foo=bar; foz=baz'`                   | 底层自动转化为Cookies对象, 并设置其domain为当前的uri, 具有[浏览器级别的完备属性](#cookies). |
| useragent             | string                | 用户代理           | `curl-1.0`                                                   | 默认为macos平台的chrome                                      |
| referer               | string                | 来源地址           | `https://www.google.com`                                     | 默认为空                                                     |
| redirect              | int                   | 最大重定向次数     | 5                                                            | 默认为3, 为0时不重定向.                                      |
| keep_alive            | bool                  | 是否保持连接       | `true` \| `false`                                            | 默认为true, 重定向时会自动复用连接                           |
| content_type          | string                | 发送的内容编码类型 | `text/plain` \| `Swlib\Http\ContentType::JSON`               | 默认为application/x-www-form-urlencoded                      |
| data                  | `array` \| `string`   | 发送的数据         | `'foo=bar&dog=cat'` \|` ['foo' => 'bar']`                    | 会根据content_type自动编码数据                               |
| before                | `callable` \| `array` | 请求前拦截器       | `function(Request $request){}`                               | [具体参考拦截器一节](#拦截器)                                |
| after                 | `callable` \| `array` | 响应后拦截器       | `function(Response $response){}`                             | [具体参考拦截器一节](#拦截器)                                |
| before_redirect       | `callable` \| `array` | 重定向后拦截器     | `function(Request $request, Response $response){}`           | [具体参考拦截器一节](#拦截器)                                |
| timeout               | float                 | 超时时间           | 0.5                                                          | 默认5s, 支持毫秒级超时                                       |
| proxy                 | string                | 代理               | `http://127.0.0.1:1087` \| `socks5://127.0.0.1:1087`         | 支持http和socks5                                             |
| ssl                   | int                   | 是否开启ssl连接    | `0=关闭` `1=开启` `2=自动`                                   | 默认自动                                                     |
| cafile                | string                | ca文件             | `__DIR__ . '/cacert.pem'`                                    | 默认自带                                                     |
| ssl_verify_peer       | bool                  | 验证服务器端证书   | `false` \| `true`                                            | 默认关闭                                                     |
| ssl_allow_self_signed | bool                  | 允许自签名证书     | `true` \| `false`                                            | 默认允许                                                     |
| iconv                 | array                 | 指定编码转换       | `['gbk', 'utf-8']`                                           | 共三个参数为`from,to,use_mb`, 默认自动识别                   |
| exception_report      | int                   | 异常报告级别       | HttpExceptionMask::E_ALL                                     | 默认汇报所有异常                                             |
| exception_handle      | callable\|array       | 异常自定义处理函数 | `function(Exception $e){}`                                   | 函数返回true时可忽略错误                                     |
| retry                 | callable              | 自动重试拦截器     | `function(Request $request, Response $response){}`           | 位于发生错误后及重试之前                                     |
| retry_time            | int                   | 自动重试次数       |                                                              | 默认不重试                                                   |
| use_pool              | bool\|int             | 连接池             | `true`                                                       | `false`                                                      |

### 配置参数别名

为了使用方便与容错, 配置项的键值具有别名机制, 建议尽量使用本名: 

| key      | alias       |
| -------- | ----------- |
|method|0|
|uri|`1` \| `url`|
|data|`2` \| `body`|
|base_uri|base_url|
|after|callback|
|content_type|`content-type` \| `contentType`|
|cookies|cookie|
|headers|header|
|redirect|follow|
|useragent|`ua` \| `user-agent`|
|exception_report|`error_report` \| `report`|
|before_retry|retry|
|referer|`ref` \| `referrer`|


<br>

------

## 拦截器

拦截器是Saber的一个**非常强大的特性**, 它可以让你非常方便地处理各种事情, 比如打印dev日志:

```php
SaberGM::get('http://twosee.cn/', [
    'before' => function (Saber\Request $request) {
        $uri = $request->getUri();
        echo ""log: request $uri now...\n"";
    },
    'after' => function (Saber\Response $response) {
        if ($response->success) {
            echo ""log: success!\n"";
        } else {
            echo ""log: failed\n"";
        }
        echo ""use {$response->time}s"";
    }
]);
// log: request http://twosee.cn/ now...
// log: success!
// use 0.52036285400391s
```

甚至连`异常自定义处理函数`,`会话`都是通过拦截器来实现的.

拦截器可以有多个, 会依照注册顺序执行, 并且你可以**为拦截器命名**, 只需要使用数组包裹并指定key值, 如果你要删除这个拦截器, 给它覆盖一个null值即可.

```php
[
    'after' => [
        'interceptor_new' => function(){},
        'interceptor_old' => null
    ]
]
```

拦截器可以使用四种方式注册([4种PHP回调函数](http://twosee.cn/2018/01/04/PHP-callback/)):

```php
callable: function(){}
string: 'function_name'
string: 'ClassName::method_name'
array: [$object, 'method_name']
```

<br>

------

## Cookies

Cookie的实现是**浏览器级别完备**的, 它具体参考了Chrome浏览器的实现, 并遵循其相关规则.

#### 属性

Cookies是一堆Cookie的集合, 而每个Cookie具有以下属性:

 `name`, `value`, `expires`, `path`, `session`, `secure`, `httponly`, `hostonly`

#### 任意格式互转

并且Cookies类支持多种格式互转, 如

- `foo=bar; foz=baz; apple=banana`

- `Set-Cookie: logged_in=no; domain=.github.com; path=/; expires=Tue, 06 Apr 2038 00:00:00 -0000; secure; HttpOnly`

- `['foo'=>'bar', 'foz'=>'baz']`

等格式转到Cookie类, 或是Cookie类到该几种格式的序列化.

#### 域名路径和过期时限校验

Cookie也支持域名和时限校验, 不会丢失任何信息, 如domain是`github.com`cookie, 不会出现在`help.github.com`, 除非domain不是hostonly的(`.github.com`通配).

如果是session-cookie(没有过期时间,浏览器关闭则过期的), expires属性会设置为当前时间, 你可以通过**拦截器**来对其设置具体的时间.

#### 持久化存储

通过读取Cookies的raw属性, 可以轻松地将其**持久化到数据库中**, 非常适合登录类爬虫应用.

> 更多详情具体请参考[Swlib/Http](https://github.com/swlib/http/)库文档和例子.

<br>

------

## 异常机制

Saber遵循将**业务与错误**分离的守则, 当请求任意环节失败时, **默认都将会抛出异常**.

强大的是, Saber的异常处理也是多样化的, 且和PHP的原生的异常处理一样完善.

异常的命名空间位于`Swlib\Http\Exception`

| Exception                 | Intro              | scene                                                        |
| ------------------------- | ------------------ | ------------------------------------------------------------ |
| RequestException          | 请求失败           | 请求配置错误                                                 |
| ConnectException          | 连接失败           | 如无网络连接, DNS查询失败, 超时等,  errno的值等于Linux errno。可使用swoole_strerror将错误码转为错误信息。 |
| TooManyRedirectsException | 重定向次数超限     | 重定向的次数超过了设定的限制, 抛出的异常将会打印重定向追踪信息 |
| ClientException           | 客户端异常         | 服务器返回了4xx错误码                                        |
| ServerException           | 服务器异常         | 服务器返回了5xx错误码                                        |
| BadResponseException      | 未知的获取响应失败 | 服务器无响应或返回了无法识别的错误码                         |

除一般异常方法外, 所有HTTP异常类还拥有以下方法 :

| Method                 | Intro                  |
| ---------------------- | ---------------------- |
| getRequest             | 获取请求实例           |
| hasResponse            | 是否获得响应           |
| getResponse            | 获取响应实例           |
| getResponseBodySummary | 获取响应主体的摘要内容 |

#### 捕获例子

```php
try {
    echo SaberGM::get('http://httpbin.org/redirect/10');
} catch (TooManyRedirectsException $e) {
    var_dump($e->getCode());
    var_dump($e->getMessage());
    var_dump($e->hasResponse());
    echo $e->getRedirectsTrace();
}
// int(302)
// string(28) ""Too many redirects occurred!""
// bool(true)
#0 http://httpbin.org/redirect/10
#1 http://httpbin.org/relative-redirect/9
#2 http://httpbin.org/relative-redirect/8
```

### 异常报告级别控制

同时, Saber亦支持以温和的方式来对待异常, 以免使用者陷入在不稳定的网络环境下, 必须在每一步都使用try包裹代码的恐慌中:

设定errorReport级别, 它是**全局生效**的, 对**已创建的实例不会生效**.

```php
// 启用所有异常但忽略重定向次数过多异常
SaberGM::exceptionReport(
    HttpExceptionMask::E_ALL ^ HttpExceptionMask::E_REDIRECT
);
```

#### 掩码表

下面的值（数值或者符号）用于建立一个二进制位掩码，来制定要报告的错误信息。可以使用按位运算符来组合这些值或者屏蔽某些类型的错误。[标志位与掩码](http://twosee.cn/2018/04/06/mask-code/)

| Mask           | Value | Intro                |
| -------------- | ----- | -------------------- |
| E_NONE         | 0     | 忽略所有异常         |
| E_REQUEST      | 1     | 对应RequestException |
| E_CONNECT      | 2     | 对应RequestException |
| E_REDIRECT     | 4     | 对应RequestException |
| E_BAD_RESPONSE | 8     | 对应BadRException    |
| E_CLIENT       | 16    | 对应ClientException  |
| E_SERVER       | 32    | 对应ServerException  |
| E_ALL          | 63    | 所有异常             |

### 异常自定义处理函数

本函数可以用你自己定义的方式来处理HTTP请求中产生的错误, 可以更加随心所欲地定义你想要捕获/忽略的异常.

注意: 除非函数返回 **TRUE** (或其它真值)，否则异常会继续抛出而不是被自定义函数捕获.

```php
SaberGM::exceptionHandle(function (\Exception $e) {
    echo get_class($e) . "" is caught!"";
    return true;
});
SaberGM::get('http://httpbin.org/redirect/10');
//output: Swlib\Http\Exception\TooManyRedirectsException is caught!
```

<br>

------

## Road Map

| File Upload  ✔    | WebSocket ✔ | AutoParser✔ | AutoRetry✔ | BigFile Download✔ | Cache | ClientPool | Random UA |
| ----------------- | ----------- | ----------- | --------- | --------- | --------- | ----- | ----------------- |
| 4 (High-priority) | 3           | 2           | 1         | .5        | .5       | .5 | .175 |

#### Why not Http2 ?

As the main HTTP/2 benefit is that it allows multiplexing many requests within a single connection, thus [almost] removing the limit on number of simultaneous requests - and there is no such limit when talking to your own backends. Moreover, things may even become worse when using HTTP/2 to backends, due to single TCP connection being used instead of multiple ones, so Http2 Will not be a priority. ([\#ref](https://www.zhihu.com/question/268666424/answer/347026835))

------

## IDE Helper

将本项目源文件加入到IDE的 `Include Path` 中.

 (使用composer安装,则可以包含整个vendor文件夹, PHPStorm会自动包含)

良好的注释书写使得Saber完美支持IDE自动提示, 只要在对象后书写箭头符号即可查看所有对象方法名称, 名称都十分通俗易懂, 大量方法都遵循**PSR**规范或是参考[Guzzle](https://github.com/guzzle/guzzle)项目(感谢)而实现.

对于底层Swoole相关类的IDE提示则需要引入eaglewu的[swoole-ide-helper](https://github.com/eaglewu/swoole-ide-helper)(composer在dev环境下会默认安装), 但是该项目为手动维护, 不太完整, 也可以使用[swoft-ide-helper](https://github.com/swoft-cloud/swoole-ide-helper)或:

**Swoole官方的[ide-helper](https://github.com/swoole/ide-helper/)并运行`php dump.php`生成一下.**

<br>

------

## 重中之重

**欢迎提交issue和PR.**

<br>

------

## 附录

### Saber API

> 由于无法在魔术方法中使用协程(\_\_call, \_\_callStatic), 源码中的方法都是手动定义.

为了使用方便，已为所有支持的请求方法提供了别名。

#### Swlib\SaberGM
```php
public static function psr(array $options = []): Swlib\Saber\Request
public static function wait(): Swlib\Saber
public static function request(array $options = [])
public static function get(string $uri, array $options = [])
public static function delete(string $uri, array $options = [])
public static function head(string $uri, array $options = [])
public static function options(string $uri, array $options = [])
public static function post(string $uri, $data = null, array $options = [])
public static function put(string $uri, $data = null, array $options = [])
public static function patch(string $uri, $data = null, array $options = [])
public static function download(string $uri, string $dir, int $offset, array $options = [])
public static function requests(array $requests, array $default_options = []): Swlib\Saber\ResponseMap
public static function list(array $options, array $default_options = []): Swlib\Saber\ResponseMap
public static function websocket(string $uri)
public static function default(?array $options = null): array
public static function exceptionReport(?int $level = null): int
public static function exceptionHandle(callable $handle): void
```
#### Swlib\Saber
```php
public static function create(array $options = []): self
public static function session(array $options = []): self
public static function websocket(string $uri): WebSocket
public function request(array $options)
public function get(string $uri, array $options = [])
public function delete(string $uri, array $options = [])
public function head(string $uri, array $options = [])
public function options(string $uri, array $options = [])
public function post(string $uri, $data = null, array $options = [])
public function put(string $uri, $data = null, array $options = [])
public function patch(string $uri, $data = null, array $options = [])
public function download(string $uri, string $dir, int $offset, array $options = [])
public function requests(array $requests, array $default_options = []): ResponseMap
public function list(array $options, array $default_options = []): ResponseMap
public function upgrade(?string $path = null): WebSocket
public function psr(array $options = []): Request
public function wait(): self
public function exceptionReport(?int $level = null): int
public function exceptionHandle(callable $handle): void
public static function getAliasMap(): array
public function setOptions(array $options = [], ?Swlib\Saber\Request $request = null): self
public static function getDefaultOptions(): array
public static function setDefaultOptions(array $options = [])
```
#### Swlib\Saber\Request
```php
public function getExceptionReport(): int
public function setExceptionReport(int $level): self
public function isWaiting(): bool
public function getPool()
public function withPool($bool_or_max_size): self
public function tryToRevertClientToPool(bool $connect_failed = false)
public function getSSL(): int
public function withSSL(int $mode = 2): self
public function getCAFile(): string
public function withCAFile(string $ca_file = '/Users/twosee/Toast/swlib/saber/src/cacert.pem'): self
public function withSSLVerifyPeer(bool $verify_peer = false, ?string $ssl_host_name = ''): self
public function withSSLAllowSelfSigned(bool $allow = true): self
public function getSSLConf()
public function getKeepAlive()
public function withKeepAlive(bool $enable): self
public function withBasicAuth(?string $username = null, ?string $password = null): self
public function withXHR(bool $enable = true)
public function getProxy(): array
public function withProxy(string $host, int $port): self
public function withSocks5(string $host, int $port, ?string $username, ?string $password): self
public function withoutProxy(): self
public function getTimeout(): float
public function withTimeout(float $timeout): self
public function getRedirect(): int
public function getName()
public function withName($name): self
public function withRedirect(int $time): self
public function isInQueue(): bool
public function withInQueue(bool $enable): self
public function getRetryTime(): int
public function withRetryTime(int $time): self
public function withAutoIconv(bool $enable): self
public function withExpectCharset(string $source = 'auto', string $target = 'utf-8', bool $use_mb = false): self
public function withDownloadDir(string $dir): self
public function withDownloadOffset(int $offset): self
public function resetClient($client)
public function exec()
public function recv()
public function getRequestTarget(): string
public function withRequestTarget($requestTarget): self
public function getMethod(): string
public function withMethod($method): self
public function getUri(): Psr\Http\Message\UriInterface
public function withUri(?Psr\Http\Message\UriInterface $uri, $preserveHost = false): self
public function getCookieParams(): array
public function getCookieParam(string $name): string
public function withCookieParam(string $name, ?string $value): self
public function withCookieParams(array $cookies): self
public function getQueryParam(string $name): string
public function getQueryParams(): array
public function withQueryParam(string $name, ?string $value): self
public function withQueryParams(array $query): self
public function getParsedBody(?string $name = null)
public function withParsedBody($data): self
public function getUploadedFile(string $name): Psr\Http\Message\UploadedFileInterface
public function getUploadedFiles(): array
public function withUploadedFile(string $name, ?Psr\Http\Message\UploadedFileInterface $uploadedFile): self
public function withoutUploadedFile(string $name): self
public function withUploadedFiles(array $uploadedFiles): self
public function __toString()
public function getProtocolVersion(): string
public function withProtocolVersion($version): self
public function hasHeader($name): bool
public function getHeader($name): array
public function getHeaderLine($name): string
public function getHeaders(bool $implode = false, bool $ucwords = false): array
public function getHeadersString(bool $ucwords = true): string
public function withHeader($raw_name, $value): self
public function withHeaders(array $headers): self
public function withAddedHeaders(array $headers): self
public function withAddedHeader($raw_name, $value): self
public function withoutHeader($name): self
public function getBody(): Psr\Http\Message\StreamInterface
public function withBody(?Psr\Http\Message\StreamInterface $body): self
public function getCookies()
public function setCookie(array $options): self
public function unsetCookie(string $name, string $path = '', string $domain = ''): self
public function withInterceptor(string $name, array $interceptor)
public function withAddedInterceptor(string $name, array $functions): self
public function removeInterceptor(string $name): self
public function callInterceptor(string $name, $arguments)
public function getSpecialMark(string $name = 'default')
public function withSpecialMark($mark, string $name = 'default'): self
```
#### Swlib\Saber\Response
```php
public function isSuccess(): bool
public function getUri(): Psr\Http\Message\UriInterface
public function getTime(): float
public function getRedirectHeaders(): array
public function getStatusCode()
public function withStatus($code, $reasonPhrase = '')
public function getReasonPhrase()
public function __toString()
public function getProtocolVersion(): string
public function withProtocolVersion($version): self
public function hasHeader($name): bool
public function getHeader($name): array
public function getHeaderLine($name): string
public function getHeaders(bool $implode = false, bool $ucwords = false): array
public function getHeadersString(bool $ucwords = true): string
public function withHeader($raw_name, $value): self
public function withHeaders(array $headers): self
public function withAddedHeaders(array $headers): self
public function withAddedHeader($raw_name, $value): self
public function withoutHeader($name): self
public function getBody(): Psr\Http\Message\StreamInterface
public function withBody(?Psr\Http\Message\StreamInterface $body): self
public function getCookies()
public function setCookie(array $options): self
public function unsetCookie(string $name, string $path = '', string $domain = ''): self
public function getSpecialMark(string $name = 'default')
public function withSpecialMark($mark, string $name = 'default'): self
public function getParsedJsonArray(bool $reParse = false): array
public function getParsedJsonObject(bool $reParse = false): object
public function getParsedQueryArray(bool $reParse = false): array
public function getParsedXmlArray(bool $reParse = false): array
public function getParsedXmlObject(bool $reParse = false): SimpleXMLElement
public function getParsedDomObject(bool $reParse = false): DOMDocument
public function getDataRegexMatch(string $regex, $group = null, int $fill_size)
public function getDataRegexMatches(string $regex, i","Summarize: # Saber is a web app that lets users control a web browser. It lets
users access the web browser from any browser. The code is open-source and free
to download and use. It's available on GitHub and Travis CI."
2946,Deep Learning for humans,"# Keras: Deep Learning for humans

![Keras logo](https://s3.amazonaws.com/keras.io/img/keras-logo-2018-large-1200.png)

This repository hosts the development of the Keras library.
Read the documentation at [keras.io](https://keras.io/).

## About Keras

Keras is a deep learning API written in Python,
running on top of the machine learning platform [TensorFlow](https://github.com/tensorflow/tensorflow).
It was developed with a focus on enabling fast experimentation.
*Being able to go from idea to result as fast as possible is key to doing good research.*

Keras is:

-   **Simple** -- but not simplistic. Keras reduces developer *cognitive load*
    to free you to focus on the parts of the problem that really matter.
-   **Flexible** -- Keras adopts the principle of *progressive disclosure of
    complexity*: simple workflows should be quick and easy, while arbitrarily
    advanced workflows should be *possible* via a clear path that builds upon
    what you've already learned.
-   **Powerful** -- Keras provides industry-strength performance and
    scalability: it is used by organizations and companies including NASA,
    YouTube, and Waymo.

---

## Keras & TensorFlow 2

[TensorFlow 2](https://www.tensorflow.org/) is an end-to-end, open-source machine learning platform.
You can think of it as an infrastructure layer for
[differentiable programming](https://en.wikipedia.org/wiki/Differentiable_programming).
It combines four key abilities:

- Efficiently executing low-level tensor operations on CPU, GPU, or TPU.
- Computing the gradient of arbitrary differentiable expressions.
- Scaling computation to many devices, such as clusters of hundreds of GPUs.
- Exporting programs (""graphs"") to external runtimes such as servers, browsers, mobile and embedded devices.

Keras is the high-level API of TensorFlow 2: an approachable, highly-productive interface
for solving machine learning problems,
with a focus on modern deep learning. It provides essential abstractions and building blocks for developing
and shipping machine learning solutions with high iteration velocity.

Keras empowers engineers and researchers to take full advantage of the scalability
and cross-platform capabilities of TensorFlow 2: you can run Keras on TPU or on large clusters of GPUs,
and you can export your Keras models to run in the browser or on a mobile device.

---

## First contact with Keras

The core data structures of Keras are __layers__ and __models__.
The simplest type of model is the [`Sequential` model](https://keras.io/guides/sequential_model/), a linear stack of layers.
For more complex architectures, you should use the [Keras functional API](https://keras.io/guides/functional_api/),
which allows you to build arbitrary graphs of layers or [write models entirely from scratch via subclassing](https://keras.io/guides/making_new_layers_and_models_via_subclassing/).

Here is the `Sequential` model:

```python
from tensorflow.keras.models import Sequential

model = Sequential()
```

Stacking layers is as easy as `.add()`:

```python
from tensorflow.keras.layers import Dense

model.add(Dense(units=64, activation='relu'))
model.add(Dense(units=10, activation='softmax'))
```

Once your model looks good, configure its learning process with `.compile()`:

```python
model.compile(loss='categorical_crossentropy',
              optimizer='sgd',
              metrics=['accuracy'])
```

If you need to, you can further configure your optimizer. The Keras philosophy is to keep simple things simple,
while allowing the user to be fully in control when they need to (the ultimate control being the easy extensibility of the source code via subclassing).

```python
model.compile(loss=tf.keras.losses.categorical_crossentropy,
              optimizer=tf.keras.optimizers.SGD(
                  learning_rate=0.01, momentum=0.9, nesterov=True))
```

You can now iterate on your training data in batches:

```python
# x_train and y_train are Numpy arrays.
model.fit(x_train, y_train, epochs=5, batch_size=32)
```

Evaluate your test loss and metrics in one line:

```python
loss_and_metrics = model.evaluate(x_test, y_test, batch_size=128)
```

Or generate predictions on new data:

```python
classes = model.predict(x_test, batch_size=128)
```

What you just saw is the most elementary way to use Keras.

However, Keras is also a highly-flexible framework suitable to iterate on state-of-the-art research ideas.
Keras follows the principle of **progressive disclosure of complexity**: it makes it easy to get started,
yet it makes it possible to handle arbitrarily advanced use cases,
only requiring incremental learning at each step.

In much the same way that you were able to train & evaluate a simple neural network above in a few lines,
you can use Keras to quickly develop new training procedures or exotic model architectures.
Here's a low-level training loop example, combining Keras functionality with the TensorFlow `GradientTape`:

```python
import tensorflow as tf

# Prepare an optimizer.
optimizer = tf.keras.optimizers.Adam()
# Prepare a loss function.
loss_fn = tf.keras.losses.kl_divergence

# Iterate over the batches of a dataset.
for inputs, targets in dataset:
    # Open a GradientTape.
    with tf.GradientTape() as tape:
        # Forward pass.
        predictions = model(inputs)
        # Compute the loss value for this batch.
        loss_value = loss_fn(targets, predictions)

    # Get gradients of loss wrt the weights.
    gradients = tape.gradient(loss_value, model.trainable_weights)
    # Update the weights of the model.
    optimizer.apply_gradients(zip(gradients, model.trainable_weights))
```

For more in-depth tutorials about Keras, you can check out:

-   [Introduction to Keras for engineers](https://keras.io/getting_started/intro_to_keras_for_engineers/)
-   [Introduction to Keras for researchers](https://keras.io/getting_started/intro_to_keras_for_researchers/)
-   [Developer guides](https://keras.io/guides/)
-   [Other learning resources](https://keras.io/getting_started/learning_resources/)

---

## Installation

Keras comes packaged with TensorFlow 2 as `tensorflow.keras`.
To start using Keras, simply [install TensorFlow 2](https://www.tensorflow.org/install).

---

## Release and compatibility

Keras has **nightly releases** (`keras-nightly` on PyPI)
and **stable releases** (`keras` on PyPI).
The nightly Keras releases are usually compatible with the corresponding version
of the `tf-nightly` releases
(e.g. `keras-nightly==2.7.0.dev2021100607` should be
used with `tf-nightly==2.7.0.dev2021100607`).
We don't maintain backward compatibility for nightly releases.
For stable releases, each Keras
version maps to a specific stable version of TensorFlow.

The table below shows the compatibility version mapping
between TensorFlow versions and Keras versions.

All the release branches can be found on [GitHub](https://github.com/keras-team/keras/releases).

All the release binaries can be found on [Pypi](https://pypi.org/project/keras/#history).

| Keras release | Note      | Compatible Tensorflow version |
| -----------   | ----------- | -----------        |
| [2.4](https://github.com/keras-team/keras/releases/tag/2.4.0)  | Last stable release of multi-backend Keras | < 2.5
| 2.5-pre| Pre-release (not formal) for standalone Keras repo | >= 2.5 < 2.6
| [2.6](https://github.com/keras-team/keras/releases/tag/v2.6.0)    | First formal release of standalone Keras.  | >= 2.6 < 2.7
| [2.7](https://github.com/keras-team/keras/releases/tag/v2.7.0-rc0)    | (Upcoming release) | >= 2.7 < 2.8
| nightly|                                            | tf-nightly

---
## Support

You can ask questions and join the development discussion:

- In the [TensorFlow forum](https://discuss.tensorflow.org/).
- On the [Keras Google group](https://groups.google.com/forum/#!forum/keras-users).

---

## Opening an issue

You can also post **bug reports and feature requests** (only)
in [GitHub issues](https://github.com/keras-team/keras/issues).


---

## Opening a PR

We welcome contributions! Before opening a PR, please read
[our contributor guide](https://github.com/keras-team/keras/blob/master/CONTRIBUTING.md),
and the [API design guideline](https://github.com/keras-team/governance/blob/master/keras_api_design_guidelines.md).
","Keras is a deep learning API written in Python. It runs on top of the machine
learning platform [TensorFlow] Keras was developed with a focus on enabling fast
experimentation. It is used by organizations and companies including NASA,
YouTube, and Waymo."
739,A distributed knowledge graph store,"# Akutan

[![Build Status](https://travis-ci.com/eBay/akutan.svg?branch=master)](https://travis-ci.com/eBay/akutan)
[![GoDoc](https://godoc.org/github.com/ebay/akutan/src/github.com/ebay/akutan?status.svg)](https://godoc.org/github.com/ebay/akutan/src/github.com/ebay/akutan)

There's a blog post that's a [good introduction to Akutan](https://www.ebayinc.com/stories/blogs/tech/beam-a-distributed-knowledge-graph-store/).

Akutan is a distributed knowledge graph store, sometimes called an RDF store or a
triple store. Knowledge graphs are suitable for modeling data that is highly
interconnected by many types of relationships, like encyclopedic information
about the world. A knowledge graph store enables rich queries on its data, which
can be used to power real-time interfaces, to complement machine learning
applications, and to make sense of new, unstructured information in the context
of the existing knowledge.

How to model your data as a knowledge graph and how to query it will feel a bit
different for people coming from SQL, NoSQL, and property graph stores. In a
knowledge graph, data is represented as a single table of *facts*, where each
fact has a *subject*, *predicate*, and *object*. This representation enables the
store to sift through the data for complex queries and to apply inference rules
that raise the level of abstraction. Here's an example of a tiny graph:

subject         | predicate | object
----------------|-----------|-----------------
`<John_Scalzi>` | `<born>`  | `<Fairfield>`
`<John_Scalzi>` | `<lives>` | `<Bradford>`
`<John_Scalzi>` | `<wrote>` | `<Old_Mans_War>`

To learn about how to represent and query data in Akutan, see
[docs/query.md](docs/query.md).

Akutan is designed to store large graphs that cannot fit on a single server. It's
scalable in how much data it can store and the rate of queries it can execute.
However, Akutan serializes all changes to the graph through a central log, which
fundamentally limits the total rate of change. The rate of change won't improve
with a larger number of servers, but a typical deployment should be able to
handle tens of thousands of changes per second. In exchange for this limitation,
Akutan's architecture is a relatively simple one that enables many features. For
example, Akutan supports transactional updates and historical global snapshots. We
believe this trade-off is suitable for most knowledge graph use cases, which
accumulate large amounts of data but do so at a modest pace. To learn more about
Akutan's architecture and this trade-off, see
[docs/central_log_arch.md](docs/central_log_arch.md).

Akutan isn't ready for production-critical deployments, but it's useful today for
some use cases. We've run a 20-server deployment of Akutan for development
purposes and off-line use cases for about a year, which we've most commonly
loaded with a dataset of about 2.5 billion facts. We believe Akutan's current
capabilities exceed this capacity and scale; we haven't yet pushed Akutan to its
limits. The project has a good architectural foundation on which additional
features can be built and higher performance could be achieved.

Akutan needs more love before it can be used for production-critical deployments.
Much of Akutan's code consists of high-quality, documented, unit-tested modules,
but some areas of the code base are inherited from Akutan's earlier prototype days
and still need attention. In other places, some functionality is lacking before
Akutan could be used as a critical production data store, including deletion of
facts, backup/restore, and automated cluster management. We have filed
GitHub issues for these and a few other things. There are also areas where Akutan
could be improved that wouldn't necessarily block production usage. For example,
Akutan's query language is not quite compatible with Sparql, and its inference
engine is limited.

So, Akutan has a nice foundation and may be useful to some people, but it also
needs additional love. If that's not for you, here are a few alternative
open-source knowledge and property graph stores that you may want to consider
(we have no affiliation with these projects):

- [Blazegraph](https://github.com/blazegraph/database): an RDF store. Supports
  several query languages, including SPARQL and Gremlin. Disk-based,
  single-master, scales out for reads only. Seems unmaintained. Powers
  <https://query.wikidata.org/>.
- [Dgraph](https://github.com/dgraph-io/dgraph): a triple-oriented property
  graph store. GraphQL-like query language, no support for SPARQL. Disk-based,
  scales out.
- [Neo4j](https://github.com/neo4j/neo4j): a property graph store. Cypher query
  language, no support for SPARQL. Single-master, scales out for reads only.
- See also Wikipedia's
  [Comparison of Triplestores](https://en.wikipedia.org/wiki/Comparison_of_triplestores)
  page.

The remainder of this README describes how to get Akutan up and running. Several
documents under the `docs/` directory describe aspects of Akutan in more
detail; see [docs/README.md](docs/README.md) for an overview.

## Installing dependencies and building Akutan

Akutan has the following system dependencies:
 - It's written in [Go](https://golang.org/). You'll need v1.11.5 or newer.
 - Akutan uses [Protocol Buffers](https://developers.google.com/protocol-buffers/)
   extensively to encode messages for [gRPC](https://grpc.io/), the log of data
   changes, and storage on disk. You'll need protobuf version 3. We reccomend
   3.5.2 or later. Note that 3.0.x is the default in many Linux distributions, but
   doesn't work with the Akutan build.
 - Akutan's Disk Views store their facts in [RocksDB](https://rocksdb.org/).

On Mac OS X, these can all be installed via [Homebrew](https://brew.sh/):

	$ brew install golang protobuf rocksdb zstd

On Ubuntu, refer to the files within the [docker/](docker/) directory for
package names to use with `apt-get`.

After cloning the Akutan repository, pull down several Go libraries and additional
Go tools:

	$ make get

Finally, build the project:

	$ make build

## Running Akutan locally

The fastest way to run Akutan locally is to launch the in-memory log store:

	$ bin/plank

Then open another terminal and run:

	$ make run

This will bring up several Akutan servers locally. It starts an API server that
listens on localhost for gRPC requests on port 9987 and for HTTP requests on
port 9988, such as <http://localhost:9988/stats.txt>.

The easiest way to interact with the API server is using `bin/akutan-client`. See
[docs/query.md](docs/query.md) for examples. The API server exposes the
`FactStore` gRPC service defined in
[proto/api/akutan_api.proto](proto/api/akutan_api.proto).

## Deployment concerns

### The log

Earlier, we used `bin/plank` as a log store, but this is unsuitable for real
usage! Plank is in-memory only, isn't replicated, and by default, it only
keeps 1000 entries at a time. It's only meant for development.

Akutan also supports using [Apache Kafka](https://kafka.apache.org/) as its log
store. This is recommended over Plank for any deployment. To use Kafka, follow the
[Kafka quick start](https://kafka.apache.org/quickstart) guide to install
Kafka, start ZooKeeper, and start Kafka. Then create a topic called ""akutan""
(not ""test"" as in the Kafka guide) with `partitions` set to 1. You'll want to
configure Kafka to synchronously write entries to disk.

To use Kafka with Akutan, set the `akutanLog`'s `type` to `kafka` in your Akutan
configuration (default: `local/config.json`), and update the `locator`'s
`addresses` accordingly (Kafka uses port 9092 by default). You'll need to clear
out Akutan's Disk Views' data before restarting the cluster. The Disk Views
by default store their data in $TMPDIR/rocksdb-akutan-diskview-{space}-{partition}
so you can delete them all with `rm -rf $TMPDIR/rocksdb-akutan-diskview*`

### Docker and Kubernetes

This repository includes support for running Akutan inside
[Docker](https://www.docker.com/) and
[Minikube](https://kubernetes.io/docs/setup/minikube/). These environments can
be tedious for development purposes, but they're useful as a step towards a
modern and robust production deployment.

See `cluster/k8s/Minikube.md` file for the steps to build and deploy Akutan
services in `Minikube`. It also includes the steps to build the Docker images.

### Distributed tracing

Akutan generates distributed [OpenTracing](https://opentracing.io/) traces for use
with [Jaeger](https://www.jaegertracing.io/). To try it, follow the
[Jaeger Getting Started Guide](https://www.jaegertracing.io/docs/getting-started/#all-in-one-docker-image)
for running the all-in-one Docker image. The default `make run` is configured to
send traces there, which you can query at <http://localhost:16686>. The Minikube
cluster also includes a Jaeger all-in-one instance.

## Development

### VS Code

You can use whichever editor you'd like, but this repository contains some
configuration for [VS Code](https://code.visualstudio.com/Download). We
suggest the following extensions:
 - [Go](https://marketplace.visualstudio.com/items?itemName=ms-vscode.Go)
 - [Code Spell Checker](https://marketplace.visualstudio.com/items?itemName=streetsidesoftware.code-spell-checker)
 - [Rewrap](https://marketplace.visualstudio.com/items?itemName=stkb.rewrap)
 - [vscode-proto3](https://marketplace.visualstudio.com/items?itemName=zxh404.vscode-proto3)
 - [Docker](https://marketplace.visualstudio.com/items?itemName=PeterJausovec.vscode-docker)

Override the default settings in `.vscode/settings.json` with
[./vscode-settings.json5](./vscode-settings.json5).

### Test targets

The `Makefile` contains various targets related to running tests:

Target       | Description
------------ | -----------
`make test`  | run all the akutan unit tests
`make cover` | run all the akutan unit tests and open the web-based coverage viewer
`make lint`  | run basic code linting
`make vet`   | run all static analysis tests including linting and formatting

## License Information

Copyright 2019 eBay Inc.

Primary authors: Simon Fell, Diego Ongaro, Raymond Kroeker, Sathish Kandasamy

Licensed under the Apache License, Version 2.0 (the ""License""); you may not use
this file except in compliance with the License. You may obtain a copy of the
License at <https://www.apache.org/licenses/LICENSE-2.0>.

Unless required by applicable law or agreed to in writing, software distributed
under the License is distributed on an ""AS IS"" BASIS, WITHOUT WARRANTIES OR
CONDITIONS OF ANY KIND, either express or implied. See the License for the
specific language governing permissions and limitations under the License.


----
**Note** the project was renamed to Akutan in July 2019.
","Akutan is a distributed knowledge graph store. It's designed to store large
graphs that cannot fit on a single server. The project has a good architectural
foundation on which additional features can be built. Akutan isn't ready for
production-critical deployments, but it's useful today."
2114,A list of resources in different fields of Computer Science,"<h1 align=""center"">Computer Science Resources</h1>

<h1 align=""center"">
    <img alt=""CS"" title=""Computer-Science-Resources"" src=""https://raw.githubusercontent.com/the-akira/Computer-Science-Resources/master/avatar.png""> </br>
</h1>

<p align=""center"">
	A list of resources in different fields of <b>Computer Science</b> (in multiple languages).
</p>

## Content

- Getting Started
  - [Map of Computer Science](https://www.youtube.com/watch?v=SzJ46YA_RaA)
  - [Map of Mathematics](https://www.youtube.com/watch?v=OmJ-4B-mS-Y)
  - [Map of Physics](https://www.youtube.com/watch?v=ZihywtixUYo&t)
  - [MIT Courses](https://ocw.mit.edu/courses/electrical-engineering-and-computer-science/)
  - [MIT 6.00 Intro to Computer Science & Programming](https://www.youtube.com/watch?v=k6U-i4gXkLM&list=PL4C4720A6F225E074)
  - [MIT 6.0001 Introduction to Computer Science & Programming in Python](https://www.youtube.com/playlist?list=PLUl4u3cNGP63WbdFxL8giv4yhgdMGaZNA)
  - [MIT 6.0002 Introduction to Computational Thinking and Data Science](https://www.youtube.com/playlist?list=PLUl4u3cNGP619EG1wp0kT-7rDE_Az5TNd)
  - [CS50 Harvard](https://www.youtube.com/watch?v=y62zj9ozPOM&list=PLhQjrBD2T3828ZVcVzEIhsHVgjANGZveu)
  - [Audio/Video Courses from Colleges and Universities](http://www.infocobuild.com/education/audio-video-courses/)
  - [Everything Computer Science](https://everythingcomputerscience.com/)
- Computer Fundamentals
  - [Algorithms & Data Structures](https://github.com/the-akira/Computer-Science-Resources/blob/master/db/algorithms_data_structures.md)
  - [Computer Architecture](https://github.com/the-akira/computer_science_web_resources/blob/master/db/computer_architecture.md)
  - [Operating Systems](https://github.com/the-akira/computer_science_web_resources/blob/master/db/operating_systems.md)
  - [Mathematics](https://github.com/the-akira/computer_science_web_resources/blob/master/db/mathematics.md)
  - [Regular Expressions](https://github.com/the-akira/computer_science_web_resources/blob/master/db/regular_expressions.md)
  - [Physics](https://github.com/the-akira/computer_science_web_resources/blob/master/db/physics.md)
  - [Signals and Systems](https://github.com/the-akira/Computer_Science_Web_Resources/blob/master/db/signals_systems.md)
  - [Information Theory](https://github.com/the-akira/Computer-Science-Resources/blob/master/db/information_theory.md)
  - [Cloud Computing](https://github.com/the-akira/computer_science_web_resources/blob/master/db/cloud_computing.md)
  - [Quantum Computing](https://github.com/the-akira/computer_science_web_resources/blob/master/db/quantum_computing.md)
  - [Computer Networks](https://github.com/the-akira/computer_science_web_resources/blob/master/db/computer_networks.md)
  - [Computer Graphics](https://github.com/the-akira/Computer_Science_Web_Resources/blob/master/db/computer_graphics.md)
  - [Virtual Reality](https://github.com/the-akira/Computer_Science_Web_Resources/blob/master/db/virtual_reality.md)
- Programming Languages
  - [Assembly](https://github.com/the-akira/computer_science_web_resources/blob/master/db/assembly.md)
  - [C](https://github.com/the-akira/computer_science_web_resources/blob/master/db/c.md)
  - [C++](https://github.com/the-akira/computer_science_web_resources/blob/master/db/cpp.md)
  - [Python](https://github.com/the-akira/computer_science_web_resources/blob/master/db/python.md)
  - [Java](https://github.com/the-akira/computer_science_web_resources/blob/master/db/java.md)
  - [Javascript](https://github.com/the-akira/computer_science_web_resources/blob/master/db/javascript.md)
  - [Ruby](https://github.com/the-akira/computer_science_web_resources/blob/master/db/ruby.md)
  - [Bash](https://github.com/the-akira/computer_science_web_resources/blob/master/db/bash.md)
  - [Go](https://github.com/the-akira/computer_science_web_resources/blob/master/db/go.md)
  - [PHP](https://github.com/the-akira/computer_science_web_resources/blob/master/db/php.md)
  - [Haskell](https://github.com/the-akira/Computer_Science_Web_Resources/blob/master/db/haskell.md)
  - [R](https://github.com/the-akira/Computer_Science_Web_Resources/blob/master/db/r.md)
  - [Julia](https://github.com/the-akira/Computer_Science_Web_Resources/blob/master/db/julia.md)
  - [Elixir](https://github.com/the-akira/Computer_Science_Web_Resources/blob/master/db/elixir.md)
- Artificial Intelligence
  - [Machine Learning](https://github.com/the-akira/computer_science_web_resources/blob/master/db/machine_learning.md)
  - [Artificial Neural Networks](https://github.com/the-akira/Computer_Science_Web_Resources/blob/master/db/artificial_neural_network.md)
  - [Natural Language Processing](https://github.com/the-akira/computer_science_web_resources/blob/master/db/natural_language_processing.md)
  - [Computer Vision](https://github.com/the-akira/Computer_Science_Web_Resources/blob/master/db/computer_vision.md)
  - [Cybernetics & Robotics](https://github.com/the-akira/computer_science_web_resources/blob/master/db/cybernetics_and_robotics.md)
- Information Security
  - [Computer Security](https://github.com/the-akira/computer_science_web_resources/blob/master/db/cyber_security.md)
  - [Web Hacking](https://github.com/the-akira/computer_science_web_resources/blob/master/db/web_hacking.md)
  - [Exploits](https://github.com/the-akira/computer_science_web_resources/blob/master/db/exploits.md) 
  - [Reverse Engineering](https://github.com/the-akira/computer_science_web_resources/blob/master/db/reverse_engineering.md)
  - [Social Engineering](https://github.com/the-akira/computer_science_web_resources/blob/master/db/social_engineering.md)
  - [Cryptography](https://github.com/the-akira/computer_science_web_resources/blob/master/db/cryptography.md)
- Databases
  - [SQL](https://github.com/the-akira/computer_science_web_resources/blob/master/db/sql.md)
  - [NOSQL](https://github.com/the-akira/computer_science_web_resources/blob/master/db/nosql.md)
  - [Big Data](https://github.com/the-akira/computer_science_web_resources/blob/master/db/big_data.md)
  - [Data Mining](https://github.com/the-akira/computer_science_web_resources/blob/master/db/data_mining.md)","A list of resources in different fields of <b>Computer Science (in multiple
languages) The resources are broken down into three categories: Getting Started,
Computer Fundamentals, Cloud Computing, and Graphics. The resources can be found
on GitHub."
2903,Algebraic graphs,"# Algebraic graphs

[![Hackage version](https://img.shields.io/hackage/v/algebraic-graphs.svg?label=Hackage)](https://hackage.haskell.org/package/algebraic-graphs) [![Build status](https://img.shields.io/github/workflow/status/snowleopard/alga/ci/master.svg)](https://github.com/snowleopard/alga/actions)

**Alga** is a library for algebraic construction and manipulation of graphs in Haskell. See
[this Haskell Symposium paper](https://github.com/snowleopard/alga-paper) and the
corresponding [talk](https://www.youtube.com/watch?v=EdQGLewU-8k) for the motivation
behind the library, the underlying theory and implementation details. There is also a
[Haskell eXchange talk](https://skillsmatter.com/skillscasts/10635-algebraic-graphs),
and a [tutorial](https://nobrakal.github.io/alga-tutorial) by Alexandre Moine.

## Main idea

Consider the following data type, which is defined in the top-level module
[Algebra.Graph](http://hackage.haskell.org/package/algebraic-graphs/docs/Algebra-Graph.html)
of the library:

```haskell
data Graph a = Empty | Vertex a | Overlay (Graph a) (Graph a) | Connect (Graph a) (Graph a)
```

We can give the following semantics to the constructors in terms of the pair **(V, E)** of graph *vertices* and *edges*:

* `Empty` constructs the empty graph **(∅, ∅)**.
* `Vertex x` constructs a graph containing a single vertex, i.e. **({x}, ∅)**.
* `Overlay x y` overlays graphs **(Vx, Ex)** and **(Vy, Ey)** constructing **(Vx ∪ Vy, Ex ∪ Ey)**.
* `Connect x y` connects graphs **(Vx, Ex)** and **(Vy, Ey)** constructing **(Vx ∪ Vy, Ex ∪ Ey ∪ Vx × Vy)**.

Alternatively, we can give an algebraic semantics to the above graph construction primitives by defining the following
type class and specifying a set of laws for its instances (see module [Algebra.Graph.Class](http://hackage.haskell.org/package/algebraic-graphs/docs/Algebra-Graph-Class.html)):

```haskell
class Graph g where
    type Vertex g
    empty   :: g
    vertex  :: Vertex g -> g
    overlay :: g -> g -> g
    connect :: g -> g -> g
```

The laws of the type class are remarkably similar to those of a [semiring](https://en.wikipedia.org/wiki/Semiring),
so we use `+` and `*` as convenient shortcuts for `overlay` and `connect`, respectively:

* (`+`, `empty`) is an idempotent commutative monoid.
* (`*`, `empty`) is a monoid.
* `*` distributes over `+`, that is: `x * (y + z) == x * y + x * z` and `(x + y) * z == x * z + y * z`.
* `*` can be decomposed: `x * y * z == x * y + x * z + y * z`.

This algebraic structure corresponds to *unlabelled directed graphs*: every expression represents a graph, and every
graph can be represented by an expression. Other types of graphs (e.g. undirected) can be obtained by modifying the
above set of laws. Algebraic graphs provide a convenient, safe and powerful interface for working with graphs in Haskell,
and allow the application of equational reasoning for proving the correctness of graph algorithms.

To represent *non-empty graphs*, we can drop the `Empty` constructor -- see module
[Algebra.Graph.NonEmpty](http://hackage.haskell.org/package/algebraic-graphs/docs/Algebra-Graph-NonEmpty.html).

To represent *edge-labelled graphs*, we can switch to the following data type, as
explained in my [Haskell eXchange 2018 talk](https://skillsmatter.com/skillscasts/12361-labelled-algebraic-graphs):

```haskell
data Graph e a = Empty
               | Vertex a
               | Connect e (Graph e a) (Graph e a)
```

Here `e` is the type of edge labels. If `e` is a monoid `(<+>, zero)` then graph overlay can be recovered
as `Connect zero`, and `<+>` corresponds to *parallel composition* of edge labels.

## How fast is the library?

Alga can handle graphs comprising millions of vertices and billions of edges in a matter of seconds, which is fast
enough for many applications. We believe there is a lot of potential for improving the performance of the library, and
this is one of our top priorities. If you come across a performance issue when using the library, please let us know.

Some preliminary benchmarks can be found [here](https://github.com/haskell-perf/graphs).

## Blog posts

The development of the library has been documented in the series of blog posts:
* Introduction: https://blogs.ncl.ac.uk/andreymokhov/an-algebra-of-graphs/
* A few different flavours of the algebra: https://blogs.ncl.ac.uk/andreymokhov/graphs-a-la-carte/
* Graphs in disguise or How to plan you holiday using Haskell: https://blogs.ncl.ac.uk/andreymokhov/graphs-in-disguise/
* Old graphs from new types: https://blogs.ncl.ac.uk/andreymokhov/old-graphs-from-new-types/

## Algebraic graphs in other languages

Algebraic graphs were implemented in a few other languages, including
[Agda](http://github.com/algebraic-graphs/agda),
[F#](https://github.com/algebraic-graphs/fsharp),
[Scala](http://github.com/algebraic-graphs/scala) and
[TypeScript](https://github.com/algebraic-graphs/typescript).
","Alga is a library for algebraic construction and manipulation of graphs in
Haskell. It provides a safe and powerful interface for working with graphs. It
can also be used to prove correctness of graph algorithms. The library is
available on Hackage and GitHub."
1876,"A simple React Native library, enabling the creation of fully customized header for your iOS and Android apps.","<div align=""center"">
  <image align=""center"" src=""./assets/readme_header.svg""/>
</div>
<div align=""center"">
  <h1>Sticky Parallax Header</h1>
</div>

<div align=""center"">
  <image src=""https://app.bitrise.io/app/1ffc1637c8691f4f/status.svg?token=2vMEootz4cobIHmtr5UeYg&branch=develop""/>
  <image src=""https://badge.fury.io/js/react-native-sticky-parallax-header.svg""/>
  <image src=""https://img.shields.io/npm/dt/react-native-sticky-parallax-header""/>
</div>
<div align=""center"">
  <br/><em>Brought with</em> &nbsp;❤️ <em>by</em> &nbsp; <a href=""https://www.netguru.com""><img align=""center"" alt=""Netguru logo"" src='./assets/readme_netguru_logo.png' width='30'/></a>
</div>

# Introduction

<p align=""center"">
  react-native-sticky-parallax-header is a simple React Native library, enabling to create a fully custom header layout for your iOS, Android and web apps.
</p>

<div align=""center"">
  <a href=""#Docs"">Documentation</a> &nbsp;|&nbsp; <a href=""#Preview"">Preview</a> &nbsp;|&nbsp; <a href=""#Installation"">Installation</a> &nbsp;|&nbsp; <a href=""#Contributing"">Contributing</a> &nbsp;
</div>

## Documentation <a name=""Docs""></a>
Read the full Docs at: <a href=""https://netguru.github.io/sticky-parallax-header/"">https://netguru.github.io/sticky-parallax-header/</a>

## Preview

Sticky Parallax Header ships with 3 different use cases for sticky headers and a possibility to create fully custom header!

|                     Tabbed Header                      |                     Avatar Header                      |                      Details Header                      |
| :----------------------------------------------------: | :----------------------------------------------------: | :------------------------------------------------------: |
| ![Tabbed Header Gif](./assets/readme_TabbedHeader.gif) | ![Avatar Header Gif](./assets/readme_AvatarHeader.gif) | ![Details Header Gif](./assets/readme_DetailsHeader.gif) |

## In Use

**Check the live demo on Expo Snack [here](https://snack.expo.dev/@netguru_rnd/sticky-parallax-header-example).**

This is how you can display header in your app:

```tsx
import * as React from 'react'
import { DetailsHeaderScrollView } from 'react-native-sticky-parallax-header'
import { SafeAreaProvider } from 'react-native-safe-area-context'

const TestScreen = () => (
  <SafeAreaProvider>
    <DetailsHeaderScrollView {...scrollProps} {...detailsHeaderProps}>
      {/** scroll view content */}
    </DetailsHeaderScrollView>
  </SafeAreaProvider>
)

export default TestScreen
```

## Installation

### Installation & requirements

:information_source: Library supports react-native version 0.64+

#### Install latest library version

```sh
$ yarn add react-native-sticky-parallax-header@rc
```

#### Install library's dependencies

```sh
yarn add react-native-reanimated react-native-safe-area-context
```

After installation:
- check Reanimated installation [guide](https://docs.swmansion.com/react-native-reanimated/docs/fundamentals/installation)
- handle Pods installation with `npx pod-install`
- wrap your root component with `SafeAreaProvider` from `react-native-safe-area-context`

<h1 id=""Contributing"">Contributing</h1>

[Contributing guidelines](CONTRIBUTING.md)

# License

This library is available as open source under the terms of the [MIT License](https://opensource.org/licenses/MIT).
"," react-native-sticky-parallax-header is a simple React Native library, enabling
to create a fully custom header layout for your iOS, Android and web apps. It
ships with 3 different use cases for sticky headers and a possibility to create
fully custom headers. The library is available as open source source under the
MIT License under the terms of the [opensource.org/licenses/MIT/licensing]
license. It can be downloaded from the GitHub repository at:
http://www.netguru.com/react-native/reanimated."
2654,Preview GitHub README.md files locally before committing them.,"Grip -- GitHub Readme Instant Preview
=====================================

[![Current version on PyPI](http://img.shields.io/pypi/v/grip.svg)][pypi]
[![Say Thanks!](https://img.shields.io/badge/Say%20Thanks-!-1EAEDB.svg)](https://saythanks.io/to/joeyespo)

Render local readme files before sending off to GitHub.

Grip is a command-line server application written in Python that uses the
[GitHub markdown API][markdown] to render a local readme file. The styles
and rendering come directly from GitHub, so you'll know exactly how it will appear.
Changes you make to the Readme will be instantly reflected in the browser without
requiring a page refresh.


Motivation
----------

Sometimes you just want to see the exact readme
result before committing and pushing to GitHub.

Especially when doing [Readme-driven development][rdd].


Installation
------------

To install grip, simply:

```console
$ pip install grip
```

On OS X, you can also install with Homebrew:

```console
$ brew install grip
```


Usage
-----

To render the readme of a repository:

```console
$ cd myrepo
$ grip
 * Running on http://localhost:6419/
```

Now open a browser and visit [http://localhost:6419](http://localhost:6419/).
Or run with `-b` and Grip will open a new browser tab for you.

You can also specify a port:

```console
$ grip 80
 * Running on http://localhost:80/
```

Or an explicit file:

```console
$ grip AUTHORS.md
 * Running on http://localhost:6419/
```

Alternatively, you could just run `grip` and visit [localhost:6419/AUTHORS.md][AUTHORS.md]
since grip supports relative URLs.

You can combine the previous examples. Or specify a hostname instead of a port. Or provide both.

```console
$ grip AUTHORS.md 80
 * Running on http://localhost:80/
```

```console
$ grip CHANGES.md 0.0.0.0
 * Running on http://0.0.0.0:6419/
```

```console
$ grip . 0.0.0.0:80
 * Running on http://0.0.0.0:80/
```

You can even bypass the server and **export** to a single HTML file, with all the styles and assets inlined:

```console
$ grip --export
Exporting to README.html
```

Control the output name with the second argument:

```console
$ grip README.md --export index.html
Exporting to index.html
```

If you're exporting a bunch of files, you can prevent styles from being inlining to save space with `--no-inline`:

```console
$ grip README.md --export --no-inline introduction.html
Exporting to introduction.html
```

Reading and writing from **stdin** and **stdout** is also supported, allowing you to use Grip with other programs:

```console
$ cat README.md | grip -
 * Running on http://localhost:6419/
```

```console
$ grip AUTHORS.md --export - | bcat
```

```console
$ cat README.md | grip --export - | less
```

This allows you to quickly test how things look by entering Markdown directly in your terminal:

```console
$ grip -
Hello **world**!
^D
 * Running on http://localhost:6419/
```

*Note: `^D` means `Ctrl+D`, which works on Linux and OS X. On Windows you'll have to use `Ctrl+Z`.*

Rendering as user-content like **comments** and **issues** is also supported, with an optional repository context for linking to issues:

```console
$ grip --user-content --context=joeyespo/grip
 * Running on http://localhost:6419/
```

For more details and additional options, see the help:

```console
$ grip -h
```


Access
------

Grip strives to be as close to GitHub as possible. To accomplish this, grip
uses [GitHub's Markdown API][markdown] so that changes to their rendering
engine are reflected immediately without requiring you to upgrade grip.
However, because of this you may hit the API's hourly rate limit. If this
happens, grip offers a way to access the API using your credentials
to unlock a much higher rate limit.

```console
$ grip --user <your-username> --pass <your-password>
```

Or use a [personal access token][] with an empty scope (note that a token is
*required* if your GitHub account is set up with two-factor authentication):

```console
$ grip --pass <token>
```

You can persist these options [in your local configuration](#configuration).
For security purposes, it's highly recommended that you **use an access token
over a password**. (You could also keep your password safe by configuring
Grip to [grab your password from a password manager][keychain-access].)

There's also a [work-in-progress branch][offline-renderer] to provide
**offline rendering**. Once this resembles GitHub more precisely, it'll
be exposed in the CLI, and will ultimately be used as a seamless fallback
engine for when the API can't be accessed.

Grip always accesses GitHub over HTTPS,
so your README and credentials are protected.


Tips
----

Here's how others from the community are using Grip.

Want to share your own? [Say hello @joeyespo][twitter] or [submit a pull request](#contributing).


#### Create a local mirror of a Github Wiki

```console
$ git clone https://github.com/YOUR_USERNAME/YOUR_REPOSITORY.wiki.git
$ cd YOUR_REPOSITORY.wiki
$ grip
```

*By [Joshua Gourneau](https://twitter.com/gourneau/status/636329126643658753).*


#### Generate HTML documentation from a collection of linked README files

1. Enter the directory:

   ```console
   $ cd YOUR_DIR
   $ export GRIPURL=$(pwd)
   ```

2. Include all assets by setting the `CACHE_DIRECTORY` [config variable](#configuration):

   ```console
   $ echo ""CACHE_DIRECTORY = '$(pwd)/assets'"" >> ~/.grip/settings.py
   ```

3. Export all your Markdown files with Grip and replace absolute asset paths with relative paths:

   ```console
   $ for f in *.md; do grip --export $f --no-inline; done
   $ for f in *.html; do sed -i '' ""s?$GRIPURL/??g"" $f; done
   ```

You can optionally compress the set of HTML files to `docs.tgz` with:

   ```console
   $ tar -czvf docs.tgz `ls | grep [\.]html$` assets
   ```

Looking for a cross platform solution? Here's an equivalent [Python script](https://gist.github.com/mrexmelle/659abc02ae1295d60647).

*By [Matthew R. Tanudjaja](https://github.com/mrexmelle).*


Configuration
-------------

To customize Grip, create `~/.grip/settings.py`, then add one or more of the following variables:

- `HOST`: The host to use when not provided as a CLI argument, `localhost` by default
- `PORT`: The port to use when not provided as a CLI argument, `6419` by default
- `DEBUG`: Whether to use Flask's debugger when an error happens, `False` by default
- `DEBUG_GRIP`: Prints extended information when an error happens, `False` by default
- `API_URL`: Base URL for the github API, for example that of a Github Enterprise instance. `https://api.github.com` by default
- `CACHE_DIRECTORY`: The directory, relative to `~/.grip`, to place cached assets (this gets run through the following filter: `CACHE_DIRECTORY.format(version=__version__)`), `'cache-{version}'` by default
- `AUTOREFRESH`: Whether to automatically refresh the Readme content when the file changes, `True` by default
- `QUIET`: Do not print extended information, `False` by default
- `STYLE_URLS`: Additional URLs that will be added to the rendered page, `[]` by default
- `USERNAME`: The username to use when not provided as a CLI argument, `None` by default
- `PASSWORD`: The password or [personal access token][] to use when not provided as a CLI argument (*Please don't save your passwords here.* Instead, use an access token or drop in this code [grab your password from a password manager][keychain-access]), `None` by default

Note that this is a Python file. If you see `'X' is not defined` errors, you
may have overlooked some quotes. For example:

```py
USERNAME = 'your-username'
PASSWORD = 'your-personal-access-token'
```


#### Environment variables

- `GRIPHOME`: Specify an alternative `settings.py` location, `~/.grip` by default
- `GRIPURL`: The URL of the Grip server, `/__/grip` by default

#### Advanced

This file is a normal Python script, so you can add more advanced configuration.

For example, to read a setting from the environment and provide a default value
when it's not set:

```python
PORT = os.environ.get('GRIP_PORT', 8080)
```


API
---

You can access the API directly with Python, using it in your own projects:

```python
from grip import serve

serve(port=8080)
 * Running on http://localhost:8080/
```

Run main directly:

```python
from grip import main

main(argv=['-b', '8080'])
 * Running on http://localhost:8080/
```

Or access the underlying Flask application for even more flexibility:

```python
from grip import create_app

grip_app = create_app(user_content=True)
# Use in your own app
```


### Documentation

#### serve

Runs a local server and renders the Readme file located
at `path` when visited in the browser.

```python
serve(path=None, host=None, port=None, user_content=False, context=None, username=None, password=None, render_offline=False, render_wide=False, render_inline=False, api_url=None, title=None, autorefresh=True, browser=False, grip_class=None)
```

- `path`: The filename to render, or the directory containing your Readme file, defaulting to the current working directory
- `host`: The host to listen on, defaulting to the HOST configuration variable
- `port`: The port to listen on, defaulting to the PORT configuration variable
- `user_content`: Whether to render a document as [user-content][] like user comments or issues
- `context`: The project context to use when `user_content` is true, which
             takes the form of `username/project`
- `username`: The user to authenticate with GitHub to extend the API limit
- `password`: The password to authenticate with GitHub to extend the API limit
- `render_offline`: Whether to render locally using [Python-Markdown][] (Note: this is a work in progress)
- `render_wide`: Whether to render a wide page, `False` by default (this has no effect when used with `user_content`)
- `render_inline`: Whether to inline the styles within the HTML file
- `api_url`: A different base URL for the github API, for example that of a Github Enterprise instance. The default is the public API https://api.github.com.
- `title`: The page title, derived from `path` by default
- `autorefresh`: Automatically update the rendered content when the Readme file changes, `True` by default
- `browser`: Open a tab in the browser after the server starts., `False` by default
- `grip_class`: Use a custom [Grip class](#class-gripflask)


#### export

Writes the specified Readme file to an HTML file with styles and assets inlined.

```python
export(path=None, user_content=False, context=None, username=None, password=None, render_offline=False, render_wide=False, render_inline=True, out_filename=None, api_url=None, title=None, quiet=None, grip_class=None)
```

- `path`: The filename to render, or the directory containing your Readme file, defaulting to the current working directory
- `user_content`: Whether to render a document as [user-content][] like user comments or issues
- `context`: The project context to use when `user_content` is true, which
             takes the form of `username/project`
- `username`: The user to authenticate with GitHub to extend the API limit
- `password`: The password to authenticate with GitHub to extend the API limit
- `render_offline`: Whether to render locally using [Python-Markdown][] (Note: this is a work in progress)
- `render_wide`: Whether to render a wide page, `False` by default (this has no effect when used with `user_content`)
- `render_inline`: Whether to inline the styles within the HTML file (Note: unlike the other API functions, this defaults to `True`)
- `out_filename`: The filename to write to, `<in_filename>.html` by default
- `api_url`: A different base URL for the github API, for example that of a Github Enterprise instance. The default is the public API https://api.github.com.
- `title`: The page title, derived from `path` by default
- `quiet`: Do not print to the terminal
- `grip_class`: Use a custom [Grip class](#class-gripflask)


#### create_app

Creates a Flask application you can use to render and serve the Readme files.
This is the same app used by `serve` and `export` and initializes the cache,
using the cached styles when available.

```python
create_app(path=None, user_content=False, context=None, username=None, password=None, render_offline=False, render_wide=False, render_inline=False, api_url=None, title=None, text=None, grip_class=None)
```

- `path`: The filename to render, or the directory containing your Readme file, defaulting to the current working directory
- `user_content`: Whether to render a document as [user-content][] like user comments or issues
- `context`: The project context to use when `user_content` is true, which
             takes the form of `username/project`
- `username`: The user to authenticate with GitHub to extend the API limit
- `password`: The password to authenticate with GitHub to extend the API limit
- `render_offline`: Whether to render locally using [Python-Markdown][] (Note: this is a work in progress)
- `render_wide`: Whether to render a wide page, `False` by default (this has no effect when used with `user_content`)
- `render_inline`: Whether to inline the styles within the HTML file
- `api_url`: A different base URL for the github API, for example that of a Github Enterprise instance. The default is the public API https://api.github.com.
- `title`: The page title, derived from `path` by default
- `text`: A string or stream of Markdown text to render instead of being loaded from `path` (Note: `path` can be used to set the page title)
- `grip_class`: Use a custom [Grip class](#class-gripflask)


#### render_app

Renders the application created by `create_app` and returns the HTML that would
normally appear when visiting that route.

```python
render_app(app, route='/')
```

- `app`: The Flask application to render
- `route`: The route to render, '/' by default


#### render_content

Renders the specified markdown text without caching.

```python
render_content(text, user_content=False, context=None, username=None, password=None, render_offline=False, api_url=None, title=None)
```

- `text`: The Markdown text to render
- `user_content`: Whether to render a document as [user-content][] like user comments or issues
- `context`: The project context to use when `user_content` is true, which
             takes the form of `username/project`
- `username`: The user to authenticate with GitHub to extend the API limit
- `password`: The password to authenticate with GitHub to extend the API limit
- `render_offline`: Whether to render locally using [Python-Markdown][] (Note: this is a work in progress)
- `api_url`: A different base URL for the github API, for example that of a Github Enterprise instance. This is required when not using the offline renderer.
- `title`: The page title, derived from `path` by default


#### render_page

Renders the markdown from the specified path or text, without caching,
and returns an HTML page that resembles the GitHub Readme view.

```python
render_page(path=None, user_content=False, context=None, username=None, password=None, render_offline=False, render_wide=False, render_inline=False, api_url=None, title=None, text=None, quiet=None, grip_class=None)
```

- `path`: The path to use for the page title, rendering `'README.md'` if None
- `user_content`: Whether to render a document as [user-content][] like user comments or issues
- `context`: The project context to use when `user_content` is true, which
             takes the form of `username/project`
- `username`: The user to authenticate with GitHub to extend the API limit
- `password`: The password to authenticate with GitHub to extend the API limit
- `render_offline`: Whether to render offline using [Python-Markdown][] (Note: this is a work in progress)
- `render_wide`: Whether to render a wide page, `False` by default (this has no effect when used with `user_content`)
- `render_inline`: Whether to inline the styles within the HTML file
- `api_url`: A different base URL for the github API, for example that of a Github Enterprise instance. The default is the public API https://api.github.com.
- `title`: The page title, derived from `path` by default
- `text`: A string or stream of Markdown text to render instead of being loaded from `path` (Note: `path` can be used to set the page title)
- `quiet`: Do not print to the terminal
- `grip_class`: Use a custom [Grip class](#class-gripflask)


#### clear_cache

Clears the cached styles and assets.

```python
clear_cache(grip_class=None)
```

#### main

Runs Grip with the specified arguments.

```python
main(argv=None, force_utf8=True)
```

- `argv`: The arguments to run with, `sys.argv[1:]` by default
- `force_utf8`: Sets the default encoding to `utf-8` in the current Python instance. This has no effect on Python 3 since Unicode is handled by default


### Classes

#### class Grip(Flask)

A Flask application that can serve a file or directory containing a README.

```python
Grip(source=None, auth=None, renderer=None, assets=None, render_wide=None, render_inline=None, title=None, autorefresh=None, quiet=None, grip_url=None, static_url_path=None, instance_path=None, **kwargs)
```

##### default_renderer

Returns the default renderer using the current config. This is only used if
renderer is set to None in the constructor.

```python
Grip.default_renderer()
```

##### default_asset_manager

Returns the default asset manager using the current config. This is only used
if asset_manager is set to None in the constructor.

```python
Grip.default_asset_manager()
```

##### add_content_types

Adds the application/x-font-woff and application/octet-stream content types if
they are missing. Override to add additional content types on initialization.

```python
Grip.add_content_types()
```

##### clear_cache

Clears the downloaded assets.

```python
Grip.clear_cache()
```

##### render

Renders the application and returns the HTML unicode that would normally appear
when visiting in the browser.

```python
Grip.render(route=None)
```

- `route`: The route to render, `/` by default

##### run

Starts a server to render the README. This calls [Flask.run][] internally.

```python
Grip.run(host=None, port=None, debug=None, use_reloader=None, open_browser=False)
```

- `host`: The hostname to listen on. Set this to `'0.0.0.0'` to have the server
          available externally as well, `'localhost'` by default
- `port`: The port of the webserver. Defaults to `6419`
- `debug`: If given, enable or disable debug mode. See [Flask.debug][].
- `use_reloader`: Should the server automatically restart the python process
                  if modules were changed? `False` by default unless the
                  `DEBUG_GRIP` setting is specified.
- `open_browser`: Opens the browser to the address when the server starts


#### class AlreadyRunningError(RuntimeError)

Raised when `Grip.run` is called while the server is already running.

```python
AlreadyRunningError()
```


#### class ReadmeNotFoundError(NotFoundError or IOError)

Raised when the specified Readme could not be found.

```python
ReadmeNotFoundError(path=None, message=None)
```


#### class ReadmeAssetManager(object)

Manages the style and font assets rendered with Readme pages. This is an
abstract base class.

```python
ReadmeAssetManager(cache_path, style_urls=None)
```


#### class GitHubAssetManager(ReadmeAssetManager)

Manages the style and font assets rendered with Readme pages. Set cache_path to
None to disable caching.


#### class ReadmeReader(object)

Reads Readme content from a URL subpath. This is an abstract base class.

```python
ReadmeReader()
```


#### class DirectoryReader(ReadmeReader)

Reads Readme files from URL subpaths.

```python
DirectoryReader(path=None, silent=False)
```


#### class TextReader(ReadmeReader)

Reads Readme content from the provided unicode string.

```python
TextReader(text, display_filename=None)
```


#### class StdinReader(TextReader)

Reads Readme text from STDIN.

```python
StdinReader(display_filename=None)
```


#### class ReadmeRenderer(object)

Renders the Readme. This is an abstract base class.

```python
ReadmeRenderer(user_content=None, context=None)
```


#### class GitHubRenderer(ReadmeRenderer)

Renders the specified Readme using the GitHub Markdown API.

```python
GitHubRenderer(user_content=None, context=None, api_url=None, raw=None)
```


#### class OfflineRenderer(ReadmeRenderer)

Renders the specified Readme locally using pure Python. Note: This is currently
an incomplete feature.

```python
OfflineRenderer(user_content=None, context=None)
```


### Constants


#### SUPPORTED_TITLES

The common Markdown file titles on GitHub.

```python
SUPPORTED_TITLES = ['README', 'Home']
```

- `filename`: The UTF-8 file to read.


#### SUPPORTED_EXTENSIONS

The supported extensions, as defined by [GitHub][markdown].

```python
SUPPORTED_EXTENSIONS = ['.md', '.markdown']
```


#### DEFAULT_FILENAMES

This constant contains the names Grip looks for when no file is provided.

```python
DEFAULT_FILENAMES = [title + ext
                     for title in SUPPORTED_TITLES
                     for ext in SUPPORTED_EXTENSIONS]
```


#### DEFAULT_FILENAME

This constant contains the default Readme filename, namely:

```python
DEFAULT_FILENAME = DEFAULT_FILENAMES[0]  # README.md
```


#### DEFAULT_GRIPHOME

This constant points to the default value if the `GRIPHOME`
[environment variable](#environment-variables) is not specified.

```python
DEFAULT_GRIPHOME = '~/.grip'
```


#### DEFAULT_GRIPURL

The default URL of the Grip server and all its assets:

```python
DEFAULT_GRIPURL = '/__/grip'
```


#### DEFAULT_API_URL

The default app_url value:

```python
DEFAULT_API_URL = 'https://api.github.com'
```


Testing
-------

Install the package and test requirements:

```console
$ pip install -e .[tests]
```

Run tests with [pytest][]:

```console
$ pytest
```

Or to re-run tests as you make changes, use [pytest-watch][]:

```console
$ ptw
```


#### External assumption tests

If you're experiencing a problem with Grip, it's likely that an assumption made
about the GitHub API has been broken. To verify this, run:

```console
$ pytest -m assumption
```

Since the external assumptions rely on an internet connection, you may want to skip
them when developing locally. Tighten the cycle even further by stopping on the
first failure with `-x`:

```console
$ pytest -xm ""not assumption""
```

Or with [pytest-watch][]:

```console
$ ptw -- -xm ""not assumption""
```


Contributing
------------

1. Check the open issues or open a new issue to start a discussion around
   your feature idea or the bug you found
2. Fork the repository and make your changes
3. Open a new pull request

If your PR has been waiting a while, feel free to [ping me on Twitter][twitter].

Use this software often? <a href=""https://saythanks.io/to/joeyespo"" target=""_blank""><img src=""https://img.shields.io/badge/Say%20Thanks-!-1EAEDB.svg"" align=""center"" alt=""Say Thanks!""></a>
:smiley:


[pypi]: http://pypi.python.org/pypi/grip/
[markdown]: http://developer.github.com/v3/markdown
[rdd]: http://tom.preston-werner.com/2010/08/23/readme-driven-development.html
[authors.md]: AUTHORS.md
[offline-renderer]: http://github.com/joeyespo/grip/tree/offline-renderer
[personal access token]: https://github.com/settings/tokens/new?scopes=
[keychain-access]: https://gist.github.com/klmr/3840aa3c12f947e4064c
[task-lists]: https://github.com/blog/1825-task-lists-in-all-markdown-documents
[user-content]: http://github.github.com/github-flavored-markdown
[python-markdown]: http://github.com/waylan/Python-Markdown
[flask.run]: http://flask.pocoo.org/docs/0.10/api/#flask.Flask.run
[flask.debug]: http://flask.pocoo.org/docs/0.10/api/#flask.Flask.debug
[pytest]: http://pytest.org/
[pytest-watch]: https://github.com/joeyespo/pytest-watch
[twitter]: http://twitter.com/joeyespo
","Grip is a command-line server application written in Python that uses the
markdown API to render a local readme file. The styles and rendering come
directly from GitHub, so you'll know exactly how it will appear. Changes you
make to the Readme will be instantly reflected in the browser."
3156,Hawtio web console helps you manage your JVM stuff and stay cool!,"![hawtio][logo]

[![Test](https://github.com/hawtio/hawtio/actions/workflows/test.yml/badge.svg)](https://github.com/hawtio/hawtio/actions/workflows/test.yml)

## Introduction

[Hawtio](http://hawt.io) is a lightweight and modular Web console for managing Java applications.

![Hawtio screenshot](https://raw.githubusercontent.com/hawtio/website/main/static/images/screenshots/camel-route.png)

Hawtio has [lots of plugins](http://hawt.io/docs/plugins/) such as: Apache ActiveMQ ""Classic,"" Apache Camel, JMX, OSGi, Logs, Spring Boot, and Diagnostics.
You can dynamically extend Hawtio with your own plugins or automatically discover plugins inside the JVM.

The only server side dependency (other than the static HTML/CSS/JS/images) is the excellent [Jolokia library](http://jolokia.org) which has small footprint (around 300KB) and is available as a [JVM agent](http://jolokia.org/agent/jvm.html), or comes embedded as a servlet inside the `hawtio-default.war` or can be deployed as [an OSGi bundle](http://jolokia.org/agent/osgi.html).

## Get Started

- [Running an executable JAR](#running-an-executable-jar)
- [Running a Spring Boot app](#running-a-spring-boot-app)
- [Deploying on Apache Karaf](#deploying-on-apache-karaf)
- [Deploying on OpenShift](https://github.com/hawtio/hawtio-online)

For more details and other containers, see [Get Started Guide](http://hawt.io/docs/get-started/).

### Running an executable JAR

You can start up Hawtio on your machine using the hawtio-app executable JAR.

* [hawtio-app-2.17.0.jar](https://repo1.maven.org/maven2/io/hawt/hawtio-app/2.17.0/hawtio-app-2.17.0.jar)

Once you have downloaded it, just run this from the command line:

    java -jar hawtio-app-2.17.0.jar

### Running a Spring Boot app

Attaching the Hawtio console to your Spring Boot app is simple.

1. Add `io.hawt:hawtio-springboot` to the dependencies in `pom.xml`:

        <dependency>
          <groupId>io.hawt</groupId>
          <artifactId>hawtio-springboot</artifactId>
          <version>2.17.0</version>
        </dependency>

2. Enable the Hawtio and Jolokia endpoints by adding the following line in `application.properties`:
   ```
   management.endpoints.web.exposure.include=hawtio,jolokia
   spring.jmx.enabled=true 
   ```




Now you should be able to run Hawtio in your Spring Boot app as follows:

    mvn spring-boot:run

Opening <http://localhost:8080/actuator/hawtio> should show the Hawtio console.

See [Spring Boot example](https://github.com/hawtio/hawtio/tree/hawtio-2.17.0/examples/springboot) for a working example app.

### Deploying on Apache Karaf

If you are using [Apache Karaf](https://karaf.apache.org/) 4.x and above:

    feature:repo-add hawtio 2.17.0
    feature:install hawtio

This will install all the features required for Hawtio. The Hawtio console can then be viewed at <http://localhost:8181/hawtio>.

Karaf versions prior to 4.x are not supported.

## Contributing

We love [contributions](http://hawt.io/docs/contributing/)!  Here are the resources on how to get you involved in Hawtio development.

* [FAQ](http://hawt.io/docs/faq/)
* [Change Log](CHANGES.md)
* [How to contribute](http://hawt.io/docs/contributing/)
* [Community](http://hawt.io/community/)

Check out the [GitHub issues](https://github.com/hawtio/hawtio/issues) for finding issues to work on.

## License

Hawtio is licensed under [Apache License, Version 2.0](LICENSE.txt).

[logo]: http://hawt.io/images/hawtio_logo.svg ""hawtio""
","Hawtio is a lightweight and modular Web console for managing Java applications.
It can be used to manage Apache ActiveMQ ""Classic,"" Apache Camel, JMX, OSGi,
Logs, Spring Boot, and Diagnostics. The only server side dependency is the
excellent [Jolokia library which has a small footprint (around 300KB) You can
start up Hawtio on your machine using the hawtio-app executable JAR. You can
also deploy it using Apache Karaf or OpenShift."
358,":leaves: A curated list of awesome MongoDB resources, libraries, tools and applications","![Awesome MongoDB](logo.png)

# Awesome MongoDB [![Awesome](https://cdn.rawgit.com/sindresorhus/awesome/d7305f38d29fed78fa85652e3a63e154dd8e8829/media/badge.svg)](https://github.com/sindresorhus/awesome)

[![Build status](https://img.shields.io/travis/ramnes/awesome-mongodb.svg)](https://travis-ci.org/ramnes/awesome-mongodb)

> A curated list of awesome MongoDB resources, libraries, tools and applications

Inspired by the [awesome](https://github.com/sindresorhus/awesome) list thing. Feel free to improve this list by [contributing](CONTRIBUTING.md)!

## Table of Contents
 - [Resources](#resources)
   - [Documentation](#documentation)
   - [Articles](#articles)
   - [Books](#books)
   - [Talks](#talks)
   - [Tutorials](#tutorials)
   - [More](#more)
 - [Libraries](#libraries)
   - [C](#c)
   - [C++](#c-1)
   - [C#/.NET](#cnet)
   - [Delphi](#delphi)
   - [Elixir](#elixir)
   - [Erlang](#erlang)
   - [Go](#go)
   - [Haskell](#haskell)
   - [Java](#java)
   - [JavaScript](#javascript)
   - [Julia](#julia)
   - [Kotlin](#kotlin)
   - [Lisp](#lisp)
   - [Mathematica](#mathematica)
   - [PHP](#php)
   - [Python](#python)
   - [R](#r)
   - [Ruby](#ruby)
   - [Rust](#rust)
   - [Scala](#scala)
 - [Tools](#tools)
   - [Administration](#administration)
   - [Data](#data)
   - [Deployment](#deployment)
   - [Desktop](#desktop)
   - [Development](#development)
   - [Monitoring](#monitoring)
   - [Low-Code](#low-code)
   - [Shell](#shell)
   - [Web](#web)
 - [Applications](#applications)

## Resources
### Documentation
 - [MongoDB Server Introduction](https://www.mongodb.com/docs/manual/introduction/)
 - [MongoDB Server Documentation](https://www.mongodb.com/manual/)
 - [MongoDB Tutorials](https://www.mongodb.com/docs/manual/tutorial/)
 - [MongoDB Guides](https://www.mongodb.com/docs/guides/)
 - [MongoDB Developer Center](https://www.mongodb.com/developer/)
 - [MongoDB Driver Documentation](https://www.mongodb.com/docs/drivers/)
 - [MongoDB Connectors](https://www.mongodb.com/connectors/)

### Articles

 - [14 Things I Wish I'd Known When Starting with MongoDB (Phil Factor)](https://www.infoq.com/articles/Starting-With-MongoDB/)
 - [A Custom WordPress Dashboard with MongoDB Atlas, Microsoft Azure, & Serverless Functions (Ahmad Awais)](https://ahmadawais.com/wordpress-mongodb-atlas-microsoft-azure-serverless-functions/)
 - [Building with Patterns](https://www.mongodb.com/blog/post/building-with-patterns-a-summary) - Series of articles regarding MongoDB Design Patterns and common use case of each Design Pattern with real world examples.
 - [Five Things About Scaling MongoDB (A. Jesse Jiryu Davis, MongoDB Inc.)](https://emptysqua.re/blog/five-things/) - Scale 101
 - [Optimizing MongoDB Compound Indexes (A. Jesse Jiryu Davis, MongoDB Inc.)](https://emptysqua.re/blog/optimizing-mongodb-compound-indexes/) - Everything you need/have to know about indexes
 - [Server Discovery And Monitoring In PyMongo, Perl, And C (A. Jesse Jiryu Davis, MongoDB Inc.) ](https://emptysqua.re/blog/server-discovery-and-monitoring-in-pymongo-perl-and-c/)
 - [Monitoring MongoDB performance metrics (Jean-Mathieu Saponaro, Datadog)](https://www.datadoghq.com/blog/monitoring-mongodb-performance-metrics-wiredtiger/)
 - [Tuning MongoDB performance for production systems (Marek Trunkat, Apify)](https://blog.apify.com/tuning-mongodb-performance/) - The techniques and MongoDB Cloud features to debug performance issues and expose sub-optimal queries

### Books
 - [50 Tips and Tricks for MongoDB Developers](https://www.oreilly.com/library/view/50-tips-and/9781449306779/) - Advanced MongoDB tips and tricks, given by a MongoDB inc. engineer
 - [Builder Book](https://builderbook.org) - Learn how to build a full stack JavaScript web app from scratch
 - [MongoDB Applied Design Patterns (Rick Copeland)](https://www.oreilly.com/library/view/mongodb-applied-design/9781449340056/)
 - [Practical MongoDB Aggregations E-Book](https://www.practical-mongodb-aggregations.com/) - Free e-book: How to develop effective and optimal data manipulation and analytics pipelines
 - [The Little MongoDB Book](https://github.com/mongodb-developer/the-little-mongodb-book) - Basic introduction
 - [SaaS Boilerplate Book](https://builderbook.org/book) - Learn how to build a production-ready SaaS web app from scratch

### Talks
 - [MongoDB Schema Design (Tugdual Grall, MongoDB Inc.)](https://www.youtube.com/watch?v=csKBT8zkRf0) [47']
 - [Partial and Fuzzy Matching with MongoDB (John Page, MongoDB Inc.)](https://www.youtube.com/watch?v=hXbLHInH5qU) [35']
 - [Scaling MongoDB on Amazon Web Services (Michael Saffitz, Apptentive)](https://www.youtube.com/watch?v=bkjVhEQocFI) [50']

### Tutorials
 - [Kubernetes examples](https://github.com/kubernetes/examples/tree/master/staging/nodesjs-mongodb) - Deployment tutorial of a basic Node.js and MongoDB web stack on Kubernetes
 - [Deploy a Highly-Available MongoDB Replica Set on AWS](https://eladnava.com/deploy-a-highly-available-mongodb-replica-set-on-aws/)
 - [Sharded Cluster with Docker Compose](https://github.com/minhhungit/mongodb-cluster-docker-compose)

### More
 - [MongoDB source code](https://github.com/mongodb/mongo)
 - [MongoDB University](https://learn.mongodb.com/) - Certifications and free online courses
 - [MongoDB 101 by Academy 3T](https://studio3t.com/academy/) - Free and self-paced MongoDB courses for beginners

## Libraries
### C
 - [mongo-c-driver](https://github.com/mongodb/mongo-c-driver) - Official C driver

### C++
 - [mongo-cxx-driver](https://github.com/mongodb/mongo-cxx-driver) - Official C++ driver

### C#/.NET ###
 - [mongo-csharp-driver](https://github.com/mongodb/mongo-csharp-driver) - Official C# driver
 - [mongo-queue-csharp](https://github.com/dominionenterprises/mongo-queue-csharp) - C# message queue on top of MongoDB
 - [MongoDB Messaging](https://github.com/loresoft/MongoDB.Messaging) - Lightweight queue pub/sub processing library
 - [MongoRepository](https://github.com/RobThree/MongoRepository) - Repository abstraction layer on top of the C# driver

### Delphi
 - [TMongoWire](https://github.com/stijnsanders/TMongoWire) - Minimal community Delphi driver

### Elixir
 - [mongodb](https://github.com/kobil-systems/mongodb) - Community Elixir driver
 - [mongodb_ecto](https://github.com/kobil-systems/mongodb_ecto) - Adapter for the Ecto database wrapper

### Erlang
 - [mongodb-erlang](https://github.com/comtihon/mongodb-erlang) - Community Erlang driver

### Go
 - [Bongo](https://github.com/go-bongo/bongo) - ODM based on mgo
 - [mgo](https://github.com/globalsign/mgo) - Community Go driver
 - [minquery](https://github.com/icza/minquery) - MongoDB cursor that paginates
 - [mongo-go-driver](https://github.com/mongodb/mongo-go-driver) - Official Go driver

### Haskell
 - [mongodb](https://github.com/mongodb-haskell/mongodb/) - Community Haskell driver

### Java
 - [Jongo](https://github.com/bguerout/jongo) - Query in Java as in Mongo shell
 - [Hibernate OGM](https://github.com/hibernate/hibernate-ogm) - The power and simplicity of JPA for NoSQL datastores
 - [mongo-java-driver](https://github.com/mongodb/mongo-java-driver) - Official Java driver
 - [mongo-queue-java](https://github.com/yonderblue/mongo-queue-java) - Java message queue on top of MongoDB
 - [mongoFS](https://github.com/dbuschman7/mongoFS) - An enhancement of GridFS to allow for more features and capabilities
 - [Mongojack](https://github.com/mongojack/mongojack) - Based on Jackson, allows you to easily handle your mongo objects as POJOs
 - [Morphia](https://github.com/MorphiaOrg/morphia) - Java ODM
 - [Morphium](https://github.com/sboesebeck/morphium) - Java ODM and caching layer
 - [Mungbean](https://github.com/jannehietamaki/mungbean) - Community driver for languages running on the JVM
 - [Spring Data MongoDB](https://github.com/spring-projects/spring-data-mongodb) - Spring based, object-document support and repositories

### JavaScript
 - [Camo](https://github.com/scottwrobinson/camo) - Class-based ES6 ODM for Mongo-like databases
 - [DeriveJS](https://github.com/yuval-a/derivejs) - Reactive ODM that uses Javascript Proxies to enable transparent DB persistence
 - [MEAN.JS](https://github.com/meanjs/mean) - Full stack based on MongoDB, Express, AngularJS, and Node.js
 - [MERN (mern-starter)](https://github.com/Hashnode/mern-starter) - Full stack based on MongoDB, Express, React and Node.js
 - [Meteor](https://github.com/meteor/meteor) - Real-time/reactive client-server framework based on MongoDB, with lots of features
 - [Mongoose](https://github.com/Automattic/mongoose) - Node.js asynchronous ODM
 - [CASL Mongoose](https://github.com/stalniy/casl/tree/master/packages/casl-mongoose) - Permissions management library integrated with Mongoose
 - [mongration](https://github.com/awapps/mongration) - Node.js migration framework
 - [Moonridge](https://github.com/capaj/Moonridge) - Framework with live querying on top of Mongoose and socket.io
 - [node-mongodb-native](https://github.com/mongodb/node-mongodb-native) - Official Node.js driver

### Julia
 - [Mongo.jl](https://github.com/Lytol/Mongo.jl) - C driver bindings
 
### Kotlin
- [kmongo](https://github.com/Litote/kmongo) - Kotlin toolkit based on the Java driver

### Lisp
 - [cl-mongo](https://github.com/fons/cl-mongo) - Community Common Lisp interface
 - [mongo-cl-driver](https://github.com/archimag/mongo-cl-driver) Community Common Lisp driver
 - [mongo-el](https://github.com/emacsorphanage/mongo) - Community Emacs Lisp driver

### Mathematica
 - [MongoDBLink](https://github.com/zbjornson/MongoDBLink) - Community Mathematica driver

### PHP
 - [eloquent-mongodb-repository](https://github.com/nilportugues/eloquent-mongodb-repository) - Repository implementation built on top of laravel-mongodb
 - [laravel-mongodb](https://github.com/jenssegers/laravel-mongodb) - Eloquent model and query builder for Laravel
 - [mongodb-repository](https://github.com/nilportugues/mongodb-repository) - Repository implementation
 - [PHP Driver](https://github.com/mongodb/mongo-php-driver) - Official PHP driver
 - [PHPMongo ODM](https://github.com/sokil/php-mongo) - ODM based on the PHP Mongo PECL extension
 - [PHPMongo Migrator](https://github.com/sokil/php-mongo-migrator) - Migration tool based on PHPMongo ODM
 - [yadm](https://github.com/formapro/yadm) - Fast schemaless ODM

### Python
 - [Beanie](https://github.com/roman-right/beanie) - Asynchronous ODM based on [Motor](https://motor.readthedocs.io/en/stable/) and [Pydantic](https://pydantic-docs.helpmanual.io/), which supports migrations out of the box
 - [Djongo](https://github.com/nesdis/djongo) - MongoDB connector for Django compatible with Django ORM
 - [Flask-Stupe](https://github.com/numberly/flask-stupe) - Flask extension that adds PyMongo support to Flask
 - [Mongo-Thingy](https://github.com/numberly/mongo-thingy) - Powerful schema-less ODM for MongoDB and Python (sync + async)
 - [MongoEngine](https://github.com/MongoEngine/mongoengine) - ODM on top of PyMongo
 - [MongoLog](https://github.com/puentesarrin/mongodb-log) - MongoDB logging handler
 - [Motor](https://github.com/mongodb/motor) - Official non-blocking Python driver for Tornado or asyncio
 - [PyMongo](https://github.com/mongodb/mongo-python-driver) - Official Python driver
 - [PyMongoExplain](https://github.com/mongodb-labs/pymongoexplain/) - A wrapper for PyMongo's Collection object that makes it easy to run `explain` on your queries.
 - [minimongo](https://github.com/slacy/minimongo) - A lightweight, schemaless, Pythonic Object-Oriented interface
 - [ODMantic](https://github.com/art049/odmantic) - Asynchronous ODM on top of pydantic
 - [scrapy-mongodb](https://github.com/sebdah/scrapy-mongodb) - MongoDB pipeline for Scrapy
 - [μMongo](https://github.com/Scille/umongo) - Driver-independent (async/sync) ODM based on marshmallow

### R
 - [mongolite](https://github.com/jeroen/mongolite) - Fast and simple client for R

### Ruby
 - [awesome_explain](https://github.com/sandboxws/awesome_explain) - A simple global method to explain Mongoid queries
 - [mongo-ruby-driver](https://github.com/mongodb/mongo-ruby-driver) - Official Ruby driver
 - [Mongoid](https://github.com/mongodb/mongoid) - ODM framework

### Rust
 - [mongodb-rust-driver](https://github.com/mongodb/mongo-rust-driver) - Official Rust driver

### Scala
 - [driver-scala](https://github.com/mongodb/mongo-java-driver/tree/master/driver-scala) - Official Scala driver
 - [ReactiveMongo](https://github.com/ReactiveMongo/ReactiveMongo) - Non-blocking Scala driver
 - [Spark-MongoDB](https://github.com/Stratio/Spark-MongoDB) - Read/write data with Spark SQL

## Tools
### Administration
 - [k8s-backup-mongodb](https://github.com/tuladhar/k8s-backup-mongodb) - Schedule MongoDB backups to S3 with a Kubernetes CronJob.
 - [mgob](https://github.com/stefanprodan/mgob) - Full-featured MongoDB dockerized backup agent
 - [mongoctl](https://github.com/mongolab/mongoctl) - Manage MongoDB servers and replica sets using JSON configurations
 - [MongoDB Smasher](https://github.com/duckie/mongo_smasher) - Generate randomized datasets and benchmark your setup
 - [mongodb-tools](https://github.com/jwilder/mongodb-tools) - Three neat Python scripts to work with collections and indexes
 - [mtools](https://github.com/rueckstiess/mtools) - Collection of scripts to set up test environments and visualize log files
 - [nginx-gridfs](https://github.com/mdirolf/nginx-gridfs) - Nginx module for serving files from GridFS
 - [nginx-mongodb-rest](https://github.com/minhajuddin/nginx-mongodb-rest) - REST client written as an Nginx module
 - [pt-mongodb-query-digest](https://www.percona.com/doc/percona-toolkit/LATEST/pt-mongodb-query-digest.html) - Aggregates queries from query profiler and reports query usage statistics
 - [pt-mongodb-summary](https://www.percona.com/doc/percona-toolkit/LATEST/pt-mongodb-summary.html) - MongoDB cluster status overview command line tool

Services:
 - [Compose](https://www.compose.com/) - IBM DBaaS offer (has other database types too)
 - [MongoDB Atlas](https://www.mongodb.com/cloud/atlas) - MongoDB Inc. DBaaS offer (works with AWS, Azure, or GCP)
 - [MongoDB Cloud Manager](https://www.mongodb.com/cloud/cloud-manager) - MongoDB Inc. databases management offer
 - [ObjectRocket](https://www.objectrocket.com/) - Rackspace DBaaS offer (has other database types too)
 - [Scalegrid](https://scalegrid.io) - Fully managed DBaaS (with option to bring your own Azure/AWS account)

### Data
 - [mongo-connector](https://github.com/yougov/mongo-connector) - Streaming replication to Elasticsearch, Solr, or MongoDB
 - [mongo_fdw](https://github.com/EnterpriseDB/mongo_fdw) - PostgreSQL foreign data wrapper
 - [mongo-hadoop](https://github.com/mongodb/mongo-hadoop) - Hadoop connector
 - [Mongolastic](https://github.com/ozlerhakan/mongolastic) - MongoDB to Elasticsearch (and vice-versa) migration tool
 - [MongoMultiMaster](https://github.com/rick446/mmm) - Multi-master replication

Services:
 - [ProvenDB](https://www.provendb.com/) -  Blockchain based Data integrity solution for MongoDB

### Deployment
 - [ansible-role-mongodb](https://github.com/UnderGreen/ansible-role-mongodb) - Ansible role
 - [chef-mongodb](https://github.com/edelight/chef-mongodb) - Chef cookbook
 - [DockerHub Official Docker Image](https://hub.docker.com/_/mongo/)
 - [Helm Chart](https://github.com/helm/charts/tree/master/stable/mongodb)
 - [puppet-mongodb](https://github.com/voxpupuli/puppet-mongodb) - Puppet module (formerly puppetlabs-mongodb)

Services:
 - [Cluster to cluster sync](https://www.mongodb.com/products/cluster-to-cluster-sync) - MongoDB Inc. solution for continuous data sync between separate clusters

### Desktop
 - [Compass](https://github.com/mongodb-js/compass) - Free Cross-platform GUI from MongoDB
 - [MongoDB for VS Code](https://marketplace.visualstudio.com/items?itemName=mongodb.mongodb-vscode) - Connect to MongoDB and prototype queries from VS Code
 - [MongoHub](https://github.com/jeromelebel/MongoHub-Mac) - Mac native client

Services:
 - [DataGrip](https://www.jetbrains.com/datagrip/) - Cross-platform JetBrains' IDE
 - [Mingo](https://mingo.io/) - MongoDB Admin. Intuitive UI. Fast. Reliable
 - [Moon Modeler](http://www.datensen.com/) - Data modeling tool for MongoDB and relational databases
 - [NoSQLBooster](https://nosqlbooster.com) - Feature-rich but easy-to-use cross-platform IDE (formerly MongoBooster)
 - [QueryAssist](https://queryassist.com) - Modern and powerful GUI tool, cross-platform and easy-to-use
 - [Studio 3T](https://studio3t.com/) - Cross-platform GUI, stable and powerful (formerly MongoChef and Robo 3T)
 - [TablePlus](https://tableplus.com/) - Native, lightweight GUI on macOS

### Development
 - [C# Analyzer](https://github.com/mongodb/mongo-csharp-analyzer) - View the MongoDB Query API equivalents of your builder expressions in Visual Studio
 - [mgodatagen](https://github.com/feliixx/mgodatagen) - Random data generator
 - [Mongo Playground](https://github.com/feliixx/mongoplayground) - Online query playground
 - [Mongo Seeding](https://github.com/pkosiec/mongo-seeding) - Node.js library, CLI and Docker image for populating databases using JS and JSON files
 - [Mongoeye](https://github.com/mongoeye/mongoeye) - Schema and data analyzer: explore data in your collections
 - [Variety](https://github.com/variety/variety) - Schema analyzer: see what fields are in your collection and what's their content
 - [VS Code Extension](https://github.com/mongodb-js/vscode)

Services:
 - [MongoDB Atlas App Services](https://www.mongodb.com/atlas/app-services) - MongoDB Inc. solution to run code without the operational overhead
 - [MongoDB Realm](https://www.mongodb.com/realm) - MongoDB Inc. solution for mobile data sync

### Monitoring
 - [check_mongodb](https://github.com/dalenys/check_mongodb) - Nagios plugin (in Bash)
 - [mongo-monitor](https://github.com/dwmkerr/mongo-monitor) - Simple monitoring CLI
 - [mongo-munin](https://github.com/erh/mongo-munin) - Collection of Munin plugins
 - [Mongoop](https://github.com/Lujeni/mongoop) - Long operations monitoring and alerting
 - [mongomon](https://github.com/pcdummy/mongomon) - More Munin plugins
 - [Motop](https://github.com/tart/motop) - MongoDB top clone
 - [mtop](https://github.com/beaufour/mtop) - Another top clone
 - [nagios-plugin-mongodb](https://github.com/mzupan/nagios-plugin-mongodb) - Nagios plugin (in Python)
 - [Percona Monitoring and Management](https://www.percona.com/software/database-tools/percona-monitoring-and-management) - Free and open-source platform for managing and monitoring databases performances
 - [mongotail](https://github.com/mrsarm/mongotail) - Log all MongoDB queries in a ""tail""able way

Services:

 - [Datadog](https://www.datadoghq.com/blog/monitor-mongodb-performance-with-datadog/) - SaaS-based monitoring
 - [Solarwindws Database Performance Monitor](https://www.solarwinds.com/database-performance-monitor) - SaaS-based query performance analytics and monitoring

### Low-Code

> 💡 These tools are not necessarily made for MongoDB in particular, but support it.

 - [Appsmith](https://github.com/appsmithorg/appsmith) - Open-source Retool alternative
 - [Appwrite](https://github.com/appwrite/appwrite) - Open-source Firebase alternative
 - [Budibase](https://github.com/Budibase/budibase) - Open-source Retool alternative
 - [ILLA Builder](https://github.com/illacloud/illa-builder) - Open-source Retool alternative
 - [Tooljet](https://github.com/ToolJet/ToolJet) - Open-source Retool alternative

Services:
- [DronaHQ](https://www.dronahq.com/) - Retool alternative
- [Retool](https://retool.com/) - Drag-and-drop editor with pre-built components to build internal tools

### Shell
 - [MongoDB Atlas CLI](https://github.com/mongodb/mongodb-atlas-cli) - Official Atlas API command-line client
 - [mongosh](https://github.com/mongodb-js/mongosh) - Official command-line client

### Web
 - [adminMongo](https://github.com/mrvautin/adminMongo) - Web-based user interface to handle connections and databases needs
 - [mongo-express](https://github.com/mongo-express/mongo-express) - Web-based admin interface built with Express
 - [mongoadmin](https://github.com/thomasst/mongoadmin) - Admin interface built with Django
 - [Mongoku](https://github.com/huggingface/Mongoku) - MongoDB client for the web
 - [mongri](https://github.com/dongri/mongri) - Web-based user interface written in JavaScript
 - [Rockmongo](https://github.com/iwind/rockmongo) - PHPMyAdmin for MongoDB, sort of

Services:

 - [HumongouS.io](https://www.humongous.io) - Easy online GUI and data-visualization dashboards

## Applications

Those open-source applications have MongoDB somewhere in their stack:

 - [Builder Book App](https://github.com/async-labs/builderbook) - Web app to publish books or documentation built with React and Express
 - [CodeCombat](https://github.com/codecombat/codecombat) - Multiplayer programming game for learning how to code
 - [Countly](https://github.com/countly/countly-server) - Mobile & web analytics and marketing platform built with Node.js
 - [FactorJS](https://github.com/fiction-com/factor) - JavaScript CMS built with Mongoose
 - [GrandNode](https://github.com/grandnode/grandnode) - Multi-platform e-commerce shopping cart built with ASP.NET
 - [Leanote](https://github.com/leanote/leanote) - Evernote clone built with Go
 - [NodeBB](https://github.com/NodeBB/NodeBB) - Node.js based forum software (""built for the modern web"")
 - [Reaction](https://github.com/reactioncommerce/reaction) - Event-driven, real-time commerce platform built with ES6
 - [SaaS Boilerplate](https://github.com/async-labs/saas) - Boilerplate for SaaS products, built with TypeScript, React and Express
 - [uptime](https://github.com/fzaninotto/uptime) - Remote monitoring application built with Node.js and Bootstrap
 - [WildDuck Mail Server](https://github.com/nodemailer/wildduck) - Scalable high availability email server that uses MongoDB for email storage

## License
[![CC0](http://mirrors.creativecommons.org/presskit/buttons/88x31/svg/cc-zero.svg)](https://creativecommons.org/publicdomain/zero/1.0/)

To the extent possible under law, [Guillaume Gelin](https://github.com/ramnes) has waived all copyright and related or neighboring rights to this work.
","summarize:![Awesome MongoDB](logo.png) # Awesome MongoDB [![Awesome](https://cdn
.rawgit.com/sindresorhus/awesome/d7305f38d29fed78fa85652e3a63e154dd8e8829/media/
badge.svg) # awesome MongoDB resources, libraries, tools and applications."
3122,a cozy nest for your scripts,"# `sd`: my `s`cript `d`irectory

- [Usage](#usage)
- [Installation](#installation)
- [Changelog](#changelog)

Has this ever happened to you?

*Black and white video plays of someone struggling to find a shell script they wrote a year ago and stuffed into their `~/bin` without giving it a very meaningful name.*

Don't you hate it when you can't find the scripts you need, when you need it? Well now there's a better way!

*Color fills the screen. Someone holds `sd` up to the camera, and flashes a winning smile. They've found the script on their first try.*

Introducing `sd`, the script directory for the refined, sophisticated professional. Simply organize your scripts in a logical directory hierarchy, and let `sd` take care of the rest!

    $ tree ~/sd
    /Users/ian/sd
    ├── blog
    │   ├── edit
    │   ├── preview
    │   └── publish
    ├── nix
    │   ├── diff
    │   ├── info
    │   └── sync
    └── tmux
        └── init

And now instead of typing `~/sd/blog/publish`, you can just type `sd blog publish` -- a savings of nearly three whole characters!

But wait! There's more! You'll wonder how you ever lived without `sd`'s best-in-class tab completion:

    $ sd nix <TAB>
    diff  -- prints what will happen if you run sync
    info  -- <package> prints package description
    sync  -- make user environment match ~/dotfiles/user.nix

Simply write a one-line comment in your script, and you'll never be left scratching your head over how you were supposed to call it!

# uhh

Hi okay sorry. [Take a look at this blog post for a real introduction and a fancy asciinema demo of how it works.](https://ianthehenry.com/posts/sd-my-script-directory/)

# Usage

The default behavior for `sd foo bar` is:

- If `~/sd/foo` is an executable file, execute `~/sd/foo bar`.
- If `~/sd/foo/bar` is an executable file, execute it with no arguments.
- If `~/sd/foo/bar` is a directory, this is the same is `sd foo bar --help` (it prints usage information).
- If `~/sd/foo/bar` is a non-executable regular file, this is the same is `sd foo bar --cat` (it just prints the file out).

There are some special flags that are significant to `sd`. If you supply any one of these arguments, `sd` will not invoke your script, and will do something fancier instead.

    $ sd foo bar --help
    $ sd foo bar --new
    $ sd foo bar --edit
    $ sd foo bar --cat
    $ sd foo bar --which
    $ sd foo bar --really

## `--help`

Print the contents of a help file, or generate a help file from comments in a script.

For executables, `sd` looks for a file with the same name but the `.help` extension. For example, `sd nix diff --help` would look for a file called `~/sd/nix/diff.help`, and print it out.

For directories, `sd` looks for a file that's just called `help`. So `sd nix --help` would look for `~/sd/nix/help`.

If there is no help file for an executable, `sd` will print the first comment block in the file instead. `sd` currently only recognizes bash-style `#` comments.

For example:

    $ cat ~/sd/nix/sync

```bash
#!/usr/bin/env bash

# make user environment match ~/dotfiles/user.nix
#
# This will remove any packages you've installed with nix-env
# but have not added to user.nix. To see exactly what this
# will do, run:
#
#     sd nix diff

set -euo pipefail

# maybe this should be configurable
nix-env -irf ~/dotfiles/user.nix
```

That will produce the following help output (note that it only prints the first contiguous comment block):

```
$ sd nix sync --help
make user environment match ~/dotfiles/user.nix

This will remove any packages you've installed with nix-env
but have not added to user.nix. To see exactly what this
will do, run:

    sd nix diff
```

If you run `--help` for a directory, it will also print out a command listing after the help text:

```
$ sd nix --help
nix commands

install    -- <package> use --latest to install from nixpkgs-unstable
shell      -- add gcroots for shell.nix
diff       -- prints what will happen if you run sync
info       -- <package> prints package description
sync       -- make user environment match ~/dotfiles/user.nix
```

## `--new`

Everything to the left of `--new` is considered a command path, and everything to the right of `--new` is considered the command body. For example:

    $ sd foo bar --new echo hi

Will try to create a new command at `~/sd/foo/bar` with an initial contents of `echo hi`.

Actually, to be more precise, it will create this script:

    $ cat ~/sd/foo/bar

```bash
#!/usr/bin/env bash

set -euo pipefail

echo hi
```

Assuming the default template.

If no body is supplied after `--new`, `sd` will open the script for editing.

### custom script templates

You can customize the template used by `--new` by creating a file called `template`, either in `~/sd` or one of its subdirectories.

`sd` will try to find a template by walking recursively up the directory hierarchy. For example, if you run:

```
$ sd foo bar baz --new
```

`sd` will try to find a template at `~/sd/foo/bar/template` first, then fall back to `~/sd/foo/template`, then `~/sd/template`. If it doesn't find any template file, it will use the default bash template shown above.

(There is no need to make your `template` executable -- `sd` will take care of that for you.)

When `--new` is used to create an inline script, that script will always go at the *end* of your template file. There is currently no way to customize this.

## `--cat`

Prints the contents of the script. See `SD_CAT` below.

## `--edit`

Open the script in an editor. See `SD_EDITOR` below.

## `--which`

Prints the path of the script.

## `--really`

Suppress special handling of all of the other special flags. This allows you to pass `--help` or `--new` as arguments to your actual script, instead of being interpreted by `sd`. For example:

    $ sd foo bar --help --really

Will invoke:

    ~/sd/foo/bar --help

The first occurrence of the `--really` argument will be removed from the arguments passed to the script, so if you need to pass a literal `--really`, you must pass it twice to `sd`. For example:

    $ sd foo bar --help --really --really

Will invoke:

    $ ~/sd/foo/bar --help --really

# Context

When a script is invoked, `sd` will set the environment variable `SD` to the directory that the script was found in -- in other words, `$(dirname ""$0"")`.

This makes it slightly more convenient to refer to shared helper files or other scripts relative to the executing script.

# Options

`sd` respects some environment variables:

- `SD_ROOT`: location of the script directory. Defaults to `$HOME/sd`.
- `SD_EDITOR`: used by `sd foo --edit` and `sd foo --new`. Defaults to `$VISUAL`, then `$EDITOR`, then finally falls back to `vi` if neither of those are set.
- `SD_CAT`: program used when printing files, in case you want to use something like [`bat`](https://github.com/sharkdp/bat). Defaults to `cat`.

# Installation

There are two ways to use `sd`:

1. source the `sd` file, which will define the shell function `sd`
2. treat `sd` as a regular executable and put it somewhere on your `PATH`

I prefer to use `sd` as a regular executable, but the function approach is more convenient if you already use a shell plugin manager that knows how to set up `fpath` automatically.

Note that you cannot invoke ""recursive `sd`"" (that is, write scripts that themselves invoke `sd`) if you use the function approach. This includes all of the helper scripts in `sdefaults/` (explained below).

## Installation as a regular script

`sd` is not currently packaged in any package manager that I am aware of, but it should be pretty easy if you want to package it for your distribution. It's just a single script and a single completion file. Until that day:

1. Put the `sd` script somewhere on your `PATH`.
2. Put the `_sd` completion script somewhere on your `fpath`.

I like to symlink `sd` to `~/bin`, which is already on my path. If you've cloned this repo to `~/src/sd`, you can do that by running something like:

    $ ln -s ~/src/sd/sd ~/bin/sd

There isn't really a standard place in your home directory to put completion scripts, so unless you've made your own, you'll probably want to add your clone directly to your `fpath`. You should add that to your `.zshrc` file before the line where you call `compinit`. It should look something like this:

    # ~/.zshrc

    fpath=(~/src/sd $fpath)
    autoload -U compinit
    compinit

If you use a zsh framework like [`oh-my-zsh`](https://github.com/ohmyzsh/ohmyzsh), it probably calls `compinit` for you. In that case, just set your `fpath` before you source the framework's initialization script.

Note that changes you make to your `~/.zshrc` will only take effect for *future* shells you create, so to start enjoying `sd` immediately you'll also want to run these commands in your existing shells:

    $ fpath=(~/src/sd $fpath)
    $ compinit

## Installation as a shell function

You can just source `sd` in your `.zshrc` and set up completion manually (as described below), but `sd` is designed to be compatible with shell plugin managers.

### [Antigen](https://github.com/zsh-users/antigen)

Add this line to your `.zshrc`:

```shell
antigen bundle ianthehenry/sd
```

### [oh-my-zsh](https://github.com/ohmyzsh/ohmyzsh):

Clone this repo into your custom plugins directory:

```
$ git clone https://github.com/ianthehenry/sd.git ${ZSH_CUSTOM:-~/.oh-my-zsh/custom}/plugins/sd
```

And then add it to the plugins list in your `~/.zshrc` before you source `oh-my-zsh`:

```
plugins+=(sd)
source ""$ZSH/oh-my-zsh.sh""
```

## `sd help command` vs. `sd command --help`

There are some scripts in `sdefaults/` that you can copy into your own `~/sd` if you like. They'll let you type `sd cat foo bar` instead of `sd foo bar --cat` or `sd new foo -- echo hi` instead of `sd foo --new echo hi` (and so on for each of the built-in commands).

These mostly exist for backwards compatibility with an earlier version of `sd`. You don't have to use them if you don't want to. Note that they will not work if you've installed `sd` as a shell function instead of an executable.

# bash/fish autocompletion support

Patrick Jackson contributed [an unofficial fish completion script](https://gist.github.com/patricksjackson/5065e4a9d8e825dafc7824112f17a5e6), which should be usable with some modification (as written it does not respect `SD_ROOT`, but it should act as a very good starting point if you use fish).

Bash doesn't support the fancy completion-with-description feature that is sort of the whole point of `sd`, but there are apparently ways to hack something similar.

# Changelog

## v1.1.0 2022-10-30

- fix a bug where `--help` would print every comment in the script

## v1.0.1 2022-04-17

- better error message if `~/sd` does not exist
- better error message if `~/sd` exists but is not a directory

## v1.0.0 2022-02-27

`sd` is now released under the MIT license. There are no functional changes from the pre-1.0 releases.

## v0.3.0 2022-02-26

- scripts now run with the `SD` environment variable set to the directory they were found in
- autocompletion now completes arguments to commands instead of just commands
    - only completes positional file arguments and the built-in flags (like `--help`)
- `sd` now only forks a subshell when invoked as a function
- `sd` now `exec`s scripts instead of `fork`+`exec`
    - this fixes the rare issue where a long-running script could throw errors when it finished if you were editing the `sd` executable itself while the script was running, because `bash` was trying to execute the ""rest"" of the file and apparently doing so by byte index or something (??)
    - this only affects me

## v0.2.0 2022-02-24

- added per-directory `template` files, to override the `bash` default

## v0.1.1 2021-12-05

- fix a bug where `--new` wouldn't work unless provided with an initial script

## v0.1.0 2021-12-01

- added `--really`
- `dir.help` files are now `dir/help` files

You used to be able to provide a description for a directory called `foo/` by writing a file called `foo.help` as a sibling of that directory.

Now directory help summaries are expected in `foo/help` instead.

This has the sort-of nice effect that `sd foo help` is sometimes similar to `sd foo --help`. Except that the latter also prints out subcommands.
","Introducing `sd, the script directory for the refined, sophisticated
professional. Simply organize your scripts in a logical directory hierarchy, and
let `sd` take care of the rest. You can write a one-line comment in your script,
and you'll never be left scratching your head over how to call it!"
3218,"A development tool for all your projects that is fast, easy, powerful and liberating","<div align=""center"">

<a href=""https://lando.dev"" target=""_blank""><img width=""250"" src=""https://docs.lando.dev/images/icon.svg"" alt=""Lando logo""></a>

# Lando

### A Liberating Dev Tool For All Your Projects

The local development and DevOps tool trusted by professional developers across the galaxy.

Free yourself from the mind-forged manacles of lesser dev tools. Save time, headaches, frustration and do more real work.

**[learn more](https://lando.dev) | 
[what is it good for?](https://docs.lando.dev/getting-started/#what-is-it-good-for) | 
[wait, doesn't docker compose do this?](https://docs.lando.dev/getting-started/#wait-doesn-t-docker-compose-do-this)**

## Support Lando

Lando is and always will be FREE and OPEN SOURCE. As such it relies on generous contributions from its community to fund its development. Join our list of list of [great sponsors!](https://lando.dev/sponsor/) by contributing.

[GitHub Sponsors](https://github.com/sponsors/lando) | 
[Patreon](https://www.patreon.com/devwithlando) | 
[OpenCollective](https://opencollective.com/lando)

## Documentation

### Getting Started

[Introduction](https://docs.lando.dev/getting-started) | 
[CLI Usage](https://docs.lando.dev/cli/) | 
[Installation](https://docs.lando.dev/getting-started/installation)

### Recipes

[Backdrop](https://docs.lando.dev/backdrop/) | 
[Drupal 6, 7, 8, 9, and 10](https://docs.lando.dev/drupal/) | 
[Joomla](https://docs.lando.dev/joomla/) | 
[Lagoon](https://docs.lando.dev/lagoon/) | 
[Laravel](https://docs.lando.dev/laravel/) | 
[LAMP](https://docs.lando.dev/lamp/) | 
[LEMP](https://docs.lando.dev/lemp/) | 
[MEAN](https://docs.lando.dev/mean/) | 
[Pantheon](https://docs.lando.dev/pantheon/) | 
[Platform.sh](https://docs.lando.dev/platformsh/) | 
[WordPress](https://docs.lando.dev/wordpress/)

### Services

[Apache](https://docs.lando.dev/apache/) | 
[Compose](https://docs.lando.dev/compose/) | 
[dotnet](https://docs.lando.dev/dotnet/) | 
[Elasticsearch](https://docs.lando.dev/elasticsearch/) | 
[Go](https://docs.lando.dev/go/) | 
[MailHog](https://docs.lando.dev/mailhog/) | 
[MariaDB](https://docs.lando.dev/mariadb/) | 
[MySQL](https://docs.lando.dev/mysql/) | 
[MSSQL](https://docs.lando.dev/mssql/) | 
[nginx](https://docs.lando.dev/nginx/) | 
[Node](https://docs.lando.dev/node/) | 
[PHP](https://docs.lando.dev/php/) | 
[PhpMyAdmin](https://docs.lando.dev/phpmyadmin/) | 
[Postgres](https://docs.lando.dev/postgres/) | 
[Python](https://docs.lando.dev/python/) | 
[Redis](https://docs.lando.dev/redis/) | 
[Ruby](https://docs.lando.dev/ruby/) | 
[Solr](https://docs.lando.dev/solr/) | 
[Tomcat](https://docs.lando.dev/tomcat/) | 
[Varnish](https://docs.lando.dev/varnish/)

### Advanced Configuration

[Landofile](https://docs.lando.dev/config/lando.html) | 
[Recipes](https://docs.lando.dev/config/recipes.html) | 
[Services & Build Steps](https://docs.lando.dev/config/services.html) | 
[Tooling](https://docs.lando.dev/config/tooling.html) | 
[Proxy & Nice Url Routing](https://docs.lando.dev/config/proxy.html) | 
[Environment](https://docs.lando.dev/config/env.html) | 
[Events & Automation](https://docs.lando.dev/config/events.html) | 
[Experimental](https://docs.lando.dev/config/experimental.html) | 
[Networking](https://docs.lando.dev/config/networking.html) | 
[Performance](https://docs.lando.dev/config/performance.html) | 
[Release Channels](https://docs.lando.dev/config/releases.html) | 
[SSH Keys](https://docs.lando.dev/config/ssh.html) | 
[Global Config](https://docs.lando.dev/config/global.html)

## Help, Troubleshooting & Support

[Guides and Tutorials](https://docs.lando.dev/guides/lando-info.html) | 
[Examples](https://docs.lando.dev/getting-started/what-it-do.html#you-have-some-examples) | 
[Known Issues](https://docs.lando.dev/help/dns-rebind.html) | 
[Accessing Logs](https://docs.lando.dev/help/logs.html) | 
[GitHub Issue Queue](https://github.com/lando/lando/issues) | 
[Slack Channel](https://launchpass.com/devwithlando) | 
[YouTube Videos](https://www.youtube.com/channel/UCl_QBNuGJNoo7yH-n18K7Kg)

## Engage

[Contribute to the Project](https://docs.lando.dev/contrib) | 
[Join the Alliance](https://docs.lando.dev/contrib) | 
[Events and Meetups](https://lando.dev/events/) | 
[Blog](https://lando.dev/blog/) | 
[Follow on Twitter](https://twitter.com/devwithlando)

## Security Issues
If you have discovered a security issue with Lando, please contact the Lando Security Team directly at [security@devwithlando.io](mailto:security@devwithlando.io). We manage security issues separately in a private repository until the issue has been resolved. Even if you're not sure if it's a security problem, please contact the security team before filing an issue, blogging, or tweeting about it.

## Other Resources
* [Mountain climbing advice](https://www.youtube.com/watch?v=tkBVDh7my9Q)
","Lando is a local development and DevOps tool trusted by professional developers
across the galaxy. Save time, headaches, frustration and do more real work with
Lando. Lando is and always will be FREE and OPEN SOURCE. As such it relies on
generous contributions from its community to fund its development. Join our list
of [great sponsors!](https://lando.dev/sponsor/)"
859,A runtime developer console and IRB alternative with powerful introspection capabilities.,"Pry
===

[![Pry Build Status](https://github.com/pry/pry/workflows/pry/badge.svg)](https://github.com/pry/pry/actions)
[![Code Climate](https://codeclimate.com/github/pry/pry.svg)](https://codeclimate.com/github/pry/pry)
[![Gem Version](https://badge.fury.io/rb/pry.svg)](https://badge.fury.io/rb/pry)
[![Documentation Status](https://inch-ci.org/github/pry/pry.svg?branch=master)](https://inch-ci.org/github/pry/pry)
[![Downloads](https://img.shields.io/gem/dt/pry.svg?style=flat)](https://rubygems.org/gems/pry)

![Pry logo](https://www.dropbox.com/s/zp8o63kquby2rln/pry_logo_350.png?raw=1)

© John Mair ([banisterfiend](https://twitter.com/banisterfiend)) 2018<br> (Creator)

© Kyrylo Silin ([kyrylosilin](https://twitter.com/kyrylosilin)) 2018<br> (Maintainer)

**Alumni:**

* Conrad Irwin
* Ryan Fitzgerald
* Robert Gleeson

**Links:**

* https://pry.github.io/
* [YARD API documentation](https://www.rubydoc.info/gems/pry)
* [Wiki](https://github.com/pry/pry/wiki)

Table of Contents
=================

* [Introduction](#introduction)
* [Key features](#key-features)
* [Installation](#installation)
* [Overview](#overview)
   * [Commands](#commands)
   * [Navigating around state](#navigating-around-state)
   * [Runtime invocation](#runtime-invocation)
   * [Command Shell Integration](#command-shell-integration)
   * [Code Browsing](#code-browsing)
   * [Documentation Browsing](#documentation-browsing)
   * [Edit methods](#edit-methods)
   * [Live Help System](#live-help-system)
   * [Use Pry as your Rails Console](#use-pry-as-your-rails-console)
   * [Syntax Highlighting](#syntax-highlighting)
* [Supported Rubies](#supported-rubies)
* [Contact](#contact)
* [License](#license)
* [Contributors](#contributors)

Introduction
------------

Pry is a runtime developer console and IRB alternative with powerful
introspection capabilities. Pry aims to be more than an IRB replacement. It is
an attempt to bring REPL driven programming to the Ruby language.

Key features
------------

* Source code browsing (including core C source with the pry-doc gem)
* Documentation browsing
* Live help system
* Open methods in editors (`edit Class#method`)
* Syntax highlighting
* Command shell integration (start editors, run git, and rake from within Pry)
* Gist integration
* Navigation around state (`cd`, `ls` and friends)
* Runtime invocation (use Pry as a developer console or debugger)
* Exotic object support (BasicObject instances, IClasses, ...)
* A powerful and flexible command system
* Ability to view and replay history
* Many convenience commands inspired by IPython, Smalltalk and other advanced
  REPLs
* A wide-range number of
  [plugins](https://github.com/pry/pry/wiki/Available-plugins) that provide
  remote sessions, full debugging functionality, and more.

Installation
------------

### Bundler

```ruby
gem 'pry', '~> 0.13.1'
```

### Manual

```sh
gem install pry
```

Overview
--------

Pry is fairly flexible and allows significant user
[customization](https://github.com/pry/pry/wiki/Customization-and-configuration).
It is trivial to read from any object that has a `readline` method and
write to any object that has a `puts` method. Many other aspects of Pry are
also configurable, making it a good choice for implementing custom shells.

Pry comes with an executable so it can be invoked at the command line. Just
enter `pry` to start. A `pryrc` file in `$XDG_CONFIG_HOME/pry/` or the user's
home directory will be loaded if it exists. Type `pry --help` at the command
line for more information.

### Commands

Nearly every piece of functionality in a Pry session is implemented as a
command. Commands are not methods and must start at the beginning of a line,
with no whitespace in between. Commands support a flexible syntax and allow
'options' in the same way as shell commands, for example the following Pry
command will show a list of all private instance methods (in scope) that begin
with 'pa'

```ruby
pry(YARD::Parser::SourceParser):5> ls -Mp --grep ^pa
YARD::Parser::SourceParser#methods: parse  parser_class  parser_type  parser_type=  parser_type_for_filename
```

### Navigating around state

Pry allows us to pop in and out of different scopes (objects) using the `cd`
command. This enables us to explore the run-time view of a program or
library. To view which variables and methods are available within a particular
scope we use the versatile [ls
command.](https://gist.github.com/c0fc686ef923c8b87715)

Here we will begin Pry at top-level, then Pry on a class and then on an instance
variable inside that class:

```ruby
pry(main)> class Hello
pry(main)*   @x = 20
pry(main)* end
=> 20
pry(main)> cd Hello
pry(Hello):1> ls -i
instance variables: @x
pry(Hello):1> cd @x
pry(20):2> self + 10
=> 30
pry(20):2> cd ..
pry(Hello):1> cd ..
pry(main)> cd ..
```

The number after the `:` in the pry prompt indicates the nesting level. To
display more information about nesting, use the `nesting` command. E.g

```ruby
pry(""friend""):3> nesting
Nesting status:
0. main (Pry top level)
1. Hello
2. 100
3. ""friend""
=> nil
```

We can then jump back to any of the previous nesting levels by using the
`jump-to` command:

```ruby
pry(""friend""):3> jump-to 1
=> 100
pry(Hello):1>
```

### Runtime invocation

Pry can be invoked in the middle of a running program. It opens a Pry session at
the point it's called and makes all program state at that point available. It
can be invoked on any object using the `my_object.pry` syntax or on the current
binding (or any binding) using `binding.pry`. The Pry session will then begin
within the scope of the object (or binding). When the session ends the program
continues with any modifications you made to it.

This functionality can be used for such things as: debugging, implementing
developer consoles and applying hot patches.

code:

```ruby
# test.rb
require 'pry'

class A
  def hello() puts ""hello world!"" end
end

a = A.new

# start a REPL session
binding.pry

# program resumes here (after pry session)
puts ""program resumes here.""
```

Pry session:

```ruby
pry(main)> a.hello
hello world!
=> nil
pry(main)> def a.goodbye
pry(main)*   puts ""goodbye cruel world!""
pry(main)* end
=> :goodbye
pry(main)> a.goodbye
goodbye cruel world!
=> nil
pry(main)> exit

program resumes here.
```

### Command Shell Integration

A line of input that begins with a '.' will be forwarded to the command
shell. This enables us to navigate the file system, spawn editors, and run git
and rake directly from within Pry.

Further, we can use the `shell-mode` command to incorporate the present working
directory into the Pry prompt and bring in (limited at this stage, sorry) file
name completion.  We can also interpolate Ruby code directly into the shell by
using the normal `#{}` string interpolation syntax.

In the code below we're going to switch to `shell-mode` and edit the `pryrc`
file. We'll then cat its contents and reload the file.

```ruby
pry(main)> shell-mode
pry main:/home/john/ruby/projects/pry $ .cd ~
pry main:/home/john $ .emacsclient .pryrc
pry main:/home/john $ .cat .pryrc
def hello_world
  puts ""hello world!""
end
pry main:/home/john $ load "".pryrc""
=> true
pry main:/home/john $ hello_world
hello world!
```

We can also interpolate Ruby code into the shell. In the example below we use
the shell command `cat` on a random file from the current directory and count
the number of lines in that file with `wc`:

```ruby
pry main:/home/john $ .cat #{Dir['*.*'].sample} | wc -l
44
```

### Code Browsing

You can browse method source code with the `show-source` command. Nearly all
Ruby methods (and some C methods, with the pry-doc gem) can have their source
viewed. Code that is longer than a page is sent through a pager (such as less),
and all code is properly syntax highlighted (even C code).

The `show-source` command accepts two syntaxes, the typical ri `Class#method`
syntax and also simply the name of a method that's in scope. You can optionally
pass the `-l` option to `show-source` to include line numbers in the output.

In the following example we will enter the `Pry` class, list the instance
methods beginning with 'se' and display the source code for the `set_last_result` method:

```ruby
pry(main)> cd Pry
pry(Pry):1> ls -M --grep se
Pry#methods: raise_up  raise_up!  raise_up_common  reset_eval_string  select_prompt  set_last_result
pry(Pry):1> show-source set_last_result -l

From: /home/john/ruby/projects/pry/lib/pry/pry_instance.rb:405:
Owner: Pry
Visibility: public
Signature: set_last_result(result, code=?)
Number of lines: 6

405: def set_last_result(result, code = """")
406:   @last_result_is_exception = false
407:   @output_ring << result
408:
409:   self.last_result = result unless code =~ /\A\s*\z/
410: end
```

Note that we can also view C methods (from Ruby Core) using the
`pry-doc` plugin; we also show off the alternate syntax for
`show-source`:

```ruby
pry(main)> show-source Array#select

From: array.c in Ruby Core (C Method):
Number of lines: 15

static VALUE
rb_ary_select(VALUE ary)
{
    VALUE result;
    long i;

    RETURN_ENUMERATOR(ary, 0, 0);
    result = rb_ary_new2(RARRAY_LEN(ary));
    for (i = 0; i < RARRAY_LEN(ary); i++) {
        if (RTEST(rb_yield(RARRAY_PTR(ary)[i]))) {
            rb_ary_push(result, rb_ary_elt(ary, i));
        }
    }
    return result;
}
```

### Documentation Browsing

One use-case for Pry is to explore a program at run-time by `cd`-ing in and out
of objects and viewing and invoking methods. In the course of exploring it may
be useful to read the documentation for a specific method that you come
across. `show-source` command supports two syntaxes - the
normal `ri` syntax as well as accepting the name of any method that is currently
in scope.

The Pry documentation system does not rely on pre-generated `rdoc` or `ri`,
instead it grabs the comments directly above the method on demand. This results
in speedier documentation retrieval and allows the Pry system to retrieve
documentation for methods that would not be picked up by `rdoc`. Pry also has a
basic understanding of both the rdoc and yard formats and will attempt to syntax
highlight the documentation appropriately.

Nonetheless, the `ri` functionality is very good and has an advantage over Pry's
system in that it allows documentation lookup for classes as well as
methods. Pry therefore has good integration with `ri` through the `ri`
command. The syntax for the command is exactly as it would be in command-line -
so it is not necessary to quote strings.

In our example we will enter the `Gem` class and view the documentation for the
`try_activate` method:

```ruby
pry(main)> cd Gem
pry(Gem):1> show-source try_activate -d

From: /Users/john/rbenv/versions/2.7.1/lib/ruby/2.7.0/rubygems.rb:194:
Owner: #<Class:Gem>
Visibility: public
Signature: try_activate(path)
Number of lines: 28

Try to activate a gem containing path. Returns true if
activation succeeded or wasn't needed because it was already
activated. Returns false if it can't find the path in a gem.

def self.try_activate(path)
  # finds the _latest_ version... regardless of loaded specs and their deps
  # if another gem had a requirement that would mean we shouldn't
  # activate the latest version, then either it would already be activated
  # or if it was ambiguous (and thus unresolved) the code in our custom
  # require will try to activate the more specific version.

  spec = Gem::Specification.find_by_path path
pry(Gem):1>
```

We can also use `ri` in the normal way:

```ruby
pry(main) ri Array#each
----------------------------------------------------------- Array#each
     array.each {|item| block }   ->   array
------------------------------------------------------------------------
     Calls _block_ once for each element in _self_, passing that element
     as a parameter.

        a = [ ""a"", ""b"", ""c"" ]
        a.each {|x| print x, "" -- "" }

     produces:

        a -- b -- c --
```

### Edit methods

You can use `edit Class#method` or `edit my_method` (if the method is in scope)
to open a method for editing directly in your favorite editor. Pry has knowledge
of a few different editors and will attempt to open the file at the line the
method is defined.

You can set the editor to use by assigning to the `Pry.editor`
accessor. `Pry.editor` will default to `$EDITOR` or failing that will use `nano`
as the backup default. The file that is edited will be automatically reloaded
after exiting the editor - reloading can be suppressed by passing the
`--no-reload` option to `edit`

In the example below we will set our default editor to ""emacsclient"" and open
the `Pry#repl` method for editing:

```ruby
pry(main)> Pry.editor = ""emacsclient""
pry(main)> edit Pry#repl
```

### Live Help System

Many other commands are available in Pry; to see the full list type `help` at
the prompt. A short description of each command is provided with basic
instructions for use; some commands have a more extensive help that can be
accessed via typing `command_name --help`. A command will typically say in its
description if the `--help` option is available.

### Use Pry as your Rails Console

The recommended way to use Pry as your Rails console is to add [the `pry-rails`
gem](https://github.com/rweng/pry-rails) to your Gemfile. This replaces the
default console with Pry, in addition to loading the Rails console helpers and
adding some useful Rails-specific commands.

If you don't want to change your Gemfile, you can still run a Pry console in
your app's environment using Pry's `-r` flag:

```sh
pry -r ./config/environment
```

Also check out the
[wiki](https://github.com/pry/pry/wiki/Setting-up-Rails-or-Heroku-to-use-Pry)
for more information about integrating Pry with Rails.

### Syntax Highlighting

Syntax highlighting is on by default in Pry. If you want to change the colors,
check out the [pry-theme](https://github.com/kyrylo/pry-theme) gem.

You can toggle the syntax highlighting on and off in a session by using the
`toggle-color` command. Alternatively, you can turn it off permanently by
putting the line `Pry.color = false` in your `pryrc` file.

Supported Rubies
----------------

* CRuby >= 2.0.0
* JRuby >= 9.0

Contact
-------

In case you have a problem, question or a bug report, feel free to:

* ask a question on IRC (#pry on Freenode)
* [file an issue](https://github.com/pry/pry/issues)
* [tweet at us](https://twitter.com/pryruby)

License
-------

The project uses the MIT License. See LICENSE.md for details.

Contributors
------------

Pry is primarily the work of [John Mair (banisterfiend)](https://github.com/banister), for full list
of contributors see the
[contributors graph](https://github.com/pry/pry/graphs/contributors).
","Pry is an IRB alternative with powerfulintrospection capabilities. It is an
attempt to bring REPL driven programming to the Ruby language. Pry is fairly
flexible and allows significant user customization. It can be used as a
developer console or as a debugger. It has a number of plugins that provide
remote sessions, and more."
3314,Multi Theft Auto is a game engine that incorporates an extendable network play element into a proprietary commercial single-player game.,"## Multi Theft Auto: San Andreas 

[![Build Status](https://github.com/multitheftauto/mtasa-blue/workflows/Build/badge.svg?event=push&branch=master)](https://github.com/multitheftauto/mtasa-blue/actions?query=branch%3Amaster+event%3Apush) [![Unique servers online](https://img.shields.io/endpoint?url=https%3A%2F%2Fmultitheftauto.com%2Fapi%2Fservers-shields.io.json)](https://community.multitheftauto.com/index.php?p=servers) [![Unique players online](https://img.shields.io/endpoint?url=https%3A%2F%2Fmultitheftauto.com%2Fapi%2Fplayers-shields.io.json)](https://multitheftauto.com) [![Unique players last 24 hours](https://img.shields.io/endpoint?url=https%3A%2F%2Fmultitheftauto.com%2Fapi%2Funique-players-shields.io.json)](https://multitheftauto.com) [![Discord](https://img.shields.io/discord/278474088903606273?label=discord&logo=discord)](https://discord.com/invite/mtasa) [![Crowdin](https://badges.crowdin.net/e/f5dba7b9aa6594139af737c85d81d3aa/localized.svg)](https://multitheftauto.crowdin.com/multitheftauto)

[Multi Theft Auto](https://www.multitheftauto.com/) (MTA) is a software project that adds network play functionality to Rockstar North's Grand Theft Auto game series, in which this functionality is not originally found. It is a unique modification that incorporates an extendable network play element into a proprietary commercial single-player PC game.

## Introduction

Multi Theft Auto is based on code injection and hooking techniques whereby the game is manipulated without altering any original files supplied with the game. The software functions as a game engine that installs itself as an extension of the original game, adding core functionality such as networking and GUI rendering while exposing the original game's engine functionality through a scripting language.

Originally founded back in early 2003 as an experimental piece of C/C++ software, Multi Theft Auto has since grown into an advanced multiplayer platform for gamers and third-party developers. Our software provides a minimal sandbox style gameplay that can be extended through the Lua scripting language in many ways, allowing servers to run custom created game modes with custom content for up to hundreds of online players.

Formerly a closed-source project, we have migrated to open-source to encourage other developers to contribute as well as showing insight into our project's source code and design for educational reasons.

Multi Theft Auto is built upon the ""Blue"" concept that implements a game engine framework. Since the class design of our game framework is based upon Grand Theft Auto's design, we are able to insert our code into the original game. The game is then heavily extended by providing new game functionality (including tweaks and crash fixes) as well as a completely new graphical interface, networking and scripting component.

## Gameplay content

By default, Multi Theft Auto provides the minimal sandbox style gameplay of Grand Theft Auto. The gameplay can be heavily extended through the use of the Lua scripting language that has been embedded in the client and server software. Both the server hosting the game, as well as the client playing the game are capable of running and synchronizing Lua scripts. These scripts are layered on top of Multi Theft Auto's game framework that consists of many classes and functions so that the game can be adjusted in virtually any possible way.

All gameplay content such as Lua scripts, images, sounds, custom models or textures is grouped into a ""resource"". This resource is nothing more than an archive (containing the content) and a metadata file describing the content and any extra information (such as dependencies on other resources).

Using a framework based on resources has a number of advantages. It allows content to be easily transferred to clients and servers. Another advantage is that we can provide a way to import and export scripting functionality in a resource. For example, different resources can import (often basic) functionality from one or more common resources. These will then be automatically downloaded and started. Another feature worth mentioning is that server administrators can control the access to specific resources by assigning a number of different user rights to them.

## Development

Our project's code repository can be found on the [multitheftauto/mtasa-blue](https://github.com/multitheftauto/mtasa-blue/) Git repository at [GitHub](https://github.com/). We are always looking for new developers, so if you're interested, here are some useful links:

* [Coding guidelines](https://github.com/multitheftauto/mtasa-blue/blob/master/CONTRIBUTING.md#contributors-guide)
* [Nightly Builds](https://nightly.multitheftauto.com/)
* [Milestones](https://github.com/multitheftauto/mtasa-blue/milestones)

### IDE Setup

If not using Visual Studio 2017, download and install the [EditorConfig](https://marketplace.visualstudio.com/items?itemName=EditorConfigTeam.EditorConfig) plugin to automatically set up your IDE for the correct formatting.

### Build Instructions

#### Windows

Prerequisites
- [Visual Studio 2022](https://visualstudio.microsoft.com/vs/)
- [Microsoft DirectX SDK](https://wiki.multitheftauto.com/wiki/Compiling_MTASA#Microsoft_DirectX_SDK)
- [Git for Windows](https://git-scm.com/download/win) (Optional)

1. Execute `win-create-projects.bat`
2. Open `MTASA.sln` in the `Build` directory
3. Compile
4. Execute: `win-install-data.bat`

#### GNU/Linux

You can build the MTA:SA server on GNU/Linux distributions only for x86, x86_64, armhf and arm64 CPU architectures. ARM architectures are currently in **experimental phase**, which means they're unstable, untested and may crash randomly. Beware that we only officially support building from x86_64 and that includes cross-compiling for x86, arm and arm64.

**Build dependencies**

*Please always read the Dockerfiles for up-to-date build dependencies.*  
*Note: ncftp is not required for building the MTA:SA server.*

- git
- make
- GNU GCC compiler (version 10 or newer)
- libncursesw5
- libncursesw5-dev
- libmysqlclient-dev

**Build instructions: Script**

**Note:** This script always deletes `Build/` and `Bin/` directories and does a clean build.

```sh
$ ./linux-build.sh [--arch=x86|x64|arm|arm64] [--config=debug|release]
$ ./linux-install-data.sh  # optional step
```

If build architecture `--arch` is not provided, then it's taken from the environment variable `BUILD_ARCHITECTURE` (defaults to: x64).

If build configuration `--config` is not provided, then it's taken from the environment variable `BUILD_CONFIG` (defaults to: release).

If you are trying to **cross-compile** to another architecture, then set `AR`, `CC`, `CXX`, `GCC_PREFIX` environment variables accordingly (see Dockerfile.arm64 for an example).

**Build instructions: Manual**

```sh
$ ./utils/premake5 gmake
$ make -C Build/ config=release_x64 all
$ ./linux-install-data.sh  # optional step
```

If you don't want to build the release configuration for the x86_64 architecture, you can instead pick another build configuration from: `{debug|release}_{x86|x64|arm|arm64}`.

#### GNU/Linux: Docker Build Environment

If you have problems resolving the required dependencies or want maximum compatibility, you can use our dockerized build environment that ships all needed dependencies. We also use this environment to build the official binaries.

**Pulling the Docker image**

```sh
$ docker pull ghcr.io/multitheftauto/mtasa-blue-build:latest
```

| Architecture | Docker image tag | Required build-time CLI-arguments |
| ------------ | ---------------- | --------------------------------- |
| x86          | latest           | `-e BUILD_ARCHITECTURE=x86`       |
| x86_64       | latest           |                                   |
| arm          | armhf            |                                   |
| arm64        | arm64            |                                   |

**Building with Docker**

These examples assume that your current directory is the mtasa-blue checkout directory. You should also know that `/build` is the code directory required by our Docker images inside the container. If the current directory is not a valid git repository, it instead create a (shallow) clone of the mtasa-blue repository. After compiling, you will find the resulting binaries in `./Bin`. To build the unoptimised debug build, add `-e BUILD_CONFIG=debug` to the docker run arguments.

| Architecture | Build command                                                                                                    |
| ------------ | ---------------------------------------------------------------------------------------------------------------- |
| x86          | ``` docker run --rm -v `pwd`:/build -e BUILD_ARCHITECTURE=x86 ghcr.io/multitheftauto/mtasa-blue-build:latest ``` |
| x86_64       | ``` docker run --rm -v `pwd`:/build ghcr.io/multitheftauto/mtasa-blue-build:latest ```                           |
| arm          | ``` docker run --rm -v `pwd`:/build ghcr.io/multitheftauto/mtasa-blue-build:armhf ```                            |
| arm64        | ``` docker run --rm -v `pwd`:/build ghcr.io/multitheftauto/mtasa-blue-build:arm64 ```                            |

### Premake FAQ

#### How to add new C++ source files?

Execute `win-create-projects.bat`

## License

Unless otherwise specified, all source code hosted on this repository is licensed under the GPLv3 license. See the [LICENSE](./LICENSE) file for more details.

Grand Theft Auto and all related trademarks are © Rockstar North 1997–2023.
","Multi Theft Auto is based on code injection and hooking techniques whereby the
game is manipulated without altering any original files supplied with the game.
The game is then heavily extended by providing new game functionality (including
tweaks and crash fixes) as well as a completely new graphical interface,
networking and scripting component. By default, Multi Theft Auto provides the
minimal sandbox style gameplay of Grand Theft Auto. The gameplay can be heavily
extended through the use of the Lua scripting language that has been embedded in
the client and server software."
524,"🚀 A command line tool aims to improve front-end engineer workflow and standard, powered by TypeScript.","English | [简体中文](./README.CN.md)

<h1 align=""center"">Feflow</h1>

<p align=""center"">
  🚀 A tool aims to improve front-end engineer workflow and standard, powered by TypeScript.
</p>

<br>

[![npm][npm]][npm-url]
[![Build Status][build-status]][build-status-url]
[![Install Size][size]][size-url]
[![Downloads][downloads]][downloads-url]
[![lerna][lerna]][lerna-url]
[![GitHub contributors][contributors]][contributors-url]
[![Issue resolution][issue-resolution]][issue-resolution-url]
[![PR's welcome][pr-welcome]][pr-welcome-url]

## Introduction

Feflow is an engineering solution of Tencent's open source front-end field, which is committed to improving development efficiency and specification.

## Getting Started

Let's start by installing Feflow with npm.

```
npm install @feflow/cli -g
```

There are three kinds of commands in Feflow

- Native Commands
  - `fef config`
  - `fef help`
  - `fef info`
  - `fef install`
  - `fef uninstall`
  - `fef list`

You can write a Feflow devkit or plugin to extends commands.

More detail document can be found:
- [Github Wiki](https://github.com/Tencent/feflow/wiki)
- [Website](https://feflowjs.com/)

## Change Log

This project adheres to [Semantic Versioning](http://semver.org/).
Every release, along with the migration instructions, is documented on the GitHub [Releases](https://github.com/Tencent/feflow/releases) page.

## License

[MIT](LICENSE.txt)


[build-status]: https://travis-ci.org/Tencent/feflow.svg
[build-status-url]: https://travis-ci.org/Tencent/feflow
[contributors]: https://img.shields.io/github/contributors/Tencent/feflow.svg
[contributors-url]: https://github.com/Tencent/feflow/graphs/contributors
[downloads]: https://img.shields.io/npm/dw/@feflow/cli.svg
[downloads-url]: https://www.npmjs.com/package/@feflow/cli
[issue-resolution]: https://isitmaintained.com/badge/resolution/Tencent/feflow.svg
[issue-resolution-url]: https://github.com/Tencent/feflow/issues
[lerna]: https://img.shields.io/badge/maintained%20with-lerna-cc00ff.svg
[lerna-url]: http://www.lernajs.io/
[npm]: https://img.shields.io/npm/v/@feflow/cli.svg
[npm-url]: https://www.npmjs.com/package/@feflow/cli
[pr-welcome]: https://img.shields.io/badge/PRs%20-welcome-brightgreen.svg
[pr-welcome-url]: https://github.com/Tencent/feflow/blob/next/.github/CONTRIBUTING.md
[size]: https://packagephobia.now.sh/badge?p=@feflow/cli
[size-url]: https://packagephobia.now.sh/result?p=@feflow/cli
","Feflow is an engineering solution of Tencent's open source front-end field,
which is committed to improving development efficiency and specification. There
are three kinds of commands in Feflow: Native Commands, Help and Lists. Every
release, along with the migration instructions, is documented on the GitHub
[Releases](https://github.com/Tencent/feflow/releases) page. You can write a
FefLow devkit or plugin to extend the commands."
612,Build your Chromium OS for Raspberry Pi 3B/3B+/4B and Pi400,"[<img src=""https://img.shields.io/endpoint?url=https://openfyde-referral-badge-njwdjt8vwpnb.runkit.sh/"">](https://github.com/openFyde/overlay-rpi4-openfyde) 

[<img src=""https://img.shields.io/endpoint?style=flat&color=fedcba&url=https://telegram-badge-t2fuv4m3rno2.runkit.sh/?url=https://t.me/hi_fydeos"">](https://t.me/hi_fydeos)

<br>

# TL;DR: (in FAQ format)

<details>
  <summary>What's this, is this FydeOS?</summary>
  <br>
  
We get it, it's confusing. There are `Chromium OS for Raspberry Pi`, `openFyde` that happens to boot on Raspberry Pi and `FydeOS for You - Raspberry Pi 400`, these are different releases.
  
This project is about **Chromium OS for Raspberry Pi**, not FydeOS for You - Raspberry Pi 400, also not openFyde. This project aims to only ship vanilla Chromium OS developed by Google and the Chromium Authors, ported to the world's favourite single-board computer - the Raspberry Pi platform.
  
The next question gives detailed differences between these confusing terms.
</details>


<details>
  <summary>What's the difference between Chromium OS, Chrome OS, openFyde and FydeOS?</summary>
  <br>
  
  - Chromium OS is an open-source project, used primarily by developers, with code that is available for anyone to checkout, modify, and build.
  - Google Chrome OS is the Google product that OEMs ship on Chromebooks for general consumer use.
  - openFyde is a downstream fork of the Chromium OS, with modifications and enhancements developed by Fyde Innovations. It's an open-source initiative sharing a similar series of relaxed licenses as per the Chromium OS upstream.
  - FydeOS is similar to Google Chrome OS, it's a commercial-grade operating system product developed and maintained by Fyde Innovations, based on openFyde and Chromium OS.
  
  Some specific differences:

  - These OS projects fundamentally share the same code base, but Google Chrome OS has some additional firmware features, including verified boot and easy recovery, which require corresponding hardware changes and thus also don't work out of the box in Chromium OS builds.
  - Google Chrome OS / ""FydeOS for You"" runs on specially optimised hardware to get enhanced performance and security.
  - Chromium OS and openFyde images do not auto-update by default (so that changes you may have made to the code are not blown away), whereas Google Chrome OS / FydeOS seamlessly auto-updates so that users have the latest and greatest features and fixes.
  - Google Chrome OS / FydeOS includes some proprietary/commercial/licensed packages which are not included in the Chromium OS project.
  - In consequence of the above, Google Chrome OS / FydeOS supports the Android subsystem, while Chromium OS and openFyde do not.
  - Google Chrome OS has a green/yellow/red logo, Chromium OS has a blue/bluer/bluest logo, openFyde has a logo that looks like ⭕️ and the logo FydeOS is only textural.

</details>


<details>
  <summary>Can I build Chromium OS? Can I build FydeOS?</summary>
  <br>
  
   - Yes you can build Chromium OS, in fact, this project is all about building your own Chromium OS for Raspberry Pi as well as offering pre-built images using the provided build artefacts.
   - No you can't build FydeOS - the same reason that you can't build Google Chrome OS.
   - You can build openFyde too, more information about openFyde is available on its [project website](https://openfyde.io/).
</details>


<details>
  <summary>I don't want to be bothered with the technicalities, where are the download links?</summary>
  <br>
  
   - To download pre-built Chromium OS for Raspberry Pi, head over to [releases](https://github.com/FydeOS/chromium_os-raspberry_pi/releases) tab, you will find all historical releases as well as important release notes. Please do read the release note!
   - To download FydeOS for You - Raspberry Pi 400, please use the [Download](https://fydeos.com/download) page of the FydeOS official site.
</details>


<details>
  <summary>Where to get help?</summary>
  <br>
  
  You are welcome to open an issue in this project if:
   - You've read the entire developer guide and even watched the [build demonstration video](https://youtu.be/og4wzzIfGA0), and then you are attempting to build Chromium OS but have encountered problems
   - You believe your copy of the Chromium OS for Raspberry Pi isn't functioning correctly as it should be

  Your issues will likely get closed if:
   - You are asking about FydeOS for You - Raspberry Pi 400: for this please use [FydeOS Community](http://community.fydeos.com/) or join [Official FydeOS Telegram Group](http://t.me/hi_fydeos)
   - You are asking for generic features/bugs about Chromium OS / Chrome OS itself: for this please use [chromium-os-dev Google Group](https://groups.google.com/a/chromium.org/g/chromium-os-dev) or report bugs to [CRBUGS](https://bugs.chromium.org/)
   - You are asking about issues about a 3rd-party app, a non-standard peripheral device or a special setup that does not benefit the general community
</details>



<br><br>

# Table of contents (for cool kids)

<!-- TOC -->

- [Introduction](#introduction)
- [System requirement](#system-requirement)
- [Prepare the system](#prepare-the-system)
- [Get Chromium OS source code](#get-chromium-os-source-code)
- [Setup Raspberry Pi overlay](#setup-raspberry-pi-overlay)
- [Setup local chromium source](#setup-local-chromium-source)
- [Build Chromium OS for Raspberry Pi](#build-chromium-os-for-raspberry-pi)
- [Boot Raspberry Pi from the image](#boot-raspberry-pi-from-the-image)
- [Video demonstration of the build process](#video-demonstration-of-the-build-process)
- [More information](#more-information)
- [About us](#about-us)
  <!-- /TOC -->


<br>

# Introduction

This document describes how to build and run Google [Chromium OS](https://www.chromium.org/chromium-os) on Raspberry Pi 3B, 3B+, 4B and the Pi 400 personal computer kit(Pi400 hereafter), from its source code and the board overlay hosted in this repository.

These overlays and the document has been tested against Raspberry Pi 3B, 3B+, 4B and Pi400 by the FydeOS team. It **will not work** on an earlier version of the Raspberry Pi line-up.

### Goal of this project

* To provide a usable Chromium OS pre-built image that everybody can download and use that offers a similar experience to Chrome OS 
* To provide an open-source code base that everybody can use to build and improve Chromium OS on Raspberry Pi.
* This project does not aim to provide support for Chromium OS itself. If you find bugs and glitches, please report to [crbugs](https://bugs.chromium.org/p/chromium/issues/list); if you have further queries regarding Chromium OS, please revert to one of the official Chromium related [Google groups](https://www.chromium.org/developers/technical-discussion-groups).


### About this repository

The code and document in this repository are the results of works by the people of the FydeOS team. We previously worked on this overlay internally and released a few disk images for Raspberry Pi to the public. Now we open this to the public.


### Branches and tags in this repository


 - **branches**

    - `main` - the default branch of this project. It has been tested against our current release version. You are welcome to test it with future releases and send feedback and/or PRs.
    - `r<revision>` - branches for specific Chromium OS revision, it could be served for archiving purposes or used as a development branch for future (non-stable) code.


 - **tags**

     - When we do release a prebuilt image, the commit would be tagged with a release number corresponding to the repo manifest. For example, if the repo manifest release is `rrelease-R102-14695.B`, then our release tag would be `r102`.
     - Often we will be doing more than one release for each repo manifest release number, so we will append a meaningful string to the tag name to identify such. For example: `r102-hardware_acceleration`


### Typography Conventions

Shell Commands are shown with different labels to indicate whether they apply to 

 - your build computer (the computer on which you're doing development)
 - the chroot (Chromium OS SDK) on your build computer
 - your Chromium OS computer (the device on which you run the images you build)


| Label     | Commands                                   |
| --------- | ------------------------------------------ |
| (outside) | on your build computer, outside the chroot |
| (inside)  | inside the chroot on your build computer   |


<br>

# System requirement

* An x86_64 system to perform the build. 64-bit hardware and OS are a must. The Chromium OS is a very large project, building from the source from scratch usually takes hours to over 10 hours, depending on the system configuration.
  * CPU: we recommend using a 4-core or higher processor. The Chromium OS build process runs in parallel so more cores can help shorten build time dramatically.

  * Memory: we recommend at least 16GB, plus enough swap space because for this project you will need to build Chromium from source code. Linking Chromium required between 8GB and 28GB of RAM as of March 2017, so you will run into massive swapping or OOM if you have less memory. However, if you are not building your copy of Chromium, the RAM requirements will be substantially lower at a cost of losing some of the key features provided by this project.

  * Disk: at least 100GB of free space, 200GB or more is recommended. SSD could noticeably shorten the build time as there are many gigabytes of files that need to be written to and read from the disk.

  * Network: total source code downloading will be over 10GB. Fast and stable Internet access is going to be very helpful.

* An x86_64 Linux OS, it is called the host OS later in this doc. The Chromium OS build process utilises chroot to isolate the built environment from the host OS. So theoretically any modern Linux system should work. However, only limited Linux distros are tested by the Chromium OS team and the FydeOS team. Linux versions that are known to work:

  * Ubuntu 18.04 LTS
  * Ubuntu 20.04 LTS 
  * Gentoo Linux

* A non-root user account with sudo access. The build process should be run by this user, not the root user. The user needs to have _sudo_ access. For simplicity and convenience password-less sudo could be set for this user.


<br>

# Prepare the system

### Install necessary tools

Git and curl as the essential tools that need to be installed in the host OS, you will also need Python3 for most of the scripting work in the build process.

```bash
(outside)
sudo apt-get install git-core gitk git-gui curl lvm2 thin-provisioning-tools \
     python-pkg-resources python-virtualenv python-oauth2client xz-utils \
     python3.6

# If Python 3.5 is the default, switch it to Python 3.6.
python3 --version
# If above version says 3.5, you'll need to run:
sudo update-alternatives --install /usr/bin/python3 python3 /usr/bin/python3.5 1
sudo update-alternatives --install /usr/bin/python3 python3 /usr/bin/python3.6 2
sudo update-alternatives --config python3
```

This command also installs git's graphical front end (`git gui`) and revision history browser (`gitk`).


### Install Google depot_tools

The depot_tools is a software package of scripts, provided by Google, to manage source code checkouts and code reviews. We need it to fetch the Chromium OS source code.

```bash
(outside)
$ sudo mkdir -p /usr/local/repo
$ sudo chmod 777 /usr/local/repo
$ cd /usr/local/repo
$ git clone https://chromium.googlesource.com/chromium/tools/depot_tools.git

```

Then add depot_tools directory to PATH and set up proper umask for the user who is going to perform the build. Add below lines to the file `~/.bash_profile` of that user. Or if you are using a different shell, handle that accordingly.

```bash
(outside)
export PATH=/usr/local/repo/depot_tools:$PATH
umask 022
```

Then re-login to make the above changes take effect.


### Configure git

Better configure git now or it may complain in some operations later.

```bash
(outside)
$ git config --global user.email ""you@email.address""
$ git config --global user.name ""Your Name""
```

<br>

# Get Chromium OS source code

### Create directory structure

The directory structure described here is a recommendation based on the best practice in the FydeOS team. You may host the files differently as you wish.

```bash
(outside)
# This is the directory to hold Chromium OS source code， aka cros-sdk
$ mkdir -p /path/to/cros-pi
```

If you are building a different release, make sure you use the actual directory name on your system, the name here mentioned is just an example.


### Fetch Chromium OS source code

First, you need to find out the reference name of the release you would like to build, by visiting this page [https://chromium.googlesource.com/chromiumos/manifest.git](https://chromium.googlesource.com/chromiumos/manifest.git):

You will see a list of Git commit IDs and its name in the form of `refs/heads/release-Rxx-xxxx.B`. That `release-Rxx-XXXX.B` link is what you need for fetching the code of that specific Chromium OS release. For example, [release-R102-14695.B](https://chromium.googlesource.com/chromiumos/manifest.git/+/refs/heads/release-R102-14695.B) for release r102.

Now run these commands to fetch the source code. Find and use a different release name if you would like to build a different release.

```bash
(outside)
#Assuming you understand what /path/to means. If not, replace it with '~'
$ cd /path/to/cros-pi

$ repo init -u https://chromium.googlesource.com/chromiumos/manifest.git --repo-url https://chromium.googlesource.com/external/repo.git -b release-R102-14695.B

# Raise this number if you have a fast internet connection
$ repo sync -j8
```

Fetching Chromium OS source code may take 20 to more than 40 minutes depending on your connection speed, around 10GB of data will need to be downloaded primarily from googlesource.com, it'd be helpful if you have a decent internet speed to reach Google's server.



### Request for Google API key

If you would like to login into the Chromium OS GUI by using your Google account, you will need to request for Google API key and include them in the disk image you build. Since the only authentication mechanism included in Chromium OS is Google ID, you probably will need this or you will only be able to log in as a guest user.

Apply for Google API on the Google website per [this document](http://www.chromium.org/developers/how-tos/api-keys). After acquiring the client ID, client secret and API key, put them in ```~/.googleapikeys``` file as in the below format.

```
'google_api_key': 'your api key',
'google_default_client_id': 'your client id',
'google_default_client_secret': 'your client secret',
```

Then the Chromium OS build script will read the necessary information from this file automatically, and the image you build will allow Google ID login.


<br>

# Setup Raspberry Pi overlay

Now fetch this overlay and also create symlinks in the designated place.

```bash
(outside)
$ cd /path/to/overlays
$ git clone https://github.com/fydeos/chromium_os-raspberry_pi.git .

$ cd /path/to/cros-pi/src/overlays
$ ln -s /path/to/overlays/* .
```

By now, your `cros-pi/src/overlays` directory should have included symbolic links for:

- `project-cros-pi`
- `baseboard-rpi3`
- `overlay-rpi3`
- `overlay-rpi4`
- `chipset-bcm2837`


<br>

# Setup local chromium source

It's recommended to build Chromium browser on your local setup so that your Chromium OS for Raspberry Pi could benefit from the additional functionalities like kiosk mode, you will also have the option to incorporate your modifications. If you wish to do so, you need to prepare the necessary files before entering the cros_sdk.

As far as this project is concerned, the chromium source that we use to build our releases can be found in the [chromium-raspberry_pi](https://github.com/FydeOS/chromium-raspberry_pi) project. You may also choose to use Google's vanilla chromium repository which can be found [here](https://chromium.googlesource.com/chromium/src.git/).

Note that we use a much simpler way to manage releases, with our [chromium-raspberry_pi](https://github.com/FydeOS/chromium-raspberry_pi) project you need to select the correct branch corresponding to the [repo manifest](#fetch-chromium-os-source-code) you used in the previous step to sync your Chromium OS code. For example, if you are building r102, you will then need to look out for ""`chromium-m102`"" branch under [chromium-raspberry_pi](https://github.com/FydeOS/chromium-raspberry_pi). The letter ""m"" stands for ""milestone"" and it correlates to the release number for Chromium OS(r102 in this case). Choosing an unmatched chromium milestone branch and Chromium OS repo will probably result in endless build errors.

With Google's repository, you need to choose a correct release tag rather than a branch. For example, if you are building r102, you can browse all existing chromium release tags on [this page](https://chromium.googlesource.com/chromium/src.git/) and deduce that the latest tag on your desired milestone version. At the point where this was written, this would be [102.0.5005.90](https://chromium.googlesource.com/chromium/src.git/+/refs/tags/102.0.5005.90).

Having understood the above, now create a directory parallel to your Chromium OS repo to house the chromium source:

```bash
(outside)
$ mkdir chromium-pi
$ cd chromium-pi
$ mkdir src
$ cd src
```

Now clone the desired chromium project:

```bash
(outside)
# use our chromium repo
$ git clone git@github.com:FydeOS/chromium-raspberry_pi.git .

# use google's vanilla chromium
$ git clone https://chromium.googlesource.com/chromium/src.git . 
```

Note that chromium is an absolute **HUGE** project, cloning the entire repo will require ~22GB of disk space and will require about 2 hours to complete even if you have a decent internet speed.

Then choose the correct branch/tag

```bash
(outside)
#with our chromium repo
$ git checkout chromium-m102

#with Google's repo and you wish to build for r102
$ git checkout 102.0.5005.90
```

Now you need to create a config file known to gclient for syncing the chromium dependencies:

```bash
(outside)
$ cd ..
# now you should be in /path/to/chromium-pi
$ touch .gclient
```

The .gclient file should have the following content, note that you should replace the correct branch name with the `url` field (in this example we use `chromium-m102`) you may also replace the `url` value to Google's per your setup.

```
solutions = [{'custom_deps': {},
  'custom_vars': {},
  'deps_file': '.DEPS.git',
  'managed': False,
  'name': 'src',
  'url': 'git@github.com:FydeOS/chromium-raspberry_pi.git@refs/remotes/origin/chromium-m102'}]
target_os = ['chromeos']
```

Now you can start syncing:

```bash
(outside)
$ gclient sync
```

Note, due to an existing issue with WebRTC, during syncing you may encounter a git related error complaining fetch failure(if you do not see such error, you can safely ignore this and move on). A temporary fix is to manually edit the `src/third_party/webrtc/.git/config` file under the WebRTC folder:

```
[core]
        repositoryformatversion = 0
        filemode = true
        bare = false
        logallrefupdates = true
[remote ""origin""]
        url = https://webrtc.googlesource.com/src.git
        fetch = +refs/heads/*:refs/remotes/origin/*
        fetch = +refs/branch-heads/*:refs/remotes/branch-heads/*
[branch ""master""]
        remote = origin
        merge = refs/heads/master
```

Once gclient sync is completed, the chromium source folder is now fully set up.


<br>

# Build Chromium OS for Raspberry Pi

### Create the chroot

As mentioned above, a chroot environment will be used to run the actual build process and some other related tasks. To create the chroot environment, run the below commands.

```
(outside)
$ cd /path/to/cros-pi
$ cros_sdk
```

If you wish to build your chromium and you have to follow the steps to set it up, you need to specify it when entering the cros_sdk by:


```bash
(outside)
$ cd /path/to/cros-pi
$ cros_sdk --chrome-root /path/to/your/chromium-pi #absolute path needed
```


It may take 10 to over 30 minutes depending on your internet connection speed and disk i/o speed. Once finished, it will enter into the chroot. The shell prompt string looks like below so it is very easy to tell whether you are currently in the chroot or not.

```
(inside)
(release-R102-14695.B/(xxxxxx...)) <user>@<host> ~/trunk/src/scripts $
```

The chroot environment is located under the `/path/to/cros-pi/chroot` directory.

Let's exit from the chroot first as we need to do some customisation before moving on. Type `exit` or `ctrl + d` to exit from the chroot shell.

Usually, the chroot only needs to be created once and can be used to build a board many times or build different boards. It very rarely needs to be removed/re-created.


### Delete the chroot

If you would like to remove the chroot and re-create it from scratch, don't delete the `chroot` directory directly. As there could be directories from the host OS bind mounted in the chroot, an `rm chroot` command could remove files from your host OS undesirably.

The correct way to remove the chroot is by using the below commands.

```bash
(outside)
$ cd /path/to/cros-pi
$ cros_sdk --delete
```


### Setup bind mount directories for chroot

Programs running inside the chroot will not be able to access files outside of the chroot. One way to circumvent this is to bind-mount those files into a directory inside the chroot.

When entering the Chromium OS chroot environment, a file named `.local_mounts` will be checked and directories listed in it will be bind-mounted inside the chroot. All we need to do is to create this file in the right place and put the necessary contents in, by using the below command.

```bash
(outside)
$ echo ""/path/to/overlays"" > /path/to/cros-pi/src/scripts/.local_mounts
```

Now, after entering the chroot, a `/path/to/overlays` directory will exist in the chroot and its content is the same as the `/path/to/overlays` directory in the host OS, as it is bind-mounted from the host OS.

If we don't do this, the `/path/to/cros-pi/src/overlays/overlay-rpi4` symbolic link will not be accessible, as the top directory (`/path/to/overlays`) it points to doesn't exist in the chroot.


### Enter the chroot

Now we can enter the chroot.

```bash
(outside)
$ cd /path/to/cros-pi
$ cros_sdk
```

It is the same command used to create the chroot. It creates the chroot if one does not exist and enters the chroot if there is already one.

And we can check whether the above `.local_mounts` setup was done correctly. 

```bash
(inside)
$ ls /path/to/overlays/             # You should be able to see the same content as in the host OS.
$ ls ../overlays/overlay-rpi4/      # You should be able to see the content of this repo.
```

Move on if it works well. If not, check and make sure you set up `.local_mounts` correctly.


### Set password for the chronos user

The chronos user is used to log into the command line interface of Chromium OS, via ssh, local console or the shell in crosh interface. It is recommended that a password is set for this user so you can log in as this user and also can do `sudo` in the Chromium OS command line, for advanced tasks.

To set a password for the chronos user, run the below command.

```bash
(inside)
$ ./set_shared_user_password.sh
```

Type in a password when prompted. If you would like to change the password, simply run the command again.

The password is encrypted and saved in the file `/etc/shared_user_passwd.txt` in the chroot. You only need to set it once and it will be used for all the images you build unless you re-create the chroot.


### Setup Raspberry Pi board

In the Chromium OS terminology, a board refers to a class of computer platforms with distinct hardware configurations. The board will be used as a target in the process of building software packages and disk images for that specific computer platform.

There are many boards in the Chromium OS code base. They are either development platforms or real selling hardware products running Chrome OS, such as Chromebooks you can buy from many vendors.

The Chromium OS project utilises the Portage package management system from Gentoo Linux. Each board lives in its own ""overlay"", which holds distinct build configuration, system configurations, collection of software packages, system services, disk image customisation etc. for that board.

In our case here, we created a board named ""rpi4"" which refers to the Raspberry Pi 4B. We call the overlay ""overlay-rpi4"" and all its files are hosted in this repository.

To build Chromium OS for a board, the first thing is to initialise the board from its overlay.

**Beginning from release 86 and onwards, we have done some efforts to add Raspberry Pi 3B/3B+ support to the Raspberry Pi 4B overlay. In the following steps, we will be using the rpi4 board as an example, the resulting image will also likely work on both Raspberry Pi 3B/3B+.**

```bash
(inside)
$ setup_board --board=rpi4
```

Again, it may take 10 to over 30 minutes depending on the speed of your internet connection and disk i/o.

Once it's done, a directory structure for the ""rpi4"" board will be created under `/build/rpi4` of the chroot.


### Re-initialise the board

It is usually not necessary to re-initialise the board as what you have already built will be lost, and you will have to spend hours rebuilding all packages from scratch. But if you need to do so, just re-run the same setup_board command with the `---force` option.

```bash
(inside)
$ setup_board --board=rpi4 --force
```

The `--force` option will remove the existing board directory `/build/rpi4` and re-create it from scratch.


### Build packages

Now it is time to build all software packages for the rpi4 board.

```bash
(inside)
$ ./build_packages --board=rpi4 --nowithautotest 
# Append ""--nowithautotest"" to speed up the build process by skipping some tests
```

It may take hours depending on your processor power, your memory size, your disk speed and the quality of your internet connection. Here are some examples for you to adjust your expectation: 

- On a decent machine with 4 cores 8 threads, 16GB memory, files on regular HDD, and 100Mb broadband, it takes about 5 to 6 hours for the command to finish.
- On a Workstation-grade server with AMD Threadripper 3990x CPU with 64-core 128-thread, 128GB memory and 300Mb broadband, it takes 44mins for the command to finish.


### Things to note

- **What is happening now**

  The `build_packages` script acts as an entry point to initialise a series of processes aiming to compile all the necessary software packages from source code and build them together forming Chromium OS as a whole. During the process there are a few required dependencies will be fetched and cloned from GitHub, so please do ensure a decent internet connection to github.com.


- **When interrupted**

  The build process is incremental. If it gets interrupted for any reason, you can always re-run the same `build_packages` command and it will resume the build instead of rebuilding from scratch.

- **Read the output**

  The `build_packages` command throws out a lot of information on the console. Fortunately, that information is very well organised.

  - <span style=""color:red"">Red text</span>: these are error messages and very likely will cause the build process to break.
  - <span style=""color:green"">Green text</span>: these are useful messages printed by the build script itself. They are useful when debugging problem.
  - White text: these are regular information that mostly is printed by the commands called in the build script. They provide more details about the build process and thus are also useful for debugging.

- **Read the logs**

  The `build_packages` script spends most of its airtime on running the `emerge` commands, to build, install and pack those hundreds of software packages required by the overlay. The `emerge` command is from the Portage system of Gentoo Linux.

  The `emerge` command saves the output of its building, installation and packing process into log files. These files are extremely useful if there is a failure when building packages. Those log files are located under the `/build/rpi4/tmp/portage/logs` directory of the chroot. They are plain text files so can be viewed right from your command-line interface.


### Build the disk image

After the build_packages command is finished successfully, you can start building the disk image.

```bash
(inside)
$ ./build_image --board=rpi4 --noenable_rootfs_verification
# Append --noenable_rootfs_verification flag to enable root file system read/write on the built image
```

It may take 10 to 30 minutes, mainly depending on the speed of your disk. It will be much faster on SSD than on HDD.


### Find your image

After the command finished successfully, you will have disk images generated, saved under `/mnt/host/source/src/build/images/rpi4/` directory in the chroot, or `/path/to/cros-pi/src/build/images/rpi4` in the host OS. These two are the same directory, just bind mounted in the chroot.

Each invocation of the build_image command will create a directory named similar to `R102-XXXX.XXX.<date time>-a1` under above directory. There is a symlink named `latest` under the above directory, that always points to the image directory of the last successful build.

The disk image is usually named `chromiumos_image.bin`, under the abovementioned directory. So full path to the latest image is

```
/mnt/host/source/src/build/images/rpi4/latest/chromiumos_image.bin
```

in the chroot, and

```
/path/to/cros-pi/src/build/images/rpi4/latest/chromiumos_image.bin
```

in the host OS.


<br>

# Boot Raspberry Pi from the image

The Raspberry Pi boots from the SD card so we need to write the previously generated disk image onto the SD card. An SD card of at least 8GB capacity is required.


### Write the disk image to an SD card

There are two usual ways to write the Chromium OS disk image to an SD card. You can copy the image out to another Windows/macOS/Linux system and write it using your favourite GUI/CLI application. It is the same as writing other Linux images for Raspberry Pi, so will not be explained here.

Another Chromium OS-specific way is by using the `cros` command in the chroot.


### Write the image by using the `cros` command

First, plug the SD card into the box used to build the image and has the chroot. Then run the below command.

```
(inside)
$ cros flash usb:// rpi4/latest
```

This asks to write the latest disk image to USB removable media. A list of USB removable media will be presented, with the index number prefixed. You can select which USB drive to write to by typing in the index number when prompted.



### Boot from the SD card

After the disk image is successfully written to the SD card, plug it into the Raspberry Pi and boot it as usual. After a few seconds, you will see a Chromium logo, later on, it will boot into GUI mode and the first time setup screen (OOBE) will pop up for you to configure the system and log in.


<br>

# Video demonstration of the build process

<https://youtu.be/og4wzzIfGA0>


<br>

# More information

[Chromium OS Developer Guide](http://www.chromium.org/chromium-os/developer-guide). This is the official source of how to build Chromium OS.

[openFyde](https://openfyde.io), the open-sourced version of FydeOS.

[The FydeOS website](https://fydeos.io), our home.

[FydeOS official Telegram group](https://t.me/hi_fydeos), to say hi and get help.


<br>

# About us

Fyde began with a vision where all applications and services we use today will be living in the Cloud. We believed that with the ever-advancing browser platform technology and web frontend performances, it’s not surprising that most things we do today with the internet can be done through a single browser window. We are stepping into an era where installable apps will soon become history. FydeOS is our answer to this new era of computing.

FydeOS is a simple, secure, fast and productive operating system. Based on the open-source Chromium Project that also powers the well-known Google Chromebooks. FydeOS inherits most of the benefits that Chromebooks have but is also bundled with our enhancements and new features. We have turned FydeOS into a more open platform, users will no longer be forced to rely on Google services and have the freedom to choose whichever services they prefer. We have also made FydeOS run on a wider range of hardware platforms ranging from x86 PCs and ARM-based single board computers, providing endless possibilities and potentials of how Fy","This document describes how to build and run Google [Chromium
OS](https://www.chromium.org/chromium-os) on Raspberry Pi 3B, 3B+, 4B and the Pi
400 personal computer kit(Pi400 hereafter) The code and document in this
repository are the results of works by the people of the FydeOS team. You are
welcome to test it with future releases and send feedback and/or PRs. The
Chromium OS build process runs in parallel so more cores can help shorten build
time dramatically."
2423,🤖 CDN assets - The #1 free and open source CDN built to make life easier for developers.,"<h1 align=""center"">
    <a href=""https://cdnjs.com""><img src=""https://raw.githubusercontent.com/cdnjs/brand/master/logo/standard/dark-512.png"" width=""175px"" alt=""< cdnjs >""></a>
</h1>

<h3 align=""center"">The #1 free and open source CDN built to make life easier for developers.</h3>

---

<p align=""center"">
 <a href=""#contributing"">
   <img src=""https://img.shields.io/badge/Robots-only-red.svg?style=flat-square"" alt=""Robots only"">
 </a>
 <a href=""https://github.com/cdnjs/cdnjs/blob/master/LICENSE"">
  <img src=""https://img.shields.io/badge/License-MIT-brightgreen.svg?style=flat-square"" alt=""MIT License"">
 </a>
 <a href=""https://github.com/cdnjs/cdnjs/discussions"">
  <img src=""https://img.shields.io/badge/GitHub-Discussions-brightgreen.svg?style=flat-square"" alt=""Discussions"">
 </a>
</p>

<p align=""center"">
 <a href=""https://github.com/cdnjs/packages/blob/master/README.md#donate-and-support-us"">
  <img src=""https://img.shields.io/badge/GitHub-Sponsors-EA4AAA.svg?style=flat-square"" alt=""GitHub Sponsors"">
 </a>
 <a href=""https://opencollective.com/cdnjs"">
  <img src=""https://img.shields.io/badge/Open%20Collective-Support%20Us-3385FF.svg?style=flat-square"" alt=""Open Collective"">
 </a>
 <a href=""https://www.patreon.com/cdnjs"">
  <img src=""https://img.shields.io/badge/Patreon-Become%20a%20Patron-E95420.svg?style=flat-square"" alt=""Patreon"">
 </a>
</p>

---

## Table of Contents

* [Introduction](#introduction)
  * [Other Repositories](#other-repositories)
* [Contributing](#contributing)
* [Sponsors](#sponsors)
* [License](#license)

## Introduction

This is the robot-only repository for cdnjs, where all the library assets that are hosted on cdnjs are stored. For the JSON files that control the libraries we host, please see the ""human"" [`cdnjs/packages`](https://github.com/cdnjs/packages) repository.

### Other Repositories

For the JSON files controlling the libraries we host on cdnjs, please take a look at the ""human"" [`cdnjs/packages`](https://github.com/cdnjs/packages) repository.

For our website, please refer to the [`cdnjs/static-website`](https://github.com/cdnjs/static-website) repository.

For the cdnjs API, please refer to the [`cdnjs/api-server`](https://github.com/cdnjs/api-server) repository.

For the full cdnjs branding and brand-related assets/guidelines, please see the [`cdnjs/brand`](https://github.com/cdnjs/brand) repository.

For our monthly CDN stats and usage reports, check out the [`cdnjs/cf-stats`](https://github.com/cdnjs/cf-stats) repository.

You can find all our repositories at [github.com/cdnjs](https://github.com/cdnjs)!

## Contributing

As this repository is now considered robot-only, pull requests are no longer accepted for this repository. If you are looking to contribute to cdnjs, please take a look at the [`cdnjs/packages`](https://github.com/cdnjs/packages) repository or any of our other [open-source repositories on GitHub](https://github.com/cdnjs)!

## Sponsors

cdnjs wouldn't be the success that it is today without our sponsors' kind support. These companies currently support cdnjs:

* [Cloudflare](https://www.cloudflare.com/?utm_source=cdnjs&utm_medium=link&utm_campaign=cdnjs_readme)
* [Algolia](https://www.algolia.com/?utm_source=cdnjs&utm_medium=link&utm_campaign=cdnjs_readme)
* [DigitalOcean](https://www.digitalocean.com/?utm_source=cdnjs&utm_medium=link&utm_campaign=cdnjs_readme)
* [Statuspage](https://www.statuspage.io/?utm_source=cdnjs&utm_medium=cdnjs_link&utm_campaign=cdnjs_readme)
* [Sentry](https://sentry.io/welcome/?utm_source=cdnjs&utm_medium=cdnjs_link&utm_campaign=cdnjs_readme)
* [UptimeRobot](https://uptimerobot.com/?utm_source=cdnjs&utm_medium=cdnjs_link&utm_campaign=cdnjs_readme)

If you are interested in becoming a sponsor, please feel free to contact us!

## License

Each library is released under its own license. This cdnjs repository is published under [MIT license](LICENSE).
","This is the robot-only repository where all the library assets that are hosted
on cdnjs are stored. For the JSON files that control the libraries we host,
please see the 'human' repository. For our website, please refer to the
[`cdnjs/static-website` repository. If you are interested in becoming a sponsor,
please feel free to contact us! Each library is released under its own license.
This repository is published under [MIT license](LICENSE)."
3345,Reddit Enhancement Suite,"# Reddit Enhancement Suite

[![RES Pipeline](https://github.com/honestbleeps/Reddit-Enhancement-Suite/actions/workflows/pipeline.yml/badge.svg)](https://github.com/honestbleeps/Reddit-Enhancement-Suite/actions/workflows/pipeline.yml)
[![Chat on Discord](https://img.shields.io/discord/681993947085799490?label=Discord)](https://discord.gg/UzkFNNa)

## [Please read this post before continuing.](https://www.reddit.com/r/RESAnnouncements/comments/sh83gx/announcement_life_of_reddit_enhancement_suite/)

Reddit Enhancement Suite (RES) is a suite of modules that enhances your Reddit browsing experience.
For general documentation, visit the [Reddit Enhancement Suite Wiki](https://www.reddit.com/r/Enhancement/wiki/index).

## Introduction

Hi there! Thanks for checking out RES on GitHub. A few important notes:

1. RES is licensed under GPLv3, which means you're technically free to do whatever you wish in terms of redistribution as long as you maintain GPLv3 licensing. However, I ask out of courtesy that should you choose to release your own, separate distribution of RES, you please name it something else entirely. Unfortunately, I have run into problems in the past with people redistributing under the same name, and causing me tech support headaches.

2. I ask that you please do not distribute your own binaries of RES (e.g. with bugfixes, etc). The version numbers in RES are important references for tech support so that we can replicate bugs that users report using the same version they are, and when you distribute your own - you run the risk of polluting/confusing that. In addition, if a user overwrites his/her extension with your distributed copy, it may not properly retain their RES settings/data depending on the developer ID used, etc.

I can't stop you from doing any of this. I'm just asking out of courtesy because I already spend a great deal of time providing tech support and chasing down bugs, and it's much harder when people think I'm the support guy for a separate branch of code.

Thanks!

Steve Sobel
steve@honestbleeps.com

## Building and contributing

See [CONTRIBUTING.md](/CONTRIBUTING.md).

## License

See [LICENSE](/LICENSE).

## Changelog

See the [`changelog/`](/changelog) directory for individual versions or https://redditenhancementsuite.com/releases/ for all versions.
","RES is licensed under GPLv3, which means you're technically free to do whatever
you wish in terms of redistribution. I ask that you please do not distribute
your own binaries of RES (e.g. with bugfixes, etc). The version numbers in RES
are important references for tech support so that we can replicate bugs that
users report using the same version they are. If a user overwrites his/her
extension with your distributed copy, it may not properly retain their RES
settings/data depending on the developer ID used, etc."
1307,"Simple clean Go REST API architecture with dependency injection and mocking example, following SOLID principles.","service-pattern-go
-------

Hey! Welcome, this is an example of simple REST API implementation with clean architecture written in Go with complete Dependency Injection along with Mocking example, following SOLID principles.

Inspired by [Manuel Kiessling go-cleanarchitecture](http://manuel.kiessling.net/2012/09/28/applying-the-clean-architecture-to-go-applications/) and [Joshua Partogi TDD training session](https://github.com/jpartogi/tennis-kata-laravel/)

It has simple dependencies:

 - [Chi (Router)](https://github.com/go-chi/chi)
 - [Testify (Test & Mock framework)](https://github.com/stretchr/testify)
 - [Mockery (Mock generator)](https://github.com/vektra/mockery)
 - [Hystrix-Go (Circuit Breaker)](https://github.com/afex/hystrix-go)

Get Started:

 - [Install](https://irahardianto.github.io/service-pattern-go/#install)
 - [Introduction](https://irahardianto.github.io/service-pattern-go/#introduction)
 - [Folder Structure](https://irahardianto.github.io/service-pattern-go/#folder-structure)
 - [Depency Injection](https://irahardianto.github.io/service-pattern-go/#dependency-injection)
 - [Mocking](https://irahardianto.github.io/service-pattern-go/#mocking)
 - [Testing](https://irahardianto.github.io/service-pattern-go/#testing)
 - [Circuit Breaker](https://irahardianto.github.io/service-pattern-go/#circuit-breaker)


----------

[Install](https://irahardianto.github.io/service-pattern-go/#install)
-------

Clone the source

    git clone https://github.com/irahardianto/service-pattern-go

Setup dependencies

    go get -u github.com/go-chi/chi
    go get -u github.com/jinzhu/gorm
    go get github.com/stretchr/testify
    go get github.com/vektra/mockery/.../
    go get github.com/afex/hystrix-go/hystrix
    go get -u github.com/mattn/go-sqlite3

Setup sqlite data structure

    sqlite3 /var/tmp/tennis.db < setup.sql

Test first for your liking

    go test ./... -v

Run the app

    go build && ./service-pattern-go

And visit

    http://localhost:8080/getScore/Rafael/vs/Serena


----------

[Introduction](https://irahardianto.github.io/service-pattern-go/#introduction)
-------
This is an example of Go clean architecture implementing Dependency Injection and Mocking for unit testing purposes to achieve safe, reliable and secure source code.

The idea of the pattern itself is to create decoupled systems that the implementation of lower level domain is not a concern of the implementor, and can be replaced without having concern of breaking implementor function.

The aim of the architecture is to produce a system that are:

 - Independent of frameworks. The system should be able to become an independent system, not bound into any framework implementation that cause the system to be bloated, instead those framework should be used as a tools to support the system implementation rather than limiting the system capabilities.
 - Highly testable. All codes are guilty and tests is the only way we can prove it otherwise, this means that our test coverage has to be able to cover as much layers as we can so we can be sure of our code reliability.
 - Independent of database. Business logic should not be bound to the database, the system should be able to swap MySQL, Maria DB, PosgreSQL, Mongo DB, Dynamo DB without breaking the logic.
 - Independent of 3rd party library. No 3rd party library should be implemented directly to the system logic, we should abstract in away that our system can replace the library anytime we want.

Every implementation should only be by using interface, there should be no direct access from the implementor to implementation, that way we can inject its dependency and replace it with mock object during unit tests. For example:

PlayerService -> implement IPlayerRepository, instead of direct PlayerRepository


    type PlayerService struct {
      interfaces.IPlayerRepository
    }

    func (service *PlayerService) GetScores(player1Name string, player2Name string) (string, error) {

      baseScore := [4]string{""Love"", ""Fifteen"", ""Thirty"", ""Forty""}
      var result string

      player1, err := service.GetPlayerByName(player1Name)
      if err != nil {
        //Handle error
      }

      player2, err := service.GetPlayerByName(player2Name)
      if err != nil {
        //Handle error
      }

      if player1.Score < 4 && player2.Score < 4 && !(player1.Score+player2.Score == 6) {

        s := baseScore[player1.Score]

        if player1.Score == player2.Score {
          result = s + ""-All""
        } else {
           result = s + ""-"" + baseScore[player2.Score]
        }
      }

      if player1.Score == player2.Score {
        result = ""Deuce""
      }

      return result, nil
    }
    
If you look into the implementation of these lines

    player1, err := service.GetPlayerByName(player1Name)
    player2, err := service.GetPlayerByName(player2Name)

Both are actually abstract implementation of the interface, not the real implementation itself.
So later on the Dependency Injection section, we will learn those interface will be injected with the implementation during the compile time. This way, we can switch the implementation of IPlayerService & IPlayerRepository during the injection with whatever implementation without changing the implementation logic.

Throughout this repo you will find implementation of design patterns such as **Strategy Pattern** when we inject our dependencies with the real implementations. We create **Singleton** and use it to wired up our router and services. We use **Composite** for all our abstract interface implementations so that the implementor can abstractly implement the methods it has, just as the example above where **PlayerService** implements **interfaces.IPlayerRepository** and allows it to directly invoke **GetPlayerByName** which is **IPlayerRepository's** method.  We also use **Decorator Pattern** to hook up our circuit breaker without needing to change / modify the original implementation.

----------

[Folder Structure](https://irahardianto.github.io/service-pattern-go/#folder-structure)
-------
    /
    |- controllers
    |- infrastructures
    |- interfaces
    |- models
    |- repositories
    |- services
    |- viewmodels
    main.go
    router.go
    servicecontainer.go

The folder structure is created to accomodate seperation of concern principle, where every struct should have single responsibility to achieve decoupled system.

Every folder is a namespace of their own, and every file / struct under the same folder should only use the same namepace as their root folder.

### controllers

controllers folder hosts all the structs under controllers namespace, controllers are the handler of all requests coming in, to the router, its doing just that, business logic and data access layer should be done separately.

controller struct implement services through their interface, no direct services implementation should be done in controller, this is done to maintain decoupled systems. The implementation will be injected during the compiled time.


### infrasctructures

infrasctructures folder host all structs under infrasctructures namespace, infrasctructures consists of setup for the system to connect to external data source, it is used to host things like database connection configurations, MySQL, MariaDB, MongoDB, DynamoDB.

### interfaces

interfaces folder hosts all the structs under interfaces namespace, interfaces as the name suggest are the bridge between different domain so they can interact with each other, in our case, this should be the only way for them to interact.

interface in Go is a bit different then you might already find in other language like Java or C#, while the later implements interface explicitly, Go implements interface implicitly. You just need to implement all method the interface has, and you're good to ""Go"".

In our system, our PlayerController implements IPlayerService to be able to interact with the implementation that will be injected. In our case, IPlayerService will be injected with PlayerService.

The same thing applies on PlayerService which implements IPlayerRepository to be able interact with the injected implementation. In our case, IPlayerRepository will be injected with PlayerRepository during the compile time.

PlayerRepository on the other hand, will be injected with infrasctructure configuration that has been setup earlier, this ensure that you can change the implementation of PlayerRepository, without changing the implementor which in this case PlayerService let alone break it. The same thing goes to PlayerService and PlayerController relationship, we can refactor PlayerService, we can change it however we want, without touching the implementor which is PlayerController.

### models

models folder hosts all structs under models namespace, model is a struct reflecting our data object from / to database. models should only define data structs, no other functionalities should be included here.

### repositories

repositories folder hosts all structs under repositories namespace, repositories is where the implementation of data access layer. All queries and data operation from / to database should happen here, and the implementor should be agnostic of what is the database engine is used, how the queries is done, all they care is they can pull the data according to the interface they are implementing.

### services

services folder hosts all structs under services namespace, services is where the business logic lies on, it handles controller request and fetch data from data layer it needs and run their logic to satisfy what controller expect the service to return.

controller might implement many services interface to satisfy the request needs, and controller should be agnostic of how services implements their logic, all they care is that they should be able to pull the result they need according to the interface they implements.

### viewmodels

viewmodels folder hosts all the structs under viewmodels namespace, viewmodels are model to be use as a response return of REST API call

### main.go

main.go is the entry point of our system, here lies the router bindings it triggers ChiRouter singleton and call InitRouter to bind the router.

### router.go

router.go is where we binds controllers to appropriate route to handle desired http request. By default we are using Chi router as it is a light weight router and not bloated with unnecessary unwanted features.

### servicecontainer.go

servicecontainer.go is where the magic begins, this is the place where we injected all implementations of interfaces. Lets cover throughly in the dependency injection section.

----------

[Dependecy Injection](https://irahardianto.github.io/service-pattern-go/#dependency-injection)
-------

Dependecy injection is the heart of TDD, without it we wont be able to do proper TDD because there will be no mocking and we cannot decoupled our code properly. This is one of the misconception when people thinks that they are doing unit testing instead actually they are doing integration test which connects the logic to database. Unit test should be done independently and database should not come in to play when we are doing unit test. One thing to not though, in Go dependency has to be injected during compile time instead of runtime which cause it a bit different than Java / C# implementation, but anyway, its just plain old dependency injection.

In essence unit test is created to test our logic not our data integrity, and by taking database during unit testing it will add huge complexity to the tests itself, and this creates barrier for programmers new to unit testing as they are struggling to create proper testing for their functions.

Now why dependency injection is a crucial part in doing proper TDD? the answer lies in the usage of interface. Back when I have never encountered mocking, I always wondering, what is the use of interface, why we should create abstraction for our functions instead of just write it all already, why the hell should we create a duplicate, abstraction that we will be implementing shortly anyway, some says that, because in doing so, your code will be much cleaner and we have proper pattern, I called that bullshit because in essence we dont have to do it if it only for that reason, and I'm still wondering until I learned about mocking.

Some other people says that interface is used so your program is decoupled, and when needed you can replace the implementations without needing to adjust the implementor. That make sense right? much better than the bullshit. Yea that make sense, we can replace whatever implement whatever interface with whatever. Yea, but how many times would you replace you database connection calls? chances are rare if not never especially if you working on software house that deliver projects after projects after projects, you will never see you component got replaced.

The when I learned about mocking, all that I have been asking coming to conclusions as if I was like having epiphany, we will discuss more about mocking in the mocking section, but for now lets discuss it in regards of dependency injection usage. So as you see in our project structure, instead of having all component directly talks to each other, we are using interface, take PlayerController for example

    type PlayerController struct {
      interfaces.IPlayerService
    }
    
    func (controller *PlayerController) GetPlayerScore(res http.ResponseWriter, req *http.Request) {
    
      player1Name := chi.URLParam(req, ""player1"")
      player2Name := chi.URLParam(req, ""player2"")
    
      scores, err := controller.GetScores(player1Name, player2Name)
      if err != nil {
        //Handle error
      }
    
	  json.NewEncoder(res).Encode(viewmodels.ScoresVM{scores})
    }

You see that PlayerController uses IPlayerService interface, and since IPlayerService has GetScores method, PlayerController can invoke it and get the result right away. Wait a minute, isn't that the interface is just merely abstraction? so how do it get executed, where is the implementation?

    type IPlayerService interface {
      GetScores(player1Name string, player2Name string) (string, error)
    }

You see, instead of calling directly to PlayerService, PlayerController uses the interface of PlayerService which is IPlayerService, there could be many implementation of IPlayerService not just limited to PlayerService it could be BrotherService etc, but how do we determined that PlayerService will be used instead?

    func (k *kernel) InjectPlayerController() controllers.PlayerController {

      sqlConn, _ := sql.Open(""sqlite3"", ""/var/tmp/tennis.db"")
      sqliteHandler := &infrastructures.SQLiteHandler{}
      sqliteHandler.Conn = sqlConn

	  playerRepository := &repositories.PlayerRepository{sqliteHandler}
	  playerService := &services.PlayerService{&repositories.PlayerRepositoryWithCircuitBreaker{playerRepository}}
	  playerController := controllers.PlayerController{playerService}

      return playerController
    }

This is where dependency injection come in to play, as you see here in servicecontainer.go we are creating **playerController** and inject it with **playerService** as simple as that, this is what dependency injection all about no more. So **playerController's IPlayerService** will be injected by **playerService** along with all implementation that it implements, so for example **GetPlayerByName** now returns whatever **GetPlayerByName** implemented by **playerService** as you can see it in **PlayerService.go**

Now, how does this relates to TDD & mocking?

	playerService := new(mocks.IPlayerService)

You see, in PlayerController_test.go we are using mock object to inject the implementation of our service, lets discuss more detail about mocking and testing in each section.

----------

[Mocking](https://irahardianto.github.io/service-pattern-go/#mocking)
-------

Mocking is a concept many times people struggle to understand, let alone implement it, at least I was the one among the one who struggles to understand this concept. But understanding this concept is essential to do TDD. The key point is, we mock dependencies that we need to run our tests, this is why dependency injection is essential to proceed. We are using testfy as our mock library

Basically what mock object do is replacing injection instead of real implementation with mock as point out at the end of dependency injection session

    playerService := new(mocks.IPlayerService)

We then create mock GetScores functionalities along with its request and response.

    playerService.On(""GetScores"", ""Rafael"", ""Serena"").Return(""Forty-Fifteen"", nil)

As you see, then the mock object is injected to **playerService** of PlayerController, this is why dependency injection is essential to this proses as it is the only way we can inject interface with mock object instead of real implementation.

	playerController := PlayerController{playerService}

We generate mock our by using vektra mockery for IPlayerService, go to the interfaces folder and then just type.

    mockery -name=IPlayerService

The output will be inside ```mocks/IPlayerService.go``` and we can use it right away for our testing.

----------

[Testing](https://irahardianto.github.io/service-pattern-go/#testing)
-------

We have cover pretty much everything there is I hope that you already get the idea of proper unit testing and why we should implement interfaces, dependency injection and mocking. The last piece is the unit test itself.

    func TestPlayerScore(t *testing.T) {

      // create an instance of our test object
      playerService := new(mocks.IPlayerService)

      // setup expectations
      playerService.On(""GetScores"", ""Rafael"", ""Serena"").Return(""Forty-Fifteen"", nil)

	  playerController := PlayerController{playerService}

      // call the code we are testing
      req := httptest.NewRequest(""GET"", ""http://localhost:8080/getScore/Rafael/vs/Serena"", nil)
      w := httptest.NewRecorder()

      r := chi.NewRouter()
      r.HandleFunc(""/getScore/{player1}/vs/{player2}"", playerController.GetPlayerScore)

      r.ServeHTTP(w, req)

      expectedResult := viewmodels.ScoresVM{}
      expectedResult.Score = ""Forty-Fifteen""

      actualResult := viewmodels.ScoresVM{}

      json.NewDecoder(w.Body).Decode(&actualResult)

      // assert that the expectations were met
      assert.Equal(t, expectedResult, actualResult)
    }

 As you see here after injecting playerService of playerController with mock object, we are calling the playerController.GetPlayer and simulate request all the way from the router.

     req := httptest.NewRequest(""GET"", ""http://localhost:8080/getScore/Rafael/vs/Serena"", nil)
     w := httptest.NewRecorder()

     r := chi.NewRouter()
     r.HandleFunc(""/getScore/{player1}/vs/{player2}"", playerController.GetPlayerScore)

     r.ServeHTTP(w, req)

And assert the result by using testify assertion library

    assert.Equal(t, expectedResult, actualResult)

----------

[Circuit Breaker](https://irahardianto.github.io/service-pattern-go/#circuit-breaker)
-------

Building a distributed system we should really think that everything is not reliable, networks could breaks, servers could suddenly crash, even your 100% unit-tested app could be the root cause of the problems.

With that in said, when designing distributed system we should keep that in mind, so when some of our system is down, it won't take the whole system. Circuit breaker is a pattern with which we could design our system to be fault-tolerant and can withstand one or more service failure. It should be wrapping all call outside application ex: db call, redis call, api call.

Essentially circuit breaker works just like electrical circuit breakers, nothing fancy here, the only different is when the breaker is tripped it can be automatically closed when the downstream service is responding properly as described in the picture below.

![circuit breaker](https://cdn.pbrd.co/images/GKpFVb1.png)

In our case, we will be using hystrix-go, it is a go port from Netflix's hystrix library, how it works is essentially the same, even hystrix-go supports turbine along with its hystrix dashboard, but in my case, I rather use the datadog plugins, since we are using datadog to monitor our system.

For the sake of SOLID principles implementation in our codebase, we will add hystrix-go to our PlayerRepository leveraging decorator pattern, this will maintain our base repository implementation, the one that calls database, clean from modification and we will create its extension which is named PlayerRepositoryWithCircuitBreaker. This is the O part of SOLID which stands for Open for extension, Close for modification.


If you recall we inject our PlayerService with PlayerRepositoryWithCircuitBreaker and the original PlayerRepository wrapped inside.

	playerService.PlayerRepository = &repositories.PlayerRepositoryWithCircuitBreaker{playerRepository}


Base PlayerRepository implementation :

	type PlayerRepository struct {
      interfaces.IDbHandler
	}

    func (repository *PlayerRepository) GetPlayerByName(name string) (models.PlayerModel, error) {

      row, err :=repository.Query(fmt.Sprintf(""SELECT * FROM player_models WHERE name = '%s'"", name))
      if err != nil {
        return models.PlayerModel{}, err
      }

      var player models.PlayerModel

      row.Next()
      row.Scan(&player.Id, &player.Name, &player.Score)

      return player, nil
	}

PlayerRepository extension implementation :

    type PlayerRepositoryWithCircuitBreaker struct {
      PlayerRepository interfaces.IPlayerRepository
    }

    func (repository *PlayerRepositoryWithCircuitBreaker) GetPlayerByName(name string) (models.PlayerModel, error) {

      output := make(chan models.PlayerModel, 1)
      hystrix.ConfigureCommand(""get_player_by_name"", hystrix.CommandConfig{Timeout: 1000})
      errors := hystrix.Go(""get_player_by_name"", func() error {

        player, _ := repository.PlayerRepository.GetPlayerByName(name)

        output <- player
        return nil
      }, nil)

      select {
      case out := <-output:
        return out, nil
      case err := <-errors:
        println(err)
        return models.PlayerModel{}, err
      }
    }

Basically PlayerRepositoryWithCircuitBreaker implement the same interface as PlayerRepository, IPlayerRepository

    type IPlayerRepository interface {
      GetPlayerByName(name string) (models.PlayerModel, error)
    }


As you see here, it is very easy to implement hystrix-go circuit breaker, you just need to wrap your db call inside hystrix if the timeout reached, the circuit breaker will be tripped and all calls to database will be halt, error will be returned instead for future call until db service is up and healthy.


Cheers,
M. Ichsan Rahardianto.
","This is an example of Go clean architecture implementing Dependency Injection
and Mocking for unit testing purposes to achieve safe, reliable and secure
source code. The aim of the architecture is to produce a system that are:
Independent of frameworks. The system should be able to become an independent
system, not bound into any framework implementation. All codes are and tests is
the only way to prove that our code can be reliable."
1252,Apache Cordova Plugin inappbrowser,"---
title: Inappbrowser
description: Open an in-app browser window.
---
<!--
# license: Licensed to the Apache Software Foundation (ASF) under one
#         or more contributor license agreements.  See the NOTICE file
#         distributed with this work for additional information
#         regarding copyright ownership.  The ASF licenses this file
#         to you under the Apache License, Version 2.0 (the
#         ""License""); you may not use this file except in compliance
#         with the License.  You may obtain a copy of the License at
#
#           http://www.apache.org/licenses/LICENSE-2.0
#
#         Unless required by applicable law or agreed to in writing,
#         software distributed under the License is distributed on an
#         ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
#         KIND, either express or implied.  See the License for the
#         specific language governing permissions and limitations
#         under the License.
-->


# cordova-plugin-inappbrowser

[![Android Testsuite](https://github.com/apache/cordova-plugin-inappbrowser/actions/workflows/android.yml/badge.svg)](https://github.com/apache/cordova-plugin-inappbrowser/actions/workflows/android.yml) [![Chrome Testsuite](https://github.com/apache/cordova-plugin-inappbrowser/actions/workflows/chrome.yml/badge.svg)](https://github.com/apache/cordova-plugin-inappbrowser/actions/workflows/chrome.yml) [![iOS Testsuite](https://github.com/apache/cordova-plugin-inappbrowser/actions/workflows/ios.yml/badge.svg)](https://github.com/apache/cordova-plugin-inappbrowser/actions/workflows/ios.yml) [![Lint Test](https://github.com/apache/cordova-plugin-inappbrowser/actions/workflows/lint.yml/badge.svg)](https://github.com/apache/cordova-plugin-inappbrowser/actions/workflows/lint.yml)

You can show helpful articles, videos, and web resources inside of your app. Users can view web pages without leaving your app.

> To get a few ideas, check out the [sample](#sample) at the bottom of this page or go straight to the [reference](#reference) content.

This plugin provides a web browser view that displays when calling `cordova.InAppBrowser.open()`.

    var ref = cordova.InAppBrowser.open('http://apache.org', '_blank', 'location=yes');

### `window.open`

The `cordova.InAppBrowser.open()` function is defined to be a drop-in replacement
for the `window.open()` function.  Existing `window.open()` calls can use the
InAppBrowser window, by replacing window.open:

    window.open = cordova.InAppBrowser.open;

If you change the browsers `window.open` function this way, it can have unintended side
effects (especially if this plugin is included only as a dependency of another
plugin).

The InAppBrowser window behaves like a standard web browser,
and can't access Cordova APIs. For this reason, the InAppBrowser is recommended
if you need to load third-party (untrusted) content, instead of loading that
into the main Cordova webview. The InAppBrowser is not subject to the
whitelist, nor is opening links in the system browser.

The InAppBrowser provides by default its own GUI controls for the user (back,
forward, done).

## Installation

    cordova plugin add cordova-plugin-inappbrowser

If you want all page loads in your app to go through the InAppBrowser, you can
simply hook `window.open` during initialization.  For example:

    document.addEventListener(""deviceready"", onDeviceReady, false);
    function onDeviceReady() {
        window.open = cordova.InAppBrowser.open;
    }

### Preferences

#### <b>config.xml</b>
- <b>InAppBrowserStatusBarStyle [iOS only]</b>: (string, options 'lightcontent', 'darkcontent' or 'default'. Defaults to 'default') set text color style for iOS. 'lightcontent' is intended for use on dark backgrounds. 'darkcontent' is only available since iOS 13 and intended for use on light backgrounds.
```xml
<preference name=""InAppBrowserStatusBarStyle"" value=""lightcontent"" />
```

## cordova.InAppBrowser.open

Opens a URL in a new `InAppBrowser` instance, the current browser
instance, or the system browser.

    var ref = cordova.InAppBrowser.open(url, target, options);

- __ref__: Reference to the `InAppBrowser` window when the target is set to `'_blank'`. _(InAppBrowser)_

- __url__: The URL to load _(String)_. Call `encodeURI()` on this if the URL contains Unicode characters.

- __target__: The target in which to load the URL, an optional parameter that defaults to `_self`. _(String)_

    - `_self`: Opens in the Cordova WebView if the URL is in the white list, otherwise it opens in the `InAppBrowser`.
    - `_blank`: Opens in the `InAppBrowser`.
    - `_system`: Opens in the system's web browser.

- __options__: Options for the `InAppBrowser`. Optional, defaulting to: `location=yes`. _(String)_

    The `options` string must not contain any blank space, and each feature's name/value pairs must be separated by a comma. Feature names are case insensitive.

    All platforms support:

    - __location__: Set to `yes` or `no` to turn the `InAppBrowser`'s location bar on or off.

    Android supports these additional options:

    - __hidden__: set to `yes` to create the browser and load the page, but not show it. The loadstop event fires when loading is complete. Omit or set to `no` (default) to have the browser open and load normally.
    - __beforeload__: set to enable the `beforeload` event to modify which pages are actually loaded in the browser. Accepted values are `get` to intercept only GET requests, `post` to intercept on POST requests or `yes` to intercept both GET & POST requests. Note that POST requests are not currently supported and will be ignored (if you set `beforeload=post` it will raise an error).
    - __clearcache__: set to `yes` to have the browser's cookie cache cleared before the new window is opened
    - __clearsessioncache__: set to `yes` to have the session cookie cache cleared before the new window is opened
    - __closebuttoncaption__: set to a string to use as the close button's caption instead of a X. Note that you need to localize this value yourself.
    - __closebuttoncolor__: set to a valid hex color string, for example: `#00ff00`, and it will change the
    close button color from default, regardless of being a text or default X. Only has effect if user has location set to `yes`.
    - __footer__: set to `yes` to show a close button in the footer similar to the iOS __Done__ button. 
    The close button will appear the same as for the header hence use __closebuttoncaption__ and __closebuttoncolor__ to set its properties.
    - __footercolor__: set to a valid hex color string, for example `#00ff00` or `#CC00ff00` (`#aarrggbb`) , and it will change the footer color from default.
    Only has effect if user has __footer__ set to `yes`.
    - __hardwareback__: set to `yes` to use the hardware back button to navigate backwards through the `InAppBrowser`'s history. If there is no previous page, the `InAppBrowser` will close.  The default value is `yes`, so you must set it to `no` if you want the back button to simply close the InAppBrowser.
    - __hidenavigationbuttons__: set to `yes` to hide the navigation buttons on the location toolbar, only has effect if user has location set to `yes`. The default value is `no`.
    - __hideurlbar__: set to `yes` to hide the url bar on the location toolbar, only has effect if user has location set to `yes`. The default value is `no`.
    - __navigationbuttoncolor__: set to a valid hex color string, for example: `#00ff00`, and it will change the color of both navigation buttons from default. Only has effect if user has location set to `yes` and not hidenavigationbuttons set to `yes`.
    - __toolbarcolor__: set to a valid hex color string, for example: `#00ff00`, and it will change the color the toolbar from default. Only has effect if user has location set to `yes`.
    - __lefttoright__: Set to `yes` to swap positions of the navigation buttons and the close button. Specifically, navigation buttons go to the right and close button to the left. Default value is `no`.
    - __zoom__: set to `yes` to show Android browser's zoom controls, set to `no` to hide them.  Default value is `yes`.
    - __mediaPlaybackRequiresUserAction__: Set to `yes` to prevent HTML5 audio or video from autoplaying (defaults to `no`).
    - __shouldPauseOnSuspend__: Set to `yes` to make InAppBrowser WebView to pause/resume with the app to stop background audio (this may be required to avoid Google Play issues like described in [CB-11013](https://issues.apache.org/jira/browse/CB-11013)).
    - __useWideViewPort__: Sets whether the WebView should enable support for the ""viewport"" HTML meta tag or should use a wide viewport. When the value of the setting is `no`, the layout width is always set to the width of the WebView control in device-independent (CSS) pixels. When the value is `yes` and the page contains the viewport meta tag, the value of the width specified in the tag is used. If the page does not contain the tag or does not provide a width, then a wide viewport will be used. (defaults to `yes`).
    - __fullscreen__: Sets whether the InappBrowser WebView is displayed fullscreen or not. In fullscreen mode, the status bar is hidden. Default value is `yes`.

    iOS supports these additional options:

    - __hidden__: set to `yes` to create the browser and load the page, but not show it. The loadstop event fires when loading is complete. Omit or set to `no` (default) to have the browser open and load normally.
    - __beforeload__: set to enable the `beforeload` event to modify which pages are actually loaded in the browser. Accepted values are `get` to intercept only GET requests, `post` to intercept on POST requests or `yes` to intercept both GET & POST requests. Note that POST requests are not currently supported and will be ignored (if you set `beforeload=post` it will raise an error).
    - __clearcache__: set to `yes` to have the browser's cookie cache cleared before the new window is opened
    - __clearsessioncache__: set to `yes` to have the session cookie cache cleared before the new window is opened. For WKWebView, requires iOS 11+ on target device.
    - __cleardata__: set to `yes` to have the browser's entire local storage cleared (cookies, HTML5 local storage, IndexedDB, etc.) before the new window is opened
    - __closebuttoncolor__: set as a valid hex color string, for example: `#00ff00`, to change from the default __Done__ button's color. Only applicable if toolbar is not disabled.
    - __closebuttoncaption__: set to a string to use as the __Done__ button's caption. Note that you need to localize this value yourself.
    - __disallowoverscroll__: Set to `yes` or `no` (default is `no`). Turns on/off the the bounce of the WKWebView's UIScrollView.
    - __hidenavigationbuttons__:  set to `yes` or `no` to turn the toolbar navigation buttons on or off (defaults to `no`). Only applicable if toolbar is not disabled.
    - __navigationbuttoncolor__:  set as a valid hex color string, for example: `#00ff00`, to change from the default color. Only applicable if navigation buttons are visible.
    - __toolbar__:  set to `yes` or `no` to turn the toolbar on or off for the InAppBrowser (defaults to `yes`)
    - __toolbarcolor__: set as a valid hex color string, for example: `#00ff00`, to change from the default color of the toolbar. Only applicable if toolbar is not disabled.
    - __toolbartranslucent__:  set to `yes` or `no` to make the toolbar translucent(semi-transparent)  (defaults to `yes`). Only applicable if toolbar is not disabled.
    - __lefttoright__: Set to `yes` to swap positions of the navigation buttons and the close button. Specifically, close button goes to the right and navigation buttons to the left.
    - __enableViewportScale__:  Set to `yes` or `no` to prevent viewport scaling through a meta tag (defaults to `no`).
    - __mediaPlaybackRequiresUserAction__: Set to `yes` to prevent HTML5 audio or video from autoplaying (defaults to `no`).
    - __allowInlineMediaPlayback__: Set to `yes` or `no` to allow in-line HTML5 media playback, displaying within the browser window rather than a device-specific playback interface. The HTML's `video` element must also include the `webkit-playsinline` attribute (defaults to `no`).
    - __presentationstyle__:  Set to `pagesheet`, `formsheet` or `fullscreen` to set the [presentation style](https://developer.apple.com/documentation/uikit/uimodalpresentationstyle) (defaults to `fullscreen`).
    - __transitionstyle__: Set to `fliphorizontal`, `crossdissolve` or `coververtical` to set the [transition style](https://developer.apple.com/documentation/uikit/uimodaltransitionstyle) (defaults to `coververtical`).
    - __toolbarposition__: Set to `top` or `bottom` (default is `bottom`). Causes the toolbar to be at the top or bottom of the window.
    - __hidespinner__: Set to `yes` or `no` to change the visibility of the loading indicator (defaults to `no`).

    Windows supports these additional options:

    - __hidden__: set to `yes` to create the browser and load the page, but not show it. The loadstop event fires when loading is complete. Omit or set to `no` (default) to have the browser open and load normally.
    - __hardwareback__: works the same way as on Android platform.
    - __fullscreen__: set to `yes` to create the browser control without a border around it. Please note that if __location=no__ is also specified, there will be no control presented to user to close IAB window.


### Supported Platforms

- Android
- Browser
- iOS
- OSX
- Windows

### Example

    var ref = cordova.InAppBrowser.open('http://apache.org', '_blank', 'location=yes');
    var ref2 = cordova.InAppBrowser.open(encodeURI('http://ja.m.wikipedia.org/wiki/ハングル'), '_blank', 'location=yes');

### OSX Quirks

At the moment the only supported target in OSX is `_system`.

`_blank` and `_self` targets are not yet implemented and are ignored silently. Pull requests and patches to get these to work are greatly appreciated.

### iOS Quirks

Since the introduction of iPadOS 13, iPads try to adapt their content mode / user agent for the optimal browsing experience. This may result in iPads having their user agent set to Macintosh, making it hard to detect them as mobile devices using user agent string sniffing. You can change this with the `PreferredContentMode` preference in `config.xml`.

```xml
<preference name=""PreferredContentMode"" value=""mobile"" />
```

The example above forces the user agent to contain `iPad`. The other option is to use the value `desktop` to turn the user agent to `Macintosh`.

### Browser Quirks

- Plugin is implemented via iframe,

- Navigation history (`back` and `forward` buttons in LocationBar) is not implemented.

## InAppBrowser

The object returned from a call to `cordova.InAppBrowser.open` when the target is set to `'_blank'`.

### Methods

- addEventListener
- removeEventListener
- close
- show
- hide
- executeScript
- insertCSS

## InAppBrowser.addEventListener

> Adds a listener for an event from the `InAppBrowser`. (Only available when the target is set to `'_blank'`)

    ref.addEventListener(eventname, callback);

- __ref__: reference to the `InAppBrowser` window _(InAppBrowser)_

- __eventname__: the event to listen for _(String)_

  - __loadstart__: event fires when the `InAppBrowser` starts to load a URL.
  - __loadstop__: event fires when the `InAppBrowser` finishes loading a URL.
  - __loaderror__: event fires when the `InAppBrowser` encounters an error when loading a URL.
  - __exit__: event fires when the `InAppBrowser` window is closed.
  - __beforeload__: event fires when the `InAppBrowser` decides whether to load an URL or not (only with option `beforeload` set).
  - __message__: event fires when the `InAppBrowser` receives a message posted from the page loaded inside the `InAppBrowser` Webview.

- __callback__: the function that executes when the event fires. The function is passed an `InAppBrowserEvent` object as a parameter.

## Example

```javascript

var inAppBrowserRef;

function showHelp(url) {

    var target = ""_blank"";

    var options = ""location=yes,hidden=yes,beforeload=yes"";

    inAppBrowserRef = cordova.InAppBrowser.open(url, target, options);

    inAppBrowserRef.addEventListener('loadstart', loadStartCallBack);

    inAppBrowserRef.addEventListener('loadstop', loadStopCallBack);

    inAppBrowserRef.addEventListener('loaderror', loadErrorCallBack);

    inAppBrowserRef.addEventListener('beforeload', beforeloadCallBack);

    inAppBrowserRef.addEventListener('message', messageCallBack);
}

function loadStartCallBack() {

    $('#status-message').text(""loading please wait ..."");

}

function loadStopCallBack() {

    if (inAppBrowserRef != undefined) {

        inAppBrowserRef.insertCSS({ code: ""body{font-size: 25px;}"" });

        inAppBrowserRef.executeScript({ code: ""\
            var message = 'this is the message';\
            var messageObj = {my_message: message};\
            var stringifiedMessageObj = JSON.stringify(messageObj);\
            webkit.messageHandlers.cordova_iab.postMessage(stringifiedMessageObj);""
        });

        $('#status-message').text("""");

        inAppBrowserRef.show();
    }

}

function loadErrorCallBack(params) {

    $('#status-message').text("""");

    var scriptErrorMesssage =
       ""alert('Sorry we cannot open that page. Message from the server is : ""
       + params.message + ""');""

    inAppBrowserRef.executeScript({ code: scriptErrorMesssage }, executeScriptCallBack);

    inAppBrowserRef.close();

    inAppBrowserRef = undefined;

}

function executeScriptCallBack(params) {

    if (params[0] == null) {

        $('#status-message').text(
           ""Sorry we couldn't open that page. Message from the server is : '""
           + params.message + ""'"");
    }

}

function beforeloadCallBack(params, callback) {

    if (params.url.startsWith(""http://www.example.com/"")) {

        // Load this URL in the inAppBrowser.
        callback(params.url);
    } else {

        // The callback is not invoked, so the page will not be loaded.
        $('#status-message').text(""This browser only opens pages on http://www.example.com/"");
    }

}

function messageCallBack(params){
    $('#status-message').text(""message received: ""+params.data.my_message);
}

```

### InAppBrowserEvent Properties

- __type__: the eventname, either `loadstart`, `loadstop`, `loaderror`, `message` or `exit`. _(String)_

- __url__: the URL that was loaded. _(String)_

- __code__: the error code, only in the case of `loaderror`. _(Number)_

- __message__: the error message, only in the case of `loaderror`. _(String)_

- __data__: the message contents , only in the case of `message`. A stringified JSON object. _(String)_


### Supported Platforms

- Android
- Browser
- iOS
- Windows
- OSX

### Browser Quirks

`loadstart`, `loaderror`, `message` events are not fired.

### Windows Quirks

`message` event is not fired.

### Quick Example

    var ref = cordova.InAppBrowser.open('http://apache.org', '_blank', 'location=yes');
    ref.addEventListener('loadstart', function(event) { alert(event.url); });

## InAppBrowser.removeEventListener

> Removes a listener for an event from the `InAppBrowser`. (Only available when the target is set to `'_blank'`)

    ref.removeEventListener(eventname, callback);

- __ref__: reference to the `InAppBrowser` window. _(InAppBrowser)_

- __eventname__: the event to stop listening for. _(String)_

  - __loadstart__: event fires when the `InAppBrowser` starts to load a URL.
  - __loadstop__: event fires when the `InAppBrowser` finishes loading a URL.
  - __loaderror__: event fires when the `InAppBrowser` encounters an error loading a URL.
  - __exit__: event fires when the `InAppBrowser` window is closed.
  - __message__: event fires when the `InAppBrowser` receives a message posted from the page loaded inside the `InAppBrowser` Webview.

- __callback__: the function to execute when the event fires.
The function is passed an `InAppBrowserEvent` object.

### Supported Platforms

- Android
- Browser
- iOS
- Windows

### Quick Example

    var ref = cordova.InAppBrowser.open('http://apache.org', '_blank', 'location=yes');
    var myCallback = function(event) { alert(event.url); }
    ref.addEventListener('loadstart', myCallback);
    ref.removeEventListener('loadstart', myCallback);

## InAppBrowser.close

> Closes the `InAppBrowser` window.

    ref.close();

- __ref__: reference to the `InAppBrowser` window _(InAppBrowser)_

### Supported Platforms

- Android
- Browser
- iOS
- Windows

### Quick Example

    var ref = cordova.InAppBrowser.open('http://apache.org', '_blank', 'location=yes');
    ref.close();

## InAppBrowser.show

> Displays an InAppBrowser window that was opened hidden. Calling this has no effect if the InAppBrowser was already visible.

    ref.show();

- __ref__: reference to the InAppBrowser window (`InAppBrowser`)

### Supported Platforms

- Android
- Browser
- iOS
- Windows

### Quick Example

    var ref = cordova.InAppBrowser.open('http://apache.org', '_blank', 'hidden=yes');
    // some time later...
    ref.show();

## InAppBrowser.hide

> Hides the InAppBrowser window. Calling this has no effect if the InAppBrowser was already hidden.

    ref.hide();

- __ref__: reference to the InAppBrowser window (`InAppBrowser`)

### Supported Platforms

- Android
- iOS
- Windows

### Quick Example

    var ref = cordova.InAppBrowser.open('http://apache.org', '_blank');
    // some time later...
    ref.hide();

## InAppBrowser.executeScript

> Injects JavaScript code into the `InAppBrowser` window. (Only available when the target is set to `'_blank'`)

    ref.executeScript(details, callback);

- __ref__: reference to the `InAppBrowser` window. _(InAppBrowser)_

- __injectDetails__: details of the script to run, specifying either a `file` or `code` key. _(Object)_
  - __file__: URL of the script to inject.
  - __code__: Text of the script to inject.

- __callback__: the function that executes after the JavaScript code is injected.
    - If the injected script is of type `code`, the callback executes
      with a single parameter, which is the return value of the
      script, wrapped in an `Array`. For multi-line scripts, this is
      the return value of the last statement, or the last expression
      evaluated.

### Supported Platforms

- Android
- Browser
- iOS
- Windows

### Quick Example

    var ref = cordova.InAppBrowser.open('http://apache.org', '_blank', 'location=yes');
    ref.addEventListener('loadstop', function() {
        ref.executeScript({file: ""myscript.js""});
    });

### Browser Quirks

- only __code__ key is supported.

### Windows Quirks

Due to [MSDN docs](https://msdn.microsoft.com/en-us/library/windows.ui.xaml.controls.webview.invokescriptasync.aspx) the invoked script can return only string values, otherwise the parameter, passed to __callback__ will be `[null]`.

## InAppBrowser.insertCSS

> Injects CSS into the `InAppBrowser` window. (Only available when the target is set to `'_blank'`)

    ref.insertCSS(details, callback);

- __ref__: reference to the `InAppBrowser` window _(InAppBrowser)_

- __injectDetails__: details of the script to run, specifying either a `file` or `code` key. _(Object)_
  - __file__: URL of the stylesheet to inject.
  - __code__: Text of the stylesheet to inject.

- __callback__: the function that executes after the CSS is injected.

### Supported Platforms

- Android
- iOS
- Windows

### Quick Example

    var ref = cordova.InAppBrowser.open('http://apache.org', '_blank', 'location=yes');
    ref.addEventListener('loadstop', function() {
        ref.insertCSS({file: ""mystyles.css""});
    });
__

## <a id=""sample""></a>Sample: Show help pages with an InAppBrowser

You can use this plugin to show helpful documentation pages within your app. Users can view online help documents and then close them without leaving the app.

Here's a few snippets that show how you do this.

* [Give users a way to ask for help](#give).
* [Load a help page](#load).
* [Let users know that you're getting their page ready](#let).
* [Show the help page](#show).
* [Handle page errors](#handle).

### <a id=""give""></a>Give users a way to ask for help

There's lots of ways to do this in your app. A drop down list is a simple way to do that.

```html

<select id=""help-select"">
    <option value=""default"">Need help?</option>
    <option value=""article"">Show me a helpful article</option>
    <option value=""video"">Show me a helpful video</option>
    <option value=""search"">Search for other topics</option>
</select>

```

Gather the users choice in the ``onDeviceReady`` function of the page and then send an appropriate URL to a helper function in some shared library file. Our helper function is named ``showHelp()`` and we'll write that function next.

```javascript

$('#help-select').on('change', function (e) {

    var url;

    switch (this.value) {

        case ""article"":
            url = ""https://cordova.apache.org/docs/en/latest/""
                        + ""reference/cordova-plugin-inappbrowser/index.html"";
            break;

        case ""video"":
            url = ""https://youtu.be/F-GlVrTaeH0"";
            break;

        case ""search"":
            url = ""https://www.google.com/#q=inAppBrowser+plugin"";
            break;
    }

    showHelp(url);

});

```

### <a id=""load""></a>Load a help page

We'll use the ``open`` function to load the help page. We're setting the ``hidden`` property to ``yes`` so that we can show the browser only after the page content has loaded. That way, users don't see a blank browser while they wait for content to appear. When the ``loadstop`` event is raised, we'll know when the content has loaded. We'll handle that event shortly.

```javascript

function showHelp(url) {

    var target = ""_blank"";

    var options = ""location=yes,hidden=yes"";

    inAppBrowserRef = cordova.InAppBrowser.open(url, target, options);

    inAppBrowserRef.addEventListener('loadstart', loadStartCallBack);

    inAppBrowserRef.addEventListener('loadstop', loadStopCallBack);

    inAppBrowserRef.addEventListener('loaderror', loadErrorCallBack);

}

```

### <a id=""let""></a>Let users know that you're getting their page ready

Because the browser doesn't immediately appear, we can use the ``loadstart`` event to show a status message, progress bar, or other indicator. This assures users that content is on the way.

```javascript

function loadStartCallBack() {

    $('#status-message').text(""loading please wait ..."");

}

```

### <a id=""show""></a>Show the help page

When the ``loadstopcallback`` event is raised, we know that the content has loaded and we can make the browser visible. This sort of trick can create the impression of better performance. The truth is that whether you show the browser before content loads or not, the load times are exactly the same.

```javascript

function loadStopCallBack() {

    if (inAppBrowserRef != undefined) {

        inAppBrowserRef.insertCSS({ code: ""body{font-size: 25px;}"" });

        $('#status-message').text("""");

        inAppBrowserRef.show();
    }

}

```
You might have noticed the call to the ``insertCSS`` function. This serves no particular purpose in our scenario. But it gives you an idea of why you might use it. In this case, we're just making sure that the font size of your pages have a certain size. You can use this function to insert any CSS style elements. You can even point to a CSS file in your project.

### <a id=""handle""></a>Handle page errors

Sometimes a page no longer exists, a script error occurs, or a user lacks permission to view the resource. How or if you handle that situation is completely up to you and your design. You can let the browser show that message or you can present it in another way.

We'll try to show that error in a message box. We can do that by injecting a script that calls the ``alert`` function. That said, this won't work in browsers on Windows devices so we'll have to look at the parameter of the ``executeScript`` callback function to see if our attempt worked. If it didn't work out for us, we'll just show the error message in a ``<div>`` on the page.

```javascript

function loadErrorCallBack(params) {

    $('#status-message').text("""");

    var scriptErrorMesssage =
       ""alert('Sorry we cannot open that page. Message from the server is : ""
       + params.message + ""');""

    inAppBrowserRef.executeScript({ code: scriptErrorMesssage }, executeScriptCallBack);

    inAppBrowserRef.close();

    inAppBrowserRef = undefined;

}

function executeScriptCallBack(params) {

    if (params[0] == null) {

        $('#status-message').text(
           ""Sorry we couldn't open that page. Message from the server is : '""
           + params.message + ""'"");
    }

}

```

## More Usage Info

### Local Urls ( source is in the app package )
```
var iab = cordova.InAppBrowser;

iab.open('local-url.html');                  // loads in the Cordova WebView
iab.open('local-url.html', '_self');         // loads in the Cordova WebView
iab.open('local-url.html', '_system');       // Security error: system browser, but url will not load (iOS)
iab.open('local-url.html', '_blank');        // loads in the InAppBrowser
iab.open('local-url.html', 'random_string'); // loads in the InAppBrowser
iab.open('local-url.html', 'random_string', 'location=no'); // loads in the InAppBrowser, no location bar

```



### Whitelisted Content

```
var iab = cordova.InAppBrowser;

iab.open('http://whitelisted-url.com');                  // loads in the Cordova WebView
iab.open('http://whitelisted-url.com', '_self');         // loads in the Cordova WebView
iab.open('http://whitelisted-url.com', '_system');       // loads in the system browser
iab.open('http://whitelisted-url.com', '_blank');        // loads in the InAppBrowser
iab.open('http://whitelisted-url.com', 'random_string'); // loads in the InAppBrowser

iab.open('http://whitelisted-url.com', 'random_string', 'location=no'); // loads in the InAppBrowser, no location bar

```

### Urls that are not white-listed

```
var iab = cordova.InAppBrowser;

iab.open('http://url-that-fails-whitelist.com');                  // loads in the InAppBrowser
iab.open('http://url-that-fails-whitelist.com', '_self');         // loads in the InAppBrowser
iab.open('http://url-that-fails-whitelist.com', '_system');       // loads in the system browser
iab.open('http://url-that-fails-whitelist.com', '_blank');        // loads in the InAppBrowser
iab.open('http://url-that-fails-whitelist.com', 'random_string'); // loads in the InAppBrowser
iab.open('http://url-that-fails-whitelist.com', 'random_string', 'location=no'); // loads in the InAppBrowser, no location bar

```
","InappBrowser is a drop-in replacement for the window.open() function. Users can
view web pages without leaving your app. The InAppBrowser is not subject to the
systemwhitelist, nor is it subject to opening links in the browser."
124,Gephi - The Open Graph Viz Platform,"# Gephi - The Open Graph Viz Platform

[![build](https://github.com/gephi/gephi/actions/workflows/build.yml/badge.svg)](https://github.com/gephi/gephi/actions/workflows/build.yml)
[![Downloads](https://img.shields.io/github/downloads/gephi/gephi/v0.10.1/total.svg)](https://github.com/gephi/gephi/releases/tag/v0.10.1)
[![Downloads](https://img.shields.io/github/downloads/gephi/gephi/total.svg)](https://github.com/gephi/gephi/releases/)
[![Translation progress](https://hosted.weblate.org/widgets/gephi/-/svg-badge.svg)](https://hosted.weblate.org/engage/gephi/?utm_source=widget)

[Gephi](http://gephi.org) is an award-winning open-source platform for visualizing and manipulating large graphs. It runs on Windows, Mac OS X and Linux. Localization is available in English, French, Spanish, Japanese, Russian, Brazilian Portuguese, Chinese, Czech, German and Romanian.

- **Fast** Powered by a built-in OpenGL engine, Gephi is able to push the envelope with very large networks. Visualize networks up to a million elements. All actions (e.g. layout, filter, drag) run in real-time.

- **Simple** Easy to install and [get started](https://gephi.github.io/users/quick-start). An UI that is centered around the visualization. Like Photoshop™ for graphs.

- **Modular** Extend Gephi with [plug-ins](https://gephi.org/plugins). The architecture is built on top of [Apache Netbeans Platform](https://netbeans.apache.org/tutorials/nbm-quick-start.html) and can be extended or reused easily through well-written APIs.

[Download Gephi](https://gephi.github.io/users/download) for Windows, Mac OS X and Linux and consult the [release notes](https://github.com/gephi/gephi/releases). Example datasets can be found on our [wiki](https://github.com/gephi/gephi/wiki/Datasets).

![Gephi](https://gephi.github.io/images/screenshots/select-tool-mini.png)

## Install and use Gephi

Download and [Install](https://gephi.github.io/users/install/) Gephi on your computer. 

Get started with the [Quick Start](https://gephi.github.io/users/quick-start/) and follow the [Tutorials](https://gephi.github.io/users/). Load a sample [dataset](https://github.com/gephi/gephi/wiki/Datasets) and start to play with the data.

If you run into any trouble or have questions consult our [discussions](https://github.com/gephi/gephi/discussions).

## Latest releases

### Stable

- Latest stable release on [gephi.org](https://gephi.org/users/download/).

### Development builds

Development builds are [generated regularly](https://github.com/gephi/gephi/actions/workflows/release.yml). Current version is 0.10.2-SNAPSHOT

- [gephi-0.10.2-SNAPSHOT-windows-x64.exe](https://oss.sonatype.org/service/local/artifact/maven/content?r=snapshots&g=org.gephi&a=gephi&v=0.10.2-SNAPSHOT&c=windows-x64&p=exe) (Windows)

- [gephi-0.10.2-SNAPSHOT-windows-x32.exe](https://oss.sonatype.org/service/local/artifact/maven/content?r=snapshots&g=org.gephi&a=gephi&v=0.10.2-SNAPSHOT&c=windows-x32&p=exe) (Windows x32)

- [gephi-0.10.2-SNAPSHOT-macos-x64.dmg](https://oss.sonatype.org/service/local/artifact/maven/content?r=snapshots&g=org.gephi&a=gephi&v=0.10.2-SNAPSHOT&c=macos-x64&p=dmg) (Mac OS X)

- [gephi-0.10.2-SNAPSHOT-macos-aarch64.dmg](https://oss.sonatype.org/service/local/artifact/maven/content?r=snapshots&g=org.gephi&a=gephi&v=0.10.2-SNAPSHOT&c=macos-aarch64&p=dmg) (Mac OS X Silicon)

- [gephi-0.10.2-SNAPSHOT-linux-x64.tar.gz](https://oss.sonatype.org/service/local/artifact/maven/content?r=snapshots&g=org.gephi&a=gephi&v=0.10.2-SNAPSHOT&c=linux-x64&p=tar.gz) (Linux)

## Developer Introduction

Gephi is developed in Java and uses OpenGL for its visualization engine. Built on the top of Netbeans Platform, it follows a loosely-coupled, modular architecture philosophy. Gephi is split into modules, which depend on other modules through well-written APIs. Plugins can reuse existing APIs, create new services and even replace a default implementation with a new one.

Consult the [**Javadoc**](http://gephi.github.io/gephi/0.9.2/apidocs/index.html) for an overview of the APIs.

### Requirements

- Java JDK 11 (or later)

- [Apache Maven](http://maven.apache.org/) version 3.6.3 or later

### Checkout and Build the sources

- Fork the repository and clone

        git clone git@github.com:username/gephi.git

- Run the following command or [open the project in an IDE](https://github.com/gephi/gephi/wiki/How-to-build-Gephi)

        mvn -T 4 clean install

- Once built, one can test running Gephi

		cd modules/application
		mvn nbm:cluster-app nbm:run-platform

Note that while Gephi can be built using JDK 11 or later, it currently requires JDK 11 to run.

### Create Plug-ins

Gephi is extensible and lets developers create plug-ins to add new features, or to modify existing features. For example, you can create a new layout algorithm, add a metric, create a filter or a tool, support a new file format or database, or modify the visualization.

- [**Plugins Portal**](https://github.com/gephi/gephi/wiki/Plugins)

- [Plugins Quick Start (5 minutes)](https://github.com/gephi/gephi/wiki/Plugin-Quick-Start)

- Browse the [plugins](https://gephi.org/plugins) created by the community

- We've created a [**Plugins Bootcamp**](https://github.com/gephi/gephi-plugins-bootcamp) to learn by examples.

## Gephi Toolkit

The Gephi Toolkit project packages essential Gephi modules (Graph, Layout, Filters, IO…) in a standard Java library which any Java project can use for getting things done. It can be used on a server or command-line tool to do the same things Gephi does but automatically.

- [Download](https://gephi.org/toolkit/)

- [GitHub Project](https://github.com/gephi/gephi-toolkit)

- [Toolkit Portal](https://github.com/gephi/gephi/wiki/Toolkit)

## Localization

We use [Weblate](https://hosted.weblate.org/projects/gephi/) for localization. Follow the guidelines on the [wiki](https://github.com/gephi/gephi/wiki/Localization) for more details how to contribute.

## Icons

Gephi uses icons from various sources. The icons are licensed under the [CC BY 3.0](https://creativecommons.org/licenses/by/3.0/) license.

All icons can be found in the `DesktopIcons` module, organised by module name.

## License

Gephi main source code is distributed under the dual license [CDDL 1.0](http://www.opensource.org/licenses/CDDL-1.0) and [GNU General Public License v3](http://www.gnu.org/licenses/gpl.html). Read the [Legal FAQs](http://gephi.github.io/legal/faq/)  to learn more.
	
Copyright 2011 Gephi Consortium. All rights reserved.

The contents of this file are subject to the terms of either the GNU
General Public License Version 3 only (""GPL"") or the Common
Development and Distribution License (""CDDL"") (collectively, the
""License""). You may not use this file except in compliance with the
License. You can obtain a copy of the License at
http://gephi.github.io/developers/license/
or /cddl-1.0.txt and /gpl-3.0.txt. See the License for the
specific language governing permissions and limitations under the
License.  When distributing the software, include this License Header
Notice in each file and include the License files at
/cddl-1.0.txt and /gpl-3.0.txt. If applicable, add the following below the
License Header, with the fields enclosed by brackets [] replaced by
your own identifying information:
""Portions Copyrighted [year] [name of copyright owner]""

If you wish your version of this file to be governed by only the CDDL
or only the GPL Version 3, indicate your decision by adding
""[Contributor] elects to include this software in this distribution
under the [CDDL or GPL Version 3] license."" If you do not indicate a
single choice of license, a recipient has the option to distribute
your version of this file under either the CDDL, the GPL Version 3 or
to extend the choice of license to its licensees as provided above.
However, if you add GPL Version 3 code and therefore, elected the GPL
Version 3 license, then the option applies only if the new code is
made subject to such option by the copyright holder.
","Gephi is an award-winning open-source platform for visualizing and manipulating
large graphs. It runs on Windows, Mac OS X and Linux. Localization is available
in English, French, Spanish, Japanese, Russian, Brazilian Portuguese, Chinese,
Czech, German and Romanian."
2545,Performance monitoring tools for Linux,"## sysstat - System performance tools for the Linux operating system
[![Coverity Scan Build Status](https://scan.coverity.com/projects/4040/badge.svg)](https://scan.coverity.com/projects/sysstat-sysstat)
[![Build Status](https://travis-ci.org/sysstat/sysstat.svg?branch=master)](https://travis-ci.org/sysstat/sysstat)
[![Donate](https://img.shields.io/badge/Donate-PayPal-blue.svg)](https://www.paypal.com/cgi-bin/webscr?cmd=_s-xclick&hosted_button_id=45U6F9R73ESFQ)

(C) 1999-2023 Sebastien GODARD (sysstat (at) orange (dot) fr)

### Introduction

The sysstat package contains various utilities, common to many commercial Unixes, to monitor system performance and usage activity:

* **iostat** reports CPU statistics and input/output statistics for block devices and partitions.
* **mpstat** reports individual or combined processor related statistics.
* **pidstat** reports statistics for Linux tasks (processes) : I/O, CPU, memory, etc.
* **tapestat** reports statistics for tape drives connected to the system.
* **cifsiostat** reports CIFS statistics.

Sysstat also contains tools you can schedule via cron or systemd to collect and historize performance and activity data:

* **sar** collects, reports and saves system activity information (see below a list of metrics collected by sar).
* **sadc** is the system activity data collector, used as a backend for sar.
* **sa1** collects and stores binary data in the system activity daily data file. It is a front end to sadc designed to be run from cron or systemd.
* **sa2** writes a summarized daily activity report. It is a front end to sar designed to be run from cron or systemd.
* **sadf** displays data collected by sar in multiple formats (CSV, XML, JSON, etc.) and can be used for data exchange with other programs. This command can also be used to draw graphs for the various activities collected by sar using SVG (Scalable Vector Graphics) format.

Default sampling interval is 10 minutes but this can be changed of course (it can be as small as 1 second).

#### System statistics collected by sar:
- Input / Output and transfer rate statistics (global, per device, per partition and per network filesystem)
- CPU statistics (global and per CPU), including support for virtualization architectures
- Memory, hugepages and swap space utilization statistics
- Virtual memory, paging and fault statistics
- Process creation activity
- Interrupt statistics (global, per CPU and per interrupt, including potential APIC interrupt sources, hardware and software interrupts)
- Extensive network statistics: network interface activity (number of packets and kB received and transmitted per second, etc.) including failures from network devices; network traffic statistics for IP, TCP, ICMP and UDP protocols based on SNMPv2 standards; support for IPv6-related protocols
- Fibre Channel traffic statistics
- Software-based network processing (softnet) statistics
- NFS server and client activity
- Sockets statistics
- Run queue and system load statistics
- Kernel internal tables utilization statistics
- Swapping statistics
- TTY devices activity
- Power management statistics (instantaneous and average CPU clock frequency, fans speed, devices temperature, voltage inputs)
- USB devices plugged into the system
- Filesystems utilization (inodes and blocks)
- Pressure-Stall Information statistics

#### Sysstat key features:
- Display average statistics values at the end of the reports.
- On-the-fly detection of new devices (disks, network interfaces, etc.) that are created or registered dynamically.
- Support for UP and SMP machines, including machines with hyperthreaded or multi-core processors.
- Support for hotplug CPUs (it detects automagically processors that are disabled or enabled on the fly) and tickless CPUs.
- Works on many different architectures, whether 32- or 64-bit.
- Needs very little CPU time to run (written in C).
- System statistics collected by sar/sadc can be saved in a file for future inspection. You can configure the length of data history to keep. There is no limit for this history length but the available space on your storage device.
- System statistics collected by sar/sadc can be exported in various different formats (CSV, XML, JSON, SVG, etc.). DTD and XML Schema documents are included in sysstat package. JSON output format is also available for mpstat and iostat commands.
- iostat can display statistics for devices managed by drivers in userspace like spdk.
- Smart color output for easier statistics reading.

![Smart color output](images/color_output.png)
- Internationalization support (sysstat has been translated into numerous different languages). Sysstat is now part of the [Translation Project](http://translationproject.org/).
- Sysstat commands can automatically select the unit used to display sizes for easier reading (see option `--human`):

![Sample iostat output](images/iostat.png)

- Graphs can be generated (SVG format - Scalable Vector Graphics) and displayed in your favorite web browser. See some sample screenshots below:

![Fancy sysstat graph](images/cpugraph.jpg)

![Fancy sysstat graph](images/tcgraph.png)

![Fancy sysstat graph](images/loadavg-svg.png)


Sysstat is Open Source / Free Software, and is freely available under the GNU General Public License, version 2.
The latest version of sysstat can always be found on my web site at:

[http://pagesperso-orange.fr/sebastien.godard/](http://pagesperso-orange.fr/sebastien.godard/)

See the CHANGES file to know the new features/improvements/bug fixes added
in this release of sysstat.
Sysstat development can be tracked on [GitHub](https://github.com/sysstat/sysstat).

### Installation

#### Install from RHEL/Fedora/CentOS

Enter:

```
$ sudo yum install sysstat
```

CentOS and Fedora systems call the collector process using a cron job in /etc/cron.d and it's enabled by default.
On recent versions, systemd is used instead of cron. You may need to enable and start the sysstat service:

```
$ sudo systemctl enable --now sysstat
```

(or enter:

```
$ sudo systemctl enable sysstat
$ sudo systemctl start sysstat
```

if option `--now` is not supported by your systemd version.)

#### Install from Ubuntu

Enter:

```
$ sudo apt-get install sysstat
```

Then enable data collecting:

```
$ sudo vi /etc/default/sysstat
change ENABLED=""false"" to ENABLED=""true""
save the file
```

Last, restart the sysstat service:

```
$ sudo service sysstat restart
```

#### Install from sources

Clone sysstat public repository with:

```
$ git clone git://github.com/sysstat/sysstat
```

Then configure sysstat for your system:

```
$ cd sysstat
$ ./configure
```

You can set several variables and parameters on the command line. For example you
can enter the following option to activate data collecting (either using cron or systemd):

```
$ ./configure --enable-install-cron
```

Enter `./configure --help` to display all possible options.
Note: There is another way to configure sysstat instead of entering `./configure`:
This is the **Interactive Configuration script** (_iconfig_) which will ask you
for the value of the main sysstat variables and parameters.
Enter `./iconfig` then answer the questions or enter Return to accept
the (sane) default values. For yes/no questions, answer 'y' or 'n'
(without the quotes): It is case sensitive! You can also enter '?' to get
a help message that will explain the meaning of each variable or parameter.

Compile and install:

```
$ make
$ sudo make install
```

### Feedback welcome!

Please use the BUG_REPORT template file to report a bug: It contains important data
that should be provided for this.
Please also remember to read the FAQ that comes with sysstat or is available
from the Wiki page on GitHub.

Opening an issue or a pull request on GitHub is the preferred way to report a bug or submit a patch.
Patches and suggestions for improvements are always welcome!

### Support sysstat!

If you are reading this README file then you are probably about to use the sysstat tools
to help you monitor your system and maybe troubleshoot some performance issues. Good choice.
Sysstat is made for you. Moreover sysstat is free software and always will be.

Yet have you ever considered making a donation to sysstat, regardless of how much your
contribution is? This in turn would encourage me to keep up the work as good as it can be...
Oh, and it would certainly also help me explain to my wife why I spend so much time in front
of my computer instead of taking care of the household ;-)

Click on the ""Donate PayPal"" button above at the beginning of this file.
You can also make a donation [from my web page](http://pagesperso-orange.fr/sebastien.godard/).

Enjoy!

--

Sebastien GODARD - sysstat (at) orange (dot) fr

","Sysstat is a tool to monitor system performance and usage activity. It is part
of the Sysstat Project, a free and open-source software package for Unix
systems. It collects, reports and saves system activity information. It can be
used to draw graphs for the various activities collected by sar using SVG
(Scalable Vector Graphics) format. It also contains tools you can schedule via
cron or systemd to collect and historize performance and activity data. It has
been translated into numerous different languages and is available in various
languages."
1458,Redefined chart library built with React and D3,"# Recharts

[![storybook](https://raw.githubusercontent.com/storybooks/brand/master/badge/badge-storybook.svg)](https://master--63da8268a0da9970db6992aa.chromatic.com/)
[![Build Status](https://github.com/recharts/recharts/workflows/Node.js%20CI/badge.svg)](https://github.com/recharts/recharts/actions)
[![Coverage Status](https://coveralls.io/repos/recharts/recharts/badge.svg?branch=master&service=github)](https://coveralls.io/github/recharts/recharts?branch=master)
[![npm version](https://badge.fury.io/js/recharts.svg)](http://badge.fury.io/js/recharts)
[![npm downloads](https://img.shields.io/npm/dm/recharts.svg?style=flat-square)](https://www.npmjs.com/package/recharts)
[![MIT License](https://img.shields.io/badge/license-MIT-blue.svg?style=flat)](/LICENSE)

## Introduction

Recharts is a **Redefined** chart library built with [React](https://facebook.github.io/react/) and [D3](http://d3js.org).

The main purpose of this library is to help you to write charts in React applications without any pain. Main principles of Recharts are:

1. **Simply** deploy with React components.
2. **Native** SVG support, lightweight depending only on some D3 submodules.
3. **Declarative** components, components of charts are purely presentational.

Documentation at [recharts.org](https://recharts.org)

Please see [the wiki](https://github.com/recharts/recharts/wiki) for FAQ.

## Examples

```jsx
<LineChart
  width={400}
  height={400}
  data={data}
  margin={{ top: 5, right: 20, left: 10, bottom: 5 }}
>
  <XAxis dataKey=""name"" />
  <Tooltip />
  <CartesianGrid stroke=""#f5f5f5"" />
  <Line type=""monotone"" dataKey=""uv"" stroke=""#ff7300"" yAxisId={0} />
  <Line type=""monotone"" dataKey=""pv"" stroke=""#387908"" yAxisId={1} />
</LineChart>
```

All the components of Recharts are clearly separated. The lineChart is composed of x axis, tooltip, grid, and line items, and each of them is an independent React Component. The clear separation and composition of components is one of the principle Recharts follows.

## Installation

### npm

NPM is the easiest and fastest way to get started using Recharts. It is also the recommended installation method when building single-page applications (SPAs). It pairs nicely with a CommonJS module bundler such as Webpack.


```sh
# latest stable
$ npm install recharts
```

### umd

The UMD build is also available on unpkg.com:

```html
 <script src=""https://unpkg.com/react/umd/react.production.min.js""></script>
 <script src=""https://unpkg.com/react-dom/umd/react-dom.production.min.js""></script>
 <script src=""https://unpkg.com/recharts/umd/Recharts.min.js""></script>
```

Then you can find the library on `window.Recharts`.

### dev build

```sh
$ git clone https://github.com/recharts/recharts.git
$ cd recharts
$ npm install
$ npm run build
```

## Demo

To examine the demos in your local build, execute:

```sh
$ npm run[-script] demo
```

and then browse to http://localhost:3000.

## Storybook

We are in the process of unifying documentation and examples in storybook. To run it locally, execute

```sh
$ npm run[-script] storybook
```

and then browse to http://localhost:6006.

## Module Formats

- [babel-plugin-recharts](https://github.com/recharts/babel-plugin-recharts) A simple transform to cherry-pick Recharts modules so you don’t have to.

## License

[MIT](http://opensource.org/licenses/MIT)

Copyright (c) 2015-2022 Recharts Group.
","Recharts is a chart library built with [React] and [D3] The main purpose of this
library is to help you to write charts in React applications without any pain.
All the components of Recharts are clearly separated. The lineChart is composed
of x axis, grid, and line items, and each of them is an independent React
component. It pairs nicely with a CommonJS module bundler such as Webpack. It is
also the recommended installation method when building single-page applications
(SPAs)"
2213,A curated list of awesome embedded programming.,"# Awesome-Embedded

A curated list of awesome embedded resource.

Table of content

- [Awesome-Embedded](#awesome-embedded)
  - [Interview](#interview)
  - [Embedded Software Skill](#embedded-software-skill)
  - [Common](#common)
  - [MCU programming](#mcu-programming)
    - [Bare-metal programming (Don't need MCU)](#bare-metal-programming-dont-need-mcu)
    - [MSP430](#msp430)
    - [TM4C123](#tm4c123)
    - [MSP432](#msp432)
    - [STM32](#stm32)
    - [STM32F7](#stm32f7)
    - [STM8](#stm8)
    - [ESP8266](#esp8266)
  - [Raspberry](#raspberry)
  - [Beaglebone](#beaglebone)
  - [Linux Kernel and device driver development](#linux-kernel-and-device-driver-development)
  - [Assembly](#assembly)
  - [RTOS](#rtos)
  - [Automotive](#automotive)
  - [OS](#os)
  - [WindowCE](#windowce)
  - [Compiler](#compiler)
  - [Bootloader](#bootloader)
  - [Makefile](#makefile)
  - [Peripheral](#peripheral)
    - [Memory Protection Unit](#memory-protection-unit)
    - [USB](#usb)
  - [Others](#others)
  - [Embedded GUI Development](#embedded-gui-development)
  - [Machine Learning & AI on MCU](#machine-learning--ai-on-mcu)
  - [Utilities](#utilities)
  - [Tips & tricks](#tips--tricks)
- [Tech blogs](#tech-blogs)
  - [FAQ_Embedded](#faqembedded)
  - [Looking for more lists like this?](#looking-for-more-lists-like-this)
  - [BOOKs](#books)

## Interview

* [Questions which are frequently asked in an interview.](https://github.com/Embedded-Systems-Guide/interview-questions)
> On the way to be a full-stack embedded software engineer.

* [coding-interview-university](https://github.com/nhivp/coding-interview-university) - A complete computer science study plan to become a software engineer.

## Embedded Software Skill

* [Skills/Knowledge required to become a champion Embedded Software Developer.](https://github.com/Embedded-Systems-Guide/embedded-software-skills)
* [How to be low-level programmer](https://github.com/gurugio/lowlevelprogramming-university)
* [Programmer Competency Matrix](http://sijinjoseph.com/programmer-competency-matrix/)

## Common

* [Integer size in C on 32-bit and 64-bit system](https://usrmisc.wordpress.com/2012/12/27/integer-sizes-in-c-on-32-bit-and-64-bit-linux/)
* [TeraTerm - TTL command reference](http://ttssh2.osdn.jp/manual/en/macro/command/index.html)
* [TeraTerm Scripts](http://processors.wiki.ti.com/index.php/Teraterm_Scripts)
* [Linker Command File Primer](http://processors.wiki.ti.com/index.php/Linker_Command_File_Primer)
* [The C build process](https://blog.feabhas.com/2012/06/the-c-build-process/)
* [Building Bare-Metal ARM Systems with GNU](https://www.embedded.com/design/mcus-processors-and-socs/4026111/Building-Bare-Metal-ARM-Systems-with-GNU-Part-9)
* [ELF – Executable and Linkable Format](https://2wisebit.wordpress.com/2018/06/08/elf-executable-and-linkable-format/)
* [Toolchains](https://web.eecs.umich.edu/~prabal/teaching/resources/eecs373/toolchain-notes.pdf)
* [What is an application binary interface (ABI)?](https://stackoverflow.com/questions/2171177/what-is-an-application-binary-interface-abi)
* [ARM Cortex M4 Blink Example (Linker Script)](http://robotics.mcmanis.com/src/arm-blink/linker-script.html)
* [A Sample Linker Script](http://hertaville.com/a-sample-linker-script.html)
* [Linking and Loading](http://www.iecc.com/linker/linker01.html)
* [Embedded Software _ Getting started](http://www2.thu.edu.tw/~emtools/DOE_project/NCCU/embedded%20system/ESD_06_GettingStarted.pdf)
* [How to convert from an armlink scatter file to a GNU ld linker script](https://www.mayrhofer.eu.org/node/24)
* [Using the GNU Linker](https://www.math.utah.edu/docs/info/ld_3.html)

## MCU programming

### Bare-metal programming (Don't need MCU)

* [Simplest bare metal program for ARM](https://balau82.wordpress.com/2010/02/14/simplest-bare-metal-program-for-arm/) ([table of content](https://balau82.wordpress.com/arm-emulation/))

### MSP430

* [MSP430-GCC](http://www.simplyembedded.org/tutorials/setting-up-a-virtual-machine/)
* [CS4101: Introduction to Embedded Systems](http://www.cs.nthu.edu.tw/~king/courses/cs4101/2016/cs4101.html) -  The course is designed around labs, using TI MSP430 LaunchPad and Arduino Uno to discuss concepts such as basic I/O, timing and clocking, interupt handling, serial communication, embedded operating systems, synchronization, etc.
* [msp430-template](https://github.com/uctools/msp430-template) - A template for MSP430 firmware.
* [MSP430 reference](https://students.cs.byu.edu/~clement/cs224/references/my_references.php)

### TM4C123

* [EmbeddedSystems.Playground](https://github.com/glennlopez/EmbeddedSystems.Playground/wiki/Periodic-SysTick-Interrupts)
* [Macros in TivaWare](https://sites.google.com/site/luiselectronicprojects/tutorials/tiva-tutorials/direct-register-access-notes/macros-in-tivaware)
* [Analog to Digital Conversion, Data Acquisition and Control](http://users.ece.utexas.edu/~valvano/Volume1/E-Book/C14_ADCdataAcquisition.htm)
* [Embedded Systems - Shape The World](http://users.ece.utexas.edu/~valvano/Volume1/E-Book/)
* [HowTo: Develop on the TI Tiva LaunchPad using Linux](http://chrisrm.com/howto-develop-on-the-ti-tiva-launchpad-using-linux/)
* [Linux command line build system to generate binaries for TM4C123 (ARM Cortex M4)](https://github.com/pitankar/TM4C)
* [The complete tutorial for Stellaris LaunchPad development with GNU/Linux (I)](http://kernelhacks.blogspot.com/2012/11/the-complete-tutorial-for-stellaris.html)
* [Getting Started with the TI Stellaris LaunchPad on Linux](https://www.jann.cc/2012/12/11/getting_started_with_the_ti_stellaris_launchpad_on_linux.html)
* [Embedded Systems with TM4C123 @Valvano](http://users.ece.utexas.edu/~valvano/arm/)
* [Create FreeRTOS Demo Project using the GCC Compiler](http://shukra.cedt.iisc.ernet.in/edwiki/EmSys:Create_freertos_on_tm4c123_CCS_Project)
* [Serial bootloader on TM4C12x Microcontroller](http://www.ti.com/lit/an/spma074a/spma074a.pdf)
* [Tivaware bootloader](http://www.ti.com/lit/ug/spmu301d/spmu301d.pdf)
* [Diagnosing Common Development Problems and Tips & Info for TM4C Devices](http://e2e.ti.com/support/microcontrollers/tiva_arm/f/908/t/374640)
* [FreeRTOS-GCC-tm4c123glx](https://github.com/nhivp/FreeRTOS-GCC-tm4c123glx) - A port of FreeRTOS to the Texas Instruments Tiva TM4C123GLX Launchpad.
* [Stellaris_TM4C123G_GCC_Template](https://github.com/AndoniV/Stellaris_TM4C123G_GCC_Template) - Texas Instruments template project for the TM4C123 series using GNU toolchain.
* [tm4c-gcc](https://github.com/martinjaros/tm4c-gcc) - TM4C123 GCC project template.
* [tivaapps](https://github.com/alexeicolin/tivaapps) - Example hello-world apps for Texas Instruments TI-RTOS for Tiva C using a Linux host
* [Drivers and examples](https://github.com/Mohammed-AhmedAF/ARM/tree/master/tiva-c) - Drivers for internal peripherals and external modules for Tiva C, examples of FreeRTOS features under development/FreeRTOS

### MSP432

* [Real-Time Bluetooth Networks - UTAustinX](https://github.com/monpeco/real_time_bn) - Learn the design fundamentals of a real-time operating system (RTOS) and how to build a Bluetooth network in this hands-on project-based course.

### STM32

* [STM32 bootloader](http://ciesie.com/post/stm32_bootloader/)
* [Tests to program STM32 Nucleo in C with GCC ARM embedded toolchain and libopencm3](https://github.com/balau/nucleo_tests)
* [A demo project of FreeRTOS running on a STM32F4 Discovery board.](https://github.com/wangyeee/STM32F4-FreeRTOS)
* [DFU Bootloader for STM32 chips](https://github.com/devanlai/dapboot)
* [Customizable Bootloader for STM32 microcontrollers.](https://github.com/akospasztor/stm32-bootloader)
* [Lightweight USB device Stack for STM32 microcontrollers](https://github.com/dmitrystu/libusb_stm32)
* [STM32 programming with Embedded GNU Compiler](https://github.com/rowol/stm32_discovery_arm_gcc)
* [A tiny portable 3D graphics lib for micro controllers (Oled display)](https://github.com/avem-labs/ol3d)
* [Getting started with the STM32F4-Discovery board using the EmBitz IDE](https://github.com/RoanFourie/STM32F4-DISCO-EMBITZ-Blinky)
* [libopencm3 and FreeRTOS projects using the STM32F103C8T6 MCU](https://github.com/ve3wwg/stm32f103c8t6)
* [A template for builting STM23F0 ARM projects with GCC](https://github.com/szczys/stm32f0-discovery-basic-template)
* [Open source flash program for STM32 using the ST serial bootloader](https://sourceforge.net/projects/stm32flash/)
* [stm32-hid-bootloader](https://github.com/bootsector/stm32-hid-bootloader) - Driverless USB HID bootloader and flashing tool for STM32F10X devices
* [stm32l1xx-template](https://github.com/uctools/stm32l1xx-template) - A template for building firmware for the STM32L1xx.
* [STM32F103C8 Examples](https://github.com/avislab/STM32F103)
* [stm32f103](https://github.com/trebisky/stm32f103) - Bare metal programming on a generic STM32F103c8 board
* [stm32_samples](https://github.com/dwelch67/stm32_samples)
* [stm32f4de example code](https://github.com/dwelch67/stm32f4d)
* [stm32f4xx with Rust at the HAL](https://apollolabsblog.hashnode.dev/series/stm32f4-embedded-rust-hal) - A series of tutorials for building STM32F4xx applications with Rust.

### STM32F7
* [STM32F7 Series](https://www.st.com/en/microcontrollers/stm32f7-series.html?querycriteria=productId=SS1858)
* [STM32 eLinux](https://elinux.org/STM32)
* [STM32F7 os.mbed](https://os.mbed.com/platforms/ST-Discovery-F746NG/)

### STM8

* [stm8-bare-min](https://github.com/lujji/stm8-bare-min) - Tiny peripheral library for STM8S
* [stm8-bootloader](https://github.com/lujji/stm8-bootloader) - Serial bootloader for STM8S microcontrollers
* [stm8-multi-tasker](https://github.com/vsch/stm8-multi-tasker) - STM8-Multi-Tasker - Preemptive/Cooperative Round Robin Scheduler for STM8
* [Wolk STM8 stuff ](https://github.com/LonelyWolf/stm8)
* [STM8S001J3_tiny_board](https://github.com/HexRx/STM8S001J3_tiny_board) - A tiny dev board for STM8S001J3 MCU designed in KiCad.

### ESP8266

* [An open source bootloader for the ESP8266](https://github.com/raburton/rboot)
* [An esp8266 rom creation tool](https://github.com/raburton/esptool2)
* [Wi-FI ESP8266 learning journey](https://github.com/xuhongv/StudyInEsp8266)
* [Wi-FI ESP32 learning journey](https://github.com/xuhongv/StudyInEsp32)
* [Sming - ESP8266/ESP32 IoT Framework](https://github.com/SmingHub/Sming)


## Raspberry

* [Raspberry Pi Bare Metal](https://github.com/fordp2002/ArmCopro/wiki/Raspberry-Pi-Bare-Metal) & [related link](https://microeletroniki.wordpress.com/)
* [ChibiOS/RT on the Raspberry Pi](https://www.stevebate.net/chibios-rpi/GettingStarted.html)
* [Raspberry Pi ARM based bare metal examples](https://github.com/dwelch67/raspberrypi)
* [Bare metal Raspberry Pi 3 tutorials](https://github.com/bztsrc/raspi3-tutorial)
* [Open Projects: Raspberry, Beaglebone BSP](https://devel.rtems.org/wiki/Developer/OpenProjects)
* [A Real-Time Operating System on the Raspberry Pi](http://www.pebblebay.com/raspberry-pi-embedded/)
* [A port of FreeRTOS to the raspberry pi](https://github.com/jameswalmsley/RaspberryPi-FreeRTOS)
* [FreeRTOS Sucessfully Ported](https://www.raspberrypi.org/forums/viewtopic.php?f=72&t=22423)
* [Exploring AArch64 assembler - Raspberry](https://thinkingeek.com/2016/10/08/exploring-aarch64-assembler-chapter1/)
* [A bootloader for the Raspberry Pi using the ethernet device](https://github.com/Nvreformat/Etherboot)
* [Bare Metal Raspberry Pi](https://taylorpetrick.com/blog/post/bare-metal-pi-setup)
* [Bare Metal Programming in C](http://www.valvers.com/open-software/raspberry-pi/step01-bare-metal-programming-in-cpt1/)
* [Baking Pi – Operating Systems Development](https://www.cl.cam.ac.uk/projects/raspberrypi/tutorials/os/)
* [Search for 'Raspberry' topic on Github](https://github.com/topics/raspberry-pi-3?l=c)
* [elinux: Raspberry Pi Programming](https://elinux.org/Raspberry_Pi_Programming) or [elinux: RPi Hub](https://elinux.org/RPi_Hub)
* [Stanford CS104e - An Experimental Course on Operating Systems](https://web.stanford.edu/class/cs140e/)
* [Computer Systems](http://cs107e.github.io/)
* [Build a Debian-based ARM64 system for Raspberry Pi 3](https://github.com/UMRnInside/RPi-arm64)
* [Learning operating system development using Linux kernel and Raspberry Pi](https://github.com/s-matyukevich/raspberry-pi-os)
* [A port of FreeRTOS to the raspberry pi 2B. With USB+Ethernet+TCP/IP.](https://github.com/Forty-Tw0/RaspberryPi-FreeRTOS)
* [64-bit Tiano Core UEFI for the Raspberry Pi 3](https://github.com/andreiw/RaspberryPiPkg)
* [CXCORE-RaspberryPi3-ubuntu-18.04-aarch64](https://github.com/chainsx/ubuntu64-rpi#cxcore-raspberrypi3-ubuntu-1804-aarch64--)
* [Sample source: Baremetal source code for Raspberry](https://github.com/LdB-ECM/Raspberry-Pi)
* [Sample source: NarcOS - A bare metal ultralight kernel for Raspberry Pi 3](https://github.com/forkachild/NarcOS)
* [Sample source: FreeRTOS v9.0.0 port for Raspberry Pi 1](https://github.com/leodido99/RaspberryPi1-FreeRTOSv9.0.0)
* [Sample source: A bare-metal experiments with the RaspberryPi](https://github.com/majorviraj/my-os)
* [「BareMetalで遊ぶ Raspberry Pi」のプログラムです。](https://github.com/jitomesky/RPi_Micon_C85book)
* [UEFI for RaspberryPi2 and RaspberryPi3 based on Linaro EDK2](https://github.com/ms-iot/RPi-UEFI)
* [ARM-episodes](https://github.com/invictus1306/ARM-episodes) & [ARM exploitation for IoT](https://quequero.org/2017/07/arm-exploitation-iot-episode-1/)
* [ARM shellcode and exploit development - BSidesMunich 2018](https://github.com/invictus1306/Workshop-BSidesMunich2018)
* [64 bit Bare Metal Programming on RPI-3](https://archive.fosdem.org/2017/schedule/event/programming_rpi3/attachments/slides/1475/export/events/attachments/programming_rpi3/slides/1475/bare_metal_rpi3.pdf)
* [Raspberry Pi 3 Bare Metal](https://adamransom.github.io/posts/raspberry-pi-bare-metal-part-1.html)
* [Assembly code for Raspberry Pi](https://github.com/Alkesst/RPIAssembly)
* [A public Baremetal Raspberry Pi code](https://github.com/LdB-ECM/Raspberry-Pi)
* [Raspberry-Pi Bare Metal Tutorial](https://github.com/BrianSidebotham/arm-tutorial-rpi)
* [uCOS-II on Raspberry Pi](https://github.com/fmlab/ucos_RaspberryPi)
* [Porting uCOSII to the raspberry pi A+/B+/2B](https://github.com/mopplayer/uCOSII_RPi)
* [Bare-metal examples](https://github.com/mrvn/RaspberryPi-baremetal)
* [Bare-metal lab](https://github.com/tzuCarlos/RaspberryPi)
* [Exploring Raspberry Pi: Interfacing to the Real World with Embedded Linux {book}](https://www.wiley.com/en-us/Exploring+Raspberry+Pi%3A+Interfacing+to+the+Real+World+with+Embedded+Linux-p-9781119188681)
* [Exploring Raspberry Pi: Interfacing to the Real World with Embedded Linux {website}](http://exploringrpi.com/)

## Beaglebone

* [BeagleBone Black I2C References](https://datko.net/2013/11/03/bbb_i2c/)
* [Learning BeagleBone Python Programming](https://hub.packtpub.com/learning-beaglebone-python-programming/)
* [Simple implementation of an OS for the BeagleBoard C4 with ARMv7 A8 processor.](https://github.com/Oxydation/MinionOS)
* [Various projects that utilize low level hardware instructions to interface with leds, speaker output and joystick input.](https://github.com/travelln/beaglebone-projects)
* [Windows Embedded Compact BSP for TI's Beaglebone](https://github.com/dvescovi1/WECBeagleBone)
* [BBB-BareMetal](https://github.com/allexoll/BBB-BareMetal)- Works on the beaglebone black (bare metal)
* [Running a Baremetal Beaglebone Black](https://www.twosixlabs.com/running-a-baremetal-beaglebone-black-part-1/) & [Part 2](https://www.twosixlabs.com/running-a-baremetal-beaglebone-black-part-2/)
* [Bare Metal on the BeagleBone (Black and Green)](https://www.cs.sfu.ca/CourseCentral/433/bfraser/other/BareMetalGuide.pdf) & [link1](https://www.cs.sfu.ca/CourseCentral/433/bfraser/other/) + [Link2](https://www.cs.sfu.ca/CourseCentral/433/bfraser/weekly.html)
* [A tutorial on bare-metal [OS] development on the Texas Instruments BeagleBoard.](https://wiki.osdev.org/ARM_Beagleboard)
* [bare metal c project for beaglebone, ti sitara am335x](https://github.com/0xCA5A/kickstart/tree/master/beaglebone/bare_metal_hello_world)
* [Bare Metal Applications on OSD335x using U-Boot](https://octavosystems.com/app_notes/bare-metal-on-osd335x-using-u-boot/#_Toc382081430)
* [bbb-asm-demo](https://github.com/mvduin/bbb-asm-demo) - Extremely tiny baremetal application for BeagleBone Black
* [Beaglebone - Getting started with JTAG and CCS](https://beagleboard.org/static/beaglebone/latest/Docs/ccs-jtag-simple.htm)
* [BeagleBoardJTAG](https://elinux.org/BeagleBoardJTAG)
* [beaglebone_samples](https://github.com/dwelch67/beaglebone_samples)
* [FreeRTOS for BeagleBone Black](https://github.com/henfos/BBBFreeRTOS)

## Linux kernel and device driver development

* [Linux inside](https://github.com/0xAX/linux-insides) - A little bit about a linux kernel
* [Writing device drivers in Linux](http://freesoftwaremagazine.com/articles/drivers_linux/)
* [YOLINUX Tutorials](http://www.yolinux.com/TUTORIALS/)
* [Linux driver programming](https://sites.google.com/site/embedded247/ddcourse)
* [Free training materials and conference presentations](https://bootlin.com/docs/)
* [eBook: Linux Drivers](https://sysplay.github.io/books/LinuxDrivers/book/index.html) or [Slides: Linux Drivers](https://sysplay.in/index.php?pagefile=linux_drivers)
* [c-periphery](https://github.com/vsergeev/c-periphery) - A C library for peripheral I/O (GPIO, SPI, I2C, MMIO, Serial) in Linux.
* [OpenEmbedded](http://www.openembedded.org/wiki/Main_Page),
* [Linux driver practices ](https://github.com/starnight/DriverPractice)
* [Linux Kernel Exploitation](https://github.com/xairy/linux-kernel-exploitation) - A bunch of links related to Linux kernel exploitation
* [Linux Kernel Module Cheat](https://github.com/cirosantilli/linux-kernel-module-cheat)
* [Start linux kernel module development!](https://rayanfam.com/topics/start-linux-kernel-module-development/)
* [Minimal Linux Live](https://github.com/ivandavidov/minimal) - a tiny educational Linux distribution
* [low-level programming university #linux-kernel-and-device-driver](https://github.com/gurugio/lowlevelprogramming-university#linux-kernel-and-device-driver)

## Assembly

* [GCC-Inline-Assembly-HOWTO](https://www.ibiblio.org/gferg/ldp/GCC-Inline-Assembly-HOWTO.html)
* [Assembly programming](https://courses.cs.washington.edu/courses/cse351/17sp/lectures/CSE351-L07-asm-I_17sp-ink.pdf)

## RTOS

* [List of open source real-time operating systems](https://www.osrtos.com/)
* [ROS](http://www.ros.org/)
* [FreeRTOS](https://freertos.org/)
* [FreeRTOS - Explaination](http://www.aosabook.org/en/freertos.html)
* [FreeRTOS API Reference Documentation](http://web.ist.utl.pt/~ist11993/FRTOS-API/index.html)
* [How to Write a Small RTOS](https://larrylisky.com/2012/07/14/how-to-create-a-small-rtos/)
* [RTOS From Scrach](https://github.com/RTOS-From-Scratch)
* [mini-arm-os & qemu with a stm32](https://github.com/embedded2015/mini-arm-os) or [here](https://github.com/jserv/mini-arm-os) - Build a minimal multi-tasking OS kernel for ARM Cortex-M series from scratch
* [Writing a simple operating system from scratch](https://www.cs.bham.ac.uk/~exr/lectures/opsys/10_11/lectures/os-dev.pdf)
* [Free real-time operating system (RTOS) designed for deeply embedded applications](https://github.com/stateos/StateOS)
* [MPSoC FreeRTOS Development](http://www.wiki.xilinx.com/MPSoC+FreeRTOS+Development)
* [Atomthreads: Open Source RTOS](https://atomthreads.com/)
* [High performance motor control](https://github.com/madcowswe/ODrive)
* [MINIX3: Open source RTOS](http://www.minix3.org/)
* [30 Days make OS](https://github.com/yourtion/30dayMakeOS) --> [YOS](https://github.com/yourtion/YOS) @[Yannik](https://yannik520.github.io/)
* Community: [OSDEV.org](https://wiki.osdev.org/Main_Page), [reddit/osdev](https://www.reddit.com/r/osdev/)
* [Real-time System Group](https://www.cs.york.ac.uk/rts/)
* [object-oriented C++ RTOS for microcontrollers](https://github.com/DISTORTEC/distortos)
* [RT-Thread is an open source IoT operating system from China.](https://github.com/RT-Thread/rt-thread)
* [How to create an OS from scratch](https://github.com/cfenollosa/os-tutorial)
* [Sample Source: TetrOS is a small feature rich Tetris clone which is written in Assembly.](https://github.com/daniel-e/tetros)
* [Sample Source: RTOS for microcontrollers](https://github.com/jimtremblay/nOS)
* [Sample Source: A Powerful embedded RTOS for ARM Cortex M microcontrollers](https://github.com/StratifyLabs/StratifyOS)
* [Sample Source: An embedded operating system for ARM Cortex-M based microcontrollers](https://github.com/onkwon/yaos)
* [Sample Source: rnk is a RTOS targeting ARM architecture.](https://github.com/raphui/rnk)
* [Sample Source: RTOS-From-Scratch](https://github.com/RTOS-From-Scratch/RTOS-From-Scratch)
* [Sample Source: Embeded OS for PIC32MX270F256B](https://github.com/envzhu/kozos-pic)
* [How I ended up writing a new real-time kernel](https://dmitryfrank.com/articles/how_i_ended_up_writing_my_own_kernel)
* [Sample Source: TNeo - a well-formed and carefully tested preemptive real-time kernel for 16- and 32-bits MCUs](https://github.com/dimonomid/tneo)
* [yaos is an embedded operating system for Internet of Things(IoT) devices, specifically for a single-core processor without MMU virtualization.](https://github.com/onkwon/yaos)
* [RT-Thread for Raspberry Pi 2B ](https://github.com/BernardXiong/raspi2)
* [tock](https://github.com/tock/tock) - A secure embedded operating system for Cortex-M based microcontrollers.
* [AliOS-Things](https://github.com/alibaba/AliOS-Things) - AliOS Things released by Alibaba is an open-source implementation of operating system (OS) for Internet of Things (IoT).
* [CoRTOS](https://forum.43oh.com/topic/13151-cortos-an-open-source-minimalist-rtos/) & [CoRTOS Simple Cooperative RTOS](https://sourceforge.net/projects/cortos-simple/) - An open source minimalist RTOS.
* [µOS++ Reference](http://micro-os-plus.github.io/develop/references/)
* [TNKernel](http://www.tnkernel.com/index.html) - a compact and very fast real-time kernel for the embedded 32/16/8 bits microprocessors.
* [Femto OS](http://www.femtoos.org/news.html) - a very concise portable real time - preemptive operating system (RTOS) for embedded microcontrollers with minimal ram and flash, say 2KB .. 16KB flash and 128 .. 1024 bytes ram.

## Automotive

* [Sample Source: Trampoline is a static RTOS for small embedded systems.](https://github.com/TrampolineRTOS/trampoline) & [labs](http://www.irccyn.ec-nantes.fr/~bechenne/trampoline-labs/)
* [Sample source: An integration an example AUTOSAR project which every part in AUTOSAR (OS, RTE, BSW, MCAL) are collected from different open source.](https://github.com/leduynguyen/My_AUTOSAR_Project)
* [automotive software(OSEK & AUTOSAR) ](https://github.com/parai/as) - Because I am not powerful so I decided to develop tiny but smart part of automotive software based on open source, and create a general AUTOSAR & Automotive Software study environment.

## OS

* [ucLinux](http://www.uclinux.org/): The Embedded Linux/Microcontroller project is a port of Linux to systems without a Memory Management Unit (MMU).
* [Tizen](https://www.elinux.org/Tizen)
* [Bootstrap yourself to write an OS from scratch. A book for self-learner.](https://github.com/tuhdo/os01)
* [Kernel 101 – Let’s write a Kernel](https://arjunsreedharan.org/post/82710718100/kernel-101-lets-write-a-kernel)
* [The little book about OS development](https://littleosbook.github.io/)
* [TetrOS](https://github.com/daniel-e/tetros) - Tetris that fits into the boot sector.
* [Writing a Simple Operating System from Scratch](https://www.cs.bham.ac.uk/~exr/lectures/opsys/10_11/lectures/os-dev.pdf)
* [JamesM's kernel development tutorials](http://www.jamesmolloy.co.uk/tutorial_html/)
* [Bare Bones](https://wiki.osdev.org/Bare_Bones) - a simple kernel for 32-bit x86 and boot it.
* [Operating System Development Series](http://www.brokenthorn.com/Resources/OSDevIndex.html)
* [7 Steps to Writing a Simple Cooperative Scheduler](https://www.edn.com/7-steps-to-writing-a-simple-cooperative-scheduler/)
* [A simple OS kernel for research, teaching, and fun](https://github.com/dthain/basekernel)
* [Operating Systems C Term 2018](https://github.com/Mcdonoughd/CS3013)

## WindowCE

* [GuruCE Blog](https://guruce.com/blog)
* [Windows CE Base Team Blog](https://blogs.msdn.microsoft.com/ce_base/)
* [DevWinCE blog](http://devwince.blogspot.com/)
* [Windows Embedded Compact BSP for Raspberry Pi](https://archive.codeplex.com/?p=ceonpi)
* [Windows Embedded Board Support Package for BeagleBone](https://archive.codeplex.com/?p=beaglebonebsp)

## Compiler

* [ARM Compiler - armasm User Guide](https://static.docs.arm.com/dui0801/i/DUI0801I_armasm_user_guide.pdf)

## Bootloader

* [Writing a boot loader in Assembly and C](https://www.codeproject.com/Articles/664165/Writing-a-boot-loader-in-Assembly-and-C-Part)
* [Writing a Bootloader Part 3](http://3zanders.co.uk/2017/10/18/writing-a-bootloader3/)
* [A bootloader for ARM Cortex-M based microcontrollers](https://github.com/onkwon/yaboot)
* [ARMv7M ELF loader ](https://github.com/martinribelotta/elfloader)
* [Writing a Bootloader Part 1](http://3zanders.co.uk/2017/10/13/writing-a-bootloader/)
* [can-bootloader](https://github.com/cvra/can-bootloader) - The bootloader used to flash our CAN-connected boards
* [Bootloaders 101](https://www.embedded.com/design/prototyping-and-development/4410233/1/Bootloaders-101--making-your-embedded-design-future-proof)
* Understand boot process: [link1](https://www.beningo.com/understanding-the-microcontroller-boot-process/), [link2](https://www.beningo.com/understanding-the-microcontroller-boot-process/), [link3](https://www.eevblog.com/forum/microcontrollers/copy-data-from-rom-to-ram-and-execute/)
* Keywords: *hello world bootloader*, *writing a bootloader from scratch*, *how to write a bootloader in assembly*, ...

## Makefile

* [Managing projects with GNU Make](http://uploads.mitechie.com/books/Managing_Projects_with_GNU_Make_Third_Edition.pdf)
* [GCC and Make](https://www3.ntu.edu.sg/home/ehchua/programming/cpp/gcc_make.html)

## Peripheral

### Memory Protection Unit

* [Building Hardware Components for Memory Protection of Applications on a Tiny Processor](https://carrv.github.io/2017/papers/oh-mpu-carrv2017.pdf)
* [KeyStone Architecture: Memory Protection Unit (MPU)](http://www.ti.com/lit/ug/sprugw5a/sprugw5a.pdf)

### USB

* [tinyusb](https://github.com/hathach/tinyusb) - An open source USB stack for a variety of Embedded Systems.

## Others

* [A practical approach to Kalman filter and how to implement it](http://blog.tkjelectronics.dk/2012/09/a-practical-approach-to-kalman-filter-and-how-to-implement-it/)
* [Embedded System programming](http://www.5square.in/): Diving into Syllabus for investigation.
* [ELC 2018 Presentations](https://elinux.org/ELC_2018_Presentations)
* [ARM Edition](https://sparkylinux.org/wiki/doku.php/sparky_arm): Sparky ARM Edition is a Sparky version created for a single board mini computer RaspberryPi.
* [The gem5 Simulator](https://developer.arm.com/research/research-enablement/system-modeling) is a well-known sophisticated simulator used for computer system research at both architecture and micro-architecture levels. Main page is [here](http://gem5.org/Main_Page).
* [LineageOS Android Distribution](https://github.com/LineageOS)
* [The NoCAN platform](http://omzlo.com/articles/the-nocan-platform)
* [Realtime OS on Embedded Systems](http://socialledge.com/sjsu/index.php/Realtime_OS_on_Embedded_Systems)
* [These projects were produced in the five weeks of ECE 4760 each year.](https://people.ece.cornell.edu/land/courses/ece4760/FinalProjects/)
* [Advanced fault backtrace library for ARM Cortex-M series MCU](https://github.com/armink/CmBacktrace)
* [mcu-starter-projects](https://github.com/ataradov/mcu-starter-projects) - Simple starter projects for bare-metal MCU development.
* [DirtyJTAG](https://github.com/jeanthom/DirtyJTAG) - JTAG adapter firmware for STM32F1
* [Generic_MCU_Software_Infrastructure](https://github.com/GorgonMeducer/Generic_MCU_Software_Infrastructure) - Provide necessary software infrastructure, service, macros to support some high level abstruct concept or paradigm, such as OOPC, FSM, delegate (event-driven) and etc.
* [apollo](https://github.com/ApolloAuto/apollo) - An open autonomous driving platform.
* * [A Development Environment for ARM TrustZone with GlobalPlatform Support](https://www.eit.lth.se/sprapport.php?uid=793)

## Embedded GUI Development
* [Embedded Wizard](https://www.embedded-wizard.de/) - Sophisticated GUI for Your Embedded Platform
* [lvgl](https://littlevgl.com) - Graphics library to create an embedded GUI with easy-to-use graphical elements, beautiful visual effects and low memory footprint. It offers anti-aliasing, opacity, and animations using only one frame buffer.

## Machine Learning & AI on MCU
* [nnom](https://github.com/majianjia/nnom) - A higher-level Neural Network library for microcontrollers.
* [nn4mp](https://github.com/correlllab/nn4mp)
* [Embedded Learning Library (ELL)](https://github.com/Microsoft/ELL) - Microsoft's library to deploy intelligent machine-learned models onto resource constrained platforms and small single-board computers.
* [Qualcomm Neural Processing SDK for AI](https://developer.qualcomm.com/software/qualcomm-neural-processing-sdk) - Libraries to developers run NN models on Snapdragon mobile platforms taking advantage of the CPU, GPU and/or DSP.
* [CMSIS NN](https://arm-software.github.io/CMSIS_5/NN/html/index.html) - A collection of efficient neural network kernels developed to maximize the performance and minimize the memory footprint of neural networks on Cortex-M processor cores.
* [ARM Compute Library](https://developer.arm.com/technologies/compute-library) - Set of optimized functions for image processing, computer vision, and machine learning.
* [uTensor](https://github.com/uTensor/uTensor) - AI inference library based on mbed (an RTOS for ARM chipsets) and TensorFlow.
* [EmbededAI](https://github.com/boralt/EmbeddedAI) - A library that provides elements of AI to C++ applications.
* [kann](https://github.com/attractivechaos/kann) - A lightweight C library for artificial neural networks.
* [m2cgen](https://github.com/BayesWitnesses/m2cgen) - A CLI tool which allows to transpile trained classic ML models into a native code of various programming languages with zero dependencies including C.

## Utilities

* [lm4tools](https://github.com/utzig/lm4tools)
* [mspdebug](https://github.com/dlbeer/mspdebug) - Debugging tool for MSP430 MCUs
* [pycs](https://github.com/deadsy/pycs) - Python Based ARM CoreSight Debug and Trace Tools

## Tips & tricks

* [Awesome Cheat Sheets](https://github.com/mintisan/awesome-cheat-sheets/blob/master/README.md)
> Awesome Cheat Sheets for Developer Utility, like Git, Vim , Tmux, SublimeText, Markdown, Shell.

* [Vim Config for Reading Linux Kernel Source Code](https://github.com/mintisan/oh-my-vim)
* [GNU GDB Debugger Command Cheat Sheet](http://www.yolinux.com/TUTORIALS/GDB-Commands.html)

# Tech blogs

* [What a C programmer should know about memory](http://marek.vavrusa.com/memory/)
* [What Every Programmer Should Know About Memory](https://people.freebsd.org/~lstewart/articles/cpumemory.pdf)
* [What Every C Programmer Should Know About Undefined Behavior ](http://blog.llvm.org/2011/05/what-every-c-programmer-should-know.html) [part 2](http://blog.llvm.org/2011/05/what-every-c-programmer-should-know_14.html) [part 3](http://blog.llvm.org/2011/05/what-every-c-programmer-should-know_21.html)
* [A Guide to Undefined Behavior in C and C++](https://blog.regehr.org/archives/213)
* [Software Engineering Takeaways](https://blog.regehr.org/archives/1594)
* [Embedsys weekly newsletter](https://embedsysweekly.com/)

## FAQ_Embedded

* [Boot section is removed (gcc, ld, ar, as)](https://www.embeddedrelated.com/showthread/lpc2000/47841-1.php)
* [What are .axf files?](https://stackoverflow.com/questions/17761328/what-are-axf-files)

## Looking for more lists like this?

* [awesome-c](https://github.com/uhub/awesome-c) - A curated list of awesome C frameworks, libraries and software.
* [A curated list of project-based tutorials in C](https://github.com/rby90/Project-Based-Tutorials-in-C)
* [Curated list of project-based tutorials](https://github.com/tuvtran/project-based-learning)
* [Curated list of awesome lists](https://github.com/sindresorhus/awesome)
* [A curated list of awesome Raspberry Pi tools, projects, images and resources](https://github.com/thibmaek/awesome-raspberry-pi)
* [Curated List of Self-Drivi","A curated list of awesome embedded resource. A complete computer science study
plan to become a software engineer. Embedded software skills required to be a
champion Embedded Software Developer. The C-build process has been updated to
make it easier to use."
2271,"The fastai book, published as Jupyter Notebooks","[English](./README.md) / [Spanish](./README_es.md) / [Korean](./README_ko.md) / [Chinese](./README_zh.md) / [Bengali](./README_bn.md) / [Indonesian](./README_id.md) / [Italian](./README_it.md) / [Portuguese](./README_pt.md) / [Vietnamese](./README_vn.md)

# The fastai book

These notebooks cover an introduction to deep learning, [fastai](https://docs.fast.ai/), and [PyTorch](https://pytorch.org/). fastai is a layered API for deep learning; for more information, see [the fastai paper](https://www.mdpi.com/2078-2489/11/2/108). Everything in this repo is copyright Jeremy Howard and Sylvain Gugger, 2020 onwards. A selection of chapters is available to [read online here](https://fastai.github.io/fastbook2e/).

The notebooks in this repo are used for [a MOOC](https://course.fast.ai) and form the basis of [this book](https://www.amazon.com/Deep-Learning-Coders-fastai-PyTorch/dp/1492045527), which is currently available for purchase. It does not have the same GPL restrictions that are on this repository.

The code in the notebooks and python `.py` files is covered by the GPL v3 license; see the LICENSE file for details. The remainder (including all markdown cells in the notebooks and other prose) is not licensed for any redistribution or change of format or medium, other than making copies of the notebooks or forking this repo for your own private use. No commercial or broadcast use is allowed. We are making these materials freely available to help you learn deep learning, so please respect our copyright and these restrictions.

If you see someone hosting a copy of these materials somewhere else, please let them know that their actions are not allowed and may lead to legal action. Moreover, they would be hurting the community because we're not likely to release additional materials in this way if people ignore our copyright.

## Colab

Instead of cloning this repo and opening it on your machine, you can read and work with the notebooks using [Google Colab](https://research.google.com/colaboratory/). This is the recommended approach for folks who are just getting started -- there's no need to set up a Python development environment on your own machine, since you can just work directly in your web-browser.

You can open any chapter of the book in Colab by clicking on one of these links: [Introduction to Jupyter](https://colab.research.google.com/github/fastai/fastbook/blob/master/app_jupyter.ipynb) | [Chapter 1, Intro](https://colab.research.google.com/github/fastai/fastbook/blob/master/01_intro.ipynb) | [Chapter 2, Production](https://colab.research.google.com/github/fastai/fastbook/blob/master/02_production.ipynb) | [Chapter 3, Ethics](https://colab.research.google.com/github/fastai/fastbook/blob/master/03_ethics.ipynb) | [Chapter 4, MNIST Basics](https://colab.research.google.com/github/fastai/fastbook/blob/master/04_mnist_basics.ipynb) | [Chapter 5, Pet Breeds](https://colab.research.google.com/github/fastai/fastbook/blob/master/05_pet_breeds.ipynb) | [Chapter 6, Multi-Category](https://colab.research.google.com/github/fastai/fastbook/blob/master/06_multicat.ipynb) | [Chapter 7, Sizing and TTA](https://colab.research.google.com/github/fastai/fastbook/blob/master/07_sizing_and_tta.ipynb) | [Chapter 8, Collab](https://colab.research.google.com/github/fastai/fastbook/blob/master/08_collab.ipynb) | [Chapter 9, Tabular](https://colab.research.google.com/github/fastai/fastbook/blob/master/09_tabular.ipynb) | [Chapter 10, NLP](https://colab.research.google.com/github/fastai/fastbook/blob/master/10_nlp.ipynb) | [Chapter 11, Mid-Level API](https://colab.research.google.com/github/fastai/fastbook/blob/master/11_midlevel_data.ipynb) | [Chapter 12, NLP Deep-Dive](https://colab.research.google.com/github/fastai/fastbook/blob/master/12_nlp_dive.ipynb) | [Chapter 13, Convolutions](https://colab.research.google.com/github/fastai/fastbook/blob/master/13_convolutions.ipynb) | [Chapter 14, Resnet](https://colab.research.google.com/github/fastai/fastbook/blob/master/14_resnet.ipynb) | [Chapter 15, Arch Details](https://colab.research.google.com/github/fastai/fastbook/blob/master/15_arch_details.ipynb) | [Chapter 16, Optimizers and Callbacks](https://colab.research.google.com/github/fastai/fastbook/blob/master/16_accel_sgd.ipynb) | [Chapter 17, Foundations](https://colab.research.google.com/github/fastai/fastbook/blob/master/17_foundations.ipynb) | [Chapter 18, GradCAM](https://colab.research.google.com/github/fastai/fastbook/blob/master/18_CAM.ipynb) | [Chapter 19, Learner](https://colab.research.google.com/github/fastai/fastbook/blob/master/19_learner.ipynb) | [Chapter 20, conclusion](https://colab.research.google.com/github/fastai/fastbook/blob/master/20_conclusion.ipynb)


## Contributions

If you make any pull requests to this repo, then you are assigning copyright of that work to Jeremy Howard and Sylvain Gugger. (Additionally, if you are making small edits to spelling or text, please specify the name of the file and a very brief description of what you're fixing. It's difficult for reviewers to know which corrections have already been made. Thank you.)

## Citations

If you wish to cite the book, you may use the following:

```
@book{howard2020deep,
title={Deep Learning for Coders with Fastai and Pytorch: AI Applications Without a PhD},
author={Howard, J. and Gugger, S.},
isbn={9781492045526},
url={https://books.google.no/books?id=xd6LxgEACAAJ},
year={2020},
publisher={O'Reilly Media, Incorporated}
}
```

","The fastai book covers an introduction to deep learning. The code in the
notebooks and python `.py` files is covered by the GPL v3 license; see the
LICENSE file for details. Everything in this repo is copyright Jeremy Howard and
Sylvain Gugger, 2020 onwards. No commercial or broadcast use is allowed."
11,Vim-fork focused on extensibility and usability,"<h1 align=""center"">
  <img src=""https://raw.githubusercontent.com/neovim/neovim.github.io/master/logos/neovim-logo-300x87.png"" alt=""Neovim"">

  <a href=""https://neovim.io/doc/"">Documentation</a> |
  <a href=""https://app.element.io/#/room/#neovim:matrix.org"">Chat</a>
</h1>

[![GitHub CI](https://github.com/neovim/neovim/actions/workflows/ci.yml/badge.svg?event=push&branch=master)](https://github.com/neovim/neovim/actions?query=workflow%3ACI+branch%3Amaster+event%3Apush)
[![Coverity Scan analysis](https://scan.coverity.com/projects/2227/badge.svg)](https://scan.coverity.com/projects/2227)
[![Clang analysis](https://neovim.io/doc/reports/clang/badge.svg)](https://neovim.io/doc/reports/clang)
[![PVS-Studio analysis](https://neovim.io/doc/reports/pvs/badge.svg)](https://neovim.io/doc/reports/pvs/PVS-studio.html.d)
[![Packages](https://repology.org/badge/tiny-repos/neovim.svg)](https://repology.org/metapackage/neovim)
[![Debian CI](https://badges.debian.net/badges/debian/testing/neovim/version.svg)](https://buildd.debian.org/neovim)
[![Downloads](https://img.shields.io/github/downloads/neovim/neovim/total.svg?maxAge=2592001)](https://github.com/neovim/neovim/releases/)

Neovim is a project that seeks to aggressively refactor [Vim](https://www.vim.org/) in order to:

- Simplify maintenance and encourage [contributions](CONTRIBUTING.md)
- Split the work between multiple developers
- Enable [advanced UIs] without modifications to the core
- Maximize [extensibility](https://github.com/neovim/neovim/wiki/Plugin-UI-architecture)

See the [Introduction](https://github.com/neovim/neovim/wiki/Introduction) wiki page and [Roadmap]
for more information.

Features
--------

- Modern [GUIs](https://github.com/neovim/neovim/wiki/Related-projects#gui)
- [API access](https://github.com/neovim/neovim/wiki/Related-projects#api-clients)
  from any language including C/C++, C#, Clojure, D, Elixir, Go, Haskell, Java/Kotlin,
  JavaScript/Node.js, Julia, Lisp, Lua, Perl, Python, Racket, Ruby, Rust
- Embedded, scriptable [terminal emulator](https://neovim.io/doc/user/nvim_terminal_emulator.html)
- Asynchronous [job control](https://github.com/neovim/neovim/pull/2247)
- [Shared data (shada)](https://github.com/neovim/neovim/pull/2506) among multiple editor instances
- [XDG base directories](https://github.com/neovim/neovim/pull/3470) support
- Compatible with most Vim plugins, including Ruby and Python plugins

See [`:help nvim-features`][nvim-features] for the full list, and [`:help news`][nvim-news] for noteworthy changes in the latest version!

Install from package
--------------------

Pre-built packages for Windows, macOS, and Linux are found on the
[Releases](https://github.com/neovim/neovim/releases/) page.

[Managed packages] are in [Homebrew], [Debian], [Ubuntu], [Fedora], [Arch Linux], [Void Linux], [Gentoo], and more!

Install from source
-------------------

See the [Building Neovim](https://github.com/neovim/neovim/wiki/Building-Neovim) wiki page and [supported platforms](https://neovim.io/doc/user/support.html#supported-platforms) for details.

The build is CMake-based, but a Makefile is provided as a convenience.
After installing the dependencies, run the following command.

    make CMAKE_BUILD_TYPE=RelWithDebInfo
    sudo make install

To install to a non-default location:

    make CMAKE_BUILD_TYPE=RelWithDebInfo CMAKE_INSTALL_PREFIX=/full/path/
    make install

CMake hints for inspecting the build:

- `cmake --build build --target help` lists all build targets.
- `build/CMakeCache.txt` (or `cmake -LAH build/`) contains the resolved values of all CMake variables.
- `build/compile_commands.json` shows the full compiler invocations for each translation unit.

Transitioning from Vim
--------------------

See [`:help nvim-from-vim`](https://neovim.io/doc/user/nvim.html#nvim-from-vim) for instructions.

Project layout
--------------

    ├─ ci/              build automation
    ├─ cmake/           CMake utils
    ├─ cmake.config/    CMake defines
    ├─ cmake.deps/      subproject to fetch and build dependencies (optional)
    ├─ runtime/         plugins and docs
    ├─ src/nvim/        application source code (see src/nvim/README.md)
    │  ├─ api/          API subsystem
    │  ├─ eval/         VimL subsystem
    │  ├─ event/        event-loop subsystem
    │  ├─ generators/   code generation (pre-compilation)
    │  ├─ lib/          generic data structures
    │  ├─ lua/          Lua subsystem
    │  ├─ msgpack_rpc/  RPC subsystem
    │  ├─ os/           low-level platform code
    │  └─ tui/          built-in UI
    └─ test/            tests (see test/README.md)

License
-------

Neovim contributions since [b17d96][license-commit] are licensed under the
Apache 2.0 license, except for contributions copied from Vim (identified by the
`vim-patch` token). See LICENSE for details.

    Vim is Charityware.  You can use and copy it as much as you like, but you are
    encouraged to make a donation for needy children in Uganda.  Please see the
    kcc section of the vim docs or visit the ICCF web site, available at these URLs:

            https://iccf-holland.org/
            https://www.vim.org/iccf/
            https://www.iccf.nl/

    You can also sponsor the development of Vim.  Vim sponsors can vote for
    features.  The money goes to Uganda anyway.

[license-commit]: https://github.com/neovim/neovim/commit/b17d9691a24099c9210289f16afb1a498a89d803
[nvim-features]: https://neovim.io/doc/user/vim_diff.html#nvim-features
[nvim-news]: https://neovim.io/doc/user/news.html
[Roadmap]: https://neovim.io/roadmap/
[advanced UIs]: https://github.com/neovim/neovim/wiki/Related-projects#gui
[Managed packages]: https://github.com/neovim/neovim/wiki/Installing-Neovim#install-from-package
[Debian]: https://packages.debian.org/testing/neovim
[Ubuntu]: https://packages.ubuntu.com/search?keywords=neovim
[Fedora]: https://packages.fedoraproject.org/pkgs/neovim/neovim/
[Arch Linux]: https://www.archlinux.org/packages/?q=neovim
[Void Linux]: https://voidlinux.org/packages/?arch=x86_64&q=neovim
[Gentoo]: https://packages.gentoo.org/packages/app-editors/neovim
[Homebrew]: https://formulae.brew.sh/formula/neovim

<!-- vim: set tw=80: -->
","Neovim is a project that seeks to aggressively refactor [Vim] in order to:
Simplify maintenance and encourage [contributions]: Split the work between
multiple developers. Enable [advanced UIs] without modifications to the core.
Maximize [extensibility] among multiple editor instances."
1892,"Berty is a secure peer-to-peer messaging app that works with or without internet access, cellular data or trust in the network","<h1 align=""center"">
  <img src=""https://berty.tech/img/berty.svg"" alt=""Berty"" title=""Berty"" height=""300px"" />
</h1>

<h3 align=""center""> Berty is an open, secure, offline-first, peer-to-peer and zero trust messaging app </h3>

<p align=""center"">
    <a href=""https://berty.tech""><img alt=""berty.tech"" src=""https://img.shields.io/badge/berty.tech-2845a7?logo=internet-explorer&style=flat"" /></a>
    <a href=""https://crpt.fyi/berty-discord""><img alt=""discord"" src=""https://img.shields.io/badge/discord-gray?logo=discord"" /></a>
    <a href=""https://github.com/berty""><img alt=""github"" src=""https://img.shields.io/badge/@berty-471961?logo=github"" /></a>
    <a href=""https://twitter.com/berty""><img alt=""twitter"" src=""https://img.shields.io/twitter/follow/berty?label=%40berty&style=flat&logo=twitter"" /></a>
</p>
<p align=""center"">
    <a href=""https://github.com/berty/berty/actions?query=workflow%3AJS""><img src=""https://github.com/berty/berty/workflows/JS/badge.svg"" /></a>
    <a href=""https://github.com/berty/berty/actions?query=workflow%3AGo""><img src=""https://github.com/berty/berty/workflows/Go/badge.svg"" /></a>
    <a href=""https://github.com/berty/berty/actions?query=workflow%3AProtobuf""><img src=""https://github.com/berty/berty/workflows/Protobuf/badge.svg"" /></a>
    <a href=""https://github.com/berty/berty/actions?query=workflow%3ARelease""><img src=""https://github.com/berty/berty/workflows/Release/badge.svg"" /></a>
    <a href=""https://github.com/berty/berty/actions?query=workflow%3AAndroid""><img src=""https://github.com/berty/berty/workflows/Android/badge.svg"" /></a>
    <a href=""https://github.com/berty/berty/actions?query=workflow%3AiOS""><img src=""https://github.com/berty/berty/workflows/iOS/badge.svg"" /></a>
    <a href=""https://github.com/berty/berty/actions?query=workflow%3AIntegration""><img src=""https://github.com/berty/berty/workflows/Integration/badge.svg"" /></a>
</p>
<p align=""center"">
  <a href=""https://pkg.go.dev/berty.tech/berty/v2/go?tab=subdirectories""><img alt=""GoDoc"" src=""https://img.shields.io/badge/go.dev-reference-007d9c?logo=go&logoColor=white"" /></a>
  <a title=""Crowdin"" href=""https://translate.berty.community""><img src=""https://badges.crowdin.net/e/a4cb8d931040fbe4a794322b86de6721/localized.svg""></a>
  <a href=""https://github.com/berty/berty/releases""><img alt=""GitHub release"" src=""https://img.shields.io/github/v/release/berty/berty"" /></a>
  <a href=""https://www.codefactor.io/repository/github/berty/berty""><img src=""https://www.codefactor.io/repository/github/berty/berty/badge?s=bf5885a3b2782ead81d91cd423915f2e9ddc9196"" alt=""CodeFactor"" /></a>
  <!--<a href=""https://goreportcard.com/report/berty/berty""><img src=""https://goreportcard.com/badge/berty/berty"" alt=""Go Report Card""></a>-->
  <!--<a href=""https://bump.sh/doc/berty-messenger""/><img src=""https://img.shields.io/badge/bump.sh-messenger%20api-black"" /></a>-->
  <!--<a href=""https://bump.sh/doc/berty-protocol""/><img src=""https://img.shields.io/badge/bump.sh-protocol%20api-black"" /></a>-->
</p>

---

## TLDR : Install it!

### Mobile

To use the latest released version, install it from [Google Play](https://play.google.com/store/apps/details?id=tech.berty.android)
or [Apple App Store](https://apps.apple.com/tt/app/berty/id1535500412).

To compile and run the mobile application on your device, see [js/README.md](js/README.md).

### CLI

You can `go run` or `go install` the CLI tool located in `go/cmd/berty`.
The two main command line utilities are:

- `berty mini`: a CLI messaging app using the Berty Protocol.
- `berty daemon`: a full node manageable through the Berty Protocol API.

## Introduction

> **Warning**: Berty is still under active development and should not yet be used to exchange sensitive data.

**[Berty](https://berty.tech/)** is a privacy-first messaging application built on top of [the Berty Protocol](https://berty.tech/docs/protocol/).

- *Secure and private* :
    - Messages are end-to-end encrypted by default
    - Metadata is kept to a minimum
    - No phone number or email address is required to create an account
    - Built to retain its properties even when used on adversarial networks
- *Censorship-resilient*
    - Decentralized, distributed, peer-to-peer and serverless
    - No internet connection is required, thanks to [BLE technology](https://en.wikipedia.org/wiki/Bluetooth_Low_Energy) and [mDNS](https://en.wikipedia.org/wiki/Multicast_DNS).
- *Open* :
    - Free forever and open-source

**Berty** is designed to be used as an everyday messaging application. Nonetheless, it was built to primarily serve the following use cases:

- When you need to share sensitive information over untrusted networks, for instance while traveling
- If you want to communicate anonymously
- If you want full control over your data and thus don't want to rely on third-party servers
- In countries that actively monitor and temper with their network, restricting its use and censoring some of its contents
- In areas with weak or no connection at all

Berty is currently developed by **[Berty Technologies](https://berty.tech/about)**, a French nonprofit organization.

**Note: this project is led by a small team made of humans, who make mistakes. Please do not hesitate to point out bugs or missing features.** _See the [contribute section](#contribute) below._

> We cannot promise we will offer you the best application, but we dedicate ourselves to doing our best to create a great one.

### The philosophy behind Berty

We want to contribute to a world where free and secure communications are common and fear of censorship or surveillance are not.

We believe that open-source is more secure, as anyone can examine the code and improve it: this is why we rely on and build open and free software.

As the founding team, our ultimate goal is to progressively relinquish control over Berty and to make it become a truly global community project.

More info on [berty/community](https://github.com/berty/community).

## Development Status

The current Berty implementation is using the [Berty Protocol](https://berty.tech/docs/protocol/), which means the encryption technique is safe, and it works as a peer-to-peer app!

Alas, Berty has not yet been hardened, so please avoid using it on devices with weak sandboxes, such as unpatchable devices that use old Android versions.

The current Berty Protocol is _partially implemented_.

The API will continue to evolve in the near future. As such, we cannot yet guarantee none-breaking changes, or any kind of API stability. Be prepared for a rough ride if you start rolling the Berty Protocol in your application.

_We will have an open beta for the different packages and applications soon, so anyone will be able to give it a try. [Subscribe](https://tech.us20.list-manage.com/subscribe/post?u=5ca3993c7f0b8f646dcda714b&id=4d7828715b) to our newsletter if you wish to be notified._

**Note: The repositories are being opened progressively, and there will be additional modifications and updates soon.**

## Under the hood

<!-- _TODO: add a high-level schema of how things are connected together_ -->

### Berty Protocol

[![go.dev reference](https://img.shields.io/badge/go.dev-reference-007d9c?logo=go&logoColor=white)](https://pkg.go.dev/berty.tech/berty/v2/go/pkg/bertyprotocol?tab=doc)
[![Code coverage](https://codecov.io/gh/berty/berty/branch/master/graph/badge.svg?token=rBPpNHNNow&flag=go.unittests)](https://codecov.io/gh/berty/berty)

The Berty Protocol comes with a generic, but full-featured SDK allowing developers to write peer-to-peer applications. You can just focus on high-level features for your app, we will take care of the rest (encryption, identities, network routing, group management, account management, device management, application lifecycle).

The main concept of the _Berty Protocol_ is called the ""group"", a virtual place where multiple devices can share messages and metadata using [OrbitDB](https://github.com/orbitdb), which itself relies on the InterPlanetary File System ([IPFS](https://en.wikipedia.org/wiki/InterPlanetary_File_System))

<!-- _TODO: add usage examples_ -->

Get it:

```
git clone https://github.com/berty/berty
```

### The Berty Messenger

[![Code coverage](https://codecov.io/gh/berty/berty/branch/master/graph/badge.svg?token=rBPpNHNNow&flag=js.unittests)](https://codecov.io/gh/berty/berty)

The Berty Messenger, or simply Berty, is a messaging application written in [React Native](https://reactnative.dev/), that uses the Berty Protocol through [gomobile-ipfs](https://github.com/ipfs-shipyard/gomobile-ipfs), which, in turns, is using [gomobile](https://github.com/golang/mobile).

## Main items in the repo

- [./go](go): Where all the Golang code lies.
  - [./go/pkg/**bertyprotocol**](go/pkg/bertyprotocol): **Berty Protocol** _Golang SDK_ to create secure and autonomous groups using _IPFS_.
  - [./go/framework/bertybridge](go/framework/bertybridge): The gomobile entrypoint.
  - [./go/cmd/**berty**](go/cmd/berty): The main **Berty CLI**:
    - `berty daemon`: Runs the whole Berty Protocol instance.
    - `berty mini`: Simple CLI messenger application using Berty Protocol.
  - [./go/cmd/**rdvp**](go/cmd/rdvp): A Rendez-Vous Point server.
  - [./go/cmd/**welcomebot**](go/cmd/welcomebot): An onboarding bot used during the early phase.
  - [./go/cmd/**testbot**](go/cmd/testbot): A bot used by integration tests and developers.
- [./js](js): Where all the Javascript/Typescript code lies:
  - The **Berty Messenger** application, written in React Native.
- [./docs](docs): Mostly auto-generated documentation.

## Contributing

![Contribute to Berty](https://assets.berty.tech/files/contribute-contribute_v2--Contribute-berty-ultra-light.gif)

We welcome contributions! Your input is deeply appreciated and extremely valuable to us. We thank you in advance for it.

There is no small feat: everyone is encouraged to do what they can to help, based on their ability and interest.

There are plenty of ways to get involved and to help our community, which can roughly be divided in two distinct parts: everything that is related to the code and everything that is not.

To put it simply:

- Code-related = GitHub
- Not code-related = Open a task

Everything about contribution is summed up here: [CONTRIBUTING.MD](https://github.com/berty/community/blob/master/CONTRIBUTING.md)

## Stargazers over time

[![Star History Chart](https://api.star-history.com/svg?repos=berty/berty&type=Date)](https://star-history.com/#berty/berty&Date)

## Other resources

- Official website: https://berty.tech
- Assets: https://assets.berty.tech/
- Application assets & mockups: https://assets.berty.tech/categories/app__v2.4/

## Contact

For a direct contact, see our [contact page](https://berty.tech/contact) of our website. Alternatively, take a look at our [community repository](https://github.com/berty/community/).

## Licensing

© 2018-2021 [Berty Technologies](https://berty.tech)

Licensed under the [Apache License, Version 2.0](https://www.apache.org/licenses/LICENSE-2.0) ([`LICENSE-APACHE`](LICENSE-APACHE)) or the [MIT license](https://opensource.org/licenses/MIT) ([`LICENSE-MIT`](LICENSE-MIT)), at your discretion. See the [`COPYRIGHT`](COPYRIGHT) file for more details.
","Berty is a privacy-first messaging application built on top of the Berty
Protocol. Messages are end-to-end encrypted by default, thanks to [BLE
technology] and [mDNS]. Berty is designed to be used as an everyday messaging
application. It was built to primarily serve the following use cases: When you
need to share sensitive information over untrusted networks, for instance while
traveling. If you want full control over your data and thus don't want to rely
on third-party servers. In countries that actively monitor and temper with their
network."
263,Hprose is a cross-language RPC. This project is Hprose for Golang.,"<p align=""center""><img src=""http://hprose.com/banner.@2x.png"" alt=""Hprose"" title=""Hprose"" width=""650"" height=""200"" /></p>

# Hprose 2.0 for Golang

[![Join the chat at https://gitter.im/hprose/hprose-golang](https://img.shields.io/badge/GITTER-join%20chat-green.svg)](https://gitter.im/hprose/hprose-golang?utm_source=badge&utm_medium=badge&utm_campaign=pr-badge&utm_content=badge)
[![Build Status](https://travis-ci.org/hprose/hprose-golang.svg?branch=master)](https://travis-ci.org/hprose/hprose-golang)
[![GoDoc](https://godoc.org/github.com/hprose/hprose-golang?status.svg&style=flat)](https://godoc.org/github.com/hprose/hprose-golang)
[![Go Report Card](https://goreportcard.com/badge/github.com/hprose/hprose-golang)](https://goreportcard.com/report/github.com/hprose/hprose-golang)
[![codebeat badge](https://img.shields.io/badge/codebeat-A-398b39.svg)](https://codebeat.co/projects/github-com-hprose-hprose-golang)
[![Coverage Status](https://coveralls.io/repos/github/hprose/hprose-golang/badge.svg?branch=master)](https://coveralls.io/github/hprose/hprose-golang?branch=master)
[![License](https://img.shields.io/github/license/hprose/hprose-golang.svg)](http://opensource.org/licenses/MIT)


[Hprose 2.0 for Golang 中文文档](https://github.com/hprose/hprose-golang/wiki) 

>---
- **[Introduction](#introduction)**
- **[Installation](#installation)**
- **[Usage](#usage)**
    - **[Http Server](#http-server)**
        - [Based on net/http](#based-on-nethttp)
        - [Based on fasthttp](#based-on-fasthttp)
        - [Based on gin](#based-on-gin)
        - [Based on echo](#based-on-echo)
        - [Based on beego](#based-on-beego)
        - [Based on iris](#based-on-iris)
    - **[Http Client](#http-client)**
        - [Synchronous Invoking](#synchronous-invoking)
        - [Asynchronous Invoking](#asynchronous-invoking)
        - [Passing by reference parameters](#passing-by-reference-parameters)
    - **[Custom Struct](#custom-struct)**
		- [Field Alias of Custom Struct](#field-alias-of-custom-struct)
    - **[Hprose Proxy](#hprose-proxy)**
    - **[Simple Mode](#simple-mode)**
    - **[WebSocket Server & Client](#websocket-server--client)**
        - [WebSocket Server](#websocket-server)
        - [WebSocket Client](#websocket-client)
    - **[Unix Socket Server & Client](#unix-socket-server--client)**
        - [Unix Socket Server](#unix-socket-server)
        - [Unix Socket Client](#unix-socket-client)
- **[Benchmark](#benchmark)**

>---

## Introduction

*Hprose* is a High Performance Remote Object Service Engine.

It is a modern, lightweight, cross-language, cross-platform, object-oriented, high performance, remote dynamic communication middleware. It is not only easy to use, but powerful. You just need a little time to learn, then you can use it to easily construct cross language cross platform distributed application system.

*Hprose* supports many programming languages, for example:

* AAuto Quicker
* ActionScript
* ASP
* C++
* Dart
* Delphi/Free Pascal
* dotNET(C#, Visual Basic...)
* Golang
* Java
* JavaScript
* Node.js
* Objective-C
* Perl
* PHP
* Python
* Ruby
* ...

Through *Hprose*, You can conveniently and efficiently intercommunicate between those programming languages.

This project is the implementation of Hprose 2.0 for Golang.

## Installation

```sh
go get -u -v github.com/hprose/hprose-golang
```

## Usage

### Http Server

#### Based on net/http

```go
package main

import (
	""net/http""

	""github.com/hprose/hprose-golang/rpc""
)

func hello(name string) string {
	return ""Hello "" + name + ""!""
}

func main() {
	service := rpc.NewHTTPService()
	service.AddFunction(""hello"", hello)
	http.ListenAndServe("":8080"", service)
}
```

#### Based on fasthttp

```go
package main

import (
	rpc ""github.com/hprose/hprose-golang/rpc/fasthttp""
	""github.com/valyala/fasthttp""
)

func hello(name string) string {
	return ""Hello "" + name + ""!""
}

func main() {
	service := rpc.NewFastHTTPService()
	service.AddFunction(""hello"", hello)
	fasthttp.ListenAndServe("":8080"", service.ServeFastHTTP)
}
```

#### Based on gin

```go
package main

import (
	""github.com/hprose/hprose-golang/rpc""
	""gopkg.in/gin-gonic/gin.v1""
)

func hello(name string) string {
	return ""Hello "" + name + ""!""
}

func main() {
	service := rpc.NewHTTPService()
	service.AddFunction(""hello"", hello)
	router := gin.Default()
	router.Any(""/path"", func(c *gin.Context) {
		service.ServeHTTP(c.Writer, c.Request)
	})
	router.Run("":8080"")
}
```

#### Based on echo

```go
package main

import (
	""github.com/hprose/hprose-golang/rpc""
	""github.com/labstack/echo""
)

func hello(name string) string {
	return ""Hello "" + name + ""!""
}

func main() {
	service := rpc.NewHTTPService()
	service.AddFunction(""hello"", hello)
	e := echo.New()
	e.Any(""/path"", echo.WrapHandler(service))
	e.Start("":8080"")
}
```

#### Based on beego

```go
package main

import (
	""github.com/astaxie/beego""
	""github.com/hprose/hprose-golang/rpc""
)

func hello(name string) string {
	return ""Hello "" + name + ""!""
}

func main() {
	service := rpc.NewHTTPService()
	service.AddFunction(""hello"", hello)
	beego.Handler(""/path"", service)
	beego.Run()
}
```

#### Based on iris

```go
package main

import (
	rpc ""github.com/hprose/hprose-golang/rpc/fasthttp""
	""github.com/kataras/iris""
)

func hello(name string) string {
	return ""Hello "" + name + ""!""
}

func main() {
	service := rpc.NewFastHTTPService()
	service.AddFunction(""hello"", hello)
	iris.Any(""/path"", func(c *iris.Context) {
		service.ServeFastHTTP(c.RequestCtx)
	})
	iris.Listen("":8080"")
}
```

### Http Client

#### Synchronous Invoking

```go
package main

import (
	""fmt""

	""github.com/hprose/hprose-golang/rpc""
)

type HelloService struct {
    Hello func(string) (string, error)
    Hello2 func(string) string `name:""hello""`
}

func main() {
	client := rpc.NewHTTPClient(""http://127.0.0.1:8080/"")
	var helloService *HelloService
	client.UseService(&helloService)
	fmt.Println(helloService.Hello(""world""))
	fmt.Println(helloService.Hello2(""world""))
}
```

Golang does not support function/method overload, but some other languages support. So hprose provides ""Function/Method Alias"" to invoke overloaded methods in other languages. You can also use it to invoke the same function/method with different names.

You just need define multiple func fields that correspond to the same remote method by the same `name` tag.

If an error (must be the last out parameter) returned by server-side function/method, or it panics in the server-side, the client will receive it. If the client func field defines an error out parameter (must be the last one), you can get the server-side error or panic from it. If the client func field has not defined an error out parameter, the client call will panic when receive the server-side error or panic.

#### Asynchronous Invoking

```go
package main

import (
	""fmt""
	""time""

	""github.com/hprose/hprose-golang/rpc""
)

type HelloService struct {
	Hello func(func(string, error), string)
	Hello2 func(func(string), string) `name:""hello""`
}

func main() {
	client := rpc.NewHTTPClient(""http://127.0.0.1:8080/"")
	var helloService *HelloService
	client.UseService(&helloService)
	helloService.Hello(func(result string, err error) {
		fmt.Println(result, err)
	}, ""async world"")
	helloService.Hello2(func(result string) {
		fmt.Println(result)
	}, ""async world"")
    time.Sleep(time.Second)
}
```

If the first in parameter is a callback function, you can invoke the remote method asynchronously.

The callback in parameters defines like the out parameters in synchronous invoking method. but if you omit the last error parameter, the asynchronous Invoking will NOT panic, the error will be ignore, too.

#### Passing by reference parameters

Hprose supports passing by reference parameters. The parameters must be pointer types and define func field with tag `byref:""true""`. For example:

```go
package main

import (
	""fmt""

	""github.com/hprose/hprose-golang/rpc""
)

func swap(a, b *int) {
	*b, *a = *a, *b
}

type SwapService struct {
	Swap func(a, b *int) error `byref:""true""`
}

func main() {
	server := rpc.NewTCPServer("""")
	server.AddFunction(""swap"", swap)
	server.Handle()
	client := rpc.NewClient(server.URI())
	var swapService *SwapService
	client.UseService(&swapService)
	a := 1
	b := 2
	swapService.Swap(&a, &b)
	fmt.Println(a, b)
	client.Close()
	server.Close()
}
```

You will find that hprose also supports TCP server and client in this example.

### Custom Struct

You can transfer custom struct objects between hprose client and hprose server directly. Using the `Register` method to register your custom struct is the the only thing you need to do.

For example:

```go
package main

import (
    ""fmt""
    ""github.com/hprose/hprose-golang/io""
    ""github.com/hprose/hprose-golang/rpc""
)

type TestUser struct {
    Name     string
    Sex      int
    Birthday time.Time
    Age      int
    Married  bool
}

type RemoteObject struct {
    GetUserList         func() []TestUser
}

func main() {
    io.Register(TestUser{}, ""User"")
    client := rpc.NewClient(""http://www.hprose.com/example/"")
    var ro *RemoteObject
    client.UseService(&ro)
    fmt.Println(ro.GetUserList())
}
```

The first argument of `Register` is an object or pointer of your custom struct. The second argument is the alias of your custom struct.

The real name of your custom struct can be different between the client and the server, as long as they registered the same alias.

The server of this example was written in PHP. In fact, You can use custom struct with golang server too.

#### Field Alias of Custom Struct

The first letter of the field name will be lowercased automatically when it is serialized by hprose. So we don't need to define a tag to implement this feature like JSON serialization when we interact with the other languages.

But it doesn't mean that hprose can't support to define field alias by tag. In fact, it can not only, and it can be compatible with the field alias definition in JSON serialization way. For example:

```go
type User struct {
	Name                         string `json:""n""`
	Age                          int    `json:""a""`
	ThisFieldWillNotBeSerialized string `json:""-""`
}

io.Register(User{}, ""User"", ""json"")
```

The struct above is defined for JSON serialization. But when we called `Register` by passing the third argument `""json""`, we can use the fields aliases defined in `json` tags for hprose serialization. If the field alias is `""-""`, it will be not serialized.

You can change the `json` tag to be anything else in the struct definition, such as `hprose`, as long as it is the same with the value of the `Register` third argument.

### Hprose Proxy

Hprose supports publishing a special method: MissingMethod. All methods not explicitly published will be redirected to the method. You can use it to implement an hprose proxy. And hprose provides an ResultMode options to improve performance of the proxy server. You can use it like this:

```go
package main

import (
	""net/http""
	""reflect""

	""github.com/hprose/hprose-golang/rpc""
)

type HproseProxy struct {
	client   rpc.Client
	settings rpc.InvokeSettings
}

func newHproseProxy() *HproseProxy {
	proxy := new(HproseProxy)
	proxy.client = rpc.NewClient(""http://www.hprose.com/example/"")
	proxy.settings = rpc.InvokeSettings{
		Mode:        rpc.Raw,
		ResultTypes: []reflect.Type{reflect.TypeOf(([]byte)(nil))},
	}
	return proxy
}

func (proxy *HproseProxy) Proxy(
	name string, args []reflect.Value, context rpc.Context) ([]reflect.Value, error) {
	return proxy.client.Invoke(name, args, &proxy.settings)
}

func main() {
	service := rpc.NewHTTPService()
	service.AddMissingMethod(newHproseProxy().Proxy, rpc.Options{Mode: rpc.Raw})
	http.ListenAndServe("":8080"", service)
}
```

You can also define func field with tag `mode` in client, and the return value must be `[]byte`. The server result mode option is setting by `Options` parameter.

The ResultMode have 4 values:

* Normal
* Serialized
* Raw
* RawWithEndTag

The `Normal` result mode is the default value.

In `Serialized` result mode, the returned value is an hprose serialized data in []byte, but the arguments and exception will be parsed to the normal value.

In `Raw` result mode, all the reply will be returned directly to the result in []byte, but the result data doesn't have the hprose `TagEnd`.

The `RawWithEndTag` is similar to the `Raw` result mode, but it has the hprose `TagEnd`.

With the ResultMode option, you can store, cache and forward the result in the original format.

### Simple Mode

By default, the data between the hprose client and server can be passed with internal references. if your data have no internal references, you can open the simple mode to improve performance.

```go
package main

import (
	""fmt""

	""github.com/hprose/hprose-golang/rpc""
)

func hello(name string) string {
	return ""Hello "" + name + ""!""
}

type HelloService struct {
	Hello func(string) (string, error) `simple:""true""`
}

func main() {
	server := rpc.NewTCPServer("""")
	server.AddFunction(""hello"", hello, rpc.Options{Simple: true})
	server.Handle()
	client := rpc.NewClient(server.URI())
	var helloService *HelloService
	client.UseService(&helloService)
	fmt.Println(helloService.Hello(""World""))
	client.Close()
	server.Close()
}
```

### WebSocket Server & Client

#### WebSocket Server

```go
package main

import (
	""net/http""
	""runtime""

	rpc ""github.com/hprose/hprose-golang/rpc/websocket""
)

func hello(name string) string {
	return ""Hello "" + name + ""!""
}

func main() {
	service := rpc.NewWebSocketService()
	service.AddFunction(""hello"", hello)
	http.ListenAndServe("":8080"", service)
}
```

#### WebSocket Client

```go
package main

import (
	""fmt""

	rpc ""github.com/hprose/hprose-golang/rpc/websocket""
)

type HelloService struct {
    Hello func(string) (string, error)
}

func main() {
	client := rpc.NewWebSocketClient(""ws://127.0.0.1:8080/"")
	var helloService *HelloService
	client.UseService(&helloService)
	fmt.Println(helloService.Hello(""world""))
}
```

### Unix Socket Server & Client

#### Unix Socket Server

```go
package main

import (
	""net/http""
	""runtime""

	""github.com/hprose/hprose-golang/rpc""
)

func hello(name string) string {
	return ""Hello "" + name + ""!""
}

func main() {
	server := rpc.NewUnixServer(""unix:///tmp/hprose.sock"")
	server.AddFunction(""hello"", hello)
	server.Start()
}
```

#### Unix Socket Client

```go
package main

import (
	""fmt""

	""github.com/hprose/hprose-golang/rpc""
)

type HelloService struct {
    Hello func(string) (string, error)
}

func main() {
	client := rpc.NewUnixClient(""unix:///tmp/hprose.sock"")
	var helloService *HelloService
	client.UseService(&helloService)
	fmt.Println(helloService.Hello(""world""))
}
```

## Benchmark

Hprose is faster than golang RPC, you can run benchmark like this:

```
go test --bench="".*"" github.com/hprose/hprose-golang/examples/bench
```

* go1.7.1 darwin/amd64
* macOS Sierra
* iMac (Retina 5K, 27-inch, Late 2015)
* CPU 4GHz Intel Core i7
* Memory 32 GB 1867 MHz DDR3

```
BenchmarkParallelHprose2-8       	  200000	     11230 ns/op
BenchmarkParallelHprose2Unix-8   	  300000	      5234 ns/op
BenchmarkParallelGobRPC-8        	  100000	     16675 ns/op
BenchmarkParallelGobRPCUnix-8    	  200000	      6798 ns/op
BenchmarkParallelJSONRPC-8       	  100000	     17261 ns/op
BenchmarkParallelJSONRPCUnix-8   	  200000	      7917 ns/op
```

```
BenchmarkHprose2-8               	   50000	     34287 ns/op
BenchmarkHprose2Unix-8           	  200000	     11470 ns/op
BenchmarkGobRPC-8                	   30000	     45576 ns/op
BenchmarkGobRPCUnix-8            	  100000	     24216 ns/op
BenchmarkJSONRPC-8               	   30000	     51298 ns/op
BenchmarkJSONRPCUnix-8           	   50000	     27408 ns/op
```
","This project is the implementation of Hprose 2.0 for Golang. It is a cross-
language, cross-platform, object-oriented, high performance, remote dynamic
communication middleware. You can conveniently and efficiently intercommunicate
between those programming languages. It supports many programming languages, for
example: AAuto Quicker, ActionScript, ASP, Dart, Delphi/Free Pascal, dotNET(C#,
Visual Basic...) It is not only easy to use, but powerful. You just need a
little time to learn."
2149,📦 A simplified example of a modern module bundler written in JavaScript,"## 📦 Minipack

> A simplified example of a modern module bundler written in JavaScript

### Introduction

As front-end developers, we spend a lot of time working with tools like [Webpack](https://github.com/webpack/webpack), [Browserify](https://github.com/browserify/browserify), and [Parcel](https://github.com/parcel-bundler/parcel).

Understanding how those tools work can help us make better decisions on how we write our code. By understanding how our code turns into a bundle and how that bundle looks like we can also debug it better.

The purpose of this project is to explain how most bundlers work under the hood. It contains a short implementation of a simplified but still reasonably accurate bundler. Along with the code, there are comments explaining what the code is trying to achieve.

### Cool, where do I start?

Head on to the source code: [src/minipack.js](src/minipack.js).

### Try running the code

Start by installing dependencies:

```sh
$ npm install
```

And then run our script:

```sh
$ node src/minipack.js
```

### Additional links

- [AST Explorer](https://astexplorer.net)
- [Babel REPL](https://babeljs.io/repl)
- [Babylon](https://github.com/babel/babel/tree/master/packages/babel-parser)
- [Babel Plugin Handbook](https://github.com/thejameskyle/babel-handbook/blob/master/translations/en/plugin-handbook.md)
- [Webpack: Modules](https://webpack.js.org/concepts/modules)

### Read this in other languages

- [한글/Korean](https://github.com/hg-pyun/minipack-kr)
- [中文/Chinese](https://github.com/chinanf-boy/minipack-explain)
- [Русский/Russian](https://github.com/makewebme/build-your-own-webpack)
","The purpose of this project is to explain how most bundlers work under the hood.
It contains a short implementation of a simplified but still reasonably accurate
bundler. Along with the code, there are comments explaining what the code is
trying to achieve. Read this in other languages such as Chinese, Korean,
Russian, and Chinese. The source code is available on GitHub and can be
downloaded from the project's GitHub page. For more information on bundlers, see
the [Babel] and [Parcel] mailing lists."
2103,Simple HTML5 Charts using the <canvas> tag,"<p align=""center"">
  <a href=""https://www.chartjs.org/"" target=""_blank"">
    <img src=""https://www.chartjs.org/media/logo-title.svg"" alt=""https://www.chartjs.org/""><br/>
  </a>
    Simple yet flexible JavaScript charting for designers & developers
</p>

<p align=""center"">
    <a href=""https://www.chartjs.org/docs/latest/getting-started/installation.html""><img src=""https://img.shields.io/github/release/chartjs/Chart.js.svg?style=flat-square&maxAge=600"" alt=""Downloads""></a>
    <a href=""https://github.com/chartjs/Chart.js/actions?query=workflow%3ACI+branch%3Amaster""><img alt=""GitHub Workflow Status"" src=""https://img.shields.io/github/actions/workflow/status/chartjs/Chart.js/ci.yml?branch=master""></a>
    <a href=""https://coveralls.io/github/chartjs/Chart.js?branch=master""><img src=""https://img.shields.io/coveralls/chartjs/Chart.js.svg?style=flat-square&maxAge=600"" alt=""Coverage""></a>
    <a href=""https://github.com/chartjs/awesome""><img src=""https://awesome.re/badge-flat2.svg"" alt=""Awesome""></a>
    <a href=""https://join.slack.com/t/chartjs/shared_invite/zt-1lo81skkk-AZk6ollhOdrjt9GzPeOsLw""><img src=""https://img.shields.io/badge/slack-chartjs-blue.svg?style=flat-square&maxAge=3600"" alt=""Slack""></a>
</p>

## Documentation

All the links point to the new version 4 of the lib.

* [Introduction](https://www.chartjs.org/docs/latest/)
* [Getting Started](https://www.chartjs.org/docs/latest/getting-started/index)
* [General](https://www.chartjs.org/docs/latest/general/data-structures)
* [Configuration](https://www.chartjs.org/docs/latest/configuration/index)
* [Charts](https://www.chartjs.org/docs/latest/charts/line)
* [Axes](https://www.chartjs.org/docs/latest/axes/index)
* [Developers](https://www.chartjs.org/docs/latest/developers/index)
* [Popular Extensions](https://github.com/chartjs/awesome)
* [Samples](https://www.chartjs.org/samples/)

In case you are looking for an older version of the docs, you will have to specify the specific version in the url like this: [https://www.chartjs.org/docs/2.9.4/](https://www.chartjs.org/docs/2.9.4/)

## Contributing

Instructions on building and testing Chart.js can be found in [the documentation](https://www.chartjs.org/docs/master/developers/contributing.html#building-and-testing). Before submitting an issue or a pull request, please take a moment to look over the [contributing guidelines](https://www.chartjs.org/docs/master/developers/contributing) first. For support, please post questions on [Stack Overflow](https://stackoverflow.com/questions/tagged/chart.js) with the `chart.js` tag.

## License

Chart.js is available under the [MIT license](LICENSE.md).
","Charts.js is a simple yet flexible JavaScript charting tool for designers &
developers. It is available under the MIT license under the `chartjs` tag. All
the links point to the new version 4 of the lib. The documentation can be found
in [the documentation]"
789,"pandas on AWS - Easy integration with Athena, Glue, Redshift, Timestream, Neptune, OpenSearch, QuickSight, Chime, CloudWatchLogs, DynamoDB, EMR, SecretManager, PostgreSQL, MySQL, SQLServer and S3 (Parquet, CSV, JSON and EXCEL).","# AWS SDK for pandas (awswrangler)

AWS Data Wrangler is now **AWS SDK for pandas (awswrangler)**.  We’re changing the name we use when we talk about the library, but everything else will stay the same.  You’ll still be able to install using `pip install awswrangler` and you won’t need to change any of your code.  As part of this change, we’ve moved the library from AWS Labs to the main AWS GitHub organisation but, thanks to the GitHub’s redirect feature, you’ll still be able to access the project by its old URLs until you update your bookmarks.  Our documentation has also moved to [aws-sdk-pandas.readthedocs.io](https://aws-sdk-pandas.readthedocs.io), but old bookmarks will redirect to the new site.

*Pandas on AWS*

Easy integration with Athena, Glue, Redshift, Timestream, OpenSearch, Neptune, QuickSight, Chime, CloudWatchLogs, DynamoDB, EMR, SecretManager, PostgreSQL, MySQL, SQLServer and S3 (Parquet, CSV, JSON and EXCEL).

![AWS SDK for pandas](docs/source/_static/logo2.png?raw=true ""AWS SDK for pandas"")
![tracker](https://d3tiqpr4kkkomd.cloudfront.net/img/pixel.png?asset=GVOYN2BOOQ573LTVIHEW)

> An [AWS Professional Service](https://aws.amazon.com/professional-services/) open source initiative | aws-proserve-opensource@amazon.com

[![Release](https://img.shields.io/badge/release-2.19.0-brightgreen.svg)](https://pypi.org/project/awswrangler/)
[![Python Version](https://img.shields.io/badge/python-3.7%20%7C%203.8%20%7C%203.9%20%7C%203.10-brightgreen.svg)](https://anaconda.org/conda-forge/awswrangler)
[![Code style: black](https://img.shields.io/badge/code%20style-black-000000.svg)](https://github.com/psf/black)
[![License](https://img.shields.io/badge/License-Apache%202.0-blue.svg)](https://opensource.org/licenses/Apache-2.0)

[![Checked with mypy](http://www.mypy-lang.org/static/mypy_badge.svg)](http://mypy-lang.org/)
[![Coverage](https://img.shields.io/badge/coverage-91%25-brightgreen.svg)](https://pypi.org/project/awswrangler/)
![Static Checking](https://github.com/aws/aws-sdk-pandas/workflows/Static%20Checking/badge.svg?branch=main)
[![Documentation Status](https://readthedocs.org/projects/aws-sdk-pandas/badge/?version=latest)](https://aws-sdk-pandas.readthedocs.io/?badge=latest)

| Source | Downloads | Installation Command |
|--------|-----------|----------------------|
| **[PyPi](https://pypi.org/project/awswrangler/)**  | [![PyPI Downloads](https://pepy.tech/badge/awswrangler)](https://pypi.org/project/awswrangler/) | `pip install awswrangler` |
| **[Conda](https://anaconda.org/conda-forge/awswrangler)** | [![Conda Downloads](https://img.shields.io/conda/dn/conda-forge/awswrangler.svg)](https://anaconda.org/conda-forge/awswrangler) | `conda install -c conda-forge awswrangler` |

> ⚠️ **For platforms without PyArrow 3 support (e.g. [EMR](https://aws-sdk-pandas.readthedocs.io/en/2.19.0/install.html#emr-cluster), [Glue PySpark Job](https://aws-sdk-pandas.readthedocs.io/en/2.19.0/install.html#aws-glue-pyspark-jobs), MWAA):**<br>
➡️ `pip install pyarrow==2 awswrangler`

Powered By [<img src=""https://arrow.apache.org/img/arrow.png"" width=""200"">](https://arrow.apache.org/powered_by/)

## Table of contents

- [Quick Start](#quick-start)
- [Read The Docs](#read-the-docs)
- [Getting Help](#getting-help)
- [Community Resources](#community-resources)
- [Logging](#logging)
- [Who uses AWS SDK for pandas?](#who-uses-aws-sdk-pandas)

## Quick Start

Installation command: `pip install awswrangler`

> ⚠️ **For platforms without PyArrow 3 support (e.g. [EMR](https://aws-sdk-pandas.readthedocs.io/en/2.19.0/install.html#emr-cluster), [Glue PySpark Job](https://aws-sdk-pandas.readthedocs.io/en/2.19.0/install.html#aws-glue-pyspark-jobs), MWAA):**<br>
➡️`pip install pyarrow==2 awswrangler`

```py3
import awswrangler as wr
import pandas as pd
from datetime import datetime

df = pd.DataFrame({""id"": [1, 2], ""value"": [""foo"", ""boo""]})

# Storing data on Data Lake
wr.s3.to_parquet(
    df=df,
    path=""s3://bucket/dataset/"",
    dataset=True,
    database=""my_db"",
    table=""my_table""
)

# Retrieving the data directly from Amazon S3
df = wr.s3.read_parquet(""s3://bucket/dataset/"", dataset=True)

# Retrieving the data from Amazon Athena
df = wr.athena.read_sql_query(""SELECT * FROM my_table"", database=""my_db"")

# Get a Redshift connection from Glue Catalog and retrieving data from Redshift Spectrum
con = wr.redshift.connect(""my-glue-connection"")
df = wr.redshift.read_sql_query(""SELECT * FROM external_schema.my_table"", con=con)
con.close()

# Amazon Timestream Write
df = pd.DataFrame({
    ""time"": [datetime.now(), datetime.now()],   
    ""my_dimension"": [""foo"", ""boo""],
    ""measure"": [1.0, 1.1],
})
rejected_records = wr.timestream.write(df,
    database=""sampleDB"",
    table=""sampleTable"",
    time_col=""time"",
    measure_col=""measure"",
    dimensions_cols=[""my_dimension""],
)

# Amazon Timestream Query
wr.timestream.query(""""""
SELECT time, measure_value::double, my_dimension
FROM ""sampleDB"".""sampleTable"" ORDER BY time DESC LIMIT 3
"""""")

```

## [Read The Docs](https://aws-sdk-pandas.readthedocs.io/)

- [**What is AWS SDK for pandas?**](https://aws-sdk-pandas.readthedocs.io/en/2.19.0/about.html)
- [**Install**](https://aws-sdk-pandas.readthedocs.io/en/2.19.0/install.html)
  - [PyPi (pip)](https://aws-sdk-pandas.readthedocs.io/en/2.19.0/install.html#pypi-pip)
  - [Conda](https://aws-sdk-pandas.readthedocs.io/en/2.19.0/install.html#conda)
  - [AWS Lambda Layer](https://aws-sdk-pandas.readthedocs.io/en/2.19.0/install.html#aws-lambda-layer)
  - [AWS Glue Python Shell Jobs](https://aws-sdk-pandas.readthedocs.io/en/2.19.0/install.html#aws-glue-python-shell-jobs)
  - [AWS Glue PySpark Jobs](https://aws-sdk-pandas.readthedocs.io/en/2.19.0/install.html#aws-glue-pyspark-jobs)
  - [Amazon SageMaker Notebook](https://aws-sdk-pandas.readthedocs.io/en/2.19.0/install.html#amazon-sagemaker-notebook)
  - [Amazon SageMaker Notebook Lifecycle](https://aws-sdk-pandas.readthedocs.io/en/2.19.0/install.html#amazon-sagemaker-notebook-lifecycle)
  - [EMR](https://aws-sdk-pandas.readthedocs.io/en/2.19.0/install.html#emr)
  - [From source](https://aws-sdk-pandas.readthedocs.io/en/2.19.0/install.html#from-source)
- [**Tutorials**](https://github.com/aws/aws-sdk-pandas/tree/main/tutorials)
  - [001 - Introduction](https://github.com/aws/aws-sdk-pandas/blob/main/tutorials/001%20-%20Introduction.ipynb)
  - [002 - Sessions](https://github.com/aws/aws-sdk-pandas/blob/main/tutorials/002%20-%20Sessions.ipynb)
  - [003 - Amazon S3](https://github.com/aws/aws-sdk-pandas/blob/main/tutorials/003%20-%20Amazon%20S3.ipynb)
  - [004 - Parquet Datasets](https://github.com/aws/aws-sdk-pandas/blob/main/tutorials/004%20-%20Parquet%20Datasets.ipynb)
  - [005 - Glue Catalog](https://github.com/aws/aws-sdk-pandas/blob/main/tutorials/005%20-%20Glue%20Catalog.ipynb)
  - [006 - Amazon Athena](https://github.com/aws/aws-sdk-pandas/blob/main/tutorials/006%20-%20Amazon%20Athena.ipynb)
  - [007 - Databases (Redshift, MySQL, PostgreSQL, SQL Server and Oracle)](https://github.com/aws/aws-sdk-pandas/blob/main/tutorials/007%20-%20Redshift%2C%20MySQL%2C%20PostgreSQL%2C%20SQL%20Server%2C%20Oracle.ipynb)
  - [008 - Redshift - Copy & Unload.ipynb](https://github.com/aws/aws-sdk-pandas/blob/main/tutorials/008%20-%20Redshift%20-%20Copy%20%26%20Unload.ipynb)
  - [009 - Redshift - Append, Overwrite and Upsert](https://github.com/aws/aws-sdk-pandas/blob/main/tutorials/009%20-%20Redshift%20-%20Append%2C%20Overwrite%2C%20Upsert.ipynb)
  - [010 - Parquet Crawler](https://github.com/aws/aws-sdk-pandas/blob/main/tutorials/010%20-%20Parquet%20Crawler.ipynb)
  - [011 - CSV Datasets](https://github.com/aws/aws-sdk-pandas/blob/main/tutorials/011%20-%20CSV%20Datasets.ipynb)
  - [012 - CSV Crawler](https://github.com/aws/aws-sdk-pandas/blob/main/tutorials/012%20-%20CSV%20Crawler.ipynb)
  - [013 - Merging Datasets on S3](https://github.com/aws/aws-sdk-pandas/blob/main/tutorials/013%20-%20Merging%20Datasets%20on%20S3.ipynb)
  - [014 - Schema Evolution](https://github.com/aws/aws-sdk-pandas/blob/main/tutorials/014%20-%20Schema%20Evolution.ipynb)
  - [015 - EMR](https://github.com/aws/aws-sdk-pandas/blob/main/tutorials/015%20-%20EMR.ipynb)
  - [016 - EMR & Docker](https://github.com/aws/aws-sdk-pandas/blob/main/tutorials/016%20-%20EMR%20%26%20Docker.ipynb)
  - [017 - Partition Projection](https://github.com/aws/aws-sdk-pandas/blob/main/tutorials/017%20-%20Partition%20Projection.ipynb)
  - [018 - QuickSight](https://github.com/aws/aws-sdk-pandas/blob/main/tutorials/018%20-%20QuickSight.ipynb)
  - [019 - Athena Cache](https://github.com/aws/aws-sdk-pandas/blob/main/tutorials/019%20-%20Athena%20Cache.ipynb)
  - [020 - Spark Table Interoperability](https://github.com/aws/aws-sdk-pandas/blob/main/tutorials/020%20-%20Spark%20Table%20Interoperability.ipynb)
  - [021 - Global Configurations](https://github.com/aws/aws-sdk-pandas/blob/main/tutorials/021%20-%20Global%20Configurations.ipynb)
  - [022 - Writing Partitions Concurrently](https://github.com/aws/aws-sdk-pandas/blob/main/tutorials/022%20-%20Writing%20Partitions%20Concurrently.ipynb)
  - [023 - Flexible Partitions Filter](https://github.com/aws/aws-sdk-pandas/blob/main/tutorials/023%20-%20Flexible%20Partitions%20Filter.ipynb)
  - [024 - Athena Query Metadata](https://github.com/aws/aws-sdk-pandas/blob/main/tutorials/024%20-%20Athena%20Query%20Metadata.ipynb)
  - [025 - Redshift - Loading Parquet files with Spectrum](https://github.com/aws/aws-sdk-pandas/blob/main/tutorials/025%20-%20Redshift%20-%20Loading%20Parquet%20files%20with%20Spectrum.ipynb)
  - [026 - Amazon Timestream](https://github.com/aws/aws-sdk-pandas/blob/main/tutorials/026%20-%20Amazon%20Timestream.ipynb)
  - [027 - Amazon Timestream 2](https://github.com/aws/aws-sdk-pandas/blob/main/tutorials/027%20-%20Amazon%20Timestream%202.ipynb)
  - [028 - Amazon DynamoDB](https://github.com/aws/aws-sdk-pandas/blob/main/tutorials/028%20-%20DynamoDB.ipynb)
  - [029 - S3 Select](https://github.com/aws/aws-sdk-pandas/blob/main/tutorials/029%20-%20S3%20Select.ipynb)
  - [030 - Data Api](https://github.com/aws/aws-sdk-pandas/blob/main/tutorials/030%20-%20Data%20Api.ipynb)
  - [031 - OpenSearch](https://github.com/aws/aws-sdk-pandas/blob/main/tutorials/031%20-%20OpenSearch.ipynb)
  - [032 - Lake Formation Governed Tables](https://github.com/aws/aws-sdk-pandas/blob/main/tutorials/032%20-%20Lake%20Formation%20Governed%20Tables.ipynb)
  - [033 - Amazon Neptune](https://github.com/aws/aws-sdk-pandas/blob/main/tutorials/033%20-%20Amazon%20Neptune.ipynb)
  - [034 - Glue Data Quality](https://github.com/aws/aws-sdk-pandas/blob/main/tutorials/034%20-Glue%20%20Data%20Quality.ipynb)
- [**API Reference**](https://aws-sdk-pandas.readthedocs.io/en/2.19.0/api.html)
  - [Amazon S3](https://aws-sdk-pandas.readthedocs.io/en/2.19.0/api.html#amazon-s3)
  - [AWS Glue Catalog](https://aws-sdk-pandas.readthedocs.io/en/2.19.0/api.html#aws-glue-catalog)
  - [Amazon Athena](https://aws-sdk-pandas.readthedocs.io/en/2.19.0/api.html#amazon-athena)
  - [AWS Lake Formation](https://aws-sdk-pandas.readthedocs.io/en/2.19.0/api.html#aws-lake-formation)
  - [Amazon Redshift](https://aws-sdk-pandas.readthedocs.io/en/2.19.0/api.html#amazon-redshift)
  - [PostgreSQL](https://aws-sdk-pandas.readthedocs.io/en/2.19.0/api.html#postgresql)
  - [MySQL](https://aws-sdk-pandas.readthedocs.io/en/2.19.0/api.html#mysql)
  - [SQL Server](https://aws-sdk-pandas.readthedocs.io/en/2.19.0/api.html#sqlserver)
  - [Oracle](https://aws-sdk-pandas.readthedocs.io/en/2.19.0/api.html#oracle)
  - [Data API Redshift](https://aws-sdk-pandas.readthedocs.io/en/2.19.0/api.html#data-api-redshift)
  - [Data API RDS](https://aws-sdk-pandas.readthedocs.io/en/2.19.0/api.html#data-api-rds)
  - [OpenSearch](https://aws-sdk-pandas.readthedocs.io/en/2.19.0/api.html#opensearch)
  - [Amazon Neptune](https://aws-sdk-pandas.readthedocs.io/en/2.19.0/api.html#amazon-neptune)
  - [DynamoDB](https://aws-sdk-pandas.readthedocs.io/en/2.19.0/api.html#dynamodb)
  - [Amazon Timestream](https://aws-sdk-pandas.readthedocs.io/en/2.19.0/api.html#amazon-timestream)
  - [Amazon EMR](https://aws-sdk-pandas.readthedocs.io/en/2.19.0/api.html#amazon-emr)
  - [Amazon CloudWatch Logs](https://aws-sdk-pandas.readthedocs.io/en/2.19.0/api.html#amazon-cloudwatch-logs)
  - [Amazon Chime](https://aws-sdk-pandas.readthedocs.io/en/2.19.0/api.html#amazon-chime)
  - [Amazon QuickSight](https://aws-sdk-pandas.readthedocs.io/en/2.19.0/api.html#amazon-quicksight)
  - [AWS STS](https://aws-sdk-pandas.readthedocs.io/en/2.19.0/api.html#aws-sts)
  - [AWS Secrets Manager](https://aws-sdk-pandas.readthedocs.io/en/2.19.0/api.html#aws-secrets-manager)
  - [Global Configurations](https://aws-sdk-pandas.readthedocs.io/en/2.19.0/api.html#global-configurations)
- [**License**](https://github.com/aws/aws-sdk-pandas/blob/main/LICENSE.txt)
- [**Contributing**](https://github.com/aws/aws-sdk-pandas/blob/main/CONTRIBUTING.md)

## Getting Help

The best way to interact with our team is through GitHub. You can open an [issue](https://github.com/aws/aws-sdk-pandas/issues/new/choose) and choose from one of our templates for bug reports, feature requests...
You may also find help on these community resources:
* The #aws-sdk-pandas Slack [channel](https://join.slack.com/t/aws-sdk-pandas/shared_invite/zt-sxdx38sl-E0coRfAds8WdpxXD2Nzfrg)
* Ask a question on [Stack Overflow](https://stackoverflow.com/questions/tagged/awswrangler)
  and tag it with `awswrangler`

## Community Resources

Please [send a Pull Request](https://github.com/aws/aws-sdk-pandas/edit/main/README.md) with your resource reference and @githubhandle.

- [Optimize Python ETL by extending Pandas with AWS SDK for pandas](https://aws.amazon.com/blogs/big-data/optimize-python-etl-by-extending-pandas-with-aws-data-wrangler/) [[@igorborgest](https://github.com/igorborgest)]
- [Reading Parquet Files With AWS Lambda](https://aprakash.wordpress.com/2020/04/14/reading-parquet-files-with-aws-lambda/) [[@anand086](https://github.com/anand086)]
- [Transform AWS CloudTrail data using AWS SDK for pandas](https://aprakash.wordpress.com/2020/09/17/transform-aws-cloudtrail-data-using-aws-data-wrangler/) [[@anand086](https://github.com/anand086)]
- [Rename Glue Tables using AWS SDK for pandas](https://ananddatastories.com/rename-glue-tables-using-aws-sdk-pandas/) [[@anand086](https://github.com/anand086)]
- [Getting started on AWS SDK for pandas and Athena](https://medium.com/@dheerajsharmainampudi/getting-started-on-aws-sdk-pandas-and-athena-7b446c834076) [[@dheerajsharma21](https://github.com/dheerajsharma21)]
- [Simplifying Pandas integration with AWS data related services](https://medium.com/@bv_subhash/aws-sdk-pandas-simplifying-pandas-integration-with-aws-data-related-services-2b3325c12188) [[@bvsubhash](https://github.com/bvsubhash)]
- [Build an ETL pipeline using AWS S3, Glue and Athena](https://www.linkedin.com/pulse/build-etl-pipeline-using-aws-s3-glue-athena-data-wrangler-tom-reid/) [[@taupirho](https://github.com/taupirho)]

## Logging

Enabling internal logging examples:

```py3
import logging
logging.basicConfig(level=logging.INFO, format=""[%(name)s][%(funcName)s] %(message)s"")
logging.getLogger(""awswrangler"").setLevel(logging.DEBUG)
logging.getLogger(""botocore.credentials"").setLevel(logging.CRITICAL)
```

Into AWS lambda:

```py3
import logging
logging.getLogger(""awswrangler"").setLevel(logging.DEBUG)
```

## Who uses AWS SDK for pandas?

Knowing which companies are using this library is important to help prioritize the project internally.
If you would like us to include your company’s name and/or logo in the README file to indicate that your company is using the AWS SDK for pandas, please raise a ""Support Us"" issue. If you would like us to display your company’s logo, please raise a linked pull request to provide an image file for the logo. Note that by raising a Support Us issue (and related pull request), you are granting AWS permission to use your company’s name (and logo) for the limited purpose described here and you are confirming that you have authority to grant such permission.

- [Amazon](https://www.amazon.com/)
- [AWS](https://aws.amazon.com/)
- [Cepsa](https://cepsa.com) [[@alvaropc](https://github.com/alvaropc)]
- [Cognitivo](https://www.cognitivo.ai/) [[@msantino](https://github.com/msantino)]
- [Digio](https://www.digio.com.br/) [[@afonsomy](https://github.com/afonsomy)]
- [DNX](https://www.dnx.solutions/) [[@DNXLabs](https://github.com/DNXLabs)]
- [Fortescue Future Industries](https://ffi.com.au/) [[@spencervoorend](https://github.com/spencervoorend)]
- [Funcional Health Tech](https://www.funcionalcorp.com.br/) [[@webysther](https://github.com/webysther)]
- [Funding Circle](https://www.fundingcircle.com/) [[@pfig](https://github.com/pfig)]
- [Infomach](https://www.infomach.com.br/)
- [Informa Markets](https://www.informamarkets.com/en/home.html) [[@mateusmorato]](http://github.com/mateusmorato)
- [LINE TV](https://www.linetv.tw/) [[@bryanyang0528](https://github.com/bryanyang0528)]
- [Magnataur](https://magnataur.com) [[@brianmingus2](https://github.com/brianmingus2)]
- [M4U](https://www.m4u.com.br/) [[@Thiago-Dantas](https://github.com/Thiago-Dantas)]
- [NBCUniversal](https://www.nbcuniversal.com/) [[@vibe](https://github.com/vibe)]
- [nrd.io](https://nrd.io/) [[@mrtns](https://github.com/mrtns)]
- [OKRA Technologies](https://okra.ai) [[@JPFrancoia](https://github.com/JPFrancoia), [@schot](https://github.com/schot)]
- [Pier](https://www.pier.digital/) [[@flaviomax](https://github.com/flaviomax)]
- [Pismo](https://www.pismo.io/) [[@msantino](https://github.com/msantino)]
- [ringDNA](https://www.ringdna.com/) [[@msropp](https://github.com/msropp)]
- [Serasa Experian](https://www.serasaexperian.com.br/) [[@andre-marcos-perez](https://github.com/andre-marcos-perez)]
- [Shipwell](https://shipwell.com/) [[@zacharycarter](https://github.com/zacharycarter)]
- [strongDM](https://www.strongdm.com/) [[@mrtns](https://github.com/mrtns)]
- [Thinkbumblebee](https://www.thinkbumblebee.com/) [[@dheerajsharma21]](https://github.com/dheerajsharma21)
- [VTEX](https://vtex.com/us-en/) [[@igorborgest]](https://github.com/igorborgest)
- [Zillow](https://www.zillow.com/) [[@nicholas-miles]](https://github.com/nicholas-miles)
","AWS Data Wrangler is now **AWS SDK for pandas (awswrangler) We’re changing the
name we use when we talk about the library, but everything else will stay the
same. Easy integration with Athena, Glue, Redshift, Timestream, OpenSearch,
Neptune, QuickSight, Chime, CloudWatchLogs."
1689,A platform to ease integration&delivery of React Native apps in existing mobile applications,"<h1 align=""center"">
	<br>
	<img src=""https://cdn.rawgit.com/electrode-io/electrode-native/b3b3fcaf/docs/images/electrode-native.png"" alt=""chalk"">
	<br>
  <br>
</h1>

> Electrode Native is a mobile platform that streamlines the integration of React Native components into existing mobile applications. With minimal changes required to the application code base and infrastructure, Electrode Native makes it simpler to leverage React Native potential in any mobile application.

![Current version](https://img.shields.io/npm/v/ern-local-cli.svg?label=current)
[![Coverage Status](https://coveralls.io/repos/github/electrode-io/electrode-native/badge.svg?branch=master&service=github)](https://coveralls.io/github/electrode-io/electrode-native?branch=master&service=github)
[![License](https://img.shields.io/badge/License-Apache%202.0-blue.svg)](https://opensource.org/licenses/Apache-2.0)
[![ci][1]][2]

| Test Suite | Status |
| :--- | :--- |
| Unit Tests | [![Unit Tests](https://dev.azure.com/ElectrodeNative/Electrode%20Native/_apis/build/status/electrode-io.electrode-native?branchName=master&stageName=UnitTests)](https://dev.azure.com/ElectrodeNative/Electrode%20Native/_build/latest?definitionId=1&branchName=master) |
| System Tests | [![System Tests](https://dev.azure.com/ElectrodeNative/Electrode%20Native/_apis/build/status/electrode-io.electrode-native?branchName=master&stageName=SystemTests)](https://dev.azure.com/ElectrodeNative/Electrode%20Native/_build/latest?definitionId=1&branchName=master)|

## Getting Started

### Prerequisites

- Node.js >= 12
- npm >= 5.6.0
- Android Studio (for Android apps)
- Xcode >= 10 (for iOS apps)
- CocoaPods (if using a version of React Native >= 0.60)

### Install

```sh
npm install -g electrode-native
```

## Documentation

The [documentation of Electrode Native] is maintained as [GitBook] pages in the [docs](/docs) directory. It is divided into multiple sections:

- An [Overview] of Electrode Native

 This should be read first, as an introduction to learn about [what is Electrode Native] or [what is a MiniApp]. This section also contains some documentation regarding the [Electrode Native workflow], native dependencies management or JS/Native communication.

- A Platform Reference section

 This section covers each Electrode Native module in depth, such as [Container], [Cauldron], [Manifest], [Apis] ...

- A CLI command reference section

 In this section you will find a documentation page for each of the CLI commands available in Electrode Native, for example [create-miniapp], [run-android], [platform use] ...

## Contributing

We embrace contributions, be it documentation, issue reporting, or contributing code.

Please read our [CONTRIBUTING guide](docs/overview/contributing.md) for more details on how to contribute.

## Further Reading

- Check out our [Announcement Blog Post].
- Have a look at the [TechCrunch article].
- See [What is Electrode Native] for more details on Electrode Native.
- Read [Electrode Native Case Study] to learn about key facts.

## License

Copyright 2017 WalmartLabs

Licensed under the [Apache License, Version 2.0].

## Support and Acknowledgment

We'd like to thank our employer, WalmartLabs because we can work on the development of Electrode Native platform as Open Sourced Software for the needs of our internal teams and projects.

We love the public community and the support we get, and we address your requests as much as we can.

We are always excited to get feedback, bug reports, and pull requests.

Thank you.

[react-native]: https://github.com/facebook/react-native

[TechCrunch article]: https://techcrunch.com/2017/09/29/walmart-labs-open-sources-its-tool-for-bringing-react-native-to-existing-mobile-apps/?ncid=mobilenavtrend

[Announcement Blog Post]: https://medium.com/walmartlabs/electrode-native-the-platform-for-integrating-react-native-into-your-apps-129cbabda7b8

[documentation of electrode native]: https://native.electrode.io/

[apache license, version 2.0]: https://www.apache.org/licenses/LICENSE-2.0

[gitbook]: https://www.gitbook.com/

[what is electrode native]: https://native.electrode.io/introduction/what-is-ern/what-is-ern

[overview]: https://native.electrode.io/introduction/what-is-ern

[what is Electrode Native]: https://native.electrode.io/introduction/what-is-ern/what-is-ern

[what is a MiniApp]: https://native.electrode.io/introduction/what-is-ern/what-is-a-miniapp

[Electrode Native workflow]: https://native.electrode.io/introduction/what-is-ern/ern-workflow

[Container]: https://native.electrode.io/reference/index-1

[Cauldron]: https://native.electrode.io/reference/index-2

[Manifest]: https://native.electrode.io/reference/index-3

[apis]: https://native.electrode.io/reference/index-5

[create-miniapp]: https://native.electrode.io/cli-commands/create-miniapp

[run-android]: https://native.electrode.io/cli-commands/run-android

[platform use]: https://native.electrode.io/cli-commands/platform/use

[Electrode Native Case Study]: https://www.walmartlabs.com/case-studies/electrode-native

[CocoaPods]: https://cocoapods.org

[1]: https://github.com/electrode-io/electrode-native/workflows/ci/badge.svg
[2]: https://github.com/electrode-io/electrode-native/actions
","Electrode Native is a mobile platform that streamlines the integration of React
Native components into existing mobile applications. With minimal changes
required to the application code base and infrastructure, Electrode Native makes
it simpler to leverage React Native potential in any mobile application."
3090,openHAB client for Android,"<p align=""center"">
    <a href=""https://github.com/openhab/openhab-android/actions?query=workflow%3A%22Build+App%22""><img alt=""GitHub Action"" src=""https://github.com/openhab/openhab-android/workflows/Build%20App/badge.svg""></a>
    <a href=""https://crowdin.com/project/openhab-android""><img alt=""Crowdin"" src=""https://d322cqt584bo4o.cloudfront.net/openhab-android/localized.svg""></a>
    <a href=""https://www.bountysource.com/teams/openhab/issues?tracker_ids=968858""><img alt=""Bountysource"" src=""https://www.bountysource.com/badge/tracker?tracker_id=968858""></a>
    <br>
    <img alt=""Logo"" src=""fastlane/metadata/android/en-US/images/icon.png"" width=""100"">
    <br>
    <b>openHAB client for Android</b>
</p>

## Introduction

This app is a native client for openHAB which allows easy access to your sitemaps.
The documentation is available at [www.openhab.org/docs/](https://www.openhab.org/docs/apps/android.html).

<a href=""https://play.google.com/store/apps/details?id=org.openhab.habdroid""><img src=""https://play.google.com/intl/en_us/badges/images/generic/en_badge_web_generic.png"" alt=""Get it on Play Store"" height=""80""></a>
<a href=""https://f-droid.org/app/org.openhab.habdroid""><img src=""docs/images/get-it-on-fdroid.png"" alt=""Get it on F-Droid"" height=""80""></a>
<a href=""https://github.com/openhab/openhab-android/releases""><img src=""assets/direct-apk-download.png"" alt=""Get it on GitHub"" height=""80""></a>

## Features
* Control your openHAB server and/or [openHAB Cloud instance](https://github.com/openhab/openhab-cloud), e.g., an account with [myopenHAB](http://www.myopenhab.org/)
* Receive notifications through an openHAB Cloud connection, [read more](https://www.openhab.org/docs/configuration/actions.html#cloud-notification-actions)
* Change items via NFC tags
* Send voice commands to openHAB
* [Send alarm clock time to openHAB](https://www.openhab.org/docs/apps/android.html#alarm-clock)
* [Supports wall mounted tablets](https://www.openhab.org/docs/apps/android.html#permanent-deployment)
* [Tasker](https://play.google.com/store/apps/details?id=net.dinglisch.android.taskerm) action plugin included

<img src=""docs/images/main-menu.png"" alt=""Demo Overview"" width=200px> <img src=""docs/images/widget-overview.png"" alt=""Widget Overview"" width=200px> <img src=""docs/images/main-ui.png"" alt=""Main UI"" width=200px>

## Beta builds

Beta builds are distributed via [GitHub](https://github.com/openhab/openhab-android/releases) and [F-Droid](https://f-droid.org/packages/org.openhab.habdroid.beta). Those builds can be installed alongside the stable version.

On Google Play you can opt-in to get updates of stable versions before others: https://play.google.com/apps/testing/org.openhab.habdroid

## Localization

Concerning all `strings.xml` files at [mobile/src/\*/res/values-\*/](mobile/src/main/res/)

All language/regional translations are managed with [Crowdin](https://crowdin.com/).
Please do NOT contribute translations as pull requests against the `mobile/src/*/res/values-*/strings.xml` files directly, but submit them through the Crowdin web service:

- [https://crowdin.com/project/openhab-android](https://crowdin.com/project/openhab-android)

Thanks for your consideration and contribution!

## Setting up development environment

If you want to contribute to Android application we are here to help you to set up development environment. openHAB client for Android is developed using Android Studio.

- Download and install [Android Studio](https://developer.android.com/studio)
- Check out the latest code from GitHub via Android Studio
- Install SDKs and Gradle if you get asked
- Click on ""Build Variants"" on the left side and change the build variant of the module ""mobile"" to ""fullStableDebug"".

You are ready to contribute!

Before producing any amount of code please have a look at [contribution guidelines](CONTRIBUTING.md)

## Build flavors

An optional build flavor ""foss"" is available for distribution through F-Droid. This build has FCM and crash reporting removed and will not be able to receive push notifications from openHAB Cloud.

For using map view support in the ""full"" build flavor, you need to visit the [Maps API page](https://developers.google.com/maps/android) and generate an API key via the 'Get a key' button at the top. Then add a line in the following format to the 'gradle.properties' file (either in the same directory as this readme file, or in $HOME/.gradle): `mapsApiKey=<key>`, replacing `<key>` with the API key you just obtained.

## Trademark Disclaimer

Product names, logos, brands and other trademarks referred to within the openHAB website are the property of their respective trademark holders. These trademark holders are not affiliated with openHAB or our website. They do not sponsor or endorse our materials.

Google Play and the Google Play logo are trademarks of Google Inc.
","The openHAB client for Android is developed using Android Studio. It allows easy
access to your sitemaps. Users can change items via NFC tags and send voice
commands. The app has FCM and FDroid flavors for distribution through F-Droid.
It is available on Google Play in flavors ""fossoss"" and ""full flavor"" The app is
free to download and use, but it is not yet available for public distribution.
For confidential support call the Samaritans on 08457 90 90 90, visit a local
Samaritans branch or see www.samaritans.org."
2907,Embedded language for high-performance array computations,"<div align=""center"">
<img width=""450"" src=""https://github.com/AccelerateHS/accelerate/raw/master/images/accelerate-logo-text-v.png?raw=true"" alt=""henlo, my name is Theia""/>

# High-performance parallel arrays for Haskell

[![CI-Linux](https://github.com/tmcdonell/accelerate/workflows/ci-linux/badge.svg)](https://github.com/tmcdonell/accelerate/actions?query=workflow%3Aci-linux)
[![CI-MacOS](https://github.com/tmcdonell/accelerate/workflows/ci-macos/badge.svg)](https://github.com/tmcdonell/accelerate/actions?query=workflow%3Aci-macos)
[![CI-Windows](https://github.com/tmcdonell/accelerate/workflows/ci-windows/badge.svg)](https://github.com/tmcdonell/accelerate/actions?query=workflow%3Aci-windows)
[![Gitter](https://img.shields.io/gitter/room/nwjs/nw.js.svg)](https://gitter.im/AccelerateHS/Lobby)
<br>
[![Stackage LTS](https://stackage.org/package/accelerate/badge/lts)](https://stackage.org/lts/package/accelerate)
[![Stackage Nightly](https://stackage.org/package/accelerate/badge/nightly)](https://stackage.org/nightly/package/accelerate)
[![Hackage](https://img.shields.io/hackage/v/accelerate.svg)](https://hackage.haskell.org/package/accelerate)

</div>

`Data.Array.Accelerate` defines an embedded language of array computations for high-performance computing in Haskell. Computations on multi-dimensional, regular arrays are expressed in the form of parameterised collective operations (such as maps, reductions, and permutations). These computations are online-compiled and executed on a range of architectures.

For more details, see our papers:

 * [Accelerating Haskell Array Codes with Multicore GPUs][CKLM+11]
 * [Optimising Purely Functional GPU Programs][MCKL13] ([slides][MCKL13-slides])
 * [Embedding Foreign Code][CMCK14]
 * [Type-safe Runtime Code Generation: Accelerate to LLVM][MCGN15] ([slides][MCGN15-slides]) ([video][MCGN15-video])
 * [Streaming Irregular Arrays][CMCK17] ([video][CMCK17-video])

There are also slides from some fairly recent presentations:

 * [Embedded Languages for High-Performance Computing in Haskell][Embedded]
 * [GPGPU Programming in Haskell with Accelerate][YLJ13-slides] ([video][YLJ13-video]) ([workshop][YLJ13-workshop])

Chapter 6 of Simon Marlow's book [Parallel and Concurrent Programming in Haskell][Mar13] contains a tutorial introduction to Accelerate.

[Trevor's PhD thesis][Trevor-thesis] details the design and implementation of frontend optimisations and CUDA backend.


**Table of Contents**

- [An Embedded Language for Accelerated Array Computations](#an-embedded-language-for-accelerated-array-computations)
  - [A simple example](#a-simple-example)
  - [Availability](#availability)
  - [Additional components](#additional-components)
  - [Requirements](#requirements)
  - [Documentation](#documentation)
  - [Examples](#examples)
  - [Who are we?](#who-are-we)
  - [Mailing list and contacts](#mailing-list-and-contacts)
  - [Citing Accelerate](#citing-accelerate)
  - [What's missing?](#whats-missing)

A simple example
----------------

As a simple example, consider the computation of a dot product of two vectors of single-precision floating-point numbers:

    dotp :: Acc (Vector Float) -> Acc (Vector Float) -> Acc (Scalar Float)
    dotp xs ys = fold (+) 0 (zipWith (*) xs ys)

Except for the type, this code is almost the same as the corresponding Haskell code on lists of floats. The types indicate that the computation may be online-compiled for performance; for example, using `Data.Array.Accelerate.LLVM.PTX.run` it may be on-the-fly off-loaded to a GPU.

Availability
------------

Package accelerate is available from

 * Hackage: [accelerate][Hackage] - install with `cabal install accelerate`
 * GitHub: [AccelerateHS/accelerate][GitHub] - get the source with `git clone https://github.com/AccelerateHS/accelerate.git`. The easiest way to compile the source distributions is via the Haskell [stack](https://docs.haskellstack.org/en/stable/README/) tool.

Additional components
---------------------

The following supported add-ons are available as separate packages:

  * [accelerate-llvm-native][accelerate-llvm-native]: Backend targeting multicore CPUs
  * [accelerate-llvm-ptx][accelerate-llvm-ptx]: Backend targeting CUDA-enabled NVIDIA GPUs. Requires a GPU with compute capability 2.0 or greater (see the [table on Wikipedia][wiki-cc])
  * [accelerate-examples][accelerate-examples]: Computational kernels and applications showcasing the use of Accelerate as well as a regression test suite (supporting function and performance testing)
  * Conversion between various formats:
    * [accelerate-io](https://hackage.haskell.org/package/accelerate-io): For copying data directly between raw pointers
    * [accelerate-io-array](https://hackage.haskell.org/package/accelerate-io-array): Immutable arrays
    * [accelerate-io-bmp](https://hackage.haskell.org/package/accelerate-io-bmp): Uncompressed BMP image files
    * [accelerate-io-bytestring](https://hackage.haskell.org/package/accelerate-io-bytestring): Compact, immutable binary data
    * [accelerate-io-cereal](https://hackage.haskell.org/package/accelerate-io-cereal): Binary serialisation of arrays using [cereal](https://hackage.haskell.org/package/cereal)
    * [accelerate-io-JuicyPixels](https://hackage.haskell.org/package/accelerate-io-JuicyPixels): Images in various pixel formats
    * [accelerate-io-repa](https://hackage.haskell.org/package/accelerate-io-repa): Another Haskell library for high-performance parallel arrays
    * [accelerate-io-serialise](https://hackage.haskell.org/package/accelerate-io-serialise): Binary serialisation of arrays using [serialise](https://hackage.haskell.org/package/serialise)
    * [accelerate-io-vector](https://hackage.haskell.org/package/accelerate-io-vector): Efficient boxed and unboxed one-dimensional arrays
  * [accelerate-fft][accelerate-fft]: Fast Fourier transform implementation, with FFI bindings to optimised implementations
  * [accelerate-blas][accelerate-blas]: BLAS and LAPACK operations, with FFI bindings to optimised implementations
  * [accelerate-bignum][accelerate-bignum]: Fixed-width large integer arithmetic
  * [colour-accelerate][colour-accelerate]: Colour representations in Accelerate (RGB, sRGB, HSV, and HSL)
  * [containers-accelerate](http://hackage.haskell.org/package/containers-accelerate): Hashing-based container types
  * [gloss-accelerate][gloss-accelerate]: Generate [gloss][gloss] pictures from Accelerate
  * [gloss-raster-accelerate][gloss-raster-accelerate]: Parallel rendering of raster images and animations
  * [hashable-accelerate](http://hackage.haskell.org/package/hashable-accelerate): A class for types which can be converted into a hash value
  * [lens-accelerate][lens-accelerate]: [Lens][lens] operators for Accelerate types
  * [linear-accelerate][linear-accelerate]: [Linear][linear] vector spaces in Accelerate
  * [mwc-random-accelerate][mwc-random-accelerate]: Generate Accelerate arrays filled with high quality pseudorandom numbers
  * [numeric-prelude-accelerate][numeric-prelude-accelerate]: Lifting the [numeric-prelude][numeric-prelude] to Accelerate
  * [wigner-ville-accelerate](https://github.com/Haskell-mouse/wigner-ville-accelerate): Wigner-Ville time-frequency distribution.

Install them from Hackage with `cabal install PACKAGENAME`.


Documentation
-------------

  * Haddock documentation is included and linked with the individual package releases on [Hackage][Hackage].
  * Haddock documentation for in-development components can be found [here](http://tmcdonell-bot.github.io/accelerate-travis-buildbot/).
  * The idea behind the HOAS (higher-order abstract syntax) to de-Bruijn conversion used in the library is [described separately][HOAS-conv].

Examples
--------

### accelerate-examples

The [accelerate-examples][accelerate-examples] package provides a range of computational kernels and a few complete applications. To install these from Hackage, issue `cabal install accelerate-examples`. The examples include:

  * An implementation of [canny edge detection][wiki-canny]
  * An interactive [mandelbrot set][wiki-mandelbrot] generator
  * An [N-body simulation][wiki-nbody] of gravitational attraction between solid particles
  * An implementation of the [PageRank][wiki-pagerank] algorithm
  * A simple [ray-tracer][wiki-raytracing]
  * A particle based simulation of stable fluid flows
  * A cellular automata simulation
  * A ""password recovery"" tool, for dictionary lookup of MD5 hashes

[![Mandelbrot](https://i.imgur.com/5Tbsp1j.jpg ""accelerate-mandelbrot"")](https://i.imgur.com/RgXRqsc.jpg)
[![Raytracer](https://i.imgur.com/7ohhKm9.jpg ""accelerate-ray"")](https://i.imgur.com/ZNEGEJK.jpg)

<!--
<video width=400 height=300 controls=false autoplay loop>
  <source=""http://www.cse.unsw.edu.au/~tmcdonell/images/ray.mp4"" type=""video/mp4"">
</video>
-->


### LULESH

[LULESH-accelerate][lulesh-accelerate] is in implementation of the Livermore Unstructured Lagrangian Explicit Shock Hydrodynamics (LULESH) mini-app. [LULESH][LULESH] represents a typical hydrodynamics code such as [ALE3D][ALE3D], but is a highly simplified application, hard-coded to solve the Sedov blast problem on an unstructured hexahedron mesh.

![LULESH mesh](https://i.imgur.com/bIkODKd.jpg)


### Additional examples

Accelerate users have also built some substantial applications of their own.
Please feel free to add your own examples!

  * Jonathan Fraser, [GPUVAC](https://github.com/GeneralFusion/gpuvac): An explicit advection magnetohydrodynamics simulation
  * David van Balen, [Sudokus](https://github.com/dpvanbalen/Sudokus): A sudoku solver
  * Trevor L. McDonell, [lol-accelerate][lol-accelerate]: A backend to the Λ ○ λ ([Lol][lol]) library for ring-based lattice cryptography
  * Henning Thielemann, [patch-image](http://hackage.haskell.org/package/patch-image): Combine a collage of overlapping images
  * apunktbau, [bildpunkt](https://github.com/abau/bildpunkt): A ray-marching distance field renderer
  * klarh, [hasdy](https://github.com/klarh/hasdy): Molecular dynamics in Haskell using Accelerate
  * Alexandros Gremm used Accelerate as part of the [2014 CSCS summer school](http://user.cscs.ch/blog/2014/cscs_usi_summer_school_2014_30_june_10_july_2014_in_serpiano_tessin/index.html) ([code](https://github.com/agremm/cscs))


Who are we?
-----------

The Accelerate team (past and present) consists of:

  * Manuel M T Chakravarty ([@mchakravarty])  <!-- 2008..2017? -->
  * Gabriele Keller ([@gckeller])             <!-- 2008..     -->
  * Trevor L. McDonell ([@tmcdonell])         <!-- 2009..     -->
  * Robert Clifton-Everest ([@robeverest])    <!-- 2013..     -->
  * Frederik M. Madsen ([@fmma])              <!-- 2014       -->
  * Ryan R. Newton ([@rrnewton])              <!-- 2012..2013 -->
  * Joshua Meredith ([@JoshMeredith])         <!-- 2018..     -->
  * Ben Lever ([@blever])                     <!-- 2010..2011 -->
  * Sean Seefried ([@sseefried])              <!-- 2010..2011 -->
  * Ivo Gabe de Wolff ([@ivogabe])            <!-- 2019..     -->

The maintainer and principal developer of Accelerate is Trevor L.
McDonell <trevor.mcdonell@gmail.com>.


Mailing list and contacts
-------------------------

  * Mailing list: [`accelerate-haskell@googlegroups.com`](mailto:accelerate-haskell@googlegroups.com) (discussions on both use and development are welcome)
  * Sign up for the mailing list at the [Accelerate Google Groups page][Google-Group]
  * Bug reports and issues tracking: [GitHub project page][Issues]
  * Chat with us on [gitter](https://gitter.im/AccelerateHS/Lobby)


Citing Accelerate
-----------------

If you use Accelerate for academic research, you are encouraged (though not
required) to cite the following papers:
<!-- ([BibTeX](http://www.cse.unsw.edu.au/~tmcdonell/papers/accelerate.bib)): -->

  * Manuel M. T. Chakravarty, Gabriele Keller, Sean Lee, Trevor L. McDonell, and Vinod Grover.
    [Accelerating Haskell Array Codes with Multicore GPUs][CKLM+11].
    In _DAMP '11: Declarative Aspects of Multicore Programming_, ACM, 2011.

  * Trevor L. McDonell, Manuel M. T. Chakravarty, Gabriele Keller, and Ben Lippmeier.
    [Optimising Purely Functional GPU Programs][MCKL13].
    In _ICFP '13: The 18th ACM SIGPLAN International Conference on Functional Programming_, ACM, 2013.

  * Robert Clifton-Everest, Trevor L. McDonell, Manuel M. T. Chakravarty, and Gabriele Keller.
    [Embedding Foreign Code][CMCK14].
    In _PADL '14: The 16th International Symposium on Practical Aspects of Declarative Languages_, Springer-Verlag, LNCS, 2014.

  * Trevor L. McDonell, Manuel M. T. Chakravarty, Vinod Grover, and Ryan R. Newton.
    [Type-safe Runtime Code Generation: Accelerate to LLVM][MCGN15].
    In _Haskell '15: The 8th ACM SIGPLAN Symposium on Haskell_, ACM, 2015.

  * Robert Clifton-Everest, Trevor L. McDonell, Manuel M. T. Chakravarty, and Gabriele Keller.
    [Streaming Irregular Arrays][CMCK17].
    In Haskell '17: The 10th ACM SIGPLAN Symposium on Haskell, ACM, 2017.


Accelerate is primarily developed by academics, so citations matter a lot to us.
As an added benefit, you increase Accelerate's exposure and potential user (and
developer!) base, which is a benefit to all users of Accelerate. Thanks in advance!


What's missing?
---------------

Here is a list of features that are currently missing:

 * Preliminary API (parts of the API may still change in subsequent releases)
 * Many more features... contact us!

  [@mchakravarty]:              https://github.com/mchakravarty
  [@gckeller]:                  https://github.com/gckeller
  [@tmcdonell]:                 https://github.com/tmcdonell
  [@robeverest]:                https://github.com/robeverest
  [@fmma]:                      https://github.com/fmma
  [@rrnewton]:                  https://github.com/rrnewton
  [@JoshMeredith]:              https://github.com/JoshMeredith
  [@blever]:                    https://github.com/blever
  [@sseefried]:                 https://github.com/sseefried
  [@ivogabe]:                   https://github.com/ivogabe

  [CKLM+11]:                    https://github.com/tmcdonell/tmcdonell.github.io/raw/master/papers/acc-cuda-damp2011.pdf
  [MCKL13]:                     https://github.com/tmcdonell/tmcdonell.github.io/raw/master/papers/acc-optim-icfp2013.pdf
  [MCKL13-slides]:              https://speakerdeck.com/tmcdonell/optimising-purely-functional-gpu-programs
  [CMCK14]:                     https://github.com/tmcdonell/tmcdonell.github.io/raw/master/papers/acc-ffi-padl2014.pdf
  [MCGN15]:                     https://github.com/tmcdonell/tmcdonell.github.io/raw/master/papers/acc-llvm-haskell2015.pdf
  [MCGN15-slides]:              https://speakerdeck.com/tmcdonell/type-safe-runtime-code-generation-accelerate-to-llvm
  [MCGN15-video]:               https://www.youtube.com/watch?v=snXhXA5noVc
  [HIW'09]:                     https://wiki.haskell.org/HaskellImplementorsWorkshop
  [CMCK17]:                     https://github.com/tmcdonell/tmcdonell.github.io/raw/master/papers/acc-seq2-haskell2017.pdf
  [CMCK17-video]:               https://www.youtube.com/watch?v=QIWSqp7AaNo
  [Mar13]:                      http://chimera.labs.oreilly.com/books/1230000000929
  [Embedded]:                   https://speakerdeck.com/mchakravarty/embedded-languages-for-high-performance-computing-in-haskell
  [Hackage]:                    http://hackage.haskell.org/package/accelerate
  [accelerate-cuda]:            https://github.com/AccelerateHS/accelerate-cuda
  [accelerate-examples]:        https://github.com/AccelerateHS/accelerate-examples
  [accelerate-io]:              https://github.com/AccelerateHS/accelerate-io
  [accelerate-fft]:             https://github.com/AccelerateHS/accelerate-fft
  [accelerate-blas]:            https://github.com/tmcdonell/accelerate-blas
  [accelerate-backend-kit]:     https://github.com/AccelerateHS/accelerate-backend-kit
  [accelerate-buildbot]:        https://github.com/AccelerateHS/accelerate-buildbot
  [accelerate-repa]:            https://github.com/blambo/accelerate-repa
  [accelerate-opencl]:          https://github.com/hiPERFIT/accelerate-opencl
  [accelerate-cabal]:           https://github.com/AccelerateHS/accelerate/accelerate.cabal
  [accelerate-cuda-cabal]:      https://github.com/AccelerateHS/accelerate-cuda/accelerate-cuda.cabal
  [accelerate-llvm]:            https://github.com/AccelerateHS/accelerate-llvm
  [accelerate-llvm-native]:     https://github.com/AccelerateHS/accelerate-llvm
  [accelerate-llvm-ptx]:        https://github.com/AccelerateHS/accelerate-llvm
  [accelerate-bignum]:          https://github.com/tmcdonell/accelerate-bignum
  [GitHub]:                     https://github.com/AccelerateHS/accelerate
  [Wiki]:                       https://github.com/AccelerateHS/accelerate/wiki
  [Issues]:                     https://github.com/AccelerateHS/accelerate/issues
  [Google-Group]:               http://groups.google.com/group/accelerate-haskell
  [HOAS-conv]:                  https://github.com/mchakravarty/hoas-conv
  <!-- [HOAS-conv]:                  https://web.archive.org/web/20180805092417/http://www.cse.unsw.edu.au/~chak/haskell/term-conv/ -->
  [repa]:                       http://hackage.haskell.org/package/repa
  [wiki-cc]:                    https://en.wikipedia.org/wiki/CUDA#Supported_GPUs
  [YLJ13-video]:                http://youtu.be/ARqE4yT2Z0o
  [YLJ13-slides]:               https://speakerdeck.com/tmcdonell/gpgpu-programming-in-haskell-with-accelerate
  [YLJ13-workshop]:             https://speakerdeck.com/tmcdonell/gpgpu-programming-in-haskell-with-accelerate-workshop
  [wiki-canny]:                 https://en.wikipedia.org/wiki/Canny_edge_detector
  [wiki-mandelbrot]:            https://en.wikipedia.org/wiki/Mandelbrot_set
  [wiki-nbody]:                 https://en.wikipedia.org/wiki/N-body
  [wiki-raytracing]:            https://en.wikipedia.org/wiki/Ray_tracing
  [wiki-pagerank]:              https://en.wikipedia.org/wiki/Pagerank
  [Trevor-thesis]:              https://github.com/tmcdonell/tmcdonell.github.io/raw/master/papers/TrevorMcDonell_PhD_Thesis.pdf
  [colour-accelerate]:          https://github.com/tmcdonell/colour-accelerate
  [gloss]:                      https://hackage.haskell.org/package/gloss
  [gloss-accelerate]:           https://github.com/tmcdonell/gloss-accelerate
  [gloss-raster-accelerate]:    https://github.com/tmcdonell/gloss-raster-accelerate
  [lens]:                       https://hackage.haskell.org/package/lens
  [lens-accelerate]:            https://github.com/tmcdonell/lens-accelerate
  [linear]:                     https://hackage.haskell.org/package/linear
  [linear-accelerate]:          https://github.com/tmcdonell/linear-accelerate
  [mwc-random-accelerate]:      https://github.com/tmcdonell/mwc-random-accelerate
  [numeric-prelude]:            https://hackage.haskell.org/package/numeric-prelude
  [numeric-prelude-accelerate]: https://github.com/tmcdonell/numeric-prelude-accelerate
  [LULESH]:                     https://codesign.llnl.gov/lulesh.php
  [ALE3D]:                      https://wci.llnl.gov/simulation/computer-codes/ale3d
  [lulesh-accelerate]:          https://github.com/tmcdonell/lulesh-accelerate
  [lol]:                        https://hackage.haskell.org/package/lol
  [lol-accelerate]:             https://github.com/tmcdonell/lol-accelerate

","Accelerate defines an embedded language of array computations for high-
performance computing in Haskell. Computations on multi-dimensional, regular
arrays are expressed in the form of parameterised collective operations (such as
maps, reductions, and permutations) These computations are online-compiled and
executed on a range of architectures."
2218,"Pika is a nosql compatible with redis, it is developed by Qihoo's DBA and infrastructure team","<img src=""https://s1.ax1x.com/2020/05/08/YnbjQf.png"" alt=""YnbjQf.png""  width=""300"" />

[![Build Status](https://travis-ci.org/Qihoo360/pika.svg?branch=master)](https://travis-ci.org/Qihoo360/pika) ![Downloads](https://img.shields.io/github/downloads/Qihoo360/pika/total)

## Introduction[中文](https://github.com/Qihoo360/pika/blob/master/README_CN.md)

Pika is a persistent huge storage service , compatible  with the vast majority of redis interfaces ([details](https://github.com/Qihoo360/pika/wiki/pika-支持的redis接口及兼容情况)), including string, hash, list, zset, set and management interfaces. With the huge amount of data stored, redis may suffer for a capacity bottleneck, and pika was born for solving it. Except huge storage capacity, pika also support master-slave mode by slaveof command, including full and partial synchronization. You can also use pika together with twemproxy or codis(*pika has supported data migration in codis，thanks [left2right](https://github.com/left2right) and [fancy-rabbit](https://github.com/fancy-rabbit)*) for distributed Redis solution


## UserList

<table>
<tr>
<td height = ""100"" width = ""150""><img src=""http://i.imgur.com/dcHpCm4.png"" alt=""Qihoo""></td>
<td height = ""100"" width = ""150""><img src=""https://i.imgur.com/BIjqe9R.jpg"" alt=""360game""></td>
<td height = ""100"" width = ""150""><img src=""http://i.imgur.com/jjZczkN.png"" alt=""Weibo""></td>
<td height = ""100"" width = ""150""><img src=""http://i.imgur.com/zoel46r.gif"" alt=""Garena""></td>
</tr>
<tr>
<td height = ""100"" width = ""150""><img src=""http://i.imgur.com/kHqACbn.png"" alt=""Apus""></td>
<td height = ""100"" width = ""150""><img src=""http://i.imgur.com/2c57z8U.png"" alt=""Ffan""></td>
<td height = ""100"" width = ""150""><img src=""http://i.imgur.com/rUiO5VU.png"" alt=""Meituan""></td>
<td height = ""100"" width = ""150""><img src=""http://i.imgur.com/px5mEuW.png"" alt=""XES""></td>
</tr>
<tr>
<td height = ""100"" width = ""150""><img src=""http://imgur.com/yJe4FP8.png"" alt=""HX""></td>
<td height = ""100"" width = ""150""><img src=""http://i.imgur.com/o8ZDXCH.png"" alt=""XL""></td>
<td height = ""100"" width = ""150""><img src=""http://imgur.com/w3qNQ9T.png"" alt=""GWD""></td>
<td height = ""100"" width = ""150""><img src=""https://imgur.com/KMVr3Z6.png"" alt=""DYD""></td>
</tr>
<tr>
<td height = ""100"" width = ""150""><img src=""http://i.imgur.com/vJbAfri.png"" alt=""YM""></td>
<td height = ""100"" width = ""150""><img src=""http://i.imgur.com/aNxzwsY.png"" alt=""XM""></td>
<td height = ""100"" width = ""150""><img src=""http://i.imgur.com/mrWxwkF.png"" alt=""XL""></td>
<td height = ""100"" width = ""150""><img src=""http://imgur.com/0oaVKlk.png"" alt=""YM""></td>
</tr>
<tr>
<td height = ""100"" width = ""150""><img src=""https://i.imgur.com/PI89mec.png"" alt=""MM""></td>
<td height = ""100"" width = ""150""><img src=""https://i.imgur.com/G9MOvZe.jpg"" alt=""VIP""></td>
<td height = ""100"" width = ""150""><img src=""https://imgur.com/vQW5qr3.png"" alt=""LK""></td>
<td height = ""100"" width = ""150""><img src=""https://i.imgur.com/jIMG4mi.jpg"" alt=""KS""></td>
</tr>
</table>

[More](docs/USERS.md)

## Feature

* huge storage capacity
* compatible with redis interface, you can migrate to pika easily
* support master-slave mode (slaveof)
* various [management](https://github.com/Qihoo360/pika/wiki/pika的一些管理命令方式说明) interfaces

## For developer

### Releases
The User can download the binary release from [releases](https://github.com/Qihoo360/pika/releases) or compile the source release.

### Dependencies

* snappy - a library for fast data compression
* glog - google log library

Upgrade your gcc to version at least 4.8 to get C++11 support.

### Supported platforms

* linux - CentOS 6&7

* linux - Ubuntu

If it comes to some missing libs, install them according to the prompts and retry it.

### Compile

Upgrade your gcc to version at least 4.8 to get C++11 support.

Get the source code

```
git clone https://github.com/Qihoo360/pika.git

git submodule init
git submodule update
```


Then compile pika, all submodules will be updated automatically.

```
make
```

## Usage

```
./output/bin/pika -c ./conf/pika.conf
```

## Performance

More details on [Performance](docs/benchmark/performance.md).


## Documents

1. [doc](docs/catalogue.md)


## Contact Us


QQ group: 294254078

","Pika is a persistent huge storage service. compatible with the vast majority of
redis interfaces. You can also use pika together with twemproxy or codis. Pika
has supported data migration in codis thanks to [left2right] and [fancy-rabbit.
It is a distributed Redis solution for distributed data storage. It has huge
storage capacity, including master-slave mode by slaveof command, including full
and partial synchronization. It can also be used to store large amounts of data
at once."
2488,Frustum PointNets for 3D Object Detection from RGB-D Data,"## Frustum PointNets for 3D Object Detection from RGB-D Data
Created by <a href=""http://charlesrqi.com"" target=""_blank"">Charles R. Qi</a>, <a href=""http://www.cs.unc.edu/~wliu/"" target=""_black"">Wei Liu</a>, <a href=""http://www.cs.cornell.edu/~chenxiawu/"" target=""_blank"">Chenxia Wu</a>, <a href=""http://cseweb.ucsd.edu/~haosu/"" target=""_blank"">Hao Su</a> and <a href=""http://geometry.stanford.edu/member/guibas/"" target=""_blank"">Leonidas J. Guibas</a> from <a href=""http://www.stanford.edu"" target=""_blank"">Stanford University</a> and <a href=""http://nuro.ai"" target=""_blank"">Nuro Inc.</a>

![teaser](https://github.com/charlesq34/frustum-pointnets/blob/master/doc/teaser.jpg)

## Introduction
This repository is code release for our CVPR 2018 paper (arXiv report [here](https://arxiv.org/abs/1711.08488)). In this work, we study 3D object detection from RGB-D data. We propose a novel detection pipeline that combines both mature 2D object detectors and the state-of-the-art 3D deep learning techniques. In our pipeline, we firstly build object proposals with a 2D detector running on RGB images, where each 2D bounding box defines a 3D frustum region. Then based on 3D point clouds in those frustum regions, we achieve 3D instance segmentation and amodal 3D bounding box estimation, using PointNet/PointNet++ networks (see references at bottom).

By leveraging 2D object detectors, we greatly reduce 3D search space for object localization. The high resolution and rich texture information in images also enable high recalls for smaller objects like pedestrians or cyclists that are harder to localize by point clouds only. By adopting PointNet architectures, we are able to directly work on 3D point clouds, without the necessity to voxelize them to grids or to project them to image planes. Since we directly work on point clouds, we are able to fully respect and exploit the 3D geometry -- one example is the series of coordinate normalizations we apply, which help canocalizes the learning problem. Evaluated on KITTI and SUNRGBD benchmarks, our system significantly outperforms previous state of the art and is still in leading positions on current <a href=""http://www.cvlibs.net/datasets/kitti/eval_object.php?obj_benchmark=3d"">KITTI leaderboard</a>.

For more details of our architecture, please refer to our paper or <a href=""http://stanford.edu/~rqi/frustum-pointnets"" target=""_blank"">project website</a>.

## Citation
If you find our work useful in your research, please consider citing:

        @article{qi2017frustum,
          title={Frustum PointNets for 3D Object Detection from RGB-D Data},
          author={Qi, Charles R and Liu, Wei and Wu, Chenxia and Su, Hao and Guibas, Leonidas J},
          journal={arXiv preprint arXiv:1711.08488},
          year={2017}
        }

## Installation
Install <a href=""https://www.tensorflow.org/install/"">TensorFlow</a>.There are also some dependencies for a few Python libraries for data processing and visualizations like `cv2`, `mayavi`  etc. It's highly recommended that you have access to GPUs.

To use the Frustum PointNets v2 model, we need access to a few custom Tensorflow operators from PointNet++. The TF operators are included under `models/tf_ops`, you need to compile them (check `tf_xxx_compile.sh` under each ops subfolder) first. Update `nvcc` and `python` path if necessary. The compile script is written for TF1.4. There is also an option for TF1.2 in the script. If you are using earlier version it's possible that you need to remove the `-D_GLIBCXX_USE_CXX11_ABI=0` flag in g++ command in order to compile correctly.

If we want to evaluate 3D object detection AP (average precision), we need also to compile the evaluation code (by running `compile.sh` under `train/kitti_eval`). Check `train/kitti_eval/README.md` for details.

Some of the demos require `mayavi` library. We have provided a convenient script to install `mayavi` package in Python, a handy package for 3D point cloud visualization. You can check it at `mayavi/mayavi_install.sh`. If the installation succeeds, you should be able to run `mayavi/test_drawline.py` as a simple demo. Note: the library works for local machines and seems do not support remote access with `ssh` or `ssh -X`.

The code is tested under TF1.2 and TF1.4 (GPU version) and Python 2.7 (version 3 should also work) on Ubuntu 14.04 and Ubuntu 16.04 with NVIDIA GTX 1080 GPU. It is highly recommended to have GPUs on your machine and it is required to have at least 8GB available CPU memory.

## Usage

Currently, we support training and testing of the Frustum PointNets models as well as evaluating 3D object detection results based on precomputed 2D detector outputs (under `kitti/rgb_detections`). You are welcomed to extend the code base to support your own 2D detectors or feed your own data for network training.

### Prepare Training Data
In this step we convert original KITTI data to organized formats for training our Frustum PointNets. <b>NEW:</b> You can also directly download the prepared data files <a href=""https://shapenet.cs.stanford.edu/media/frustum_data.zip"" target=""_blank"">HERE (960MB)</a> -- to support training and evaluation, just unzip the file and move the `*.pickle` files to the `kitti` folder.

Firstly, you need to download the <a href=""http://www.cvlibs.net/datasets/kitti/eval_object.php?obj_benchmark=3d"" target=""_blank"">KITTI 3D object detection dataset</a>, including left color images, Velodyne point clouds, camera calibration matrices, and training labels. Make sure the KITTI data is organized as required in `dataset/README.md`. You can run `python kitti/kitti_object.py` to see whether data is downloaded and stored properly. If everything is fine, you should see image and 3D point cloud visualizations of the data. 

Then to prepare the data, simply run: (warning: this step will generate around 4.7GB data as pickle files)

    sh scripts/command_prep_data.sh

Basically, during this process, we are extracting frustum point clouds along with ground truth labels from the original KITTI data, based on both ground truth 2D bounding boxes and boxes from a 2D object detector. We will do the extraction for the train (`kitti/image_sets/train.txt`) and validation set (`kitti/image_sets/val.txt`) using ground truth 2D boxes, and also extract data from validation set with predicted 2D boxes (`kitti/rgb_detections/rgb_detection_val.txt`).

You can check `kitti/prepare_data.py` for more details, and run `python kitti/prepare_data.py --demo` to visualize the steps in data preparation.

After the command executes, you should see three newly generated data files under the `kitti` folder. You can run `python train/provider.py` to visualize the training data (frustum point clouds and 3D bounding box labels, in rect camera coordinate).

### Training Frustum PointNets

To start training (on GPU 0) the Frustum PointNets model, just run the following script:

    CUDA_VISIBLE_DEVICES=0 sh scripts/command_train_v1.sh

You can run `scripts/command_train_v2.sh` to trian the v2 model as well. The training statiscs and checkpoints will be stored at `train/log_v1` (or `train/log_v2` if it is a v2 model). Run `python train/train.py -h` to see more options of training. 

<b>NEW:</b> We have also prepared some pretrained snapshots for both the v1 and v2 models. You can find them <a href=""https://shapenet.cs.stanford.edu/media/frustum_pointnets_snapshots.zip"" target=""_blank"">HERE (40MB)</a> -- to support evaluation script, you just need to unzip the file and move the `log_*` folders to the `train` folder.

### Evaluation
To evaluate a trained model (assuming you already finished the previous training step) on the validation set, just run:

    CUDA_VISIBLE_DEVICES=0 sh scripts/command_test_v1.sh

Similarly, you can run `scripts/command_test_v2.sh` to evaluate a trained v2 model. The script will automatically evaluate the Frustum PointNets on the validation set based on precomputed 2D bounding boxes from a 2D detector (not released here), and then run the KITTI offline evaluation scripts to compute precision recall and calcuate average precisions for 2D detection, bird's eye view detection and 3D detection.

Currently there is no script for evaluation on test set, yet it is possible to do it by yourself. To evaluate on the test set, you need to get outputs from a 2D detector on KITTI test set, store it as something in `kitti/rgb_detections`. Then, you need to prepare test set frustum point clouds for the test set, by modifying the code in `kitti/prepare_data.py`. Then you can modify test scripts in `scripts` by changing the data path, idx path and output file name. For our test set results reported, we used the entire `trainval` set for training.

## License
Our code is released under the Apache 2.0 license (see LICENSE file for details).

## References
* <a href=""http://stanford.edu/~rqi/pointnet"" target=""_blank"">PointNet: Deep Learning on Point Sets for 3D Classification and Segmentation</a> by Qi et al. (CVPR 2017 Oral Presentation). Code and data: <a href=""https://github.com/charlesq34/pointnet"">here</a>.
* <a href=""http://stanford.edu/~rqi/pointnet2"" target=""_black"">PointNet++: Deep Hierarchical Feature Learning on Point Sets in a Metric Space</a> by Qi et al. (NIPS 2017). Code and data: <a href=""https://github.com/charlesq34/pointnet2"">here</a>.

### Todo

- Add a demo script to run inference of Frustum PointNets based on raw input data.
- Add related scripts for SUNRGBD dataset
","This repository is code release for our CVPR 2018 paper. In this work, we study
3D object detection from RGB-D data. We propose a novel detection pipeline that
combines both mature 2D object detectors and the state-of-the-art 3D deep
learning techniques. By adopting PointNet architectures, we are able to directly
work on 3D point clouds, without the necessity to voxelize them to grids or to
project them to image planes. Evaluated on KITTI and SUNRGBD benchmarks, our
system significantly outperforms previous state of the art."
1796,A curated list of awesome privilege escalation,"# Awesome Privilege Escalation
A curated list of awesome privilege escalation

## Table of Contents

* [Linux](#linux)
    * [Escape restricted shells](#escape-restricted-shells)
    * [SUDO and SUID](#sudo-and-suid)
    * [Capabilities](#capabilities)
    * [Tools](#tools)
        * [Find CVEs](#find-cves)
    * [Chkrootkit](#chkrootkit)
    * [NFS](#nfs)
    * [Presentations](#presentations)
* [Windows](#windows)
    * [DLL Hijacking](#dll-hijacking)
    * [Potato](#potato)
    * [Unquoted services with spaces](#unquoted-services-with-spaces)
    * [Groups.xml](#groupsxml)
    * [Tools](#tools-1)
    * [Presentations](#presentations-1)
* [Linux and Windows](#linux-and-windows)
* [Docker](#docker)
    * [Tools](#tools-2)
    * [Presentations](#presentations-2)
* [Cloud](#cloud)
   * [AWS](#aws)
   * [GCP](#gcp)

## Linux
 - [A guide to Linux Privilege Escalation](https://payatu.com/guide-linux-privilege-escalation/)
 - [Attack and Defend: LinuxPrivilege Escalation Techniques of 2016](https://www.sans.org/reading-room/whitepapers/linux/attack-defend-linux-privilege-escalation-techniques-2016-37562): This paper will examine Linux privilege escalation techniques used throughout 2016 in detail, highlighting how these techniques work and how adversaries are using them.
 - [Back To The Future: Unix Wildcards Gone Wild](https://www.defensecode.com/public/DefenseCode_Unix_WildCards_Gone_Wild.txt): This article will cover one interesting old-school Unix hacking technique, that will still work in 2013.
 - [Basic Linux Privilege Escalation](https://blog.g0tmi1k.com/2011/08/basic-linux-privilege-escalation/): by g0tmi1k
 - [Enumeration is the Key](https://medium.com/basic-linux-privilege-escalation/basic-linux-privilege-escalation-966de11f9997): by Marcos Tolosa
 - [Hackers Hut](https://www.win.tue.nl/~aeb/linux/hh/hh.html): Some random hacking hints, mainly from a Linux point of view.
 - [Hacking Linux Part I: Privilege Escalation](http://www.dankalia.com/tutor/01005/0100501004.htm)
 - [How privileges work in operating systems?](https://www.future-processing.pl/blog/privilege-escalation/)
 - [Linux elevation of privileges ToC](https://guif.re/linuxeop)
 - [Linux - Privilege Escalation](https://github.com/swisskyrepo/PayloadsAllTheThings/blob/master/Methodology%20and%20Resources/Linux%20-%20Privilege%20Escalation.md): Methodology from PayloadsAllTheThings 
 - [Linux Privilege Escalation](https://percussiveelbow.github.io/linux-privesc/): an introduction to Linux escalation techniques, mainly focusing on file/process permissions, but along with some other stuff too.
 - [Linux Privilege Escalation](https://github.com/lamontns/pentest/blob/master/privilege-escalation/linux-privilege-escalation.md): Linux Privilege Escalation by lamontns.
 - [Linux Privilege Escalation](https://book.hacktricks.xyz/linux-unix/privilege-escalation): by HackTricks
 - [Linux Privilege Escalation via Dynamically Linked Shared Object Library](https://www.contextis.com/en/blog/linux-privilege-escalation-via-dynamically-linked-shared-object-library): How RPATH and Weak File Permissions can lead to a system compromise.
 - [Local Linux Enumeration & Privilege Escalation Cheatsheet](https://www.rebootuser.com/?p=1623): a few Linux commands that may come in useful when trying to escalate privileges on a target system.
 - [Local Linux Enumeration & Privilege Escalation](https://hackingandsecurity.blogspot.com/2016/05/local-linux-enumeration-privilege.html): a few Linux commands that may come in useful when trying to escalate privileges on a target system.
 - [Local Linux privilege escalation overview](https://myexperiments.io/linux-privilege-escalation.html): This article will give an overview of the basic Linux privilege escalation techniques. It separates the local Linux privilege escalation in different scopes: kernel, process, mining credentials, sudo, cron, NFS, and file permission.
 - [Penetration-Testing-Grimoire/Privilege Escalation/linux.md](https://github.com/weaknetlabs/Penetration-Testing-Grimoire/blob/master/Privilege%20Escalation/linux.md)
 - [PENETRATION TESTING PRACTICE LAB - VULNERABLE APPS / SYSTEMS](https://www.amanhardikar.com/mindmaps/Practice.html)
 - [Pentest Book - Privilege Escalation](https://chryzsh.gitbooks.io/pentestbook/privilege_escalation_-_linux.html): common Linux privilege escalation techniques.
 - [POST CATEGORY : Privilege Escalation](https://www.hackingarticles.in/category/privilege-escalation/): Privilege escalation post category in Raj Chandel's Blog.
 - [Privilege Escalation Cheatsheet (Vulnhub)](https://github.com/Ignitetechnologies/Privilege-Escalation): This cheasheet is aimed at the CTF Players and Beginners to help them understand the fundamentals of Privilege Escalation with examples.
 - [Privilege escalation: Linux](https://vulp3cula.gitbook.io/hackers-grimoire/post-exploitation/privesc-linux)
 - [Privilege Escalation & Post-Exploitation](https://github.com/rmusser01/Infosec_Reference/blob/master/Draft/PrivescPostEx.md)
 - [Reach the root! How to gain privileges in Linux?](https://hackmag.com/security/reach-the-root/)
 - [TTY Input Pushback Privilege Escalation](https://www.halfdog.net/Security/2012/TtyPushbackPrivilegeEscalation/): When user working as root switches to another user with su and happens to execute the pushback program as that user, the tty input data pushed back is executed in the shell and context of user root.
 - [Understanding Privilege Escalation](http://www.admin-magazine.com/Articles/Understanding-Privilege-Escalation): Some techniques malicious users employ to escalate their privileges on a Linux system.

### Escape restricted shells
 - [Breaking out of rbash using scp](http://pentestmonkey.net/blog/rbash-scp)
 - [Escaping from Restricted Shell and Gaining Root Access to SolarWinds Log & Event Manager (SIEM) Product](https://pentest.blog/unexpected-journey-4-escaping-from-restricted-shell-and-gaining-root-access-to-solarwinds-log-event-manager-siem-product/)
 - [Escaping Restricted Linux Shells](https://pen-testing.sans.org/blog/pen-testing/2012/06/06/escaping-restricted-linux-shells): Resource for penetration testers to assist them when confronted with a restricted shell.
 - [Linux Restricted Shell Bypass](https://www.exploit-db.com/docs/english/44592-linux-restricted-shell-bypass-guide.pdf)
 - [Restricted Linux Shell Escaping Techniques](https://fireshellsecurity.team/restricted-linux-shell-escaping-techniques/): The focus of this article is on discussing and summarizing different techniques to escape common Linux restricted shells and also simple recommendations for administrators to protect against it.

### SUDO and SUID
 - [Abusing SUDO](https://touhidshaikh.com/blog/?p=790): Some of the binary which helps you to escalate privilege using the sudo command.
 - [Gaining a Root shell using MySQL User Defined Functions and SETUID Binaries](https://infamoussyn.wordpress.com/2014/07/11/gaining-a-root-shell-using-mysql-user-defined-functions-and-setuid-binaries/): How a MySQL User Defined Function (UDF) and a SETUID binary can be used to elevate user privilege to a root shell.
 - [GTFOBins](https://gtfobins.github.io/): GTFOBins is a curated list of Unix binaries that can be exploited by an attacker to bypass local security restrictions.
 - [How I got root with Sudo](https://www.securusglobal.com/community/2014/03/17/how-i-got-root-with-sudo/)
 - [Sudo (LD_PRELOAD)](https://touhidshaikh.com/blog/?p=827): Privilege Escalation from an LD_PRELOAD environment variable. 

### Capabilities
 - [An Interesting Privilege Escalation vector (getcap/setcap)](https://nxnjz.net/2018/08/an-interesting-privilege-escalation-vector-getcap/)
 - [Capabilities](https://wiki.archlinux.org/index.php/Capabilities)
 - [Exploiting capabilities](http://blog.sevagas.com/IMG/pdf/exploiting_capabilities_the_dark_side.pdf): Parcel root power, the dark side of capabilities
 - [getcap, setcap and file capabilities](https://www.insecure.ws/linux/getcap_setcap.html)
 - [Spicing up your own access with capabilities](https://www.redpill-linpro.com/sysadvent/2016/12/06/spicing-up-your-access.html)

### Tools
 - [AutoLocalPrivilegeEscalation](https://github.com/ngalongc/AutoLocalPrivilegeEscalation): An automated script that download potential exploit for linux kernel from exploitdb, and compile them automatically.
 - [BeRoot](https://github.com/AlessandroZ/BeRoot): BeRoot Project is a post exploitation tool to check common misconfigurations to find a way to escalate our privilege.
exploits.
 - [exploit-suggester](https://github.com/pentestmonkey/exploit-suggester): This tool reads the output of “showrev -p” on Solaris machines and outputs a list of exploits that you might want to try.
is intended to be executed locally on a Linux box to enumerate basic system info and search for common privilege escalation vectors such as word writable files, misconfigurations, clear-text password and applicable
 - [kernelpop](https://github.com/spencerdodd/kernelpop): kernelpop is a framework for performing automated kernel vulnerability enumeration and exploitation.
 - [LES](https://github.com/mzet-/linux-exploit-suggester): LES: Linux privilege escalation auditing tool
 - [LinEnum](https://github.com/rebootuser/LinEnum): Scripted local Linux enumeration & privilege escalation checks
 - [LinPEAS](https://github.com/carlospolop/privilege-escalation-awesome-scripts-suite/tree/master/linPEAS): Linux Privilege Escalation Awesome Script
 - [Linux Exploit Suggester 2](https://github.com/jondonas/linux-exploit-suggester-2): Next-generation exploit suggester based on Linux_Exploit_Suggester
 - [Linux_Exploit_Suggester](https://github.com/InteliSecureLabs/Linux_Exploit_Suggester): Linux Exploit Suggester; based on operating system release number.
 - [linux-kernel-exploits](https://github.com/SecWiki/linux-kernel-exploits)
 - [Linuxprivchecker.py](https://github.com/sleventyeleven/linuxprivchecker): This script is intended to be executed locally on a Linux box to enumerate basic system info and search for common privilege escalation vectors such as world writable files, misconfigurations, clear-text passwords and applicable exploits.
 - [Linux Privilege Escalation Check Script](https://github.com/linted/linuxprivchecker): Originally forked from the linuxprivchecker.py (Mike Czumak), this script is intended to be executed locally on a Linux box to enumerate basic system info and search for common privilege escalation vectors such as word writable files, misconfigurations, clear-text password and applicable exploits.
 - [linux-smart-enumeration](https://github.com/diego-treitos/linux-smart-enumeration): Linux enumeration tools for pentesting and CTFs
 - [linux-soft-exploit-suggester](https://github.com/belane/linux-soft-exploit-suggester): linux-soft-exploit-suggester finds exploits for all vulnerable software in a system helping with the privilege escalation.
 - [PrivEsc](https://github.com/1N3/PrivEsc): A collection of Windows, Linux and MySQL privilege escalation scripts and exploits.
 - [pspy](https://github.com/DominicBreuker/pspy): unprivileged Linux process snooping
 - [traitor](https://github.com/liamg/traitor): Automatically exploit low-hanging fruit to pop a root shell. Linux privilege escalation made easy!
 - [unix-privesc-check](https://github.com/pentestmonkey/unix-privesc-check): Shell script to check for simple privilege escalation vectors on Unix systems
 - [Unix-Privilege-Escalation-Exploits-Pack](https://github.com/Kabot/Unix-Privilege-Escalation-Exploits-Pack): Exploits for getting local root on Linux, BSD, AIX, HP-UX, Solaris, RHEL, SUSE etc.
 - [uptux](https://github.com/initstring/uptux): Specialized privilege escalation checks for Linux systems.

#### Find CVEs
 - [active-cve-check](https://github.com/davbo/active-cve-check): Checks a list of packages against the ""active"" (not yet patched) CVE's as listed in the Ubuntu CVE Tracker.
 - [Arch-Audit](https://www.2daygeek.com/arch-audit-a-tool-to-check-vulnerable-packages-in-arch-linux/): A tool to check vulnerable packages in Arch Linux.
 - [cve-check-tool](https://github.com/clearlinux/cve-check-tool): Original Automated CVE Checking Tool.
 - [LPVS](https://github.com/lwindolf/lpvs): Linux Package Vulnerability Scanner for CentOS and Ubuntu.

### Chkrootkit
 - [Local root exploit in Chkrootkit](https://lepetithacker.wordpress.com/2017/04/30/local-root-exploit-in-chkrootkit/): Security researchers have found an local exploit for Chkrootkit 0.49 who allow to a simple user to make root’s commands.

### NFS
 - [Exploiting a Mis-Configured NFS Share](https://www.computersecuritystudent.com/SECURITY_TOOLS/METASPLOITABLE/EXPLOIT/lesson4/index.html)
 - [Linux Privilege Escalation using Misconfigured NFS](https://www.hackingarticles.in/linux-privilege-escalation-using-misconfigured-nfs/): How to exploit a misconfigured NFS share to gain root access to a remote host machine.
 - [NFS weak permissions](https://touhidshaikh.com/blog/?p=788)
 - [Linux Privilege Escalation using weak NFS permissions](https://haiderm.com/linux-privilege-escalation-using-weak-nfs-permissions/): t Linux Privilege Escalation using weak NFS permissions in “/etc/exports”. by Haider Mahmood

### Presentations
 - [Linux privilege escalation for fun, profit, and all around mischief](https://www.irongeek.com/i.php?page=videos/bsidesaugusta2016/its-too-funky-in-here04-linux-privilege-escalation-for-fun-profit-and-all-around-mischief-jake-williams): Examine opportunities for privilege escalation that can vault you from zero to hero in a few easy steps.
 - [Linux Privilege Escalation - Tradecraft Security Weekly #22](https://www.youtube.com/watch?v=oYHAi0cgur4): Methodology for performing various privilege escalation techniques against Linux-based systems.
 - [Privilege Escalation FTW](https://www.youtube.com/watch?v=yXe4X-AIbps): Demonstrate various privilege escalation techniques that are possible primarily due to misconfigurations.

## Windows
 - [awesome-windows-security](https://github.com/chryzsh/awesome-windows-security#-privilege-escalation)
 - [LOLBAS](https://lolbas-project.github.io/): Living Off The Land Binaries and Scripts (and also Libraries)
 - [OSCP Windows PrivEsc - Part 1](https://butter0verflow.github.io/oscp/OSCP-WindowsPrivEsc-Part1/)
 - [Privilege Escalation](https://www.offensive-security.com/metasploit-unleashed/privilege-escalation/): There are also various other (local) exploits that can be used to also escalate privileges.
 - [Privilege Escalation Windows](https://sushant747.gitbooks.io/total-oscp-guide/privilege_escalation_windows.html)
 - [Privilege escalation: Windows](https://vulp3cula.gitbook.io/hackers-grimoire/post-exploitation/privesc-windows)
 - [Windows elevation of privileges ToC](https://guif.re/windowseop)
 - [Windows Local Privilege Escalation](https://book.hacktricks.xyz/windows/windows-local-privilege-escalation): by HackTricks
 - [Windows Post Gather Modules](https://www.offensive-security.com/metasploit-unleashed/windows-post-gather-modules/): Metasploit offers a number of post exploitation modules that allow for further information gathering on your target network.
 - [Windows Priv Esc](https://www.sock-raw.org/wiki/doku.php/windows_priv_esc)
 - [Windows Privilege Escalation Fundamentals](https://www.fuzzysecurity.com/tutorials/16.html)
 - [Windows Privilege Escalation Guide](https://www.absolomb.com/2018-01-26-Windows-Privilege-Escalation-Guide/)
 - [Windows-Privilege-Escalation](https://github.com/frizb/Windows-Privilege-Escalation): Step-by-step windows privlege escalation methodology.
 - [Windows-Privilege-Escalation-Resources](https://github.com/Gr1mmie/Windows-Privilege-Escalation-Resources): Compilation of Resources from TCM's Windows Priv Esc Udemy Course. By Gr1mmie
 - [Windows - Privilege Escalation](https://github.com/swisskyrepo/PayloadsAllTheThings/blob/master/Methodology%20and%20Resources/Windows%20-%20Privilege%20Escalation.md)
 - [Windows Privilege Escalation](http://www.bhafsec.com/wiki/index.php/Windows_Privilege_Escalation)
 - [Windows Privilege Escalation](https://github.com/lamontns/pentest/blob/master/privilege-escalation/windows-privilege-escalation.md): Windows Privilege Escalation by lamontns.
 - [Windows Privilege Escalations](https://www.exploit-db.com/docs/46131)


### DLL Hijacking
 - [DLL Hijacking](https://ired.team/offensive-security/privilege-escalation/t1038-dll-hijacking): DLL Search Order Hijacking for privilege escalation, code execution, etc. by Red Teaming Experiments
 - [DLL Hijacking](https://pentestlab.blog/2017/03/27/dll-hijacking/): by PentestLab
 - [DLL Search Order Hijacking](https://attack.mitre.org/techniques/T1038/): by MITRE
 - [PrivEsc: DLL Hijacking](https://web.archive.org/web/20210805085547/https://gracefulsecurity.com/privesc-dll-hijacking/): by GracefulSecurity
 - [Windows Privilege Escalation via DLL Hijacking](https://web.archive.org/web/20200215215536/https://hacknpentest.com/windows-privilege-escalation-dll-hijacking/): Crystal-clear view on one of the most used techniques for privilege escalation by the Threat Actors. by HacknPentest


### Potato
 - [CertPotato](https://sensepost.com/blog/2022/certpotato-using-adcs-to-privesc-from-virtual-and-network-service-accounts-to-local-system/): Using ADCS to privesc from virtual and network service accounts to local system.
 - [Hot Potato](https://pentestlab.blog/2017/04/13/hot-potato/): Hot potato is the code name of a Windows privilege escalation technique that was discovered by Stephen Breen. This technique is actually a combination of two known windows issues  like NBNS spoofing and NTLM relay with the implementation of a fake WPAD proxy server which is running locally on the target host.
 - [Hot Potato](https://securityonline.info/hot-potato-windows-privilege-escalation-metasploit-powershellhot-potato-windows-privilege-escalation/): Windows 7, 8, 10, Server 2008, Server 2012 Privilege Escalation in Metasploit & PowerShell.
 - [Hot Potato – Windows Privilege Escalation](https://foxglovesecurity.com/2016/01/16/hot-potato/): Privilege Escalation on Windows 7, 8, 10, Server 2008, Server 2012 … and a new network attack.
 - [Juicy Potato (abusing the golden privileges)](https://ohpe.it/juicy-potato/)
 - [No more JuicyPotato? Old story, welcome RoguePotato!](https://decoder.cloud/2020/05/11/no-more-juicypotato-old-story-welcome-roguepotato/): by decoder_it and splinter_code/antonioCoco
 - [Remote Potato](https://pentestlab.blog/2021/05/04/remote-potato-from-domain-user-to-enterprise-admin/): Remote Potato – From Domain User to Enterprise Admin
 - [Rotten Potato – Privilege Escalation from Service Accounts to SYSTEM](https://foxglovesecurity.com/2016/09/26/rotten-potato-privilege-escalation-from-service-accounts-to-system/)

### Unquoted services with spaces
 - [Practical Guide to exploiting the unquoted service path vulnerability in Windows](https://trustfoundry.net/practical-guide-to-exploiting-the-unquoted-service-path-vulnerability-in-windows/)
 - [PrivEsc: Unquoted Service Path](https://web.archive.org/web/20210731080629/https://gracefulsecurity.com/privesc-unquoted-service-path/)
 - [Unquoted Service Path](https://pentestlab.blog/2017/03/09/unquoted-service-path/)
 - [UNQUOTED SERVICE PATHS](https://web.archive.org/web/20210421085608/https://www.commonexploits.com/unquoted-service-paths/)
 - [Windows Privilege Escalation — Part 1 (Unquoted Service Path)](https://medium.com/@SumitVerma101/windows-privilege-escalation-part-1-unquoted-service-path-c7a011a8d8ae)
 - [Windows Privilege Escalation – Unquoted Services](https://web.archive.org/web/20210616195939/https://www.ethicalhacker.net/community/windows-privilege-escalation-unquoted-services/)
 - [Windows Privilege Escalation via Unquoted Service Paths](https://hausec.com/2018/10/05/windows-privilege-escalation-via-unquoted-service-paths/)

### Groups.xml
 - [Finding Passwords in SYSVOL & Exploiting Group Policy Preferences](https://adsecurity.org/?p=2288)
 - [gpp-decrypt Package Description](https://tools.kali.org/password-attacks/gpp-decrypt): A simple ruby script that will decrypt a given GPP encrypted string.

### PrintNightmare
 - [Universal Privilege Escalation and Persistence](https://pentestlab.blog/2021/08/02/universal-privilege-escalation-and-persistence-printer/): The Print Spooler is responsible to manage and process printer jobs. It runs as a service with SYSTEM level privileges on windows environments.

### Tools
 - [JAWS - Just Another Windows (Enum) Script](https://github.com/411Hall/JAWS): JAWS is PowerShell script designed to help penetration testers (and CTFers) quickly identify potential privilege escalation vectors on Windows systems. It is written using PowerShell 2.0 so 'should' run on every Windows version since Windows 7.
 - [juicy-potato](https://github.com/ohpe/juicy-potato): A sugared version of RottenPotatoNG, with a bit of juice, i.e. another Local Privilege Escalation tool, from a Windows Service Accounts to NT AUTHORITY\SYSTEM.
 - [Potato](https://github.com/foxglovesec/Potato): Potato Privilege Escalation on Windows 7, 8, 10, Server 2008, Server 2012.
 - [PowerSploit](https://github.com/PowerShellMafia/PowerSploit): PowerSploit is a collection of Microsoft PowerShell modules that can be used to aid penetration testers during all phases of an assessment.
 - [PrivescCheck](https://github.com/itm4n/PrivescCheck): Enumerate common Windows security misconfigurations which can be leveraged for privilege escalation and gather various information which might be useful for exploitation and/or post-exploitation, by itm4n.
 - [RemotePotato0](https://github.com/antonioCoco/RemotePotato0): Just another ""Won't Fix"" Windows Privilege Escalation from User to Domain Admin by antonioCoco.
 - [RoguePotato](https://github.com/antonioCoco/RoguePotato): Another Windows Local Privilege Escalation from Service Account to System by splinter_code/antonioCoco
 - [RottenPotato](https://github.com/foxglovesec/RottenPotato): RottenPotato local privilege escalation from service account to SYSTEM. (No longer maintained)
 - [RottenPotatoNG](https://github.com/breenmachine/RottenPotatoNG): New version of RottenPotato as a C++ DLL and standalone C++ binary - no need for meterpreter or other tools.
 - [Seatbelt](https://github.com/GhostPack/Seatbelt): Project that performs a number of security oriented host-survey ""safety checks"" relevant from both offensive and defensive security perspectives.        
 - [SessionGopher](https://github.com/Arvanaghi/SessionGopher): SessionGopher is a PowerShell tool that finds and decrypts saved session information for remote access tools.
 - [Sherlock](https://github.com/rasta-mouse/Sherlock/): PowerShell script to quickly find missing software patches for local privilege escalation vulnerabilities. (Deprecated)
 - [SweetPotato](https://github.com/CCob/SweetPotato):  Local Service to SYSTEM privilege escalation from Windows 7 to Windows 10 / Server 2019 by CCob
 - [Tater](https://github.com/Kevin-Robertson/Tater): Tater is a PowerShell implementation of the Hot Potato Windows Privilege Escalation exploit.
 - [Watson](https://github.com/rasta-mouse/Watson): Watson is a .NET tool designed to enumerate missing KBs and suggest exploits for Privilege Escalation vulnerabilities.
 - [WindowsEnum](https://github.com/absolomb/WindowsEnum): A Powershell Privilege Escalation Enumeration Script.
 - [Windows-Exploit-Suggester](https://github.com/AonCyberLabs/Windows-Exploit-Suggester): This tool compares a targets patch levels against the Microsoft vulnerability database in order to detect potential missing patches on the target. It also notifies the user if there are public exploits and Metasploit modules available for the missing bulletins. By AonCyberLabs
 - [Windows Exploit Suggester - Next Generation (WES-NG)](https://github.com/bitsadmin/wesng): WES-NG is a tool based on the output of Windows' systeminfo utility which provides the list of vulnerabilities the OS is vulnerable to, including any exploits for these vulnerabilities. Every Windows OS between Windows XP and Windows 10, including their Windows Server counterparts, is supported. By bitsadmin
 - [windows-privesc-check](https://github.com/pentestmonkey/windows-privesc-check): Standalone executable that runs on Windows systems. It tries to find misconfigurations that could allow local unprivileged users to escalate privileges to other users or to access local apps (e.g. databases).
 - [winPEAS](https://github.com/carlospolop/privilege-escalation-awesome-scripts-suite/tree/master/winPEAS): Windows Privilege Escalation Awesome Scripts
 - [WinPwnage](https://github.com/rootm0s/WinPwnage): UAC bypass, Elevate, Persistence and Execution methods. The goal of this repo is to study the Windows penetration techniques.

### Presentations
 - [Level Up! Practical Windows Privilege Escalation - Andrew Smith](https://www.youtube.com/watch?v=PC_iMqiuIRQ)
 - [Level Up! - Practical Windows Privilege Escalation (Presentation Slides)](https://pt.slideshare.net/jakx_/level-up-practical-windows-privilege-escalation)
 - [SANS Webcast: Pen Testing with PowerShell - Local Privilege Escalation Techniques](https://www.youtube.com/watch?v=bAnohAiAQ7U)
 - [Windows Privilege Escalation Techniques (Local) - Tradecraft Security Weekly #2](https://www.youtube.com/watch?v=DlJyKgfkoKQ)
 - [Windows Privilege Escalation Unquoted Service - Part 1](https://www.youtube.com/watch?v=G9yn3qNq7Vw)
 - [Windows Privilege Escalation Unquoted Service - Part 2](https://www.youtube.com/watch?v=jfZ8FKTFNTE)
 - [Windows Privilege Escalation Unquoted Service - Part 3](https://www.youtube.com/watch?v=RORaqh1DIco)

## Linux and Windows
 - [Awesome-Hacking-Resources (Privilege escalation section)](https://github.com/vitalysim/Awesome-Hacking-Resources#privilege-escalation): A collection of hacking / penetration testing resources to make you better!
 - [Metasploit Local Exploit Suggester: Do Less, Get More!](https://blog.rapid7.com/2015/08/11/metasploit-local-exploit-suggester-do-less-get-more/)
 - [My 5 Top Ways to Escalate Privileges](https://www.trustwave.com/en-us/resources/blogs/spiderlabs-blog/my-5-top-ways-to-escalate-privileges/): Bruno Oliveira's top 5 favorite ways for accomplishing privilege escalation in the most practical ways possible.
 - [Privilege Escalation](https://pentestlab.blog/category/privilege-escalation/): Privilege Escalation category by pentestlab.blog
 - [Recipe for Root](https://recipeforroot.com/): Your Cookbook for Privilege Escalation
 - [Windows / Linux Local Privilege Escalation Workshop](https://github.com/sagishahar/lpeworkshop)

## Docker
 - [Bypassing Docker Authz Plugin and Using Docker-Containerd for Privesc](https://staaldraad.github.io/post/2019-07-11-bypass-docker-plugin-with-containerd/): by Staaldraad.
 - [Container security notes](https://gist.github.com/FrankSpierings/5c79523ba693aaa38bc963083f48456c)
 - [Dirty COW - (CVE-2016-5195) - Docker Container Escape](https://blog.paranoidsoftware.com/dirty-cow-cve-2016-5195-docker-container-escape/)
 - [Docker Breakout](https://book.hacktricks.xyz/linux-unix/privilege-escalation/docker-breakout): by HackTricks
 - [Docker security checklist](https://github.com/PercussiveElbow/docker-security-checklist)
 - [Don't expose the Docker socket (not even to a container)](https://web.archive.org/web/20190623234615/https://www.lvh.io/posts/dont-expose-the-docker-socket-not-even-to-a-container.html)
 - [Escaping Docker Privileged Containers](https://betterprogramming.pub/escaping-docker-privileged-containers-a7ae7d17f5a1): by Vickie Li
 - [Escaping Containers to Execute Commands on Play with Docker Servers](https://www.bleepingcomputer.com/news/security/escaping-containers-to-execute-commands-on-play-with-docker-servers/)
 - [Escaping Docker container using waitid() – CVE-2017-5123](https://www.twistlock.com/labs-blog/escaping-docker-container-using-waitid-cve-2017-5123/)
 - [Escaping the Whale: Things you probably shouldn’t do with Docker (Part 1)](https://blog.secureideas.com/2018/05/escaping-the-whale-things-you-probably-shouldnt-do-with-docker-part-1.html)
 - [Hack Allows Escape of Play-with-Docker Containers](https://threatpost.com/hack-allows-escape-of-play-with-docker-containers/140831/)
 - [Hacking Docker the Easy way](https://pt.slideshare.net/BorgHan/hacking-docker-the-easy-way)
 - [Understanding Docker container escapes](https://blog.trailofbits.com/2019/07/19/understanding-docker-container-escapes/): by Trail of Bits

### Tools
 - [BOtB](https://github.com/brompwnie/botb): BOtB is a container analysis and exploitation tool designed to be used by pentesters and engineers while also being CI/CD friendly with common CI/CD technologies.
 - [CDK](https://github.com/cdk-team/CDK): CDK is an open-sourced container penetration toolkit, offering stable exploitation in different slimmed containers without any OS dependency.
 - [Deepce](https://github.com/stealthcopter/deepce): Docker Enumeration, Escalation of Privileges and Container Escapes (DEEPCE)
 - [Dokcer-escape-tool](https://github.com/PercussiveElbow/docker-escape-tool): This tool will help identify if you're in a Docker container and try some quick escape techniques to help assess the security of your containers.
 - [PrivilegedDockerEscape](https://github.com/0x03f3/PrivilegedDockerEscape): A bash script to create an interactive shell from a privileged docker container to the container host

### Presentations
 - [Introduction to Docker Hacking](https://www.youtube.com/watch?v=XiLfEU9wK-w): by NahamSec

## Cloud
### AWS
 - [AWS-IAM-Privilege-Escalation](https://github.com/RhinoSecurityLabs/AWS-IAM-Privilege-Escalation): A centralized source of all AWS IAM privilege escalation methods released by Rhino Security Labs.

#### Tools
 - [Pacu](https://github.com/RhinoSecurityLabs/pacu): The AWS exploitation framework, designed for testing the security of Amazon Web Services environments. By RhinoSecurityLabs.

### GCP
 - [Tutorial on privilege escalation and post exploitation tactics in Google Cloud Platform environments](https://about.gitlab.com/blog/2020/02/12/plundering-gcp-escalating-privileges-in-google-cloud-platform/): Very deep-dive into manual post-exploitation tactics and techniques for GCP.
 - [GCP-IAM-Privilege-Escalation](https://github.com/RhinoSecurityLabs/GCP-IAM-Privilege-Escalation): IAM Privilege Escalation in GCP by RhinoSecurity.

#### Tools
 - [GCPBucketBrute](https://github.com/RhinoSecurityLabs/GCPBucketBrute): A script to enumerate Google Storage buckets, determine what access you have to them, and determine if they can be privilege escalated. By RhinoSecurity.
","A curated list of awesome privilege escalation techniques. The list includes:
Linux, Windows, Docker, NFS, Capabilities, and tools. There are also some random
hacking hints, mainly from a Linux point of view. There is also a guide to Linux
Privilege Escalation."
1193,Build custom admin panels. Fast!,"<p align=""center"">
    <br>
    <br>
    <a href=""https://backpackforlaravel.com"" title=""Backpack Logo""><img src=""https://camo.githubusercontent.com/50eeab913baf60d3e0dbc8bd4a7b35e1d18456fad04e353a75a4a444948b1a95/68747470733a2f2f6261636b7061636b666f726c61726176656c2e636f6d2f70726573656e746174696f6e2f696d672f6261636b7061636b2f6c6f676f732f6261636b7061636b5f6c6f676f5f636f6c6f722e706e673f763d32""></a>
    <br>
    <br>
</p>


<h3 align=""center"">Quickly build an admin panel for your Eloquent models, then customize every little detail.</h3>



<p align=""center"">
    <br>
    <a href=""https://packagist.org/packages/backpack/crud"" title=""Latest Version on Packagist""><img src=""https://img.shields.io/packagist/v/backpack/crud.svg?style=flat-square""></a>
    <a href=""https://packagist.org/packages/backpack/crud"" title=""Total Downloads""><img src=""https://img.shields.io/packagist/dt/backpack/crud.svg?style=flat-square""></a>
    <a href=""https://github.com/Laravel-Backpack/CRUD/commits/master"" title=""Last commit""><img alt=""GitHub last commit"" src=""https://img.shields.io/github/last-commit/laravel-backpack/crud""></a>
    <a href=""https://scrutinizer-ci.com/g/laravel-backpack/crud"" title=""Quality Score""><img src=""https://img.shields.io/scrutinizer/g/laravel-backpack/crud.svg?style=flat-square""></a>
    <a href=""https://travis-ci.org/Laravel-Backpack/CRUD"" title=""Build Status""><img src=""https://img.shields.io/travis/Laravel-Backpack/CRUD/master.svg?style=flat-square""></a>
    <a href=""https://styleci.io/repos/53581270"" title=""Style CI""><img src=""https://styleci.io/repos/53581270/shield""></a>
    <a href=""https://scrutinizer-ci.com/g/laravel-backpack/crud/code-structure"" title=""Coverage Status""><img src=""https://raw.githubusercontent.com/laravel-backpack/CRUD/coverage-badge-dont-delete/test-coverage.svg""></a>
    <a href=""LICENSE.md"" title=""Software License""><img src=""https://img.shields.io/github/license/laravel-backpack/crud?style=flat-square""></a>
    <a href=""https://github.com/the-whole-fruit/manifesto""><img src=""https://img.shields.io/badge/writing%20standard-the%20whole%20fruit-brightgreen?style=flat-square"" title=""We believe writing good code is not only about writing good code. It’s also about the words around it. We aims to deliver both: code and words.""></a>
</p>

<p align=""center"">
    <a href=""https://backpackforlaravel.com/"" title=""Backpack Screenshots Spread""><img src=""https://user-images.githubusercontent.com/1032474/86720524-c5a1d480-c02d-11ea-87ed-d03b0197eb25.gif""></a>
</p>


Among the FREE features of each admin interface:
- [List](https://backpackforlaravel.com/docs/5.x/crud-operation-list-entries) operation
   - 24 column types
   - 1-1, 1-n and n-n relationships
   - table view with search, pagination
   - click column header to sort by it
   - custom buttons
   - details row
   - easily create new column types
   - easily override an existing column type
- [Create](https://backpackforlaravel.com/docs/5.x/crud-operation-create) / [Update](https://backpackforlaravel.com/docs/5.x/crud-operation-update) operations
   - 29 field types
   - back-end validation using Laravel Form Requests
   - translatable models (multi-language)
   - have multiple fields per line
   - split fields into tabs
- [Delete](https://backpackforlaravel.com/docs/5.x/crud-operation-delete) operation
- [Reorder](https://backpackforlaravel.com/docs/5.x/crud-operation-reorder) operation
- [Revise](https://backpackforlaravel.com/docs/5.x/crud-operation-revisions) operation (aka. audit log)

But professionals don't love Backpack just because it's feature-packed. They also love it because it's **ridiculously easy to override a functionality**. Generally, you just need to create a function (or blade file) with the right name. Yes, it can be _that_ easy.

> Need more complex features? Purchase [Backpack PRO](https://backpackforlaravel.com/pricing), our closed-source paid add-on. It will add **5 more operations, 10 filters, 28 more fields, 6 more columns and 1 more widget**. For more info, see our [FREE vs PRO comparison table](https://backpackforlaravel.com/docs/5.x/features-free-vs-paid). We believe it's everything you need to build admin panels of _any_ complexity.

## Links

<p align=""left"">
    <a href=""https://backpackforlaravel.com/"">Website</a> &nbsp; • &nbsp; 
    <a href=""https://backpackforlaravel.com/docs/"">Documentation</a> &nbsp; • &nbsp;  
    <a href=""https://backpackforlaravel.com/addons"">Add-ons</a> &nbsp; • &nbsp; 
    <a href=""https://backpackforlaravel.com/pricing"">Pricing</a> &nbsp; • &nbsp; 
    <a href=""https://backpackforlaravel.com/need-freelancer-or-development-team"">Services</a> &nbsp; • &nbsp; 
    <a href=""https://stackoverflow.com/questions/tagged/backpack-for-laravel"">Stack Overflow</a> &nbsp; • &nbsp; 
    <a href=""https://backpackforlaravel.com/articles"">Blog</a> &nbsp; • &nbsp; 
    <a href=""https://backpackforlaravel.com/newsletter"">Newsletter</a>
</p>

## Demo

Please see [demo.backpackforlaravel.com](https://demo.backpackforlaravel.com/admin).

## Getting Started

Start with the [""Introduction"" page in our docs](https://backpackforlaravel.com/docs/5.x/introduction) in our docs. It will explain what you can do with Backpack, and let you choose a guide, depending on how you like to learn:
- a 31-minute [""Getting Started"" video course](https://backpackforlaravel.com/docs/5.x/getting-started-videos);
- a 20-minute [""Getting Started"" text course](https://backpackforlaravel.com/docs/5.x/getting-started-basics);
- a 4-day, 5min/day [""Getting Started"" drip email course](https://sendy.digitallyhappy.com/subscription?f=jlldf83763papd2Ifee0838Xs65TkXSvi17yEAuEnJiNj9ct53p5tikGHM4OkvpCeFUCbwcEYRt763ZSTILFXRWWEQ);

## Install

For the current version (recommended):
- [Install Backpack v5 on Laravel 9 or 8](https://backpackforlaravel.com/docs/5.x/installation);

For the previous versions (not recommended):
- [Install Backpack 4.1 on Laravel 6, 7 or 8](https://backpackforlaravel.com/docs/4.1/installation) - last feature update was 1st Jan 2021;
- [Install Backpack 4.0 on Laravel 5.8, 6 or 7](https://backpackforlaravel.com/docs/4.0/installation) - last feature update was 21st Apr 2020;
- [Install Backpack 3.6 on Laravel 5.8 or 6.x](https://backpackforlaravel.com/docs/3.6/installation) - last feature update was 17th Sep 2019;
- [Install Backpack 3.5 on Laravel 5.5, 5.6, 5.7](https://backpackforlaravel.com/docs/3.5/installation) - last feature update was 27th Feb 2019;
- [Install Backpack 3.x on Laravel 5.4](https://laravel-backpack.readme.io/docs/install-on-laravel-54) - last feature update was 27 Sep 2017;
- [Install Backpack 3.x on Laravel 5.3](https://laravel-backpack.readme.io/docs/installation-on-laravel-53) - last feature update was 02 Feb 2017;
- [Install Backpack 3.x on Laravel 5.2](https://laravel-backpack.readme.io/docs/installation) - deprecated, lacks a lot of features;

## Change Log

For v5.x and v4.x please see [the Releases tab](https://github.com/Laravel-Backpack/CRUD/releases). For previous versions (Backpack <=4.0.x), please see our old [CHANGELOG](CHANGELOG.md) file.

## Security

> It's _heavily_ recommended that you **[subscribe to the Backpack Newsletter](http://backpackforlaravel.com/newsletter)** so you can find out about any security updates, breaking changes or major features. We send an email about 1-2 emails per year. Sometimes less.

If you discover any security related issues, please email hello@backpackforlaravel.com instead of using the issue tracker. Alternatively, please disclose the issue on [huntr.dev](https://huntr.dev/) to also get a small bounty ($25-40).

## License

Starting with v5, Backpack has become open-core. Its features have been separated into two packages:
- **Backpack CRUD is licensed under the [MIT License](LICENSE.md)** (open-source free software); it is perfect if you're building a simple admin panel - it's packed with features! it's also perfect if you're building an open-source project, the permissive license allows you to do whatever you want;
- **Backpack PRO is licensed under our [EULA](https://backpackforlaravel.com/eula)**; it is a closed-source, paid add-on; [PRO](https://backpackforlaravel.com/products/pro) will be useful when your admin panel needs grow, because it adds adds A LOT of features for complex use cases (see our [FREE vs PRO comparison](https://backpackforlaravel.com/docs/5.x/features-free-vs-paid));

[Our documentation](https://backpackforlaravel.com/docs) covers both CRUD and PRO, with all the PRO features clearly labeled <span class=""badge badge-pill badge-info"">PRO</span>.

<a name=""versioning""></a>
## Versioning

Starting with Backpack v5, all our packages follow [semantic versioning](https://semver.org/). Here's what `major.minor.patch` (eg. `5.0.1`) means for us:
- `major` - breaking changes, major new features, complete rewrites; released **once a year**, in February; it adds features that were previously impossible and upgrades our dependencies; upgrading is done by following our clear and detailed upgrade guides;
- `minor` - new features, released in backwards-compatible ways; **every few months**; update takes seconds;
- `patch` - bug fixes & small non-breaking changes; historically **every week**; update takes seconds;

When we release a new Backpack\CRUD version, all paid addons receive support for it the same day. 

When you buy a premium Backpack addon, you get access to not only _updates_, but also _upgrades_ (for 12mo), that means that... **any time you buy a Backpack addon, it is very likely that you're not only buying the _current_ version** (`v5` at the moment), **but also the upgrade to the _next version_** (`v6` for example).

## Contributing Guidelines

This project stands by [The Whole Fruit Manifesto](https://github.com/the-whole-fruit/manifesto). We believe that “_writing good code_” is not only about “_writing good code_”. It’s also about the words around it. That’s why, to make sure your contribution is well received, we ask you to [read and keep in mind the ONE=MOR framework and guidelines](https://github.com/the-whole-fruit/manifesto) when writing comment blocks, PR titles, PR descriptions, and in general, when writing to our community. 

For tasks & details about how you can help our project, please see [CONTRIBUTING](CONTRIBUTING.md).

## Credits

- [Cristian Tabacitu](http://tabacitu.ro) - creator & lead maintainer;
- [Pedro Martins](https://github.com/pxpm) - maintainer;
- [António Almeida](https://github.com/promatik) - maintainer;
- [All Contributors][link-contributors]

Special thanks go to:
- [Owen Melbourne](https://github.com/OwenMelbz), [Oliver Ziegler](https://github.com/OliverZiegler), [Thomas Swonke](https://github.com/tswonke), [Catalin Tudorache](https://github.com/tumf87), [Abby Janke](https://github.com/AbbyJanke), [David Lloyd](https://github.com/lloy0076) - A LOT of new features, bug fixing, support, feedback and code review;
- [Łukasz Holeczek](https://coreui.io/) - creator of CoreUI (used in Backpack v4);
- [Abdullah Almsaeed](https://adminlte.io/) - creator of AdminLTE (used in Backpack v3);
- [John Skoumbourdis](http://www.grocerycrud.com/) - Grocery CRUD for CodeIgniter was a big inspiration for Backpack v1 & v2;
- [Taylor Otwell](https://github.com/taylorotwell) & Laravel contributors (of course);

## Hire us

We've spend more than 10.000 hours creating, polishing and maintaining administration panels on Laravel. We've developed e-Commerce, e-Learning, ERPs, social networks, payment gateways and much more. We've worked on admin panels _so much_, that we've created one of the most popular packages for Laravel - just from making public what was repetitive in our projects.

If you are looking for a developer/team to help you build an admin panel on Laravel, look no further. You'll have a difficult time finding someone with more experience & enthusiasm for admin panels. This is _what we do_. [Contact us](https://backpackforlaravel.com/need-freelancer-or-development-team).



[ico-version]: https://img.shields.io/packagist/v/dick/crud.svg?style=flat-square
[ico-license]: https://img.shields.io/badge/license-MIT-brightgreen.svg?style=flat-square
[ico-downloads]: https://img.shields.io/packagist/dt/tabacitu/crud.svg?style=flat-square

[link-packagist]: https://packagist.org/packages/backpack/crud
[link-downloads]: https://packagist.org/packages/backpack/crud
[link-author]: https://tabacitu.ro
[link-contributors]: ../../contributors
","Summarize: ""Quickly build an admin panel for your Eloquent models, then
customize every little detail"" ""We believe writing good code is not only about
the words around it. It’s also about the code itself. We aims to deliver both
code and words."""
3160,TensorFlow Tutorial and Examples for Beginners (support TF v1 & v2),"# TensorFlow Examples

This tutorial was designed for easily diving into TensorFlow, through examples. For readability, it includes both notebooks and source codes with explanation, for both TF v1 & v2.

It is suitable for beginners who want to find clear and concise examples about TensorFlow. Besides the traditional 'raw' TensorFlow implementations, you can also find the latest TensorFlow API practices (such as `layers`, `estimator`, `dataset`, ...).

**Update (05/16/2020):** Moving all default examples to TF2. For TF v1 examples: [check here](https://github.com/aymericdamien/TensorFlow-Examples/blob/master/tensorflow_v1).

## Tutorial index

#### 0 - Prerequisite
- [Introduction to Machine Learning](https://github.com/aymericdamien/TensorFlow-Examples/blob/master/tensorflow_v2/notebooks/0_Prerequisite/ml_introduction.ipynb).
- [Introduction to MNIST Dataset](https://github.com/aymericdamien/TensorFlow-Examples/blob/master/tensorflow_v2/notebooks/0_Prerequisite/mnist_dataset_intro.ipynb).

#### 1 - Introduction
- **Hello World** ([notebook](https://github.com/aymericdamien/TensorFlow-Examples/blob/master/tensorflow_v2/notebooks/1_Introduction/helloworld.ipynb)). Very simple example to learn how to print ""hello world"" using TensorFlow 2.0+.
- **Basic Operations** ([notebook](https://github.com/aymericdamien/TensorFlow-Examples/blob/master/tensorflow_v2/notebooks/1_Introduction/basic_operations.ipynb)). A simple example that cover TensorFlow 2.0+ basic operations.

#### 2 - Basic Models
- **Linear Regression** ([notebook](https://github.com/aymericdamien/TensorFlow-Examples/blob/master/tensorflow_v2/notebooks/2_BasicModels/linear_regression.ipynb)). Implement a Linear Regression with TensorFlow 2.0+.
- **Logistic Regression** ([notebook](https://github.com/aymericdamien/TensorFlow-Examples/blob/master/tensorflow_v2/notebooks/2_BasicModels/logistic_regression.ipynb)). Implement a Logistic Regression with TensorFlow 2.0+.
- **Word2Vec (Word Embedding)** ([notebook](https://github.com/aymericdamien/TensorFlow-Examples/blob/master/tensorflow_v2/notebooks/2_BasicModels/word2vec.ipynb)). Build a Word Embedding Model (Word2Vec) from Wikipedia data, with TensorFlow 2.0+.
- **GBDT (Gradient Boosted Decision Trees)** ([notebooks](https://github.com/aymericdamien/TensorFlow-Examples/blob/master/tensorflow_v2/notebooks/2_BasicModels/gradient_boosted_trees.ipynb)). Implement a Gradient Boosted Decision Trees with TensorFlow 2.0+ to predict house value using Boston Housing dataset.

#### 3 - Neural Networks
##### Supervised

- **Simple Neural Network** ([notebook](https://github.com/aymericdamien/TensorFlow-Examples/blob/master/tensorflow_v2/notebooks/3_NeuralNetworks/neural_network.ipynb)). Use TensorFlow 2.0 'layers' and 'model' API to build a simple neural network to classify MNIST digits dataset.
- **Simple Neural Network (low-level)** ([notebook](https://github.com/aymericdamien/TensorFlow-Examples/blob/master/tensorflow_v2/notebooks/3_NeuralNetworks/neural_network_raw.ipynb)). Raw implementation of a simple neural network to classify MNIST digits dataset.
- **Convolutional Neural Network** ([notebook](https://github.com/aymericdamien/TensorFlow-Examples/blob/master/tensorflow_v2/notebooks/3_NeuralNetworks/convolutional_network.ipynb)). Use TensorFlow 2.0+ 'layers' and 'model' API to build a convolutional neural network to classify MNIST digits dataset.
- **Convolutional Neural Network (low-level)** ([notebook](https://github.com/aymericdamien/TensorFlow-Examples/blob/master/tensorflow_v2/notebooks/3_NeuralNetworks/convolutional_network_raw.ipynb)). Raw implementation of a convolutional neural network to classify MNIST digits dataset.
- **Recurrent Neural Network (LSTM)** ([notebook](https://github.com/aymericdamien/TensorFlow-Examples/blob/master/tensorflow_v2/notebooks/3_NeuralNetworks/recurrent_network.ipynb)). Build a recurrent neural network (LSTM) to classify MNIST digits dataset, using TensorFlow 2.0 'layers' and 'model' API.
- **Bi-directional Recurrent Neural Network (LSTM)** ([notebook](https://github.com/aymericdamien/TensorFlow-Examples/blob/master/tensorflow_v2/notebooks/3_NeuralNetworks/bidirectional_rnn.ipynb)). Build a bi-directional recurrent neural network (LSTM) to classify MNIST digits dataset, using TensorFlow 2.0+ 'layers' and 'model' API.
- **Dynamic Recurrent Neural Network (LSTM)** ([notebook](https://github.com/aymericdamien/TensorFlow-Examples/blob/master/tensorflow_v2/notebooks/3_NeuralNetworks/dynamic_rnn.ipynb)). Build a recurrent neural network (LSTM) that performs dynamic calculation to classify sequences of variable length, using TensorFlow 2.0+ 'layers' and 'model' API.

##### Unsupervised
- **Auto-Encoder** ([notebook](https://github.com/aymericdamien/TensorFlow-Examples/blob/master/tensorflow_v2/notebooks/3_NeuralNetworks/autoencoder.ipynb)). Build an auto-encoder to encode an image to a lower dimension and re-construct it.
- **DCGAN (Deep Convolutional Generative Adversarial Networks)** ([notebook](https://github.com/aymericdamien/TensorFlow-Examples/blob/master/tensorflow_v2/notebooks/3_NeuralNetworks/dcgan.ipynb)). Build a Deep Convolutional Generative Adversarial Network (DCGAN) to generate images from noise.

#### 4 - Utilities
- **Save and Restore a model** ([notebook](https://github.com/aymericdamien/TensorFlow-Examples/blob/master/tensorflow_v2/notebooks/4_Utils/save_restore_model.ipynb)). Save and Restore a model with TensorFlow 2.0+.
- **Build Custom Layers & Modules** ([notebook](https://github.com/aymericdamien/TensorFlow-Examples/blob/master/tensorflow_v2/notebooks/4_Utils/build_custom_layers.ipynb)). Learn how to build your own layers / modules and integrate them into TensorFlow 2.0+ Models.
- **Tensorboard** ([notebook](https://github.com/aymericdamien/TensorFlow-Examples/blob/master/tensorflow_v2/notebooks/4_Utils/tensorboard.ipynb)). Track and visualize neural network computation graph, metrics, weights and more using TensorFlow 2.0+ tensorboard.

#### 5 - Data Management
- **Load and Parse data** ([notebook](https://github.com/aymericdamien/TensorFlow-Examples/blob/master/tensorflow_v2/notebooks/5_DataManagement/load_data.ipynb)). Build efficient data pipeline with TensorFlow 2.0 (Numpy arrays, Images, CSV files, custom data, ...).
- **Build and Load TFRecords** ([notebook](https://github.com/aymericdamien/TensorFlow-Examples/blob/master/tensorflow_v2/notebooks/5_DataManagement/tfrecords.ipynb)). Convert data into TFRecords format, and load them with TensorFlow 2.0+.
- **Image Transformation (i.e. Image Augmentation)** ([notebook](https://github.com/aymericdamien/TensorFlow-Examples/blob/master/tensorflow_v2/notebooks/5_DataManagement/image_transformation.ipynb)). Apply various image augmentation techniques with TensorFlow 2.0+, to generate distorted images for training.

#### 6 - Hardware
- **Multi-GPU Training** ([notebook](https://github.com/aymericdamien/TensorFlow-Examples/blob/master/tensorflow_v2/notebooks/6_Hardware/multigpu_training.ipynb)). Train a convolutional neural network with multiple GPUs on CIFAR-10 dataset.

## TensorFlow v1

The tutorial index for TF v1 is available here: [TensorFlow v1.15 Examples](tensorflow_v1). Or see below for a list of the examples.

## Dataset
Some examples require MNIST dataset for training and testing. Don't worry, this dataset will automatically be downloaded when running examples.
MNIST is a database of handwritten digits, for a quick description of that dataset, you can check [this notebook](https://github.com/aymericdamien/TensorFlow-Examples/blob/master/notebooks/0_Prerequisite/mnist_dataset_intro.ipynb).

Official Website: [http://yann.lecun.com/exdb/mnist/](http://yann.lecun.com/exdb/mnist/).

## Installation

To download all the examples, simply clone this repository:
```
git clone https://github.com/aymericdamien/TensorFlow-Examples
```

To run them, you also need the latest version of TensorFlow. To install it:
```
pip install tensorflow
```

or (with GPU support):
```
pip install tensorflow_gpu
```

For more details about TensorFlow installation, you can check [TensorFlow Installation Guide](https://www.tensorflow.org/install/)


## TensorFlow v1 Examples - Index

The tutorial index for TF v1 is available here: [TensorFlow v1.15 Examples](tensorflow_v1).

#### 0 - Prerequisite
- [Introduction to Machine Learning](https://github.com/aymericdamien/TensorFlow-Examples/blob/master/notebooks/tensorflow_v1/0_Prerequisite/ml_introduction.ipynb).
- [Introduction to MNIST Dataset](https://github.com/aymericdamien/TensorFlow-Examples/blob/master/notebooks/tensorflow_v1/0_Prerequisite/mnist_dataset_intro.ipynb).

#### 1 - Introduction
- **Hello World** ([notebook](https://github.com/aymericdamien/TensorFlow-Examples/blob/master/tensorflow_v1/notebooks/1_Introduction/helloworld.ipynb)) ([code](https://github.com/aymericdamien/TensorFlow-Examples/blob/master/tensorflow_v1/examples/1_Introduction/helloworld.py)). Very simple example to learn how to print ""hello world"" using TensorFlow.
- **Basic Operations** ([notebook](https://github.com/aymericdamien/TensorFlow-Examples/blob/master/notebooks/tensorflow_v1/1_Introduction/basic_operations.ipynb)) ([code](https://github.com/aymericdamien/TensorFlow-examples/Examples/blob/master/tensorflow_v1/1_Introduction/basic_operations.py)). A simple example that cover TensorFlow basic operations.
- **TensorFlow Eager API basics** ([notebook](https://github.com/aymericdamien/TensorFlow-Examples/blob/master/tensorflow_v1/notebooks/1_Introduction/basic_eager_api.ipynb)) ([code](https://github.com/aymericdamien/TensorFlow-Examples/blob/master/tensorflow_v1/examples/1_Introduction/basic_eager_api.py)). Get started with TensorFlow's Eager API.

#### 2 - Basic Models
- **Linear Regression** ([notebook](https://github.com/aymericdamien/TensorFlow-Examples/blob/master/tensorflow_v1/notebooks/2_BasicModels/linear_regression.ipynb)) ([code](https://github.com/aymericdamien/TensorFlow-Examples/blob/master/tensorflow_v1/examples/2_BasicModels/linear_regression.py)). Implement a Linear Regression with TensorFlow.
- **Linear Regression (eager api)** ([notebook](https://github.com/aymericdamien/TensorFlow-Examples/blob/master/tensorflow_v1/notebooks/2_BasicModels/linear_regression_eager_api.ipynb)) ([code](https://github.com/aymericdamien/TensorFlow-Examples/blob/master/tensorflow_v1/examples/2_BasicModels/linear_regression_eager_api.py)). Implement a Linear Regression using TensorFlow's Eager API.
- **Logistic Regression** ([notebook](https://github.com/aymericdamien/TensorFlow-Examples/blob/master/tensorflow_v1/notebooks/2_BasicModels/logistic_regression.ipynb)) ([code](https://github.com/aymericdamien/TensorFlow-Examples/blob/master/tensorflow_v1/examples/2_BasicModels/logistic_regression.py)). Implement a Logistic Regression with TensorFlow.
- **Logistic Regression (eager api)** ([notebook](https://github.com/aymericdamien/TensorFlow-Examples/blob/master/tensorflow_v1/notebooks/2_BasicModels/logistic_regression_eager_api.ipynb)) ([code](https://github.com/aymericdamien/TensorFlow-Examples/blob/master/tensorflow_v1/examples/2_BasicModels/logistic_regression_eager_api.py)). Implement a Logistic Regression using TensorFlow's Eager API.
- **Nearest Neighbor** ([notebook](https://github.com/aymericdamien/TensorFlow-Examples/blob/master/tensorflow_v1/notebooks/2_BasicModels/nearest_neighbor.ipynb)) ([code](https://github.com/aymericdamien/TensorFlow-Examples/blob/master/tensorflow_v1/examples/2_BasicModels/nearest_neighbor.py)). Implement Nearest Neighbor algorithm with TensorFlow.
- **K-Means** ([notebook](https://github.com/aymericdamien/TensorFlow-Examples/blob/master/tensorflow_v1/notebooks/2_BasicModels/kmeans.ipynb)) ([code](https://github.com/aymericdamien/TensorFlow-Examples/blob/master/tensorflow_v1/examples/2_BasicModels/kmeans.py)). Build a K-Means classifier with TensorFlow.
- **Random Forest** ([notebook](https://github.com/aymericdamien/TensorFlow-Examples/blob/master/tensorflow_v1/notebooks/2_BasicModels/random_forest.ipynb)) ([code](https://github.com/aymericdamien/TensorFlow-Examples/blob/master/tensorflow_v1/examples/2_BasicModels/random_forest.py)). Build a Random Forest classifier with TensorFlow.
- **Gradient Boosted Decision Tree (GBDT)** ([notebook](https://github.com/aymericdamien/TensorFlow-Examples/blob/master/tensorflow_v1/notebooks/2_BasicModels/gradient_boosted_decision_tree.ipynb)) ([code](https://github.com/aymericdamien/TensorFlow-Examples/blob/master/tensorflow_v1/examples/2_BasicModels/gradient_boosted_decision_tree.py)). Build a Gradient Boosted Decision Tree (GBDT) with TensorFlow.
- **Word2Vec (Word Embedding)** ([notebook](https://github.com/aymericdamien/TensorFlow-Examples/blob/master/tensorflow_v1/notebooks/2_BasicModels/word2vec.ipynb)) ([code](https://github.com/aymericdamien/TensorFlow-Examples/blob/master/tensorflow_v1/examples/2_BasicModels/word2vec.py)). Build a Word Embedding Model (Word2Vec) from Wikipedia data, with TensorFlow.

#### 3 - Neural Networks
##### Supervised

- **Simple Neural Network** ([notebook](https://github.com/aymericdamien/TensorFlow-Examples/blob/master/tensorflow_v1/3_NeuralNetworks/notebooks/neural_network_raw.ipynb)) ([code](https://github.com/aymericdamien/TensorFlow-Examples/blob/master/tensorflow_v1/examples/3_NeuralNetworks/neural_network_raw.py)). Build a simple neural network (a.k.a Multi-layer Perceptron) to classify MNIST digits dataset. Raw TensorFlow implementation.
- **Simple Neural Network (tf.layers/estimator api)** ([notebook](https://github.com/aymericdamien/TensorFlow-Examples/blob/master/tensorflow_v1/notebooks/3_NeuralNetworks/neural_network.ipynb)) ([code](https://github.com/aymericdamien/TensorFlow-Examples/blob/master/tensorflow_v1/examples/3_NeuralNetworks/neural_network.py)). Use TensorFlow 'layers' and 'estimator' API to build a simple neural network (a.k.a Multi-layer Perceptron) to classify MNIST digits dataset.
- **Simple Neural Network (eager api)** ([notebook](https://github.com/aymericdamien/TensorFlow-Examples/blob/master/tensorflow_v1/notebooks/3_NeuralNetworks/neural_network_eager_api.ipynb)) ([code](https://github.com/aymericdamien/TensorFlow-Examples/blob/master/tensorflow_v1/examples/3_NeuralNetworks/neural_network_eager_api.py)). Use TensorFlow Eager API to build a simple neural network (a.k.a Multi-layer Perceptron) to classify MNIST digits dataset.
- **Convolutional Neural Network** ([notebook](https://github.com/aymericdamien/TensorFlow-Examples/blob/master/tensorflow_v1/notebooks/3_NeuralNetworks/convolutional_network_raw.ipynb)) ([code](https://github.com/aymericdamien/TensorFlow-Examples/blob/master/tensorflow_v1/examples/3_NeuralNetworks/convolutional_network_raw.py)). Build a convolutional neural network to classify MNIST digits dataset. Raw TensorFlow implementation.
- **Convolutional Neural Network (tf.layers/estimator api)** ([notebook](https://github.com/aymericdamien/TensorFlow-Examples/blob/master/tensorflow_v1/notebooks/3_NeuralNetworks/convolutional_network.ipynb)) ([code](https://github.com/aymericdamien/TensorFlow-Examples/blob/master/tensorflow_v1/examples/3_NeuralNetworks/convolutional_network.py)). Use TensorFlow 'layers' and 'estimator' API to build a convolutional neural network to classify MNIST digits dataset.
- **Recurrent Neural Network (LSTM)** ([notebook](https://github.com/aymericdamien/TensorFlow-Examples/blob/master/tensorflow_v1/notebooks/3_NeuralNetworks/recurrent_network.ipynb)) ([code](https://github.com/aymericdamien/TensorFlow-Examples/blob/master/tensorflow_v1/examples/3_NeuralNetworks/recurrent_network.py)). Build a recurrent neural network (LSTM) to classify MNIST digits dataset.
- **Bi-directional Recurrent Neural Network (LSTM)** ([notebook](https://github.com/aymericdamien/TensorFlow-Examples/blob/master/tensorflow_v1/notebooks/3_NeuralNetworks/bidirectional_rnn.ipynb)) ([code](https://github.com/aymericdamien/TensorFlow-Examples/blob/master/tensorflow_v1/examples/3_NeuralNetworks/bidirectional_rnn.py)). Build a bi-directional recurrent neural network (LSTM) to classify MNIST digits dataset.
- **Dynamic Recurrent Neural Network (LSTM)** ([notebook](https://github.com/aymericdamien/TensorFlow-Examples/blob/master/tensorflow_v1/notebooks/3_NeuralNetworks/dynamic_rnn.ipynb)) ([code](https://github.com/aymericdamien/TensorFlow-Examples/blob/master/tensorflow_v1/examples/3_NeuralNetworks/dynamic_rnn.py)). Build a recurrent neural network (LSTM) that performs dynamic calculation to classify sequences of different length.

##### Unsupervised
- **Auto-Encoder** ([notebook](https://github.com/aymericdamien/TensorFlow-Examples/blob/master/tensorflow_v1/notebooks/3_NeuralNetworks/autoencoder.ipynb)) ([code](https://github.com/aymericdamien/TensorFlow-Examples/blob/master/tensorflow_v1/examples/3_NeuralNetworks/autoencoder.py)). Build an auto-encoder to encode an image to a lower dimension and re-construct it.
- **Variational Auto-Encoder** ([notebook](https://github.com/aymericdamien/TensorFlow-Examples/blob/master/tensorflow_v1/notebooks/3_NeuralNetworks/variational_autoencoder.ipynb)) ([code](https://github.com/aymericdamien/TensorFlow-Examples/blob/master/tensorflow_v1/examples/3_NeuralNetworks/variational_autoencoder.py)). Build a variational auto-encoder (VAE), to encode and generate images from noise.
- **GAN (Generative Adversarial Networks)** ([notebook](https://github.com/aymericdamien/TensorFlow-Examples/blob/master/tensorflow_v1/notebooks/3_NeuralNetworks/gan.ipynb)) ([code](https://github.com/aymericdamien/TensorFlow-Examples/blob/master/tensorflow_v1/examples/3_NeuralNetworks/gan.py)). Build a Generative Adversarial Network (GAN) to generate images from noise.
- **DCGAN (Deep Convolutional Generative Adversarial Networks)** ([notebook](https://github.com/aymericdamien/TensorFlow-Examples/blob/master/tensorflow_v1/notebooks/3_NeuralNetworks/dcgan.ipynb)) ([code](https://github.com/aymericdamien/TensorFlow-Examples/blob/master/tensorflow_v1/examples/3_NeuralNetworks/dcgan.py)). Build a Deep Convolutional Generative Adversarial Network (DCGAN) to generate images from noise.

#### 4 - Utilities
- **Save and Restore a model** ([notebook](https://github.com/aymericdamien/TensorFlow-Examples/blob/master/tensorflow_v1/notebooks/4_Utils/save_restore_model.ipynb)) ([code](https://github.com/aymericdamien/TensorFlow-Examples/blob/master/tensorflow_v1/examples/4_Utils/save_restore_model.py)). Save and Restore a model with TensorFlow.
- **Tensorboard - Graph and loss visualization** ([notebook](https://github.com/aymericdamien/TensorFlow-Examples/blob/master/tensorflow_v1/notebooks/4_Utils/tensorboard_basic.ipynb)) ([code](https://github.com/aymericdamien/TensorFlow-Examples/blob/master/tensorflow_v1/examples/4_Utils/tensorboard_basic.py)). Use Tensorboard to visualize the computation Graph and plot the loss.
- **Tensorboard - Advanced visualization** ([notebook](https://github.com/aymericdamien/TensorFlow-Examples/blob/master/tensorflow_v1/notebooks/4_Utils/tensorboard_advanced.ipynb)) ([code](https://github.com/aymericdamien/TensorFlow-Examples/blob/master/tensorflow_v1/examples/4_Utils/tensorboard_advanced.py)). Going deeper into Tensorboard; visualize the variables, gradients, and more...

#### 5 - Data Management
- **Build an image dataset** ([notebook](https://github.com/aymericdamien/TensorFlow-Examples/blob/master/tensorflow_v1/notebooks/5_DataManagement/build_an_image_dataset.ipynb)) ([code](https://github.com/aymericdamien/TensorFlow-Examples/blob/master/tensorflow_v1/examples/5_DataManagement/build_an_image_dataset.py)). Build your own images dataset with TensorFlow data queues, from image folders or a dataset file.
- **TensorFlow Dataset API** ([notebook](https://github.com/aymericdamien/TensorFlow-Examples/blob/master/tensorflow_v1/notebooks/5_DataManagement/tensorflow_dataset_api.ipynb)) ([code](https://github.com/aymericdamien/TensorFlow-Examples/blob/master/tensorflow_v1/examples/5_DataManagement/tensorflow_dataset_api.py)). Introducing TensorFlow Dataset API for optimizing the input data pipeline.
- **Load and Parse data** ([notebook](https://github.com/aymericdamien/TensorFlow-Examples/blob/master/tensorflow_v1/notebooks/5_DataManagement/load_data.ipynb)). Build efficient data pipeline (Numpy arrays, Images, CSV files, custom data, ...).
- **Build and Load TFRecords** ([notebook](https://github.com/aymericdamien/TensorFlow-Examples/blob/master/tensorflow_v1/notebooks/5_DataManagement/tfrecords.ipynb)). Convert data into TFRecords format, and load them.
- **Image Transformation (i.e. Image Augmentation)** ([notebook](https://github.com/aymericdamien/TensorFlow-Examples/blob/master/tensorflow_v1/notebooks/5_DataManagement/image_transformation.ipynb)). Apply various image augmentation techniques, to generate distorted images for training.

#### 6 - Multi GPU
- **Basic Operations on multi-GPU** ([notebook](https://github.com/aymericdamien/TensorFlow-Examples/blob/master/tensorflow_v1/notebooks/6_MultiGPU/multigpu_basics.ipynb)) ([code](https://github.com/aymericdamien/TensorFlow-Examples/blob/master/tensorflow_v1/examples/6_MultiGPU/multigpu_basics.py)). A simple example to introduce multi-GPU in TensorFlow.
- **Train a Neural Network on multi-GPU** ([notebook](https://github.com/aymericdamien/TensorFlow-Examples/blob/master/tensorflow_v1/notebooks/6_MultiGPU/multigpu_cnn.ipynb)) ([code](https://github.com/aymericdamien/TensorFlow-Examples/blob/master/tensorflow_v1/examples/6_MultiGPU/multigpu_cnn.py)). A clear and simple TensorFlow implementation to train a convolutional neural network on multiple GPUs.

## More Examples
The following examples are coming from [TFLearn](https://github.com/tflearn/tflearn), a library that provides a simplified interface for TensorFlow. You can have a look, there are many [examples](https://github.com/tflearn/tflearn/tree/master/examples) and [pre-built operations and layers](http://tflearn.org/doc_index/#api).

### Tutorials
- [TFLearn Quickstart](https://github.com/tflearn/tflearn/blob/master/tutorials/intro/quickstart.md). Learn the basics of TFLearn through a concrete machine learning task. Build and train a deep neural network classifier.

### Examples
- [TFLearn Examples](https://github.com/tflearn/tflearn/blob/master/examples). A large collection of examples using TFLearn.

","This tutorial was designed for easily diving into TensorFlow, through examples.
For readability, it includes both notebooks and source codes with explanation.
It is suitable for beginners who want to find clear and concise examples.
Besides the traditional 'raw' Tensor Flow implementations, you can also find the
latest Tensorflow API practices."
477,"Enable Self-Service Operations: Give specific users access to your existing tools, services, and scripts","Rundeck
========

| Travis | Deb | RPM | War |
|--------|-----|-----|-----|
|[![Travis CI](https://travis-ci.org/rundeck/rundeck.svg?branch=master)](https://travis-ci.org/rundeck/rundeck/builds#)|[Download](https://www.rundeck.com/downloads)|[Download](https://www.rundeck.com/downloads)|[Download](https://www.rundeck.com/downloads)|

Rundeck is an open source automation service with a web console,
command line tools and a WebAPI.
It lets you easily run automation tasks across a set of nodes.

* Site: <https://www.rundeck.com>

* Latest documentation: <https://docs.rundeck.com/docs/>

* Get Help: <https://docs.rundeck.com/docs/introduction/getting-help.html>

* Installation: <https://docs.rundeck.com/docs/administration/install/installing-rundeck.html>


See the [Release Notes](https://docs.rundeck.com/docs/history/) for the latest version information.


How To Build:
=====

Primary build is supported with gradle. More info in the [wiki](https://github.com/rundeck/rundeck/wiki/Building-and-Testing).

Requirements: Java 1.8, NodeJs 16

Build with Gradle
---

Produces: `rundeckapp/build/libs/rundeck-X.Y.war`

    ./gradlew build

Docker Build
---

Uses the war artifact and produces a docker image.

Creates image `rundeck/rundeck:SNAPSHOT`, you can define `-PdockerTags` to add additional tags

    ./gradlew :docker:officialBuild

Documentation
======

Available online at <https://docs.rundeck.com/docs>

FAQ: <https://github.com/rundeck/rundeck/wiki/FAQ>

Development
======

Refer to the [IDE Development Environment](https://github.com/rundeck/rundeck/wiki/IDE-Development-Environment) to get set up using IntelliJ IDEA or Eclipse/STS.

* [Issue tracker](https://github.com/rundeck/rundeck/issues) at github.com

Do you have changes to contribute? Please see the [Development](https://github.com/rundeck/rundeck/wiki/Development) wiki page.

License
======

Copyright 2020 Rundeck, Inc.

Licensed under the Apache License, Version 2.0 (the ""License"");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an ""AS IS"" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
","Rundeck is an open source automation service with a web console, command line
tools and a WebAPI. It lets you easily run automation tasks across a set of
nodes. It is licensed under the Apache License, Version 2.0 (the ""License"")"
2947,"Automatically remove the mosaics in images and videos, or add mosaics to them.","<div align=""center"">
  <img src=""./imgs/logo.png"" width=""250""><br><br>
  <img src=""https://badgen.net/github/stars/hypox64/deepmosaics?icon=github&color=4ab8a1"">&emsp;<img src=""https://badgen.net/github/forks/hypox64/deepmosaics?icon=github&color=4ab8a1"">&emsp;<a href=""https://github.com/HypoX64/DeepMosaics/releases""><img src=https://img.shields.io/github/downloads/hypox64/deepmosaics/total></a>&emsp;<a href=""https://github.com/HypoX64/DeepMosaics/releases""><img src=https://img.shields.io/github/v/release/hypox64/DeepMosaics></a>&emsp;<img src=https://img.shields.io/github/license/hypox64/deepmosaics>
</div>

# DeepMosaics

**English | [中文](./README_CN.md)**<br>
You can use it to automatically remove the mosaics in images and videos, or add mosaics to them.<br>This project is based on ""semantic segmentation"" and ""Image-to-Image Translation"".<br>Try it at this [website](http://118.89.27.46:5000/)!<br>

### Examples

![image](./imgs/hand.gif)

|                origin                |             auto add mosaic              |             auto clean mosaic              |
| :----------------------------------: | :--------------------------------------: | :----------------------------------------: |
|  ![image](./imgs/example/lena.jpg)   |  ![image](./imgs/example/lena_add.jpg)   |  ![image](./imgs/example/lena_clean.jpg)   |
| ![image](./imgs/example/youknow.png) | ![image](./imgs/example/youknow_add.png) | ![image](./imgs/example/youknow_clean.png) |

- Compared with [DeepCreamPy](https://github.com/deeppomf/DeepCreamPy)

|                mosaic image                |            DeepCreamPy             |                   ours                    |
| :----------------------------------------: | :--------------------------------: | :---------------------------------------: |
| ![image](./imgs/example/face_a_mosaic.jpg) | ![image](./imgs/example/a_dcp.png) | ![image](./imgs/example/face_a_clean.jpg) |
| ![image](./imgs/example/face_b_mosaic.jpg) | ![image](./imgs/example/b_dcp.png) | ![image](./imgs/example/face_b_clean.jpg) |

- Style Transfer

|              origin              |               to Van Gogh                |                   to winter                    |
| :------------------------------: | :--------------------------------------: | :--------------------------------------------: |
| ![image](./imgs/example/SZU.jpg) | ![image](./imgs/example/SZU_vangogh.jpg) | ![image](./imgs/example/SZU_summer2winter.jpg) |

An interesting example:[Ricardo Milos to cat](https://www.bilibili.com/video/BV1Q7411W7n6)

## Run DeepMosaics

You can either run DeepMosaics via a pre-built binary package, or from source.<br>

### Try it on web

You can simply try to remove the mosaic on the **face** at this [website](http://118.89.27.46:5000/).<br>

### Pre-built binary package

For Windows, we bulid a GUI version for easy testing.<br>
Download this version, and a pre-trained model via [[Google Drive]](https://drive.google.com/open?id=1LTERcN33McoiztYEwBxMuRjjgxh4DEPs) [[百度云,提取码1x0a]](https://pan.baidu.com/s/10rN3U3zd5TmfGpO_PEShqQ) <br>

- [[Help document]](./docs/exe_help.md)<br>
- Video tutorial => [[youtube]](https://www.youtube.com/watch?v=1kEmYawJ_vk) [[bilibili]](https://www.bilibili.com/video/BV1QK4y1a7Av)

![image](./imgs/GUI.png)<br>
Attentions:<br>

- Requires Windows_x86_64, Windows10 is better.<br>
- Different pre-trained models are suitable for different effects.[[Introduction to pre-trained models]](./docs/pre-trained_models_introduction.md)<br>
- Run time depends on computers performance (GPU version has better performance but requires CUDA to be installed).<br>
- If output video cannot be played, you can try with [potplayer](https://daumpotplayer.com/download/).<br>
- GUI version updates slower than source.<br>

### Run From Source

#### Prerequisites

- Linux, Mac OS, Windows
- Python 3.6+
- [ffmpeg 3.4.6](http://ffmpeg.org/)
- [Pytorch 1.0+](https://pytorch.org/)
- CPU or NVIDIA GPU + CUDA CuDNN<br>

#### Dependencies

This code depends on opencv-python, torchvision available via pip install.

#### Clone this repo

```bash
git clone https://github.com/HypoX64/DeepMosaics.git
cd DeepMosaics
```

#### Get Pre-Trained Models

You can download pre_trained models and put them into './pretrained_models'.<br>
[[Google Drive]](https://drive.google.com/open?id=1LTERcN33McoiztYEwBxMuRjjgxh4DEPs) [[百度云,提取码1x0a]](https://pan.baidu.com/s/10rN3U3zd5TmfGpO_PEShqQ)<br>
[[Introduction to pre-trained models]](./docs/pre-trained_models_introduction.md)<br>

In order to add/remove mosaic, there must be a model file `mosaic_position.pth` at `./pretrained_models/mosaic/mosaic_position.pth`

#### Install dependencies

(Optional) Create a virtual environment

```bash
virtualenv mosaic
source mosaic/bin/activate
```

Then install the dependencies

```bash
pip install -r requirements.txt
```

If you can not build `scikit-image`, running `export CFLAGS='-Wno-implicit-function-declaration` then try to rebuild.

#### Simple Example

- Add Mosaic (output media will be saved in './result')<br>

```bash
python deepmosaic.py --media_path ./imgs/ruoruo.jpg --model_path ./pretrained_models/mosaic/add_face.pth --gpu_id 0
```

- Clean Mosaic (output media will save in './result')<br>

```bash
python deepmosaic.py --media_path ./result/ruoruo_add.jpg --model_path ./pretrained_models/mosaic/clean_face_HD.pth --gpu_id 0
```

If you see the error `Please check mosaic_position_model_path!`, check if there is a model file named `mosaic_position.pth` at `./pretrained_models/mosaic/mosaic_position.pth`

#### More Parameters

If you want to test other images or videos, please refer to this file.<br>
[[options_introduction.md]](./docs/options_introduction.md) <br>

## Training With Your Own Dataset

If you want to train with your own dataset, please refer to [training_with_your_own_dataset.md](./docs/training_with_your_own_dataset.md)

## Acknowledgements

This code borrows heavily from [[pytorch-CycleGAN-and-pix2pix]](https://github.com/junyanz/pytorch-CycleGAN-and-pix2pix) [[Pytorch-UNet]](https://github.com/milesial/Pytorch-UNet) [[pix2pixHD]](https://github.com/NVIDIA/pix2pixHD) [[BiSeNet]](https://github.com/ooooverflow/BiSeNet) [[DFDNet]](https://github.com/csxmli2016/DFDNet) [[GFRNet_pytorch_new]](https://github.com/sonack/GFRNet_pytorch_new).
","This project is based on ""semantic segmentation"" and ""Image-to-Image
Translation"" You can use it to automatically remove the mosaics in images and
videos, or add mosaics to them. It can also be used to transfer images from one
language to another."
1713,A library used to create beautiful animations and transitions for iOS.,"![Motion Logo](http://www.cosmicmind.com/motion/logo/motion_logo.png)

# Motion

Welcome to **Motion,** a library used to create beautiful animations and transitions for views, layers, and view controllers.

## Photos Sample

Take a look at a sample [Photos](https://github.com/CosmicMind/Samples/tree/master/Projects/Programmatic/Photos) project to get started.

![Photos](http://www.cosmicmind.com/motion/projects/photos.gif)

* [Photos Sample](https://github.com/CosmicMind/Samples/tree/master/Projects/Programmatic/Photos)

### Who is Motion for?

Motion is designed for beginner to expert developers. For beginners, you will be exposed to very powerful APIs that would take time and experience to develop on your own, and experts will appreciate the time saved by using Motion.

### What you will learn

You will learn how to use Motion with a general introduction to fundamental concepts and easy to use code snippets.

# Transitions

Motion transitions a source view to a destination view using a linking identifier property named `motionIdentifier`.

| Match | Translate | Rotate | Arc | Scale |
|:---:|:---:|:---:|:---:|:---:|
| ![Match](http://www.cosmicmind.com/motion/transitions_identifier/match.gif) |  ![Translate](http://www.cosmicmind.com/motion/transitions_identifier/translate.gif) | ![Rotate](http://www.cosmicmind.com/motion/transitions_identifier/rotate.gif) | ![Arc](http://www.cosmicmind.com/motion/transitions_identifier/arc.gif) | ![Scale](http://www.cosmicmind.com/motion/transitions_identifier/scale.gif) |

### Example Usage

An example of transitioning from one view controller to another with transitions:

#### View Controller 1

```swift
greyView.motionIdentifier = ""foo""
orangeView.motionIdentifier = ""bar""
```

#### View Controller 2

```swift
isMotionEnabled = true
greyView.motionIdentifier = ""foo""
orangeView.motionIdentifier = ""bar""
orangeView.transition(.translate(x: -100))
```

The above code snippet tells the source views in `view controller 1` to link to the destination views in `view controller 2` using the `motionIdentifier`. Animations may be added to views during a transition using the **transition** method. The *transition* method accepts MotionTransition structs that configure the view's animation.

* [MotionTransition API](https://cosmicmind.gitbooks.io/motion/content/motion_transition_api.html)
* [Code Samples](https://github.com/CosmicMind/Samples/tree/master/Projects/Programmatic/TransitionsWithIdentifier)

## UINavigationController, UITabBarController, and UIViewController Transitions

Motion offers default transitions that may be used by UINavigationControllers, UITabBarControllers, and presenting UIViewControllers.

| Push | Slide | ZoomSlide | Cover | Page | Fade | Zoom |
|:---:|:---:|:---:|:---:|:---:|:---:|:---:|
| ![Push](http://www.cosmicmind.com/motion/transitions/push.gif)  | ![Slide](http://www.cosmicmind.com/motion/transitions/slide.gif)| ![Zoom Slide](http://www.cosmicmind.com/motion/transitions/zoom_slide.gif) | ![Cover](http://www.cosmicmind.com/motion/transitions/cover.gif) | ![Page](http://www.cosmicmind.com/motion/transitions/page_in.gif) | ![Fade](http://www.cosmicmind.com/motion/transitions/fade.gif) | ![Zoom](http://www.cosmicmind.com/motion/transitions/zoom.gif)|

### Example Usage

An example of transitioning from one view controller to another using a UINavigationController with a zoom transition:

#### UINavigationController

```swift
class AppNavigationController: UINavigationController {
    open override func viewDidLoad() {
        super.viewDidLoad()
        isMotionEnabled = true
        motionNavigationTransitionType = .zoom
    }
}
```

To add an automatic reverse transition, use `autoReverse`.

```swift
motionNavigationTransitionType = .autoReverse(presenting: .zoom)
```

* [Code Samples](https://github.com/CosmicMind/Samples/tree/master/Projects/Programmatic/Transitions)

# Animations

Motion provides the building blocks necessary to create stunning animations without much effort. Motion's animation API will make maintenance a breeze and changes even easier. To create an animation, use the **animate** method of a view or layer and pass in a list of MotionAnimation structs. MotionAnimation structs are configurable values that describe how to animate a property or group of properties.

| Background Color | Corner Radius | Fade | Rotate | Size | Spring |
|:---:|:---:|:---:|:---:|:---:|:---:|
| ![Background Color](http://www.cosmicmind.com/motion/animations/background_color.gif) | ![Corner Radius](http://www.cosmicmind.com/motion/animations/corner_radius.gif) | ![Fade](http://www.cosmicmind.com/motion/animations/fade.gif) | ![Rotate](http://www.cosmicmind.com/motion/animations/rotate.gif) | ![Size](http://www.cosmicmind.com/motion/animations/size.gif) | ![Spring](http://www.cosmicmind.com/motion/animations/spring.gif) |

| Border Color & Border Width | Depth | Position | Scale | Spin | Translate |
|:---:|:---:|:---:|:---:|:---:|:---:|
|![Border Color & Border Width](http://www.cosmicmind.com/motion/animations/border_color.gif) | ![Depth](http://www.cosmicmind.com/motion/animations/depth.gif) | ![Position](http://www.cosmicmind.com/motion/animations/position.gif) | ![Scale](http://www.cosmicmind.com/motion/animations/scale.gif) | ![Spin](http://www.cosmicmind.com/motion/animations/spin.gif) | ![Translate](http://www.cosmicmind.com/motion/animations/translate.gif) |

### Example Usage

```swift
let box = UIView(frame: CGRect(x: 0, y: 0, width: 100, height: 100))
box.backgroundColor = .blue

box.animate(.background(color: .red), .rotate(180), .delay(1))
```

In the above code example, a box view is created with a width of 100, height of 100, and an initial background color of blue. Following the general creation of the view, the _Motion animate_ method is passed _MotionAnimation structs_ that tell the view to animate to a red background color and rotate 180 degrees after a delay of 1 second. That's pretty much the general idea of creating animations.

* [MotionAnimation API](https://cosmicmind.gitbooks.io/motion/content/motion_animation_api.html)
* [Code Samples](https://github.com/CosmicMind/Samples/tree/master/Projects/Programmatic/Animations)

## Requirements

* iOS 8.0+
* Xcode 8.0+

## Communication

- If you **need help**, use [Stack Overflow](http://stackoverflow.com/questions/tagged/cosmicmind). (Tag 'cosmicmind')
- If you'd like to **ask a general question**, use [Stack Overflow](http://stackoverflow.com/questions/tagged/cosmicmind).
- If you **found a bug**, _and can provide steps to reliably reproduce it_, open an issue.
- If you **have a feature request**, open an issue.
- If you **want to contribute**, submit a pull request.

## Installation

> **Embedded frameworks require a minimum deployment target of iOS 8.**
> - [Download Motion](https://github.com/CosmicMind/Motion/archive/master.zip)

## CocoaPods

[CocoaPods](http://cocoapods.org) is a dependency manager for Cocoa projects. You can install it with the following command:

```bash
$ gem install cocoapods
```

To integrate Motion's core features into your Xcode project using CocoaPods, specify it in your `Podfile`:

```ruby
source 'https://github.com/CocoaPods/Specs.git'
platform :ios, '8.0'
use_frameworks!

pod 'Motion', '~> 3.1.0'
```

Then, run the following command:

```bash
$ pod install
```

## Carthage

Carthage is a decentralized dependency manager that builds your dependencies and provides you with binary frameworks.

You can install Carthage with Homebrew using the following command:

```bash
$ brew update
$ brew install carthage
```
To integrate Motion into your Xcode project using Carthage, specify it in your Cartfile:

```bash
github ""CosmicMind/Motion""
```

Run `carthage update` to build the framework and drag the built `Motion.framework` into your Xcode project.

## Change Log

Motion is a growing project and will encounter changes throughout its development. It is recommended that the [Change Log](https://github.com/CosmicMind/Motion/blob/master/CHANGELOG.md) be reviewed prior to updating versions.

## License

The MIT License (MIT)

Copyright (C) 2019, CosmicMind, Inc. <http://cosmicmind.com>.
All rights reserved.

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the ""Software""), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in
all copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED ""AS IS"", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN
THE SOFTWARE.
","Motion is a library used to create beautiful animations and transitions for
views, layers, and view controllers. It is designed for beginner to expert
developers. For beginners, you will be exposed to very powerful APIs that would
take time and experience to develop on your own, and experts will appreciate the
time saved."
3375,Canonical actor model implementation for .NET with local + distributed actors in C# and F#.,"# Akka.NET

![Akka.NET logo](docs/shfb/icons/AkkaNetLogo.Normal.png)

[![Gitter](https://badges.gitter.im/Join%20Chat.svg)](https://gitter.im/akkadotnet/akka.net?utm_source=badge&utm_medium=badge&utm_campaign=pr-badge&utm_content=badge) <br/>

**Akka.NET** is a professional-grade port of the popular Java/Scala framework [Akka](http://akka.io) distributed actor framework to .NET.

Akka.NET is a [.NET Foundation](https://dotnetfoundation.org/) project.

![.NET Foundation Logo](docs/images/dotnetfoundationhorizontal.svg)

## Build Status

| Stage                                   | Status                                                                                                                                                                                                                                                                |
|-------------------------------------    |-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------    |
| Build                                   | [![Build Status](https://dev.azure.com/dotnet/Akka.NET/_apis/build/status/akka.net/PR%20Validation?branchName=dev&jobName=Windows%20Build)](https://dev.azure.com/dotnet/Akka.NET/_build/latest?definitionId=84&branchName=dev)                                       |
| NuGet Pack                              | [![Build Status](https://dev.azure.com/dotnet/Akka.NET/_apis/build/status/akka.net/PR%20Validation?branchName=dev&jobName=NuGet%20Pack)](https://dev.azure.com/dotnet/Akka.NET/_build/latest?definitionId=84&branchName=dev)                                          |
| .NET Framework Unit Tests               | [![Build Status](https://dev.azure.com/dotnet/Akka.NET/_apis/build/status/akka.net/PR%20Validation?branchName=dev&jobName=.NET%20Framework%20Unit%20Tests%20(Windows))](https://dev.azure.com/dotnet/Akka.NET/_build/latest?definitionId=84&branchName=dev)           |
| .NET Framework MultiNode Tests          | [![Build Status](https://dev.azure.com/dotnet/Akka.NET/_apis/build/status/akka.net/PR%20Validation?branchName=dev&jobName=.NET%20Framework%20Multi-Node%20Tests%20(Windows))](https://dev.azure.com/dotnet/Akka.NET/_build/latest?definitionId=84&branchName=dev)     |
| .NET Core (Windows) Unit Tests          | [![Build Status](https://dev.azure.com/dotnet/Akka.NET/_apis/build/status/akka.net/PR%20Validation?branchName=dev&jobName=.NET%20Core%20Unit%20Tests%20(Windows))](https://dev.azure.com/dotnet/Akka.NET/_build/latest?definitionId=84&branchName=dev)                |
| .NET Core (Linux) Unit Tests            | [![Build Status](https://dev.azure.com/dotnet/Akka.NET/_apis/build/status/akka.net/PR%20Validation?branchName=dev&jobName=.NET%20Core%20Unit%20Tests%20(Linux))](https://dev.azure.com/dotnet/Akka.NET/_build/latest?definitionId=84&branchName=dev)                  |
| .NET Core (Windows) MultiNode Tests     | [![Build Status](https://dev.azure.com/dotnet/Akka.NET/_apis/build/status/akka.net/PR%20Validation?branchName=dev&jobName=.NET%20Core%20Multi-Node%20Tests%20(Windows))](https://dev.azure.com/dotnet/Akka.NET/_build/latest?definitionId=84&branchName=dev)          |
| .NET Core (Linux) MultiNode Tests       |                                                                                                                                                                                                                                                                       |
| Docs                                    | [![Build Status](https://dev.azure.com/petabridge/akkadotnet-tools/_apis/build/status/Akka.NET%20Docs?branchName=dev)](https://dev.azure.com/petabridge/akkadotnet-tools/_build/latest?definitionId=82&branchName=dev)                                                |


### Documentation and resources

#### [Akka.NET Project Site](http://getakka.net)


### Install Akka.NET via NuGet

If you want to include Akka.NET in your project, you can [install it directly from NuGet](https://www.nuget.org/packages/Akka)

To install Akka.NET Distributed Actor Framework, run the following command in the Package Manager Console

```
PM> Install-Package Akka
PM> Install-Package Akka.Remote
```

And if you need F# support:

```
PM> Install-Package Akka.FSharp
```

## Builds
Please see [Building Akka.NET](http://getakka.net/community/building-akka-net.html).

To access nightly Akka.NET builds, please [see the instructions here](http://getakka.net/community/getting-access-to-nightly-builds.html).

## Support
If you need help getting started with Akka.NET, there's a number of great community resources online:

* Subscribe to the Akka.NET project feed on Twitter: https://twitter.com/AkkaDotNet  (@AkkaDotNet)
* Join the Akka.NET project Gitter chat: https://gitter.im/akkadotnet/akka.net
* Ask Akka.NET questions on Stack Overflow: http://stackoverflow.com/questions/tagged/akka.net

If you and your company are interested in getting professional Akka.NET support, you can [contact Petabridge for dedicated Akka.NET support](https://petabridge.com/).
","Akka.NET** is a professional-grade port of the popular Java/Scala framework
[Akka](http://akka.io) distributed actor framework to.NET. It is a [.NET
Foundation](https://dotnetfoundation.org/) project."
3157,"12 weeks, 26 lessons, 52 quizzes, classic Machine Learning for all","[![GitHub license](https://img.shields.io/github/license/microsoft/ML-For-Beginners.svg)](https://github.com/microsoft/ML-For-Beginners/blob/master/LICENSE)
[![GitHub contributors](https://img.shields.io/github/contributors/microsoft/ML-For-Beginners.svg)](https://GitHub.com/microsoft/ML-For-Beginners/graphs/contributors/)
[![GitHub issues](https://img.shields.io/github/issues/microsoft/ML-For-Beginners.svg)](https://GitHub.com/microsoft/ML-For-Beginners/issues/)
[![GitHub pull-requests](https://img.shields.io/github/issues-pr/microsoft/ML-For-Beginners.svg)](https://GitHub.com/microsoft/ML-For-Beginners/pulls/)
[![PRs Welcome](https://img.shields.io/badge/PRs-welcome-brightgreen.svg?style=flat-square)](http://makeapullrequest.com)

[![GitHub watchers](https://img.shields.io/github/watchers/microsoft/ML-For-Beginners.svg?style=social&label=Watch)](https://GitHub.com/microsoft/ML-For-Beginners/watchers/)
[![GitHub forks](https://img.shields.io/github/forks/microsoft/ML-For-Beginners.svg?style=social&label=Fork)](https://GitHub.com/microsoft/ML-For-Beginners/network/)
[![GitHub stars](https://img.shields.io/github/stars/microsoft/ML-For-Beginners.svg?style=social&label=Star)](https://GitHub.com/microsoft/ML-For-Beginners/stargazers/)

# Machine Learning for Beginners - A Curriculum

> 🌍 Travel around the world as we explore Machine Learning by means of world cultures 🌍

Azure Cloud Advocates at Microsoft are pleased to offer a 12-week, 26-lesson curriculum all about **Machine Learning**. In this curriculum, you will learn about what is sometimes called **classic machine learning**, using primarily Scikit-learn as a library and avoiding deep learning, which is covered in our forthcoming 'AI for Beginners' curriculum. Pair these lessons with our ['Data Science for Beginners' curriculum](https://aka.ms/datascience-beginners), as well!

Travel with us around the world as we apply these classic techniques to data from many areas of the world. Each lesson includes pre- and post-lesson quizzes, written instructions to complete the lesson, a solution, an assignment, and more. Our project-based pedagogy allows you to learn while building, a proven way for new skills to 'stick'.

**✍️ Hearty thanks to our authors** Jen Looper, Stephen Howell, Francesca Lazzeri, Tomomi Imura, Cassie Breviu, Dmitry Soshnikov, Chris Noring, Anirban Mukherjee, Ornella Altunyan, and Amy Boyd

**🎨 Thanks as well to our illustrators** Tomomi Imura, Dasani Madipalli, and Jen Looper

**🙏 Special thanks 🙏 to our Microsoft Student Ambassador authors, reviewers, and content contributors**, notably Rishit Dagli, Muhammad Sakib Khan Inan, Rohan Raj, Alexandru Petrescu, Abhishek Jaiswal, Nawrin Tabassum, Ioan Samuila, and Snigdha Agarwal

**🤩 Extra gratitude to Microsoft Student Ambassador Eric Wanjau for our R lessons!**

---

# Getting Started

**[Students](https://aka.ms/student-page)**, to use this curriculum, fork the entire repo to your own GitHub account and complete the exercises on your own or with a group:

- Start with a pre-lecture quiz.
- Read the lecture and complete the activities, pausing and reflecting at each knowledge check.
- Try to create the projects by comprehending the lessons rather than running the solution code; however that code is available in the `/solution` folders in each project-oriented lesson.
- Take the post-lecture quiz.
- Complete the challenge.
- Complete the assignment.
- After completing a lesson group, visit the [Discussion Board](https://github.com/microsoft/ML-For-Beginners/discussions) and ""learn out loud"" by filling out the appropriate PAT rubric. A 'PAT' is a Progress Assessment Tool that is a rubric you fill out to further your learning. You can also react to other PATs so we can learn together.

> For further study, we recommend following these [Microsoft Learn](https://docs.microsoft.com/en-us/users/jenlooper-2911/collections/k7o7tg1gp306q4?WT.mc_id=academic-77952-leestott) modules and learning paths.

**Teachers**, we have [included some suggestions](for-teachers.md) on how to use this curriculum.

---

## Meet the Team

[![Promo video](ml.gif)](https://youtu.be/Tj1XWrDSYJU ""Promo video"")

**Gif by** [Mohit Jaisal](https://linkedin.com/in/mohitjaisal)

> 🎥 Click the image above for a video about the project and the folks who created it!

---

## Pedagogy

We have chosen two pedagogical tenets while building this curriculum: ensuring that it is hands-on **project-based** and that it includes **frequent quizzes**. In addition, this curriculum has a common **theme** to give it cohesion.

By ensuring that the content aligns with projects, the process is made more engaging for students and retention of concepts will be augmented. In addition, a low-stakes quiz before a class sets the intention of the student towards learning a topic, while a second quiz after class ensures further retention. This curriculum was designed to be flexible and fun and can be taken in whole or in part. The projects start small and become increasingly complex by the end of the 12-week cycle. This curriculum also includes a postscript on real-world applications of ML, which can be used as extra credit or as a basis for discussion.

> Find our [Code of Conduct](CODE_OF_CONDUCT.md), [Contributing](CONTRIBUTING.md), and [Translation](TRANSLATIONS.md) guidelines. We welcome your constructive feedback!

## Each lesson includes:

- optional sketchnote
- optional supplemental video
- pre-lecture warmup quiz
- written lesson
- for project-based lessons, step-by-step guides on how to build the project
- knowledge checks
- a challenge
- supplemental reading
- assignment
- post-lecture quiz

> **A note about languages**: These lessons are primarily written in Python, but many are also available in R. To complete an R lesson, go to the `/solution` folder and look for R lessons. They include an .rmd extension that represents an **R Markdown** file which can be simply defined as an embedding of `code chunks` (of R or other languages) and a `YAML header` (that guides how to format outputs such as PDF) in a `Markdown document`. As such, it serves as an exemplary authoring framework for data science since it allows you to combine your code, its output, and your thoughts by allowing you to write them down in Markdown. Moreover, R Markdown documents can be rendered to output formats such as PDF, HTML, or Word.

> **A note about quizzes**: All quizzes are contained [in this app](https://gray-sand-07a10f403.1.azurestaticapps.net/), for 52 total quizzes of three questions each. They are linked from within the lessons but the quiz app can be run locally; follow the instruction in the `quiz-app` folder.

| Lesson Number |                             Topic                              |                   Lesson Grouping                   | Learning Objectives                                                                                                             |                                                              Linked Lesson                                                               |                        Author                        |
| :-----------: | :------------------------------------------------------------: | :-------------------------------------------------: | ------------------------------------------------------------------------------------------------------------------------------- | :--------------------------------------------------------------------------------------------------------------------------------------: | :--------------------------------------------------: |
|      01       |                Introduction to machine learning                |      [Introduction](1-Introduction/README.md)       | Learn the basic concepts behind machine learning                                                                                |                                             [Lesson](1-Introduction/1-intro-to-ML/README.md)                                             |                       Muhammad                       |
|      02       |                The History of machine learning                 |      [Introduction](1-Introduction/README.md)       | Learn the history underlying this field                                                                                         |                                            [Lesson](1-Introduction/2-history-of-ML/README.md)                                            |                     Jen and Amy                      |
|      03       |                 Fairness and machine learning                  |      [Introduction](1-Introduction/README.md)       | What are the important philosophical issues around fairness that students should consider when building and applying ML models? |                                              [Lesson](1-Introduction/3-fairness/README.md)                                               |                        Tomomi                        |
|      04       |                Techniques for machine learning                 |      [Introduction](1-Introduction/README.md)       | What techniques do ML researchers use to build ML models?                                                                       |                                          [Lesson](1-Introduction/4-techniques-of-ML/README.md)                                           |                    Chris and Jen                     |
|      05       |                   Introduction to regression                   |        [Regression](2-Regression/README.md)         | Get started with Python and Scikit-learn for regression models                                                                  |         <ul><li>[Python](2-Regression/1-Tools/README.md)</li><li>[R](2-Regression/1-Tools/solution/R/lesson_1-R.ipynb)</li></ul>         |      <ul><li>Jen</li><li>Eric Wanjau</li></ul>       |
|      06       |                North American pumpkin prices 🎃                |        [Regression](2-Regression/README.md)         | Visualize and clean data in preparation for ML                                                                                  |          <ul><li>[Python](2-Regression/2-Data/README.md)</li><li>[R](2-Regression/2-Data/solution/R/lesson_2-R.ipynb)</li></ul>          |      <ul><li>Jen</li><li>Eric Wanjau</li></ul>       |
|      07       |                North American pumpkin prices 🎃                |        [Regression](2-Regression/README.md)         | Build linear and polynomial regression models                                                                                   |        <ul><li>[Python](2-Regression/3-Linear/README.md)</li><li>[R](2-Regression/3-Linear/solution/R/lesson_3-R.ipynb)</li></ul>        |      <ul><li>Jen and Dmitry</li><li>Eric Wanjau</li></ul>       |
|      08       |                North American pumpkin prices 🎃                |        [Regression](2-Regression/README.md)         | Build a logistic regression model                                                                                               |     <ul><li>[Python](2-Regression/4-Logistic/README.md) </li><li>[R](2-Regression/4-Logistic/solution/R/lesson_4-R.ipynb)</li></ul>      |      <ul><li>Jen</li><li>Eric Wanjau</li></ul>       |
|      09       |                          A Web App 🔌                          |           [Web App](3-Web-App/README.md)            | Build a web app to use your trained model                                                                                       |                                                 [Python](3-Web-App/1-Web-App/README.md)                                                  |                         Jen                          |
|      10       |                 Introduction to classification                 |    [Classification](4-Classification/README.md)     | Clean, prep, and visualize your data; introduction to classification                                                            | <ul><li> [Python](4-Classification/1-Introduction/README.md) </li><li>[R](4-Classification/1-Introduction/solution/R/lesson_10-R.ipynb)  | <ul><li>Jen and Cassie</li><li>Eric Wanjau</li></ul> |
|      11       |             Delicious Asian and Indian cuisines 🍜             |    [Classification](4-Classification/README.md)     | Introduction to classifiers                                                                                                     | <ul><li> [Python](4-Classification/2-Classifiers-1/README.md)</li><li>[R](4-Classification/2-Classifiers-1/solution/R/lesson_11-R.ipynb) | <ul><li>Jen and Cassie</li><li>Eric Wanjau</li></ul> |
|      12       |             Delicious Asian and Indian cuisines 🍜             |    [Classification](4-Classification/README.md)     | More classifiers                                                                                                                | <ul><li> [Python](4-Classification/3-Classifiers-2/README.md)</li><li>[R](4-Classification/3-Classifiers-2/solution/R/lesson_12-R.ipynb) | <ul><li>Jen and Cassie</li><li>Eric Wanjau</li></ul> |
|      13       |             Delicious Asian and Indian cuisines 🍜             |    [Classification](4-Classification/README.md)     | Build a recommender web app using your model                                                                                    |                                              [Python](4-Classification/4-Applied/README.md)                                              |                         Jen                          |
|      14       |                   Introduction to clustering                   |        [Clustering](5-Clustering/README.md)         | Clean, prep, and visualize your data; Introduction to clustering                                                                |         <ul><li> [Python](5-Clustering/1-Visualize/README.md)</li><li>[R](5-Clustering/1-Visualize/solution/R/lesson_14-R.ipynb)         |      <ul><li>Jen</li><li>Eric Wanjau</li></ul>       |
|      15       |              Exploring Nigerian Musical Tastes 🎧              |        [Clustering](5-Clustering/README.md)         | Explore the K-Means clustering method                                                                                           |           <ul><li> [Python](5-Clustering/2-K-Means/README.md)</li><li>[R](5-Clustering/2-K-Means/solution/R/lesson_15-R.ipynb)           |      <ul><li>Jen</li><li>Eric Wanjau</li></ul>       |
|      16       |        Introduction to natural language processing ☕️         |   [Natural language processing](6-NLP/README.md)    | Learn the basics about NLP by building a simple bot                                                                             |                                             [Python](6-NLP/1-Introduction-to-NLP/README.md)                                              |                       Stephen                        |
|      17       |                      Common NLP Tasks ☕️                      |   [Natural language processing](6-NLP/README.md)    | Deepen your NLP knowledge by understanding common tasks required when dealing with language structures                          |                                                    [Python](6-NLP/2-Tasks/README.md)                                                     |                       Stephen                        |
|      18       |             Translation and sentiment analysis ♥️              |   [Natural language processing](6-NLP/README.md)    | Translation and sentiment analysis with Jane Austen                                                                             |                                            [Python](6-NLP/3-Translation-Sentiment/README.md)                                             |                       Stephen                        |
|      19       |                  Romantic hotels of Europe ♥️                  |   [Natural language processing](6-NLP/README.md)    | Sentiment analysis with hotel reviews 1                                                                                         |                                               [Python](6-NLP/4-Hotel-Reviews-1/README.md)                                                |                       Stephen                        |
|      20       |                  Romantic hotels of Europe ♥️                  |   [Natural language processing](6-NLP/README.md)    | Sentiment analysis with hotel reviews 2                                                                                         |                                               [Python](6-NLP/5-Hotel-Reviews-2/README.md)                                                |                       Stephen                        |
|      21       |            Introduction to time series forecasting             |        [Time series](7-TimeSeries/README.md)        | Introduction to time series forecasting                                                                                         |                                             [Python](7-TimeSeries/1-Introduction/README.md)                                              |                      Francesca                       |
|      22       | ⚡️ World Power Usage ⚡️ - time series forecasting with ARIMA |        [Time series](7-TimeSeries/README.md)        | Time series forecasting with ARIMA                                                                                              |                                                 [Python](7-TimeSeries/2-ARIMA/README.md)                                                 |                      Francesca                       |
|      23       |  ⚡️ World Power Usage ⚡️ - time series forecasting with SVR  |        [Time series](7-TimeSeries/README.md)        | Time series forecasting with Support Vector Regressor                                                                           |                                                  [Python](7-TimeSeries/3-SVR/README.md)                                                  |                       Anirban                        |
|      24       |             Introduction to reinforcement learning             | [Reinforcement learning](8-Reinforcement/README.md) | Introduction to reinforcement learning with Q-Learning                                                                          |                                             [Python](8-Reinforcement/1-QLearning/README.md)                                              |                        Dmitry                        |
|      25       |                 Help Peter avoid the wolf! 🐺                  | [Reinforcement learning](8-Reinforcement/README.md) | Reinforcement learning Gym                                                                                                      |                                                [Python](8-Reinforcement/2-Gym/README.md)                                                 |                        Dmitry                        |
|  Postscript   |            Real-World ML scenarios and applications            |      [ML in the Wild](9-Real-World/README.md)       | Interesting and revealing real-world applications of classical ML                                                               |                                             [Lesson](9-Real-World/1-Applications/README.md)                                              |                         Team                         |

## Offline access

You can run this documentation offline by using [Docsify](https://docsify.js.org/#/). Fork this repo, [install Docsify](https://docsify.js.org/#/quickstart) on your local machine, and then in the root folder of this repo, type `docsify serve`. The website will be served on port 3000 on your localhost: `localhost:3000`.

## PDFs

Find a pdf of the curriculum with links [here](https://microsoft.github.io/ML-For-Beginners/pdf/readme.pdf).

## Help Wanted!

Would you like to contribute a translation? Please read our [translation guidelines](TRANSLATIONS.md) and add a templated issue to manage the workload [here](https://github.com/microsoft/ML-For-Beginners/issues).

## Other Curricula

Our team produces other curricula! Check out:

- [Web Dev for Beginners](https://aka.ms/webdev-beginners)
- [IoT for Beginners](https://aka.ms/iot-beginners)
- [Data Science for Beginners](https://aka.ms/datascience-beginners)
- [AI for Beginners](https://aka.ms/ai-beginners)
","Machine Learning for Beginners is a 12-week, 26-lesson curriculum all about
**Machine Learning** In this curriculum, you will learn about what is sometimes
called **classic machine learning, using primarily Scikit-learn as a library and
avoiding deep learning. Each lesson includes pre- and post-lessons quizzes,
written instructions to complete the lesson, a solution, an assignment and more."
2432,Reasonable System for CSS Stylesheet Structure,"##### Viewing this from GitHub? Visit the website for the full experience. **[ricostacruz.com/rscss →](https://ricostacruz.com/rscss)**
<!-- {h5: style='display:none'} -->

----
<!-- {hr: style='display:none'} -->

# rscss

<!-- {h1:.massive-header.-with-tagline} -->

> Styling CSS without losing your sanity

Reasonable System for CSS Stylesheet Structure.<br>
A set of simple ideas to guide your process of building maintainable CSS.

Introduction
------------

Any CSS greater than 1000 lines will get unwieldy. You'll eventually run into these common pitfalls:

* ""What does this class mean?""
* ""Is this class still being used?""
* ""If I make a new class `green`, will there be a clash?""

**rscss** is an attempt to make sense of all these. It is not a framework. It's simply a set of ideas to guide your process of building maintainable CSS for any modern website or application.

Let's get started by learning about components.
[Continue →](docs/components.md)
<!-- {p:.pull-box} -->

----
<!-- {hr: style='display:none'} -->

**rscss** © 2015+, Rico Sta. Cruz. Released under the [MIT] License.<br>
Authored and maintained by Rico Sta. Cruz with help from contributors ([list][contributors]).
<!-- {p: style='display:none'} -->

> [ricostacruz.com](http://ricostacruz.com) &nbsp;&middot;&nbsp;
> GitHub [@rstacruz](https://github.com/rstacruz) &nbsp;&middot;&nbsp;
> Twitter [@rstacruz](https://twitter.com/rstacruz)
<!-- {blockquote: style='display:none'} -->

[MIT]: http://mit-license.org/
[contributors]: http://github.com/rstacruz/rscss/contributors
","Styling CSS without losing your sanity. A set of simple ideas to guide your
process of building maintainable CSS. GitHub [@rstacruz]:
http://github.com/rscss/contributors. Released under the [MIT] License."
572,The Tcl Core. (Mirror of core.tcl-lang.org),"# README:  Tcl

This is the **Tcl 9.0a4** source distribution.

You can get any source release of Tcl from [our distribution
site](https://sourceforge.net/projects/tcl/files/Tcl/).

8.6 (production release, daily build)
[![Build Status](https://github.com/tcltk/tcl/workflows/Linux/badge.svg?branch=core-8-6-branch)](https://github.com/tcltk/tcl/actions?query=workflow%3A%22Linux%22+branch%3Acore-8-6-branch)
[![Build Status](https://github.com/tcltk/tcl/workflows/Windows/badge.svg?branch=core-8-6-branch)](https://github.com/tcltk/tcl/actions?query=workflow%3A%22Windows%22+branch%3Acore-8-6-branch)
[![Build Status](https://github.com/tcltk/tcl/workflows/macOS/badge.svg?branch=core-8-6-branch)](https://github.com/tcltk/tcl/actions?query=workflow%3A%22macOS%22+branch%3Acore-8-6-branch)
<br>
8.7 (in development, daily build))
[![Build Status](https://github.com/tcltk/tcl/workflows/Linux/badge.svg?branch=core-8-branch)](https://github.com/tcltk/tcl/actions?query=workflow%3A%22Linux%22+branch%3Acore-8-branch)
[![Build Status](https://github.com/tcltk/tcl/workflows/Windows/badge.svg?branch=core-8-branch)](https://github.com/tcltk/tcl/actions?query=workflow%3A%22Windows%22+branch%3Acore-8-branch)
[![Build Status](https://github.com/tcltk/tcl/workflows/macOS/badge.svg?branch=core-8-branch)](https://github.com/tcltk/tcl/actions?query=workflow%3A%22macOS%22+branch%3Acore-8-branch)
<br>
9.0 (in development, daily build))
[![Build Status](https://github.com/tcltk/tcl/workflows/Linux/badge.svg?branch=main)](https://github.com/tcltk/tcl/actions?query=workflow%3A%22Linux%22+branch%3Amain)
[![Build Status](https://github.com/tcltk/tcl/workflows/Windows/badge.svg?branch=main)](https://github.com/tcltk/tcl/actions?query=workflow%3A%22Windows%22+branch%3Amain)
[![Build Status](https://github.com/tcltk/tcl/workflows/macOS/badge.svg?branch=main)](https://github.com/tcltk/tcl/actions?query=workflow%3A%22macOS%22+branch%3Amain)

## Contents
 1. [Introduction](#intro)
 2. [Documentation](#doc)
 3. [Compiling and installing Tcl](#build)
 4. [Development tools](#devtools)
 5. [Tcl newsgroup](#complangtcl)
 6. [The Tcler's Wiki](#wiki)
 7. [Mailing lists](#email)
 8. [Support and Training](#support)
 9. [Tracking Development](#watch)
 10. [Thank You](#thanks)

## <a id=""intro"">1.</a> Introduction
Tcl provides a powerful platform for creating integration applications that
tie together diverse applications, protocols, devices, and frameworks.
When paired with the Tk toolkit, Tcl provides the fastest and most powerful
way to create GUI applications that run on PCs, Unix, and Mac OS X.
Tcl can also be used for a variety of web-related tasks and for creating
powerful command languages for applications.

Tcl is maintained, enhanced, and distributed freely by the Tcl community.
Source code development and tracking of bug reports and feature requests
take place at [core.tcl-lang.org](https://core.tcl-lang.org/).
Tcl/Tk release and mailing list services are [hosted by
SourceForge](https://sourceforge.net/projects/tcl/)
with the Tcl Developer Xchange hosted at
[www.tcl-lang.org](https://www.tcl-lang.org).

Tcl is a freely available open-source package.  You can do virtually
anything you like with it, such as modifying it, redistributing it,
and selling it either in whole or in part.  See the file
`license.terms` for complete information.

## <a id=""doc"">2.</a> Documentation
Extensive documentation is available on our website.
The home page for this release, including new features, is
[here](https://www.tcl-lang.org/software/tcltk/9.0.html).
Detailed release notes can be found at the
[file distributions page](https://sourceforge.net/projects/tcl/files/Tcl/)
by clicking on the relevant version.

Information about Tcl itself can be found at the [Developer
Xchange](https://www.tcl-lang.org/about/).
There have been many Tcl books on the market.  Many are mentioned in
[the Wiki](https://wiki.tcl-lang.org/_/ref?N=25206).

The complete set of reference manual entries for Tcl 9.0 is [online,
here](https://www.tcl-lang.org/man/tcl9.0/).

### <a id=""doc.unix"">2a.</a> Unix Documentation
The `doc` subdirectory in this release contains a complete set of
reference manual entries for Tcl.  Files with extension ""`.1`"" are for
programs (for example, `tclsh.1`); files with extension ""`.3`"" are for C
library procedures; and files with extension ""`.n`"" describe Tcl
commands.  The file ""`doc/Tcl.n`"" gives a quick summary of the Tcl
language syntax.  To print any of the man pages on Unix, cd to the
""doc"" directory and invoke your favorite variant of troff using the
normal -man macros, for example

		groff -man -Tpdf Tcl.n >output.pdf

to print Tcl.n to PDF.  If Tcl has been installed correctly and your ""man"" program
supports it, you should be able to access the Tcl manual entries using the
normal ""man"" mechanisms, such as

		man Tcl

### <a id=""doc.win"">2b.</a> Windows Documentation
The ""doc"" subdirectory in this release contains a complete set of Windows
help files for Tcl.  Once you install this Tcl release, a shortcut to the
Windows help Tcl documentation will appear in the ""Start"" menu:

		Start | Programs | Tcl | Tcl Help

## <a id=""build"">3.</a> Compiling and installing Tcl
There are brief notes in the `unix/README`, `win/README`, and `macosx/README`
about compiling on these different platforms.  There is additional information
about building Tcl from sources
[online](https://www.tcl-lang.org/doc/howto/compile.html).

## <a id=""devtools"">4.</a> Development tools
ActiveState produces a high-quality set of commercial quality development
tools that is available to accelerate your Tcl application development.
Tcl Dev Kit builds on the earlier TclPro toolset and provides a debugger,
static code checker, single-file wrapping utility, bytecode compiler, and
more.  More information can be found at

	https://www.activestate.com/products/tcl/

## <a id=""complangtcl"">5.</a> Tcl newsgroup
There is a USENET newsgroup, ""`comp.lang.tcl`"", intended for the exchange of
information about Tcl, Tk, and related applications.  The newsgroup is a
great place to ask general information questions.  For bug reports, please
see the ""Support and bug fixes"" section below.

## <a id=""wiki"">6.</a> Tcl'ers Wiki
There is a [wiki-based open community site](https://wiki.tcl-lang.org/)
covering all aspects of Tcl/Tk.

It is dedicated to the Tcl programming language and its extensions.  A
wealth of useful information can be found there.  It contains code
snippets, references to papers, books, and FAQs, as well as pointers to
development tools, extensions, and applications.  You can also recommend
additional URLs by editing the wiki yourself.

## <a id=""email"">7.</a> Mailing lists
Several mailing lists are hosted at SourceForge to discuss development or use
issues (like Macintosh and Windows topics).  For more information and to
subscribe, visit [here](https://sourceforge.net/projects/tcl/) and go to the
Mailing Lists page.

## <a id=""support"">8.</a> Support and Training
We are very interested in receiving bug reports, patches, and suggestions for
improvements.  We prefer that you send this information to us as tickets
entered into [our issue tracker](https://core.tcl-lang.org/tcl/reportlist).

We will log and follow-up on each bug, although we cannot promise a
specific turn-around time.  Enhancements may take longer and may not happen
at all unless there is widespread support for them (we're trying to
slow the rate at which Tcl/Tk turns into a kitchen sink).  It's very
difficult to make incompatible changes to Tcl/Tk at this point, due to
the size of the installed base.

The Tcl community is too large for us to provide much individual support for
users.  If you need help we suggest that you post questions to `comp.lang.tcl`
or ask a question on [Stack
Overflow](https://stackoverflow.com/questions/tagged/tcl).  We read the
newsgroup and will attempt to answer esoteric questions for which no one else
is likely to know the answer.  In addition, see the wiki for [links to other
organizations](https://wiki.tcl-lang.org/training) that offer Tcl/Tk training.

## <a id=""watch"">9.</a> Tracking Development
Tcl is developed in public.  You can keep an eye on how Tcl is changing at
[core.tcl-lang.org](https://core.tcl-lang.org/).

## <a id=""thanks"">10.</a> Thank You
We'd like to express our thanks to the Tcl community for all the
helpful suggestions, bug reports, and patches we have received.
Tcl/Tk has improved vastly and will continue to do so with your help.
","This is the **Tcl 9.0a4** source distribution. You can get any source release of
Tcl from [our distribution
site](https://sourceforge.net/projects/tcl/files/Tcl/). Tcl provides the fastest
and most powerful toolkit to create applications."
3377,Jenkins Configuration as Code Plugin,"# Jenkins Configuration as Code (a.k.a. JCasC) Plugin

[![Build Status](https://ci.jenkins.io/job/Plugins/job/configuration-as-code-plugin/job/master/badge/icon)](https://ci.jenkins.io/job/Plugins/job/configuration-as-code-plugin/job/master/)
[![Contributors](https://img.shields.io/github/contributors/jenkinsci/configuration-as-code-plugin.svg)](https://github.com/jenkinsci/configuration-as-code-plugin/graphs/contributors)
[![Jenkins Plugin](https://img.shields.io/jenkins/plugin/v/configuration-as-code.svg)](https://plugins.jenkins.io/configuration-as-code)
[![GitHub release](https://img.shields.io/github/release/jenkinsci/configuration-as-code-plugin.svg?label=changelog)](https://github.com/jenkinsci/configuration-as-code-plugin/releases/latest)
[![Jenkins Plugin Installs](https://img.shields.io/jenkins/plugin/i/configuration-as-code.svg?color=blue)](https://plugins.jenkins.io/configuration-as-code)
[![Gitter](https://badges.gitter.im/jenkinsci/configuration-as-code-plugin.svg)](https://gitter.im/jenkinsci/configuration-as-code-plugin)

<img src=""plugin/src/main/webapp/img/logo-head.svg"" width=""192"">


- [Introduction](#introduction)
- [Getting Started](#getting-started)
- [Examples and demos](./demos)
- [Handling Secrets](./docs/features/secrets.adoc)
- [Security considerations](#security-considerations)
- [Exporting configurations](./docs/features/configExport.md)
- [Validating configurations](./docs/features/jsonSchema.md)
- [Merge Strategy](./docs/features/mergeStrategy.md)
- [Triggering Configuration Reload](./docs/features/configurationReload.md)
- [Installing plugins](#installing-plugins)
- [Supported Plugins](#supported-plugins)
- [Adding JCasC support to a plugin](#adding-jCasC-support-to-a-plugin)
- [Configuration-as-Code extension plugins](#configuration-as-Code-extension-plugins)
- [Jenkins Enhancement Proposal](#jenkins-enhancement-proposal)

## Introduction

Setting up Jenkins is a complex process, as both Jenkins and its plugins require some tuning and configuration,
with dozens of parameters to set within the web UI `manage` section.

Experienced Jenkins users rely on groovy init scripts to customize Jenkins and enforce the desired state. Those
scripts directly invoke Jenkins API and, as such, can do everything (at your own risk). But they also require
you to know Jenkins internals and are confident in writing groovy scripts on top of Jenkins API.

The Configuration as Code plugin is an _**opinionated**_ way to configure Jenkins based on
human-readable declarative configuration files. Writing such a file should be feasible without being a Jenkins
expert, just translating into _code_ a configuration process one is used to executing in the web UI.

The below configuration file includes root entries for various components of your primary Jenkins installation. The `jenkins` one is for the root Jenkins object, and the other ones are for different global configuration elements.

```yaml
jenkins:
  systemMessage: ""Jenkins configured automatically by Jenkins Configuration as Code plugin\n\n""
  globalNodeProperties:
  - envVars:
      env:
      - key: VARIABLE1
        value: foo
      - key: VARIABLE2
        value: bar
  securityRealm:
    ldap:
      configurations:
        - groupMembershipStrategy:
            fromUserRecord:
              attributeName: ""memberOf""
          inhibitInferRootDN: false
          rootDN: ""dc=acme,dc=org""
          server: ""ldaps://ldap.acme.org:1636""

  nodes:
    - permanent:
        name: ""static-agent""
        remoteFS: ""/home/jenkins""
        launcher:
          jnlp:
            workDirSettings:
              disabled: true
              failIfWorkDirIsMissing: false
              internalDir: ""remoting""
              workDirPath: ""/tmp""

  slaveAgentPort: 50000
  agentProtocols:
    - ""jnlp2""

tool:
  git:
    installations:
      - name: git
        home: /usr/local/bin/git

credentials:
  system:
    domainCredentials:
      - credentials:
          - basicSSHUserPrivateKey:
              scope: SYSTEM
              id: ssh_with_passphrase_provided
              username: ssh_root
              passphrase: ${SSH_KEY_PASSWORD}
              description: ""SSH passphrase with private key file. Private key provided""
              privateKeySource:
                directEntry:
                  privateKey: ${SSH_PRIVATE_KEY}
```

Additionally, we want to have a well-documented syntax file and tooling to assist in writing and testing,
so end users have full guidance in using this toolset and do not have to search for examples on the Internet.

See the [presentation slides](https://docs.google.com/presentation/d/1VsvDuffinmxOjg0a7irhgJSRWpCzLg_Yskf7Fw7FpBg/edit?usp=sharing) from DevOps World - Jenkins World 2018 for an overview.

## Getting Started

First, start a Jenkins instance with the [Configuration as Code](https://plugins.jenkins.io/configuration-as-code) plugin installed.

- Those running Jenkins as a [Docker](https://github.com/jenkinsci/docker) container (and maybe also [pre-installing plugins](https://github.com/jenkinsci/docker#preinstalling-plugins)), do include [Configuration as Code](https://plugins.jenkins.io/configuration-as-code) plugin.

Second, the plugin looks for the `CASC_JENKINS_CONFIG` environment variable. The variable points to a comma-separated list of any of the following:

- Path to a folder containing a set of config files. For example, `/var/jenkins_home/casc_configs`.
- A full path to a single file. For example, `/var/jenkins_home/casc_configs/jenkins.yaml`.
- A URL pointing to a file served on the web. For example, `https://acme.org/jenkins.yaml`.

If an element of `CASC_JENKINS_CONFIG` points to a folder, the plugin will recursively traverse the folder to find file(s) with .yml,.yaml,.YAML,.YML suffix. It will exclude hidden files or files that contain a hidden folder in **any part** of the full path. It follows symbolic links for both files and directories.
<details><summary>Exclusion examples</summary>

`CASC_JENKINS_CONFIG=/jenkins/casc_configs`  
:heavy_check_mark: `/jenkins/casc_configs/jenkins.yaml`  
:heavy_check_mark: `/jenkins/casc_configs/dir1/config.yaml`  
:x: `/jenkins/casc_configs/.dir1/config.yaml`  
:x: `/jenkins/casc_configs/..dir2/config.yaml`  
  
`CASC_JENKINS_CONFIG=/jenkins/.configs/casc_configs` contains hidden folder `.config`  
:x: `/jenkins/.configs/casc_configs/jenkins.yaml`  
:x: `/jenkins/.configs/casc_configs/dir1/config.yaml`  
:x: `/jenkins/.configs/casc_configs/.dir1/config.yaml`  
:x: `/jenkins/.configs/casc_configs/..dir2/config.yaml`  
</details>

All configuration files that are discovered MUST be supplementary. They cannot overwrite each other's configuration values. This creates a conflict and raises a `ConfiguratorException`. Thus, the order of traversal does not matter to the final outcome.

Instead of setting the `CASC_JENKINS_CONFIG` environment variable, you can also define using
the `casc.jenkins.config` Java property.  This is useful when installing Jenkins via a package
management tool and can't set an environment variable outside of a package-managed file, which could
be overwritten by an update.  For RHEL/CentOS systems, you can append the following to the
`JENKINS_JAVA_OPTIONS` entry in `/etc/sysconfig/jenkins`
 
  `-Dcasc.jenkins.config=/jenkins/casc_configs`
 
If you do not set the `CASC_JENKINS_CONFIG` environment variable or the `casc.jenkins.config` Java
property, the plugin will default to looking for a single config file in
`$JENKINS_HOME/jenkins.yaml`.

If set up correctly, you should be able to browse the Configuration as Code page `Manage Jenkins` -> `Configuration as Code`.

## Initial Configuration

When configuring the first Jenkins instance, browse the examples shown in the [demos](demos)
directory of this repository. If you have a plugin that does not have an example, consult the reference
help document. Click the `Documentation` link at the bottom of the Configuration as Code page.

![Reference Page](images/reference.png)

If you want to configure a specific plugin, search the page for the name of the plugin. The page will
show you which root element belongs to the configuration. Most installed plugins belong under the `unclassified` root
element.

![Unclassified Section](images/unclassified.png)

## Examples

See [demos](demos) folder with various samples.

### LDAP

Replace user interface based configuration for LDAP with the text-based configuration.

![configuration form](images/sample_form.png)

```yaml
jenkins:
  securityRealm:
    ldap:
      configurations:
        - groupMembershipStrategy:
            fromUserRecord:
              attributeName: ""memberOf""
          inhibitInferRootDN: false
          rootDN: ""dc=acme,dc=org""
          server: ""ldaps://ldap.acme.org:1636""
```

### Yaml Aliases and Anchors

Replace repeated elements with yaml anchors.
Anchor keys must be prefixed with `x-` due to JCasC handling unknown root elements.

```yaml
x-jenkins-linux-node: &jenkins_linux_node_anchor
  remoteFS: ""/home/jenkins""
  launcher:
    jnlp:
      workDirSettings:
        disabled: true
        failIfWorkDirIsMissing: false
        internalDir: ""remoting""
        workDirPath: ""/tmp""

jenkins:
  nodes:
    - permanent:
        name: ""static-agent1""
        <<: *jenkins_linux_node_anchor
    - permanent:
        name: ""static-agent2""
        <<: *jenkins_linux_node_anchor
```

Which produces two permanent agent nodes which can also be written like this.

```yaml
jenkins:
  nodes:
    - permanent:
        name: ""static-agent1""
        remoteFS: ""/home/jenkins""
        launcher:
          jnlp:
            workDirSettings:
              disabled: true
              failIfWorkDirIsMissing: false
              internalDir: ""remoting""
              workDirPath: ""/tmp""
    - permanent:
        name: ""static-agent2""
        remoteFS: ""/home/jenkins""
        launcher:
          jnlp:
            workDirSettings:
              disabled: true
              failIfWorkDirIsMissing: false
              internalDir: ""remoting""
              workDirPath: ""/tmp""
```

## Security considerations
Only Jenkins administrators are able to create or update a Jenkins instance using configuration as code configuration files.
However, in some environments, administrators may choose to allow less privileged users to modify portions of the configuration files, for example by storing them in an SCM repository that those users have access to.
Allowing non-administrators to edit these configuration files can pose various security risks, so any changes made by non-administrators must be reviewed for safety before they are applied.

Here are some examples of changes that could be problematic:

- Modification of the security realm or authorization strategy settings could give users higher permissions than intended.
- Interpolation of secrets in unprotected contexts may expose sensitive data. For example, a snippet like `systemMessage: ""${SENSITIVE_VARIABLE}""` could expose the value of a sensitive environment variable to all users who are able to access Jenkins.

## Installing plugins

We don't support installing plugins with JCasC, so you need to use something else for this,

Dockers users can use:\
[https://github.com/jenkinsci/docker/#preinstalling-plugins](https://github.com/jenkinsci/docker/#preinstalling-plugins)

Kubernetes users:\
[https://github.com/jenkinsci/helm-charts](https://github.com/jenkinsci/helm-charts)

## Supported Plugins

Most plugins should be supported out-of-the-box or maybe require some minimal changes. See this [dashboard](https://issues.jenkins.io/secure/Dashboard.jspa?selectPageId=18341) for known compatibility issues.

## Adding JCasC support to a plugin

Plugin developers wanting to support JCasC in their plugin should [check out our how-to guide](docs/PLUGINS.md).

## Configuration-as-Code extension plugins

- [configuration-as-code-groovy-plugin](https://github.com/jenkinsci/configuration-as-code-groovy-plugin)\
  Allows specifying groovy code that should run on during configuration.

## Jenkins Enhancement Proposal

As configuration as code is demonstrated to be a highly requested topic in the Jenkins community, we have published
[JEP 201](https://github.com/jenkinsci/jep/tree/master/jep/201) as a proposal to make this a standard component
of the Jenkins project. The proposal was accepted. :tada:
","Jenkins and its plugins require some tuning and configuration. The Configuration
as Code plugin is an _**opinionated** way to configure Jenkins based on human-
readable declarative configuration files. We want to have a well-documented
syntax file and tooling to assist in writing and writing and testing in this
tooling. We do not have full guidance using this tool set and do not need to
search to find examples on the Internet. We hope this guide will help you get
started with Jenkins."
2009,"Self-validating, secure and smart models for Laravel's Eloquent ORM","Ardent
======

[![Latest Stable Version](https://poser.pugx.org/laravelbook/ardent/v/stable.svg)](https://packagist.org/packages/laravelbook/ardent)
[![License](https://poser.pugx.org/laravelbook/ardent/license.svg)](https://packagist.org/packages/laravelbook/ardent)
[![Total Downloads](https://poser.pugx.org/laravelbook/ardent/downloads.svg)](https://packagist.org/packages/laravelbook/ardent)
[![Monthly Downloads](https://poser.pugx.org/laravelbook/ardent/d/monthly.png)](https://packagist.org/packages/laravelbook/ardent)
[![Daily Downloads](https://poser.pugx.org/laravelbook/ardent/d/daily.png)](https://packagist.org/packages/laravelbook/ardent)


Self-validating smart models for Laravel Framework 5's Eloquent ORM.

Based on the Aware bundle for Laravel 3 by Colby Rabideau.

Copyright (C) 2013-2015 [Max Ehsan](http://laravelbook.com/) & [Igor Santos](http://www.igorsantos.com.br)

## Changelog

Visit our [Releases list](https://github.com/laravelbook/ardent/releases). The changelog is made there :)

## Installation

Add `laravelbook/ardent` as a requirement to `composer.json` (see our latest stable version on the badges!):

```javascript
{
    ""require"": {
        ""laravelbook/ardent"": ""3.*""
    }
}
```

Update your packages with `composer update` or install with `composer install`.

You can also add the package using `composer require laravelbook/ardent` and later specifying the version you want (for now, `dev-master` is your best bet).

### Usage outside of Laravel (since [1.1](https://github.com/laravelbook/ardent/tree/v1.1.0))

If you're want to use Ardent as a standalone ORM package you're invited to do so by using the
following configuration in your project's boot/startup file (changing the properties according
to your database, obviously):

```php
\LaravelArdent\Ardent\Ardent::configureAsExternal(array(
  'driver'    => 'mysql',
  'host'      => 'localhost',
  'port'      => 3306,
  'database'  => 'my_system',
  'username'  => 'myself',
  'password'  => 'h4ckr',
  'charset'   => 'utf8',
  'collation' => 'utf8_unicode_ci'
), 'en'); //English is the default messages language, may be left empty
```

------------------------------------------------------------------------------------------------------------

## Documentation

* [Introduction](#introduction)
* [Getting Started](#getting-started)
* [Effortless Validation with Ardent](#effortless-validation-with-ardent)
* [Retrieving Validation Errors](#retrieving-validation-errors)
* [Overriding Validation](#overriding-validation)
* [Custom Validation Error Messages](#custom-validation-error-messages)
* [Custom Validation Rules](#custom-validation-rules)
* [Model hooks](#model-hooks-since-20)
* [Cleaner definition of relationships](#cleaner-definition-of-relationships-since-20)
* [Automatically Hydrate Ardent Entities](#automatically-hydrate-ardent-entities)
* [Automatically Purge Redundant Form Data](#automatically-purge-redundant-form-data)
* [Automatically Transform Secure-Text Attributes](#automatically-transform-secure-text-attributes)
* [Updates with Unique Rules](#updates-with-unique-rules)


## Introduction

How often do you find yourself re-creating the same boilerplate code in the applications you build? Does this typical form processing code look all too familiar to you?

```php
Route::post('register', function() {
        $rules = array(
            'name'                  => 'required|between:3,80|alpha_dash',
            'email'                 => 'required|between:5,64|email|unique:users',
            'password'              => 'required|min:6|confirmed',
            'password_confirmation' => 'required|min:6'
        );

        $validator = Validator::make(Input::all(), $rules);

        if ($validator->passes()) {
            User::create(array(
                    'name'     => Input::get('name'),
                    'email'    => Input::get('email'),
                    'password' => Hash::make(Input::get('password'))
                ));

            return Redirect::to('/')->with('message', 'Thanks for registering!');
        } else {
            return Redirect::to('/')->withErrors($validator->getMessages());
        }
    }
);
```

Implementing this yourself often results in a lot of repeated boilerplate code. As an added bonus, you controllers (or route handlers) get prematurely fat, and your code becomes messy, ugly and difficult to understand.

What if someone else did all the heavy-lifting for you? What if, instead of regurgitating the above mess, all you needed to type was these few lines?...

```php
Route::post('register', function() {
        $user = new User;
        if ($user->save()) {
            return Redirect::to('/')->with('message', 'Thanks for registering!');
        } else {
            return Redirect::to('/')->withErrors($user->errors());
        }
    }
);
```

**Enter Ardent!** 

**Ardent** - the magic-dust-powered, wrist-friendly, one-stop solution to all your dreary input sanitization boilerplates!

Puns aside, input validation functionality can quickly become tedious to write and maintain. Ardent deals away with these complexities by providing helpers for automating many repetitive tasks.

Ardent is not just great for input validation, though - it will help you significantly reduce your Eloquent data model code. Ardent is particularly useful if you find yourself wearily writing very similar code time and again in multiple individual applications.

For example, user registration or blog post submission is a common coding requirement that you might want to implement in one application and reuse again in other applications. With Ardent, you can write your *self-aware, smart* models just once, then re-use them (with no or very little modification) in other projects. Once you get used to this way of doing things, you'll honestly wonder how you ever coped without Ardent.

**No more repetitive brain strain injury for you!**


## Getting Started

`Ardent` aims to extend the `Eloquent` base class without changing its core functionality. Since `Ardent` itself is a descendant of `Illuminate\Database\Eloquent\Model`, all your `Ardent` models are fully compatible with `Eloquent` and can harness the full power of Laravels awesome OR/M.

To create a new Ardent model, simply make your model class derive from the `Ardent` base class. In the next examples we will use the complete namespaced class to make examples cleaner, but you're encouraged to make use of `use` in all your classes:

```php
use LaravelArdent\Ardent\Ardent;

class User extends Ardent {}
```

> **Note:** You can freely *co-mingle* your plain-vanilla Eloquent models with Ardent descendants. If a model object doesn't rely upon user submitted content and therefore doesn't require validation - you may leave the Eloquent model class as it is.


## Effortless Validation with Ardent

Ardent models use Laravel's built-in [Validator class](http://laravel.com/docs/validation). Defining validation rules for a model is simple and is typically done in your model class as a static variable:

```php
class User extends \LaravelArdent\Ardent\Ardent {
  public static $rules = array(
    'name'                  => 'required|between:3,80|alpha_dash',
    'email'                 => 'required|between:5,64|email|unique:users',
    'password'              => 'required|min:6|confirmed',
    'password_confirmation' => 'required|min:6',
  );
}
```

> **Note**: you're free to use the [array syntax](http://laravel.com/docs/5.0/validation#basic-usage) for validation rules as well. _I hope you don't mind the old Laravel docs link, but as good as Laravel documentation is, clear reference on pipe/array syntaxes for Validation rules is unfortunately gone since 5.1._

Ardent models validate themselves automatically when `Ardent->save()` is called.

```php
$user           = new User;
$user->name     = 'John doe';
$user->email    = 'john@doe.com';
$user->password = 'test';

$success = $user->save(); // returns false if model is invalid
```

> **Note:** You can also validate a model at any time using the `Ardent->validate()` method.


## Retrieving Validation Errors

When an Ardent model fails to validate, a `Illuminate\Support\MessageBag` object is attached to the Ardent object which contains validation failure messages.

Retrieve the validation errors message collection instance with `Ardent->errors()` method or `Ardent->validationErrors` property.

Retrieve all validation errors with `Ardent->errors()->all()`. Retrieve errors for a *specific* attribute using `Ardent->validationErrors->get('attribute')`.

> **Note:** Ardent leverages Laravel's MessagesBag object which has a [simple and elegant method](http://laravel.com/docs/validation#working-with-error-messages) of formatting errors.


## Overriding Validation

There are two ways to override Ardent's validation:

#### 1. Forced Save
`forceSave()` validates the model but saves regardless of whether or not there are validation errors.

#### 2. Override Rules and Messages
both `Ardent->save($rules, $customMessages)` and `Ardent->validate($rules, $customMessages)` take two parameters:

- `$rules` is an array of Validator rules of the same form as `Ardent::$rules`.
- The same is true of the `$customMessages` parameter (same as `Ardent::$customMessages`)

An array that is **not empty** will override the rules or custom error messages specified by the class for that instance of the method only.

> **Note:** the default value for `$rules` and `$customMessages` is empty `array()`; thus, if you pass an `array()` nothing will be overriden.


## Custom Validation Error Messages

Just like the Laravel Validator, Ardent lets you set custom error messages using the [same syntax](http://laravel.com/docs/validation#custom-error-messages).

```php
class User extends \LaravelArdent\Ardent\Ardent {
  public static $customMessages = array(
    'required' => 'The :attribute field is required.',
    ...
  );
}
```


## Custom Validation Rules

You can create custom validation rules the [same way](http://laravel.com/docs/validation#custom-validation-rules) you would for the Laravel Validator.


## Model Hooks (since [2.0](https://github.com/laravelbook/ardent/tree/v2.0.0))

Ardent provides some syntatic sugar over Eloquent's model events: traditional model hooks. They are an easy way to hook up additional operations to different moments in your model life. They can be used to do additional clean-up work before deleting an entry, doing automatic fixes after validation occurs or updating related models after an update happens.

All `before` hooks, when returning `false` (specifically boolean, not simply ""falsy"" values) will halt the operation. So, for example, if you want to stop saving if something goes wrong in a `beforeSave` method, just `return false` and the save will not happen - and obviously `afterSave` won't be called as well.

Here's the complete list of available hooks:

- `before`/`afterCreate()`
- `before`/`afterSave()`
- `before`/`afterUpdate()`
- `before`/`afterDelete()`
- `before`/`afterValidate()` - when returning false will halt validation, thus making `save()` operations fail as well since the validation was a failure.

For example, you may use `beforeSave` to hash a users password (actually, it would be a better idea to use [auto-hashing](#automatically-transform-secure-text-attributes)!):

```php
class User extends \LaravelArdent\Ardent\Ardent {
  public function beforeSave() {
    // if there's a new password, hash it
    if($this->isDirty('password')) {
      $this->password = Hash::make($this->password);
    }
    
    return true;
    //or don't return nothing, since only a boolean false will halt the operation
  }
}
```

### Additionals beforeSave and afterSave (since 1.0)

`beforeSave` and `afterSave` can be included at run-time. Simply pass in closures with the model as argument to the `save()` (or `forceSave()`) method.

```php
$user->save(array(), array(), array(),
  function ($model) { // closure for beforeSave
    echo ""saving the model object..."";
    return true;
  },
  function ($model) { // closure for afterSave
    echo ""done!"";
  }
);
```

> **Note:** the closures should have one parameter as it will be passed a reference to the model being saved.


## Cleaner definition of relationships (since [2.0](https://github.com/laravelbook/ardent/tree/v2.0.0))

Have you ever written an Eloquent model with a bunch of relations, just to notice how cluttered your class is, with all those one-liners that have almost the same content as the method name itself?

In Ardent you can cleanly define your relationships in an array with their information, and they will work just like if you had defined them in methods. Here's an example:

```php
class User extends \LaravelArdent\Ardent\Ardent {
  public static $relationsData = array(
    'address' => array(self::HAS_ONE, 'Address'),
    'orders'  => array(self::HAS_MANY, 'Order'),
    'groups'  => array(self::BELONGS_TO_MANY, 'Group', 'table' => 'groups_have_users')
  );
}

$user = User::find($id);
echo ""{$user->address->street}, {$user->address->city} - {$user->address->state}"";
```

The array syntax is as follows:

- First indexed value: relation name, being one of
[`hasOne`](http://laravel.com/api/class-Illuminate.Database.Eloquent.Model.html#_hasOne),
[`hasMany`](http://laravel.com/api/class-Illuminate.Database.Eloquent.Model.html#_hasMany),
[`belongsTo`](http://laravel.com/api/class-Illuminate.Database.Eloquent.Model.html#_belongsTo),
[`belongsToMany`](http://laravel.com/api/class-Illuminate.Database.Eloquent.Model.html#_belongsToMany),
[`morphTo`](http://laravel.com/api/class-Illuminate.Database.Eloquent.Model.html#_morphTo),
[`morphOne`](http://laravel.com/api/class-Illuminate.Database.Eloquent.Model.html#_morphOne),
[`morphMany`](http://laravel.com/api/class-Illuminate.Database.Eloquent.Model.html#_morphMany),
or one of the related constants (`Ardent::HAS_MANY` or `Ardent::MORPH_ONE` for example).
- Second indexed: class name, with complete namespace. The exception is `morphTo` relations, that take no additional argument.
- named arguments, following the ones defined for the original Eloquent methods:
    - `foreignKey` [optional], valid for `hasOne`, `hasMany`, `belongsTo` and `belongsToMany`
    - `table`,`otherKey` [optional],`timestamps` [boolean, optional], and `pivotKeys` [array, optional], valid for `belongsToMany`
    - `name`, `type` and `id`, used by `morphTo`, `morphOne` and `morphMany` (the last two requires `name` to be defined)
    
> **Note:** This feature was based on the easy [relations on Yii 1.1 ActiveRecord](http://www.yiiframework.com/doc/guide/1.1/en/database.arr#declaring-relationship).


## Automatically Hydrate Ardent Entities

Ardent is capable of hydrating your entity model class from the form input submission automatically! 

Let's see it action. Consider this snippet of code:

```php
$user           = new User;
$user->name     = Input::get('name');
$user->email    = Input::get('email');
$user->password = Hash::make(Input::get('password'));
$user->save();
```

Let's invoke the *magick* of Ardent and rewrite the previous snippet:

```php
$user = new User;
$user->save();
```

That's it! All we've done is remove the boring stuff.

Believe it or not, the code above performs essentially the same task as its older, albeit rather verbose sibling. Ardent populates the model object with attributes from user submitted form data. No more hair-pulling trying to find out which Eloquent property you've forgotten to populate. Let Ardent take care of the boring stuff, while you get on with the fun stuffs!  
It follows the same [mass assignment rules](http://laravel.com/docs/eloquent#mass-assignment) internally, depending on the `$fillable`/`$guarded` properties.

To enable the auto-hydration feature, simply set the `$autoHydrateEntityFromInput` instance variable to `true` in your model class. However, to prevent filling pre-existent properties, if you want auto-hydration also for update scenarios, you should use instead `$forceEntityHydrationFromInput`:

```php
class User extends \LaravelArdent\Ardent\Ardent {
  public $autoHydrateEntityFromInput = true;    // hydrates on new entries' validation
  public $forceEntityHydrationFromInput = true; // hydrates whenever validation is called
}
```


## Automatically Purge Redundant Form Data

Ardent models can *auto-magically* purge redundant input data (such as *password confirmation*, hidden CSRF `_token` or custom HTTP `_method` fields) - so that the extra data is never saved to database. Ardent will use the confirmation fields to validate form input, then prudently discard these attributes before saving the model instance to database!

To enable this feature, simply set the `$autoPurgeRedundantAttributes` instance variable to `true` in your model class:

```php
class User extends \LaravelArdent\Ardent\Ardent {
  public $autoPurgeRedundantAttributes = true;
}
```

You can also purge additional fields. The attribute `Ardent::$purgeFilters` is an array of closures to which you can add your custom rules. Those closures receive the attribute key as argument and should return `false` for attributes that should be purged. Like this:

```php
function __construct($attributes = array()) {
  parent::__construct($attributes);

  $this->purgeFilters[] = function($key) {
    $purge = array('tempData', 'myAttribute');
    return ! in_array($key, $purge);
  };
}
```


## Automatically Transform Secure-Text Attributes

Suppose you have an attribute named `password` in your model class, but don't want to store the plain-text version in the database. The pragmatic thing to do would be to store the hash of the original content. Worry not, Ardent is fully capable of transmogrifying any number of secure fields automatically for you!

To do that, add the attribute name to the `Ardent::$passwordAttributes` static array variable in your model class, and set the `$autoHashPasswordAttributes` instance variable to `true`:

```php
class User extends \LaravelArdent\Ardent\Ardent {
  public static $passwordAttributes  = array('password');
  public $autoHashPasswordAttributes = true;
}
```

Ardent will automatically replace the plain-text password attribute with secure hash checksum and save it to database. It uses the Laravel `Hash::make()` method internally to generate hash. _Note: It's advised to use Eloquent's [`$hidden`](https://laravel.com/docs/5.2/eloquent-serialization#hiding-attributes-from-json) attribute so the password, even hashed, won't come out that easily if you're building an API or similar :)_

In case you're using Ardent standalone, you can use `Ardent::$hasher` to verify the field value, using something like `User::$hasher->check($given_password, $user->password)`.


## Updates with Unique Rules

Ardent can assist you with unique updates. According to the Laravel Documentation, when you update (and therefore validate) a field with a unique rule, you have to pass in the unique ID of the record you are updating. Without passing this ID, validation will fail because Laravel's Validator will think this record is a duplicate.

From the Laravel Documentation:

```php
    'email' => 'unique:users,email,10'
```

In the past, programmers had to manually manage the passing of the ID and changing of the ruleset to include the ID at runtime. Not so with Ardent. Simply set up your rules with `unique`, call function `updateUniques` and Ardent will take care of the rest.

#### Example:

In your extended model define your rules

```php
  public static $rules = array(
     'email' => 'required|email|unique',
     'password' => 'required|between:4,20|confirmed',
     'password_confirmation' => 'between:4,20',
  );
```

In your controller, when you need to update, simply call

```php
$model->updateUniques();
```

If required, you can runtime pass rules to `updateUniques`, otherwise it will use the static rules provided by your model.

Note that in the above example of the rules, we did not tell the Validator which table or even which field to use as it is described in the Laravel Documentation (ie `unique:users,email,10`). Ardent is clever enough to figure it out. (Thank you to github user @Sylph)

","Ardent aims to extend the Eloquent data model without changing its core
functionality. With Ardent, you can write your *smart* models just once, then
re-use them in other applications. Ardent is a descendant of `Eloquent` and is
available as a free download from the GitHub repository. For more information
about Ardent and how to use it, visit www.ardent.org or go to the Ardent
website. Back to the page you came from."
3003,"free4.chat is a real-time audio chat service.  It is designed by the local first and privacy first principle, and is very easy to use.","# free4chat

[free4.chat](https://free4.chat/) is an instant audio conferencing service.

It is designed by the [local first](https://www.inkandswitch.com/local-first/) and `privacy first` principle, and is very easy to use.

> :warning: **This project is just using for technical test purpose, use at all your risk!** 
>
> :warning: **There is freedom of speech, but I cannot guarantee freedom after speech.** (- Idi Amin)

## Features

- **Common**
  - [ ] Use [WebSocket](https://developer.mozilla.org/en-US/docs/Web/API/WebSocket) to replace http protocol of JSON-RPC
- **Room**
  - [ ] Text chat, can sent text or emoji
  - [ ] Can send arbitrary data by WebRTC datachannel
  - [ ] Can share screen if the device support
  - [ ] Room permission setting, like public/private type setting
    - private room can't been seen on room discovery, and it needs password to enter. The password is [End-to-End Encryption](https://blog.excalidraw.com/end-to-end-encryption/), server only need check the answer which given by the client like the `PoW in blockchain`<sup>*</sup>
    - [ ] Public rooms discovery, like hot room list or filter rooms by type/tag
- **User**
  - [ ] Robot user, like game robot who can play or facilitate game
    - robot use [Web Speech API](https://developer.mozilla.org/en-US/docs/Web/API/Web_Speech_API) to play with user in room
    - robot can play some voice games like language learning, technical interview, etc.
      - [Gartic Phone - The Telephone Game](https://garticphone.com/lobby)
      - [ESL Game - Not only practicing English speaking](https://esl.bmpi.dev/)
      - [Gartic.io - Draw, Guess, WIN](https://gartic.io/)
  - [ ] User real-time collaboration, like whiteboard, you draw I guess, etc.
  
## Architecture
- **Tech Stack**
  - [ ] Use Elixir/Phoenix to rewrite the backend code 🚩
  - [ ] Use Recat/Next.js to rewrite the frontend code
- **Infra**
  - [ ] Use docker to deploy to PaaS platform like [Railway](https://railway.app/) or [Fly](https://fly.io/)
  - [ ] Backend service cluster, auto scaling, load balancing, etc.
  - [ ] Security enhancement, like coturn TLS setup, end-to-end encryption, etc.
  - [ ] Privacy enhancement.
  - [ ] IPV6 support.

__NOTE__: 
- `*` means it can be considered a VIP feature.

## Contribution

If you are interested in `webRTC`, `peer-to-peer(P2P)`, `real-time collaboration(CRDT)`, `distributed system` or `robot design`, you can join this project and contact with me by [twitter](https://twitter.com/madawei2699).

## Thanks

- free4.chat Elixir version is build on the top of [Membrane Framework](https://github.com/membraneframework), thanks for their heart of open source.
- [free4.chat Golang version](https://github.com/madawei2699/free4chat/tree/golang) is build on the top of [Kraken](https://github.com/bmpi-dev/kraken), [Mornin](https://github.com/lyricat/mornin.fm), [coturn](https://github.com/coturn/coturn) and [Pion](https://github.com/pion), thanks for their heart of open source.
- These websites also inspired me:
  - [Random voice and text chat rooms that you’ll love. | Speakrandom](https://www.speakrandom.com/)
  - [Practice Speaking English Online Free - Language Practice Community](https://www.free4talk.com/)
  - [Agora Real-Time Voice and Video Engagement](https://www.agora.io/en/)
","Free4chat is an instant audio conferencing service. It is designed by the [local
first](https://www.inkandswitch.com/local-first/) and `privacy first` principle.
It uses WebSocket to replace http protocol of JSON-RPC. It can send arbitrary
data by WebRTC datachannel."
2816,TensorFlow Similarity is a python package focused on making similarity learning quick and easy.,"# TensorFlow Similarity: Metric Learning for Humans

TensorFlow Similarity is a [TensorFlow](https://tensorflow.org) library for [similarity learning](https://en.wikipedia.org/wiki/Similarity_learning) which includes techniques such as self-supervised learning, metric learning, similarity learning, and contrastive learning. TensorFlow Similarity is still in beta and we may push breaking changes.

## Introduction

Tensorflow Similarity offers state-of-the-art algorithms for metric learning along with all the necessary components to research, train, evaluate, and serve similarity and contrastive based models. These components include models, losses, metrics, samplers, visualizers, and indexing subsystems to make this quick and easy.

![Example of nearest neighbors search performed on the embedding generated by a similarity model trained on the Oxford IIIT Pet Dataset.](https://raw.githubusercontent.com/tensorflow/similarity/master/assets/images/similar-cats-and-dogs.jpg)

With Tensorflow Similarity you can train two main types of models:

1. **Self-supervised models**: Used to learn general data representations on unlabeled data to boost the accuracy of downstream tasks where you have few labels. For example, you can pre-train a model on a large number of unlabled images using one of the supported contrastive methods supported by TensorFlow Similarity, and then fine-tune it on a small labeled dataset to achieve higher accuracy. To get started training your own self-supervised model see this [notebook](examples/unsupervised_hello_world.ipynb).

2. **Similarity models**: Output embeddings that allow you to find and cluster similar examples such as images representing the same object within a large corpus of examples. For instance, as visible above, you can train a similarity model to find and cluster similar looking, unseen cat and dog images from the [Oxford IIIT Pet Dataset](https://www.tensorflow.org/datasets/catalog/oxford_iiit_pet) while only training on a few of the dataset classes. To get started training your own similarity model see this [notebook](examples/supervised/visualization.ipynb).

## What's new

- [May 2022]: 0.16 major optimization release
    * Cross-batch memory (XBM) loss added thank to @chjort
    * Many self-supervised related improvement thanks to @dewball345
    * Major layers and callback refactoring to make them faster and more flexible. E.g `EvalCallback()` now support splited validation.
     For full changes see [the changelog](./releases.md)

- [Jan 2022]: 0.15 self-supervised release
    * Added support for self-supervised contrastive learning. Including SimCLR, SimSiam, and Barlow Twins. Checkout the in-depth [hello world notebook](examples/unsupervised_hello_world.ipynb) to get started.
    * Soft Nearest Neighbor Loss added thanks to [Abhishar Sinha](https://github.com/abhisharsinha)
    * Added GenerlizedMeanPooling2D support that improves similarity matching accuracy over GlobalMeanPooling2D.
    * Numerous speed optimizations and general bug fixes.

For previous changes and more details - see [the changelog](./releases.md)

## Getting Started

### Installation

Use pip to install the library.

**NOTE**: The Tensorflow extra_require key can be omitted if you already have tensorflow>=2.4 installed.

```shell
pip install --upgrade-strategy=only-if-needed tensorflow_similarity[tensorflow] 
```

### Documentation

The detailed and narrated [notebooks](examples/) are a good way to get started with TensorFlow Similarity. There is likely to be one that is similar to your data or your problem (if not, let us know). You can start working with the examples immediately in Google Colab by clicking the Google Colab icon.

For more information about specific functions, you can [check the API documentation](api/)

For contributing to the project please check out the [contribution guidelines](CONTRIBUTING.md)

### Minimal Example: MNIST similarity
<details>
   <summary> Click to expand and see how to train a supervised similarity model on mnist using TF.Similarity</summary>

Here is a bare bones example demonstrating how to train a TensorFlow Similarity model on the MNIST data. This example illustrates some of the main components provided by TensorFlow Similarity and how they fit together. Please refer to the [hello_world notebook](examples/supervised_hello_world.ipynb) for a more detailed introduction.

### Preparing data

TensorFlow Similarity provides [data samplers](api/TFSimilarity/samplers/), for various dataset types, that balance the batches to ensure smoother training.
In this example, we are using the multi-shot sampler that integrates directly from the TensorFlow dataset catalog.

```python
from tensorflow_similarity.samplers import TFDatasetMultiShotMemorySampler

# Data sampler that generates balanced batches from MNIST dataset
sampler = TFDatasetMultiShotMemorySampler(dataset_name='mnist', classes_per_batch=10)
```

### Building a Similarity model

Building a TensorFlow Similarity model is similar to building a standard Keras model, except the output layer is usually a [`MetricEmbedding()`](api/TFSimilarity/layers/) layer that enforces L2 normalization and the model is instantiated as a specialized subclass [`SimilarityModel()`](api/TFSimilarity/models/SimilarityModel.md) that supports additional functionality.

```python
from tensorflow.keras import layers
from tensorflow_similarity.layers import MetricEmbedding
from tensorflow_similarity.models import SimilarityModel

# Build a Similarity model using standard Keras layers
inputs = layers.Input(shape=(28, 28, 1))
x = layers.experimental.preprocessing.Rescaling(1/255)(inputs)
x = layers.Conv2D(64, 3, activation='relu')(x)
x = layers.Flatten()(x)
x = layers.Dense(64, activation='relu')(x)
outputs = MetricEmbedding(64)(x)

# Build a specialized Similarity model
model = SimilarityModel(inputs, outputs)
```

### Training model via contrastive learning

To output a metric embedding, that are searchable via approximate nearest neighbor search, the model needs to be trained using a similarity loss. Here we are using the `MultiSimilarityLoss()`, which is one of the most efficient loss functions.

```python
from tensorflow_similarity.losses import MultiSimilarityLoss

# Train Similarity model using contrastive loss
model.compile('adam', loss=MultiSimilarityLoss())
model.fit(sampler, epochs=5)
```

### Building images index and querying it

Once the model is trained, reference examples must be indexed via the model index API to be searchable. After indexing, you can use the model lookup API to search the index for the K most similar items.

```python
from tensorflow_similarity.visualization import viz_neigbors_imgs

# Index 100 embedded MNIST examples to make them searchable
sx, sy = sampler.get_slice(0,100)
model.index(x=sx, y=sy, data=sx)

# Find the top 5 most similar indexed MNIST examples for a given example
qx, qy = sampler.get_slice(3713, 1)
nns = model.single_lookup(qx[0])

# Visualize the query example and its top 5 neighbors
viz_neigbors_imgs(qx[0], qy[0], nns)
```
</details>

## Supported Algorithms

### Self-Supervised Models

- SimCLR 
- SimSiam
- Barlow Twins

### Supervised Losses

- Triplet Loss
- PN Loss
- Multi Sim Loss
- Circle Loss
- Soft Nearest Neighbor Loss

### Metrics

Tensorflow Similarity offers many of the most common metrics used for [classification](api/TFSimilarity/classification_metrics/) and [retrieval](api/TFSimilarity/retrieval_metrics/) evaluation. Including:

| Name | Type | Description |
| ---- | ---- | ----------- |
| Precision | Classification | |
| Recall | Classification | |
| F1 Score | Classification | |
| Recall@K | Retrieval | |
| Binary NDCG | Retrieval | |

## Citing

Please cite this reference if you use any part of TensorFlow similarity in your research:

```bibtex
@article{EBSIM21,
  title={TensorFlow Similarity: A Usable, High-Performance Metric Learning Library},
  author={Elie Bursztein, James Long, Shun Lin, Owen Vallis, Francois Chollet},
  journal={Fixme},
  year={2021}
}
```

## Disclaimer

This is not an official Google product.
","TensorFlow Similarity offers state-of-the-art algorithms for metric learning
along with all the necessary components to research, train, evaluate, and serve
similarity and contrastive based models. These components include models,
losses, metrics, samplers, and indexing subsystems to make this quick and easy.
With Tensorflow Similarity you can train two main types of models: self-
supervised models and supervised models. For more information about specific
functions, please check out the project's [contribution guidelines]"
2304,:memo: Подборка ресурсов по машинному обучению,"# Машинное обучение

Постоянно обновляемая подборка ресурсов по машинному обучению.

#### Оглавление

* [Библиотека ML-специалиста](#Библиотека-ml-специалиста) + выбор редакции:
  * [Дополнительные материалы](https://gist.github.com/demidovakatya/cef3d462bcf56b84f56950ea490a9e8e) к курсу «Введение в машинное обучение»
  * [Рекомендации](https://gist.github.com/demidovakatya/61e15717a9eefae0bd237b7fd959d166) от преподавателей специализации «Машинное обучение и анализ данных»
  * [Литература для поступления в ШАД](https://gist.github.com/demidovakatya/873e4dd6f1c6652ac842)
  * [Подборка научпоп-книг](https://bookmate.com/bookshelves/Nggk0rBi)
* По темам: 
  * [Big Data](/big-data.md)
  * [Dataviz](/dataviz.md)
  * [LaTeX](/latex.md)
  * [NLP](/nlp.md)
  * [Python, IPython, Scikit-learn etc](/python.md)
  * [R](/r.md)
  * [Алгоритмы](/algorithms.md)
  * [Линейная алгебра](/linalg.md)
  * [Нейронные сети, Deep learning](/neural-nets.md)
  * [Статистика и теория вероятностей](/probability-statistics.md)
* [Онлайн-курсы (MOOC)](#Онлайн-курсы-mooc)
* [Чаты/паблики/каналы про ML](#social)

----------------------------------------------------

* [Календарь соревнований по анализу данных](https://mltrainings.ru/?filter=active)
* [Машинное обучение: вводная лекция](http://www.machinelearning.ru/wiki/images/f/fc/Voron-ML-Intro-slides.pdf) – К. В. Воронцов
* [Lecture notes and code for Machine Learning practical course on CMC MSU](https://github.com/esokolov/ml-course-msu)
* [100+ Free Data Science Books](https://www.learndatasci.com/free-data-science-books/) – более 100 бесплатных книг по Data Science
* [Free O'Reilly data science ebooks](https://www.oreilly.com/data/free/archive.html)
* [100 репозиториев по машинному обучению](http://meta-guide.com/software-meta-guide/100-best-github-machine-learning)
* [awesome-machine-learning](https://github.com/josephmisiti/awesome-machine-learning) — A curated list of awesome Machine Learning frameworks, libraries and software
* [Open Source Society University's Data Science course](https://github.com/ossu/data-science) – this is a solid path for those of you who want to complete a Data Science course on your own time, for free, with courses from the best universities in the World
* [Доска по data science в Trello](https://trello.com/b/rbpEfMld/data-science) — проверенные материалы, организованные по темам (expertise tracks, языки программирования, различные инструменты)
* [Machine Learning Resource Guide](https://www.pdf-archive.com/2017/09/02/machine-learning-resource-guide/machine-learning-resource-guide.pdf)
* [17 ресурсов по машинному обучению от Типичного Программиста](https://tproger.ru/articles/free-programming-books/#machine-learning)
* [51 toy data problem in Data Science](https://www.quora.com/Data-Science/What-are-some-good-toy-problems-can-be-done-over-a-weekend-by-a-single-coder-in-data-science-Im-studying-machine-learning-and-statistics-and-looking-for-something-socially-relevant-using-publicly-available-datasets-APIs/answer/Alex-Kamil) 
* [practical-pandas-projects](https://github.com/schlende/practical-pandas-projects) — project ideas for improving one's Python data analysis skills
* [Dive into Machine Learning](https://hangtwenty.github.io/dive-into-machine-learning/) 
  * :octocat: [Dive into Machine Learning repo on github](https://github.com/hangtwenty/dive-into-machine-learning)
* [Data Science Interview Questions](https://www.itshared.org/2015/10/data-science-interview-questions.html) — огромный список вопросов для подготовки к интервью на позицию data scientist'а
* [Много книг по Natural Language Processing](https://www.dropbox.com/sh/b1c2ulwua9zy574/AACswS1E0IB9LdPDxQ6fexm4a?dl=0)
* [Список открытых источников данных, на которых можно найти бесплатные датасеты](/datasets.md)
* [What should I learn in data science in 100 hours?](https://www.quora.com/What-should-I-learn-in-data-science-in-100-hours-I-am-free-for-the-next-10-days-and-would-like-to-learn-whatever-I-can-in-the-next-10-days-and-I-can-put-in-10-hours-a-day-What-can-I-learn-to-get-a-hang-of-it-and-get-started/answer/Roman-Trusov)
* [machine-learning-for-software-engineers](https://github.com/ZuzooVn/machine-learning-for-software-engineers) — A complete daily plan for studying to become a machine learning engineer
* [Tutorials on topics in machine learning](https://homepages.inf.ed.ac.uk/rbf/IAPR/researchers/MLPAGES/mltut.htm)
* [Постоянно обновляющаяся подборка ссылок по датасаенсу](https://docs.google.com/spreadsheets/d/1dXghGL0hH6gs3H9Km7zhOpk9MWufRJ_bSrFw0NLaRuo/edit#gid=0)
* [Teach yourself Machine Learning the hard way!](https://darshanhegde.wordpress.com/2014/08/19/learn-machine-learning-the-hard-way/)
* [An article a week](https://github.com/shagunsodhani/papers-I-read) – list of good articles on ML/AI/DL
* [The most popular programming books ever mentioned on StackOverflow](https://medium.freecodecamp.org/i-analyzed-every-book-ever-mentioned-on-stack-overflow-here-are-the-most-popular-ones-eee0891f1786)
* [Cookiecutter Data Science](https://drivendata.github.io/cookiecutter-data-science/) – A logical, reasonably standardized, but flexible project structure for doing and sharing data science work
* [awesome-datascience-ideas](https://github.com/faktionai/awesome-ai-usecases) – A list of awesome and proven data science use cases and applications
* [machine-learning-surveys](https://github.com/mlreview/machine-learning-surveys) – A curated list of Machine Learning Surveys, Tutorials and Books
* [A hands-on data science crash course in Python by Bart De Vylder and Pieter Buteneers from CoScale](https://github.com/bartdevylder/velocity-tutorial-san-jose)
* [docker-setup](https://github.com/yang-zhang/docker-setup) – A Curated List of Docker Images for Data Science Projects, with Easy Setup
* [Notes on Artificial Intelligence](https://frnsys.com/ai_notes/)  – конспекты по разным ML-related темам, от алгебры до Байеса

----------------------------------------------------

## Библиотека ML-специалиста

* [A Course in Machine Learning](http://ciml.info) – Hal Daumé III
* [A Probabilistic Theory of Pattern Recognition](https://www.szit.bme.hu/%7Egyorfi/pbook.pdf) – Devroye, Gyorfi, Lugosi (pdf)
* [Applied Predictive Modeling](https://www.springer.com/us/book/9781461468486) – M. Kuhn, K. Johnson (2013)
* [Bayesian Reasoning and Machine Learning](http://web4.cs.ucl.ac.uk/staff/D.Barber/textbook/181115.pdf) - D.Barber (2015) (pdf)
* [Core Concepts in Data Analysis: Summarization, Correlation and Visualization](https://www.springer.com/us/book/9780857292865) – Boris Mirkin
* [Data Mining and Analysis. Fundamental Concepts and Algorithms](https://repo.palkeo.com/algo/information-retrieval/Data%20mining%20and%20analysis.pdf) – M.J.Zaki, W.Meira Jr (2014) (pdf)
* [Data Mining: Concepts and Techniques](https://www.sciencedirect.com/book/9780123814791/data-mining-concepts-and-techniques) – Jiawei Han et. al.
* [Data Science For Dummies](https://www.geekbooks.me/book/view/data-science-for-dummies) – Lillian Pierson (2015)
* [Doing Data Science](http://shop.oreilly.com/product/0636920028529.do)
* [Elements of Statistical Learning](https://www-stat.stanford.edu/~tibs/ElemStatLearn/printings/ESLII_print10.pdf) – Hastie, Tibshirani, Friedman (pdf)
* [Foundations of Machine Learning](https://cs.nyu.edu/~mohri/mlbook/) – Mehryar Mohri, Afshin Rostamizadeh, and Ameet Talwalkar (2012)
* [Frequent Pattern Mining](http://www.charuaggarwal.net/freqbook.pdf) – Charu C Aggarwal, Jiawei Han (eds.) (pdf)
* [Gaussian Processes for Machine Learning](http://www.gaussianprocess.org/gpml/chapters/RW.pdf) – Carl E. Rasmugit lssen, Christopher K. I. Williams (pdf)
* [Inductive Logic Programming: Techniques and Applications](http://www.e-booksdirectory.com/details.php?ebook=1105) – Nada Lavrac, Saso Dzeroski
* [Information Theory, Inference and Learning Algorithms](http://www.inference.phy.cam.ac.uk/itila/book.html) – David MacKay
* [Introduction to Information Retrieval](https://nlp.stanford.edu/IR-book/pdf/irbookprint.pdf) – Manning, Rhagavan, Shutze (pdf)
* [Introduction To Machine Learning](http://www.e-booksdirectory.com/details.php?ebook=1117) – Nils J Nilsson (1997)
* [Introduction to Machine Learning](https://alex.smola.org/drafts/thebook.pdf) – Smola and Vishwanathan (pdf)
* [Machine learning cheat sheet](https://github.com/soulmachine/machine-learning-cheat-sheet/raw/master/machine-learning-cheat-sheet.pdf) – soulmachine (2017) (pdf)
* [Machine Learning in Action](https://www.manning.com/books/machine-learning-in-action) – Peter Harrington
* [Machine Learning, Neural and Statistical Classification](http://www.e-booksdirectory.com/details.php?ebook=1118) – D. Michie, D. J. Spiegelhalter
* [Machine Learning. The Art of Science of Algorithms that Make Sense of Data](https://www.amazon.com/Machine-Learning-Science-Algorithms-Sense/dp/1107422221/) – P. Flach (2012)
* [Machine Learning](http://profsite.um.ac.ir/~monsefi/machine-learning/pdf/Machine-Learning-Tom-Mitchell.pdf) – Tom Mitchell
* [Machine Learning](https://www.mlyearning.org/) – Andrew Ng
* [Mining Massive Datasets](http://www.mmds.org/) – Jure Leskovec, Anand Rajaraman, Jeff Ullman
* [Pattern Recognition and Machine Learning](https://www.amazon.com/Pattern-Recognition-Learning-Information-Statistics/dp/0387310738/) – C.M.Bishop (2006)
* [Probabilistic Programming and Bayesian Methods for Hackers](https://camdavidsonpilon.github.io/Probabilistic-Programming-and-Bayesian-Methods-for-Hackers/) (free)
* [A Programmer's Guide to Data Mining](http://guidetodatamining.com/assets/guideChapters/Guide2DataMining.pdf) – Ron Zacharski (pdf)
* [R in Action](https://www.manning.com/books/r-in-action)
* [Reinforcement Learning: An Introduction](http://www.e-booksdirectory.com/details.php?ebook=1825) - Richard S. Sutton, Andrew G. Barto
* [The LION Way Machine Learning plus Intelligent Optimization](https://intelligent-optimization.org/LIONbook/lionbook_3v0.pdf) (pdf)
* [Understanding Machine Learning: From Theory to Algorithms](https://www.cs.huji.ac.il/%7Eshais/UnderstandingMachineLearning/copy.html)
* [Анализ больших наборов данных](https://dmkpress.com/catalog/computer/data/978-5-97060-190-7/) – перевод Mining Massive Datasets
* [Математические методы обучения по прецедентам (теория обучения машин)](http://www.machinelearning.ru/wiki/images/6/6d/Voron-ML-1.pdf) – К. В. Воронцов (pdf)
* [Машинное обучение](https://www.pdf-archive.com/2017/09/02/machine-learning-ru-flach-p/machine-learning-ru-flach-p.pdf) — Петер Флах (pdf)
* [Методы ансамблирования обучающихся алгоритмов](http://www.machinelearning.ru/wiki/images/5/56/Guschin2015Stacking.pdf) — диссертация А. Гущина (pdf)

----------------------------------------------------

## Онлайн-курсы (MOOC)

* [Перечень лучших курсов по практически любым областям математики](https://www.quora.com/What-are-the-best-online-college-level-mathematics-courses)
* [Тонна разнообразных курсов по программированию, алгоритмам, в том числе 29 курсов по ML](https://github.com/prakhar1989/awesome-courses)
* Coursera:
  * [CS229: Machine Learning (Andrew Ng, Stanford University)](https://www.coursera.org/learn/machine-learning) – самый популярный курс по машинному обучению (осторожно, вместо стандартных Питона или R – Matlab/Octave)
  * Специализация [Машинное обучение и Анализ данных (Яндекс + МФТИ/MIPT)](https://www.coursera.org/specializations/machine-learning-data-analysis) 
    * :octocat: [мой репозиторий по этой специализации](https://github.com/demidovakatya/mashinnoye-obucheniye)
  * [Machine Learning Foundations: A Case Study Approach (University of Washington)](https://www.coursera.org/learn/ml-foundations/)
  * [Data Mining Specialization](https://www.coursera.org/specializations/data-mining)
  * [Data Science at Scale Specialization (University of Washington)](https://www.coursera.org/specializations/data-science)
  * [Calculus: Single Variable Part 1 (University of Pennsylvania)](https://www.coursera.org/learn/single-variable-calculus)
  * [Современная комбинаторика (А.М. Райгородский, МФТИ/MIPT)](https://www.coursera.org/learn/modern-combinatorics)
  * [Теория вероятностей для начинающих (А.М. Райгородский, МФТИ/MIPT)](https://www.coursera.org/learn/probability-theory-basics/)
  * [Линейная алгебра (ВШЭ/HSE)](https://www.coursera.org/learn/algebra-lineynaya) — курс линейной алгебры для нематематических факультетов, подходит «для быстрого старта»
  * [Эконометрика (ВШЭ/HSE)](https://www.coursera.org/learn/ekonometrika/) (Econometrics)
  * [Business Analytics Specialization (University of Pennsylvania)](https://www.coursera.org/specializations/business-analytics) – специализация о практическом применении статистики и анализа данных. Для людей, разочаровавшихся в DS и не понимающих, на кой это всё
  * [Social Network Analysis (University of Michigan)](https://www.coursera.org/learn/python-social-network-analysis)
  * [Social and Economic Networks: Models and Analysis (Stanford University)](https://www.coursera.org/learn/social-economic-networks)
  * [Recommender Systems Specialization (University of Minnesota)](https://www.coursera.org/specializations/recommender-systems)
  * [Build Intelligent Applications Specialization (University of Washington)](https://www.coursera.org/specializations/machine-learning)
  * [Программирование на Python (МФТИ/MIPT)](https://www.coursera.org/learn/diving-in-python)
* Udacity:
  * [Machine Learning Engineer Nanodegree (co-created by Kaggle)](https://www.udacity.com/course/machine-learning-engineer-nanodegree--nd009)
  * [Data Analyst Nanodegree (co-created by Facebook & MongoDB)](https://www.udacity.com/course/data-analyst-nanodegree--nd002)
  * [Artificial Intelligence Nanodegree (co-created by IBM Watson & Amazon Alexa)](https://www.udacity.com/course/artificial-intelligence-nanodegree--nd889)
  * [Predictive Analytics for Business Nanodegree (co-created by Tableau & Alteryx)](https://www.udacity.com/degrees/predictive-analytics-for-business--nd008)
* Edx:
  * [Data Science and Engineering with Spark XSeries (Berkeley)](https://www.edx.org/xseries/data-science-engineering-apacher-sparktm)
  * [6.002x: Introduction to Computational Thinking and Data Science (MIT)](https://www.edx.org/course/introduction-to-computational-thinking-and-data-science-2)
  * [6.041x: Introduction to Probability - The Science of Uncertainty (MIT)](https://www.edx.org/course/introduction-probability-science-mitx-6-041x-2)
  * [The Analytics Edge (MIT)](https://www.edx.org/course/the-analytics-edge-0)
* [Learning from Data (Caltech)](https://work.caltech.edu/telecourse.html) – введение в машинное обучение (основная теория, алгоритмы и области практического применения)
* [Видеозаписи лекций Школы Анализа Данных (ШАД)](https://yandexdataschool.ru/edu-process/courses)
  * [Видеолекции курса «Машинное обучение» (К. В. Воронцов, ШАД)](https://yandexdataschool.ru/edu-process/courses/machine-learning)
* [Data Mining in Action course materials (МФТИ/MIPT)](https://github.com/vkantor/MIPT_Data_Mining_In_Action_2016) 
* [Открытый курс OpenDataScience по машинному обучению](https://github.com/Yorko/mlcourse.ai)
* [Intro to Python for Data Science](https://www.datacamp.com/courses/intro-to-python-for-data-science) – основы Python и немного про NumPy
* [Основы статистики](https://stepic.org/course/76) — качественное введение в статистику, целиком на русском языке
* [Data Science and Machine Learning Essentials (Microsoft)](https://mva.microsoft.com/en-US/training-courses/data-science-and-machine-learning-essentials-14100)
* [CS231n: Convolutional Neural Networks for Visual Recognition (Stanford University)](http://cs231n.stanford.edu/) — отличный десятинедельный курс по нейросетям и компьютерному зрению
  * :octocat: [repo on github](https://github.com/cs231n/cs231n.github.io)
* [Mining Massive Datasets (Stanford University)](https://lagunita.stanford.edu/courses/course-v1:ComputerScience+MMDS+Fall2016/about) - курс, основанный на книге Mining of Massive Datasets авторов Jure Leskovec, Anand Rajaraman, and Jeff Ullman (они же являются инструкторами этого курса)
* [CS109: Data Science (Harvard University)](http://web.stanford.edu/class/cs109/)
* [Foundations of Machine Learning](https://bloomberg.github.io/foml/) — a part of Bloomberg's _Machine Learning EDU_ initiative

----------------------------------------------------

## Social

Обсуждение машинного обучения в мессенджерах (группы, каналы, чаты, сообщества).

* [Open Data Science](http://ods.ai)
* [Посвященная московским ML-тренировкам группа в facebook](https://www.facebook.com/groups/1413405125598651/)
* [и группа вконтакте про тренировки по машинному обучению](https://vk.com/mltrainings)
* [Томская группа по машинному обучению](https://vk.com/tomskml)
* [Slack Томской группы по ML](https://tomskml.slack.com/)
  * [форма регистрации](https://docs.google.com/forms/d/e/1FAIpQLSdYpgm7T80JpyBPt6NMgRP_4jne7v_qaGFjy8wDrS4fNajMDA/viewform?c=0&w=1)
* Паблики/группы вконтакте:
  * [Data Science](https://vk.com/datascience)
  * [Deep Learning](https://vk.com/deeplearning)
  * [Data Mining Labs](https://vk.com/datamininglabs)
  * [DeepLearning (Глубокие нейронные сети)](https://vk.com/deeplearning_ru)
  * [Мемы про машинное обучение для юных леди](https://vk.com/weirdreparametrizationtrick)
* В телеграме:
  * [Канал сообщества DeepLearning](https://t.me/deeplearning_ru)
  * [Первый новостной канал про data science](https://t.me/opendatascience)
  * [Чат по большим данным, обработке и машинному обучению](https://t.me/bigdata_ru) — Big Data & Machine Learning
  * [Чат по теме Data Science](https://t.me/datasciencechat) — Data Science Chat
  * [Канал py_digest](https://t.me/py_digest)
  * [Чат ru_python](https://t.me/ru_python)
  * [Spark in me: Internet, statistics, data science, philosophy](https://t.me/snakers4)
  * [Чат канала Spark in me](https://t.me/joinchat/AAAAAEH9JHYBvaPLvaWPGg)
  * [Канал с горячими постами с Reddit на DS тематику](https://t.me/datascientology)
* Сабреддиты по машинному обучению и смежным темам (рекомендую посмотреть как минимум топ за всё время + sidebar):
    * [/r/analyzit](https://www.reddit.com/r/analyzit)
    * [/r/bigdata](https://www.reddit.com/r/bigdata)
    * [/r/bigdatajobs](https://www.reddit.com/r/bigdatajobs)
    * [/r/computervision](https://www.reddit.com/r/computervision)
    * [/r/datacleaning](https://www.reddit.com/r/datacleaning)
    * [/r/datagangsta](https://www.reddit.com/r/datagangsta)
    * [/r/dataisbeautiful](https://www.reddit.com/r/dataisbeautiful)
    * [/r/dataisugly](https://www.reddit.com/r/dataisugly)
    * [/r/datascience](https://www.reddit.com/r/datascience)
    * [/r/datasets](https://www.reddit.com/r/datasets)
    * [/r/dataviz](https://www.reddit.com/r/dataviz)
    * [/r/JupyterNotebooks](https://www.reddit.com/r/JupyterNotebooks)
    * [/r/LanguageTechnology](https://www.reddit.com/r/LanguageTechnology)
    * [/r/learnmachinelearning](https://www.reddit.com/r/learnmachinelearning)
    * [/r/learnpython](https://www.reddit.com/r/learnpython)
    * [/r/MachineLearning](https://www.reddit.com/r/MachineLearning)
    * [/r/opendata](https://www.reddit.com/r/opendata)
    * [/r/rstats](https://www.reddit.com/r/rstats)
    * [/r/probabilitytheory](https://www.reddit.com/r/probabilitytheory)
    * [/r/pystats](https://www.reddit.com/r/pystats)
    * [/r/SampleSize](https://www.reddit.com/r/SampleSize)
    * [/r/semanticweb](https://www.reddit.com/r/semanticweb)
    * [/r/statistics](https://www.reddit.com/r/statistics)
    * [/r/textdatamining](https://www.reddit.com/r/textdatamining)
* [People tweeting about ML and AI](https://blog.talla.com/2016/02/people-tweeting-about-machine-learning-and-ai/)
* [Блоги по датасаенс-тематике](https://github.com/rushter/data-science-blogs) + список:
  * [distill.pub](https://distill.pub/)
  * [inference.vc](https://www.inference.vc/)
  * [karpathy.github.io](https://karpathy.github.io/)
  * [deliprao.com](http://deliprao.com/)
  * [fastml.com](https://fastml.com/)
  * [timvieira.github.io](https://timvieira.github.io/)
  * [blogs.princeton.edu](https://blogs.princeton.edu/)
  * [offconvex.org](https://www.offconvex.org/)
  * [ruder.io](http://ruder.io/)
  * [argmin.net](https://www.argmin.net/)
  * [nlpers.blogspot.ru](https://nlpers.blogspot.com/)
  * [blog.shakirm.com](http://blog.shakirm.com/)
  * [blog.paralleldots.com](https://blog.paralleldots.com)
  * [alexanderdyakonov.wordpress.com](https://dyakonov.org/)
","summarize: # Мащининное    “Нейронные’’ опециализацi’   ‘‘’:  “”: “Ма’еще”  ’:
’‘: ”:’. ’ ‘:. ‘.  : ‘,’ “:”. “,”, ‘;’, “;”,. ‘?�"
365,Build ECommerce Website Like Amazon By React & Node & MongoDB,"# React & Node Tutorial - Full ECommerce in 5 Hours [2020]

Welcome to my React and Node tutorial to build a fully-functional e-commerce website in 5 hours. Open your code editor and follow me for the next hours to build an e-commerce website using React and Node.JS.

## Demo Website

👉 Demo : https://oldamazona.webacademy.pro

## Video Tutorial

👉 Click on this image to watch full 5-hours video of this tutorial

[![IMAGE ALT TEXT HERE](https://img.youtube.com/vi/Fy9SdZLBTOo/0.jpg)](https://www.youtube.com/watch?v=Fy9SdZLBTOo)

## You Will Learn

- HTML5 and CSS3: Semantic Elements, CSS Grid, Flexbox
- React: Components, Props, Events, Hooks, Router, Axios
- Redux: Store, Reducers, Actions
- Node & Express: Web API, Body Parser, File Upload, JWT
- MongoDB: Mongoose, Aggregation
- Development: ESLint, Babel, Git, Github,
- Deployment: Heroku
- Watch React & Node Tutorial

## Run Locally

### 1. Clone repo

```
$ git clone git@github.com:basir/node-react-ecommerce.git
$ cd node-react-ecommerce
```

### 2. Install MongoDB

Download it from here: https://docs.mongodb.com/manual/administration/install-community/

### 3. Run Backend

```
$ npm install
$ npm start
```

### 4. Run Frontend

```
# open new terminal
$ cd frontend
$ npm install
$ npm start
```

### 5. Create Admin User

- Run this on chrome: http://localhost:5000/api/users/createadmin
- It returns admin email and password

### 6. Login

- Run http://localhost:3000/signin
- Enter admin email and password and click signin

### 7. Create Products

- Run http://localhost:3000/products
- Click create product and enter product info

## Support

- Q/A: https://webacademy.pro/oldamazona
- Contact Instructor: [Basir](mailto:basir.jafarzadeh@gmail.com)

## Video Tutorials

### [00:02:00 Part 01- Introduction](https://www.youtube.com/watch?v=Fy9SdZLBTOo&t=120s)

It gives you an overview of the tutorial to build an eCommerce website like Amazon.

### [00:08:26 Part 02- Install Tools](https://www.youtube.com/watch?v=Fy9SdZLBTOo&t=506s)

You need to install a code editor and a web browser to start web development. In this part, we will prepare the environment to start coding.

### [00:12:36 Part 03- Website Template](https://www.youtube.com/watch?v=Fy9SdZLBTOo&t=756s)

In this part, you create a web template for the eCommerce website.
![Alt Text](https://dev-to-uploads.s3.amazonaws.com/i/56kqn8m5n1m9fejdoxkz.png)

### [00:29:47 Part 04- Products List](https://www.youtube.com/watch?v=Fy9SdZLBTOo&t=1787s)

We will create a list of products as static HTML elements.

### [00:41:54 Part 05- Create Sidebar](https://www.youtube.com/watch?v=Fy9SdZLBTOo&t=2514s)

We will create a hamburger menu that shows and hide the sidebar. Also, we design the details page of the products.
![Alt Text](https://dev-to-uploads.s3.amazonaws.com/i/3sceblg6i6790minhaxg.jpg)

### [00:52:39 Part 06- Create React App](https://www.youtube.com/watch?v=Fy9SdZLBTOo&t=3159s)

This part is about the frontend. We use React library to build the UI elements.

### [01:01:09 Part 07- Render Products](https://www.youtube.com/watch?v=Fy9SdZLBTOo&t=3669s)

This is the home page of e-commerce. It shows a list of products.
![Alt Text](https://dev-to-uploads.s3.amazonaws.com/i/hqiwteg10o8a2cnq0wwi.jpg)

### [01:06:30 Part 08- Product Details](https://www.youtube.com/watch?v=Fy9SdZLBTOo&t=3990s)

When the user clicks on a product there should a page to show details about that product. This lesson is all about making an attractive details page.
![Alt Text](https://dev-to-uploads.s3.amazonaws.com/i/csskvzbcmz4ypki2xjgk.jpg)

### [01:30:53 Part 09- Create Node Server](https://www.youtube.com/watch?v=Fy9SdZLBTOo&t=5453s)

This part is about Node and Express. They are the popular framework to create a web server using JavaScript language. We will create a MongoDB database and save and retrieve the admin user.

### [01:39:52 Part 10- Fetch Server Data](https://www.youtube.com/watch?v=Fy9SdZLBTOo&t=5992s)

In this lesson, we use React Hooks to fetch data from the server. We use the axios library to do this job in a modern async/await style.

### [01:47:55 Part 11- Manage State With Redux](https://www.youtube.com/watch?v=Fy9SdZLBTOo&t=6475s)

When it comes to handling multiple forms with their data nothing is better than state management. We use Redux in this lesson to handle complex state and keep the app behavior predictable.

### [02:07:11 Part 12- Add Redux To Details](https://www.youtube.com/watch?v=Fy9SdZLBTOo&t=7631s)

In this part, we move the details page state to Redux. First, we create reducers then define actions and connect them to the details component.

### [02:29:23 Part 13- Shopping Cart Screen](https://www.youtube.com/watch?v=Fy9SdZLBTOo&t=8963s)

Shopping Cart is the heart of any e-commerce website. We focus on creating a user-friendly shopping cart using React and Redux.
![Alt Text](https://dev-to-uploads.s3.amazonaws.com/i/fyzf0no5ej1fgxp5972e.png)

### [03:08:11 Part 14- Connect MongoDB](https://www.youtube.com/watch?v=Fy9SdZLBTOo&t=11291s)

This lesson is about persisting data on the MongoDB database. We use mongoose package to create models and save and retrieve data from the database.

### [03:21:35 Part 15- Sign In User](https://www.youtube.com/watch?v=Fy9SdZLBTOo&t=12095s)

We need to register the user before redirecting them to the checkout. In this part, we will create forms for getting user info and save them in the database.
![Alt Text](https://dev-to-uploads.s3.amazonaws.com/i/92coj0rezr5508vhfv34.png)

### [03:56:02 Part 16- Manage Products](https://www.youtube.com/watch?v=Fy9SdZLBTOo&t=14162s)

Admin should be able to define products and update the count in stock whenever they like. This page is about managing ECommerce products.
![Alt Text](https://dev-to-uploads.s3.amazonaws.com/i/154a5zk6vfapukjaxwyu.png)

### [04:38:43 Part 17- Checkout Wizard](https://www.youtube.com/watch?v=Fy9SdZLBTOo&t=16723s)

In this part, we implement the checkout wizard including sign in, shipping info, payment method, and place order.
![Alt Text](https://dev-to-uploads.s3.amazonaws.com/i/l8w3g9mc3ccijt70wpf3.png)

## Only On Udemy

Following parts are on my udemy course. [Get it by 90% discount](https://www.udemy.com/course/build-ecommerce-website-like-amazon-react-node-mongodb/?couponCode=BASIR1)

### Part 18- Order Details Screen

It shows all details about an order includeing shipping, payments and order items. Also it is possible for admin to manage orders like set them as delivered.

### Part 19- Connect to PayPal

This parts create PaypalButton component to show paypal payment button on the screen.
when users click on it, they will be redirected to paypal website to make the payment.
after payment users will be redirected to details page of the order.

### Part 20- Manage Order Screen

This is an admin page to manage list of orders. Admin can delete an order or set it as delivered.

### Part 21- User Profile Screen

When user click on thier name on the header menu, this page appears. It consists of two sections. First an profile update form and second order history.

### Part 22- Filter and Sort Products

In the home page, right after header, there is a filter bar to filter products based on their name and description. also it is possible to sort product based on prices and arrivals.

### Part 23- Deploy Website on Heroku

This section explains all steps to publish the ecommerce website on heroku. first you need to create a cloud mongodb and the make an account on heroku.

### Part 24- Rate and Review Products

This part shows list of reviews by users for each products. also it provides a form to enter rating and review for every single product. also it update the avg rating of each product by user ratings.

1. index.html
2. link fontawesome
3. Rating.js
4. create stars based on props.value
5. show text based on props.text
6. index.css
7. style rating, span color gold and last span to gray, link text to blue
8. HomeScreen.js
9. use Rating component
10. ProductScreen.js
11. use Rating component, wrap it in anchor#reviews
12. list reviews after product details
13. create new review form to get rating and reviews
14. index.css
15. style reviews
16. ProductScreen.js
17. implement submitHandler
18. productActions.js
19. create saveProductReview(productId, review)
20. productConstants.js
21. create product review constants
22. productReducers.js
23. create productReviewSaveReducer
24. store.js
25. add productReviewSaveReducer
26. backend
27. productRoute.js
28. router.post('/:id/reviews')
29. save review in product.reviews
30. update avg rating

### Part 25- Upload Product Images On Local Server

Admin shoud be able to uploads photos from their computer. This section is about uploading images on local server ans aws s3 cloud server.

1. npm install multer
2. routes/uploadRoute.js
3. import express and multer
4. create disk storage with Date.now().jpg as filename
5. set upload as multer({ storage })
6. router.post('/', upload.single('image'))
7. return req.file.path
8. server.js
9. app.use('/api/uploads',uploadRoute)
10. ProductsScreen.js
11. create state hook for uploading
12. create input image file and onChange handler
13. define handleUploadImage function
14. prepare file for upload
15. axios post file as multipart/form-data
16. set image and set uploading
17. check result

### Part 26- Upload Product Images On AWS S3

This section is about uploading images amazon aws s3 cloud server.

1. create aws account
2. open https://s3.console.aws.amazon.com
3. create public bucket as amazona
4. create api key and secret
5. past it into .env as accessKeyId and secretAccessKey
6. move dotenv to config.js
7. add accessKeyId and secretAccessKey to config.js
8. npm install aws-sdk multer-s3
9. routes/uploadRoute.js
10. set aws.config.update to config values
11. create s3 from new aws.S3()
12. create storageS3 from multerS3 by setting s3, bucket and acl
13. set uploadS3 as multer({ storage: storageS3 })
14. router.post('/s3', uploadS3.single('image'))
15. return req.file.location
16. ProductsScreen.js
17. on handleUploadImage set axios.post('api/uploads/s3')
18. check result on website and s3

## Summary

In this tutorial, we have made an eCommerce website like Amazon. Feel free to change this project based on your needs and add it to your portfolio.
Also, I will love to hear your comment about this React and Node tutorial. Please share your thoughts here.
","Open your code editor and follow me for the next hours to build an e-commerce
website using React and Node.JS. You will learn about HTML5 and CSS3: Semantic
Elements, CSS Grid, Flexbox. React: Components, Props, Events, Hooks, Router,
Axios- Redux: Store, Reducers, Actions. Node & Express: Web API, Body Parser,
File Upload, JWT."
3136,"Picocli is a modern framework for building powerful, user-friendly, GraalVM-enabled command line apps with ease. It supports colors, autocompletion, subcommands, and more.  In 1 source file so apps can include as source & avoid adding a dependency. Written in Java, usable from Groovy, Kotlin, Scala, etc. ","<p align=""center""><img src=""docs/images/logo/horizontal-400x150.png"" alt=""picocli"" height=""150px""></p>

[![GitHub Release](https://img.shields.io/github/release/remkop/picocli.svg)](https://github.com/remkop/picocli/releases)
[![Maven Central](https://img.shields.io/maven-central/v/info.picocli/picocli.svg?label=Maven%20Central)](https://search.maven.org/search?q=g:%22info.picocli%22%20AND%20a:%22picocli%22)
[![GitHub Actions Build Status](https://github.com/remkop/picocli/actions/workflows/ci.yml/badge.svg)](https://github.com/remkop/picocli/actions/workflows/ci.yml)
[![Tests](https://gist.githubusercontent.com/remkop/36bc8a3b4395f2fbdb9bc271e97ba2dd/raw/badge.svg)](https://github.com/remkop/picocli/actions/workflows/ci.yml)
[![codecov](https://codecov.io/gh/remkop/picocli/branch/master/graph/badge.svg)](https://codecov.io/gh/remkop/picocli)
[![Follow @remkopopma](https://img.shields.io/twitter/follow/remkopopma.svg?style=social)](https://twitter.com/intent/follow?screen_name=remkopopma)
[![Follow @picocli](https://img.shields.io/twitter/follow/picocli.svg?style=social)](https://twitter.com/intent/follow?screen_name=picocli)
[![Follow picocli on StackShare](https://img.shields.io/badge/Follow%20on-StackShare-blue.svg?logo=stackshare&style=flat)](https://stackshare.io/picocli)

# picocli - a mighty tiny command line interface

Picocli aims to be the easiest-to-use way to create rich command line applications that can run on and off the JVM.
Considering picocli? Check [what happy users say](https://github.com/remkop/picocli/wiki/Feedback-from-Users) about picocli.

Picocli is a modern library and framework, written in Java, that contains both an annotations API and a programmatic API. It features usage help with [ANSI colors and styles](https://picocli.info/#_ansi_colors_and_styles), [TAB autocompletion](https://picocli.info/autocomplete.html) and nested subcommands.
In a single file, so you can include it _in source form_.
This lets users run picocli-based applications without requiring picocli as an external dependency.

Picocli-based applications can be ahead-of-time compiled to a <img src=""https://www.graalvm.org/resources/img/logo-colored.svg"" alt=""GraalVM"">
[native image](https://picocli.info/#_graalvm_native_image), with extremely fast startup time and lower memory requirements,
which can be distributed as a single executable file.
Picocli comes with an [annotation processor](https://picocli.info/#_annotation_processor) that automatically Graal-enables your jar during compilation.

Picocli applications can be very compact with no boilerplate code: your command (or subcommand) can be executed with a [single line of code](#example ""(example below)"").
Simply implement `Runnable` or `Callable`, or put the business logic of your command in a `@Command`-annotated method.

<a id=""picocli_demo""></a>
![Picocli Demo help message with ANSI colors](docs/images/picocli.Demo.png?raw=true)

Picocli makes it easy to follow [Command Line Interface Guidelines](https://clig.dev/#guidelines).

How it works: annotate your class and picocli initializes it from the command line arguments,
converting the input to strongly typed data. Supports git-like [subcommands](https://picocli.info/#_subcommands)
(and nested [sub-subcommands](https://picocli.info/#_nested_sub_subcommands)),
any option prefix style, POSIX-style [grouped short options](https://picocli.info/#_short_posix_options),
custom [type converters](https://picocli.info/#_custom_type_converters),
[password options](https://picocli.info/#_interactive_password_options) and more.

Picocli distinguishes between [named options](https://picocli.info/#_options) and
[positional parameters](https://picocli.info/#_positional_parameters) and allows _both_ to be
[strongly typed](https://picocli.info/#_strongly_typed_everything).
[Multi-valued fields](https://picocli.info/#_multiple_values) can specify
an exact number of parameters or a [range](https://picocli.info/#_arity) (e.g., `0..*`, `1..2`).
Supports [Map options](https://picocli.info/#_maps) like `-Dkey1=val1 -Dkey2=val2`, where both key and value can be strongly typed.
Parser [tracing](https://picocli.info/#_tracing) facilitates troubleshooting.
Command-line [argument files](https://picocli.info/#AtFiles) (@-files) allow applications to handle very long command lines.

Generates polished and easily tailored [usage help](https://picocli.info/#_usage_help)
and  [version help](https://picocli.info/#_version_help),
using [ANSI colors](https://picocli.info/#_ansi_colors_and_styles) where possible.
Requires at minimum Java 5, but is designed to facilitate the use of Java 8 lambdas. Tested on all [Java versions between 5 and 18-ea](https://github.com/remkop/picocli/actions/workflows/ci.yml) (inclusive).

Picocli-based command line applications can have [TAB autocompletion](https://picocli.info/autocomplete.html),
interactively showing users what options and subcommands are available.
When an option has [`completionCandidates`](https://picocli.info/#_completion_candidates_variable) or has an `enum` type, autocompletion can also suggest option values.
Picocli can generate completion scripts for bash and zsh, and offers [`picocli-shell-jline2`](picocli-shell-jline2/README.md) and [`picocli-shell-jline3`](picocli-shell-jline3/README.md) modules with JLine `Completer` implementations for building interactive shell applications.

Unique features in picocli include support for [negatable options](https://picocli.info/#_negatable_options),
advanced [quoted values](https://picocli.info/#_quoted_values),
and [argument groups](https://picocli.info/#_argument_groups).
Argument groups can be used to create mutually [exclusive](https://picocli.info/#_mutually_exclusive_options) options,
mutually [dependent](https://picocli.info/#_mutually_dependent_options) options,
option [sections](https://picocli.info/#_option_sections_in_usage_help) in the usage help message
and [repeating composite arguments](https://picocli.info/#_repeating_composite_argument_groups) like
`([-a=<a> -b=<b> -c=<c>] (-x | -y | -z))...`.
For advanced use cases, applications can access the picocli command object model with the
[`@Spec` annotation](https://picocli.info/#spec-annotation), and
implement [custom parameter processing](https://picocli.info/#_custom_parameter_processing) for option parameters if the built-in logic is insufficient.


Picocli-based applications can easily [integrate](https://picocli.info/#_dependency_injection) with Dependency Injection containers.
The [Micronaut](https://micronaut.io/) microservices framework has [built-in support](https://docs.micronaut.io/latest/guide/index.html#commandLineApps) for picocli.
[Quarkus](https://quarkus.io/) has a [Command Mode with Picocli](https://quarkus.io/guides/picocli) extension for facilitating the creation of picocli-based CLI applications with Quarkus.
Picocli ships with a [`picocli-spring-boot-starter` module](https://github.com/remkop/picocli/tree/main/picocli-spring-boot-starter)
that includes a `PicocliSpringFactory` and Spring Boot auto-configuration to use Spring dependency injection in your picocli command line application.
The user manual has examples of integrating with [Guice](https://picocli.info/#_guice_example), [Spring Boot](https://picocli.info/#_spring_boot_example), [Micronaut](https://picocli.info/#_micronaut_example), [Quarkus](https://picocli.info/#_quarkus_example) and with containers that comply to [CDI 2.0 specification](https://picocli.info/#_cdi_2_0_jsr_365) (JSR 365).

### Releases
* [All Releases](https://github.com/remkop/picocli/releases)
* Latest: 4.7.1 [Release Notes](https://github.com/remkop/picocli/releases/tag/v4.7.1)
* Older: Picocli 4.0 [Release Notes](https://github.com/remkop/picocli/releases/tag/v4.0.0)
* Older: Picocli 3.0 [Release Notes](https://github.com/remkop/picocli/releases/tag/v3.0.0)
* Older: Picocli 2.0 [Release Notes](https://github.com/remkop/picocli/releases/tag/v2.0.0)

### Documentation
* [4.x User manual: https://picocli.info](https://picocli.info)
* [4.x Quick Guide](https://picocli.info/quick-guide.html)
* [4.x API Javadoc](https://picocli.info/apidocs/)
* [PREVIEW: Modular Javadoc for all artifacts (4.7.1-SNAPSHOT)](https://picocli.info/apidocs-all/)
* [Command line autocompletion](https://picocli.info/autocomplete.html)
* [Programmatic API](https://picocli.info/picocli-programmatic-api.html)
* [FAQ](https://github.com/remkop/picocli/wiki/FAQ)
* [GraalVM AOT Compilation to Native Image](https://picocli.info/picocli-on-graalvm.html) <img src=""https://www.graalvm.org/resources/img/logo-colored.svg"" >

### Older
* ~~[3.x User manual](https://picocli.info/man/3.x)~~
* ~~[3.x Quick Guide](https://picocli.info/man/3.x/quick-guide.html)~~
* ~~[3.x API Javadoc](https://picocli.info/man/3.x/apidocs/)~~
* ~~[2.x User manual](https://picocli.info/man/2.x)~~
* ~~[2.x API Javadoc](https://picocli.info/man/2.x/apidocs/)~~
* ~~[1.x User manual](https://picocli.info/man/1.x)~~

### Articles & Presentations
#### English
* [6 things you can do with JBang but you can’t with Shell](http://www.mastertheboss.com/java/jbang-vs-jshell/) (2022-02-28) by [F.Marchioni](http://www.mastertheboss.com/author/admin/).
* [VIDEO][Kotlin, CLIs and StarWars! - An introduction to creating CLI applications with Kotlin using Picocli](https://fosdem.org/2022/schedule/event/kotlin_clis_and_starwars/?utm_medium=social&utm_source=twitter&utm_campaign=postfity&utm_content=postfity77511) (2022-02-05) by [Julien Lengrand-Lambert](https://fosdem.org/2022/schedule/speaker/julien_lengrand_lambert/).
* [VIDEO][Autocomplete Java CLI using Picocli](https://www.youtube.com/watch?v=tCrQqgOYszQ) (2022-01-24) by [raksrahul](https://www.youtube.com/channel/UCpYkDrjOq3xtt0Uyg9tEqvw).
* [Picocli – Easiness for CLI arguments in Java](https://blog.adamgamboa.dev/picocli-easiness-for-cli-arguments-in-java/) (2021-10-27) by [agamboa](https://blog.adamgamboa.dev/author/agamboa/).
* [Building Command Line Interfaces with Kotlin using picoCLI](https://foojay.io/today/building-command-line-interfaces-with-kotlin-using-picocli/) (2021-09-23) by [Julien Lengrand-Lambert](https://foojay.io/today/author/jlengrand/).
* [VIDEO][Create Java CLI applications with picocli](https://www.youtube.com/watch?v=PaxBXABJIzY) (2021-09-14) by [coder4life](https://www.youtube.com/channel/UCt9lHt5bMpafypEDwj6J2WQ).
* [PICOCLI](https://www.linkedin.com/pulse/picocli-sybren-boland/) (2021-06-30) by [Sybren Boland](https://www.linkedin.com/in/sybrenboland/).
* [Picocli | Create your first Kotlin /JVM CLI application with GraalVM](https://manserpatrice.medium.com/picocli-create-your-first-kotlin-jvm-cli-application-with-graalvm-a7fea4da7e2) (2021-02-13) by [manserpatrice](https://manserpatrice.medium.com/).
* [VIDEO] [Building kubectl plugins with Quarkus, picocli, fabric8io and jbang](https://www.youtube.com/watch?v=ZL29qrpk_Kc) (2021-01-22) by [Sébastien Blanc](https://twitter.com/sebi2706).
* [VIDEO] [J-Fall Virtual 2020: Julien Lengrand - An introduction to creating CLI applications using picoCLI](https://www.youtube.com/watch?v=Rc_D4OTKidU&list=PLpQuPreMkT6D36w9d13uGpIPi5nf9I_0c&index=13) (2020-12-07) by [Julien Lengrand-Lambert](https://twitter.com/jlengrand). This was the top rated talk for [@nljug](https://twitter.com/nljug) #jfall virtual 2020! Congrats, Julien!
* [Paginate results in a command line application using picoCLI](https://lengrand.fr/paginate-results-in-a-jvm-cli-application-using-picocli/) (2020-11-17) by [Julien Lengrand-Lambert](https://twitter.com/jlengrand).
* [CLI applications with GraalVM Native Image](https://medium.com/graalvm/cli-applications-with-graalvm-native-image-d629a40aa0be) (2020-11-13) by [Oleg Šelajev](https://twitter.com/shelajev).
* [Picocli subcommands - One program, many purposes](https://aragost.com/blog/java/picocli-subcommands.html) (2020-09-22) by [Jonas Andersen](https://twitter.com/PrimusAlgo).
* [Native CLI with Picocli and GraalVM](https://dev.to/jbebar/native-cli-with-picocli-and-graalvm-566m) (2020-08-20) by [jbebar](https://dev.to/jbebar).
* [How to build a CLI app in Java using jbang and picocli](https://www.twilio.com/blog/cli-app-java-jbang-picocli) (2020-08-13) by [Matthew Gilliard](https://twitter.com/MaximumGilliard).
* [Building a GitHub Dependents Scraper with Quarkus and Picocli](https://blog.marcnuri.com/github-dependents-scraper-quarkus-picocli/) (2020-07-31) by [Marc Nuri](https://twitter.com/MarcNuri).
* [Building a decent Java CLI](https://atextor.de/2020/07/27/building-a-decent-java-cli.html) (2020-07-27) by [Andreas Textor](https://twitter.com/atextor).
* [VIDEO] (Another very well-produced video by Szymon Stepniak) [Implementing OAuth 2.0 in a Java command-line app using Micronaut, Picocli, and GraalVM](https://www.youtube.com/watch?v=js5H9UbmmMY) (2020-07-23) by [Szymon Stepniak](https://e.printstacktrace.blog/) ([YouTube channel](https://www.youtube.com/channel/UCEf8e5YAYnowq-2deW4tpsw)).
* [Micronaut, Picocli, and GraalVM](https://e.printstacktrace.blog/building-stackoverflow-cli-with-java-11-micronaut-picocli-and-graalvm/) (2020-07-08) by [Szymon Stepniak](https://e.printstacktrace.blog/).
* [VIDEO] (Extremely well-produced and informative, recommended!) [Building command-line app with Java 11, Micronaut, Picocli, and GraalVM](https://www.youtube.com/watch?v=Xdcg4Drg1hc) (2020-07-01) by [Szymon Stepniak](https://e.printstacktrace.blog/) ([YouTube channel](https://www.youtube.com/channel/UCEf8e5YAYnowq-2deW4tpsw)).
* [AUDIO] [Scala Valentines #2](https://scala.love/scala-valentines-2/) (2020-06-21) Podcast talks about picocli (from 18:11).
* [How to create a command line tool using Java?](https://fullstackdeveloper.guru/2020/06/18/how-to-create-a-command-line-tool-using-java/) (2020-06-18) by [Vijay SRJ](https://twitter.com/FullStackDevel6).
* [Command-line tools with Quarkus and Picocli](https://quarkify.net/command-line-tools-with-quarkus-and-picocli/) (2020-06-08) by [Dmytro Chaban](https://twitter.com/dmi3coder).
* Quarkus guide for [Quarkus command mode with picocli](https://quarkus.io/guides/picocli), thanks to a picocli extension by [Michał Górniewski](https://github.com/mgorniew) included in [Quarkus 1.5](https://quarkus.io/blog/quarkus-1-5-final-released/) (2020-06-03).
* [Native images with Micronaut and GraalVM](https://dev.to/stack-labs/native-images-with-micronaut-and-graalvm-4koe) (2020-06-01) by [Λ\: Olivier Revial](https://twitter.com/pommeDouze).
* [CLI applications with Micronaut and Picocli](https://dev.to/stack-labs/cli-applications-with-micronaut-and-picocli-4mc8) (2020-06-01) by [Λ\: Olivier Revial](https://twitter.com/pommeDouze).
* [Picocli introduction - Modern Java command-line parsing](https://aragost.com/blog/java/picocli-introduction.html) (2020-05-19) by [Jonas Andersen](https://twitter.com/PrimusAlgo).
* [Building Native Covid19 Tracker CLI using Java, PicoCLI & GraalVM](https://aboullaite.me/java-covid19-cli-picocli-graalvm/) (2020-05-11) by [Mohammed Aboullaite](https://aboullaite.me/author/mohammed/).
* [Quarkus Command mode with Picocli](https://quarkify.net/quarkus-command-mode-with-picocli/) (2020-04-27) by [Dmytro Chaban](https://twitter.com/dmi3coder).
* [Creating CLI tools with Scala, Picocli and GraalVM](https://medium.com/@takezoe/creating-cli-tools-with-scala-picocli-and-graalvm-ffde05bbd01d) (2020-03-09) by [Naoki Takezoe](https://twitter.com/takezoen)
* [Building native Java CLIs with GraalVM, Picocli, and Gradle](https://medium.com/@mitch.seymour/building-native-java-clis-with-graalvm-picocli-and-gradle-2e8a8388d70d) (2020-03-08) by [Mitch Seymour](https://medium.com/@mitch.seymour)
* [Build Great Native CLI Apps in Java with Graalvm and Picocli](https://www.infoq.com/articles/java-native-cli-graalvm-picocli/) (2020-03-07)
* [Picocli Structured Objects](https://gist.github.com/hanslovsky/8276da86c53bc6d95bf01447cd5cb2b7#file-00_picocli-structured-objects-md) (2019-09-10) by [Philipp Hanslovsky](https://gist.github.com/hanslovsky) explains how to use picocli's support for repeating argument groups to add or configure structured objects from the command line.
* [Create a Java Command Line Program with Picocli|Baeldung](https://www.baeldung.com/java-picocli-create-command-line-program) (2019-05-07) by [François Dupire](https://www.baeldung.com/author/francois-dupire/).
* A whirlwind tour of picocli [JAX Magazine ""Putting the spotlight on Java tools""](https://jaxenter.com/jax-mag-java-tools-157592.html) (2019-04-08).
* [An Introduction to PicoCLI](https://devops.datenkollektiv.de/an-introduction-to-picocli.html) (2019-02-10) by [devop](https://devops.datenkollektiv.de/author/devop.html).
* [Corda CLI UX (User Experience) Guide](https://docs.corda.net/head/cli-ux-guidelines.html) (2018 by R3 Limited) gives useful advice.
* [Develop a CLI tool using groovy scripts](https://medium.com/@chinthakadinadasa/develop-a-cli-tool-using-groovy-scripts-a7d545eecddd) (2018-10-26) by [Chinthaka Dinadasa](https://medium.com/@chinthakadinadasa).
* [Migrating from Commons CLI to picocli](https://picocli.info/migrating-from-commons-cli.html). You won't regret it! :-) (also on: [DZone](https://dzone.com/articles/migrating-from-commons-cli-to-picocli) and [Java Code Geeks](https://www.javacodegeeks.com/2018/11/migrating-commons-cli-picocli.html)).
* [Groovy 2.5 CliBuilder Renewal](https://picocli.info/groovy-2.5-clibuilder-renewal.html) (also on [blogs.apache.org](https://blogs.apache.org/logging/entry/groovy-2-5-clibuilder-renewal)). In two parts: [Part 1](https://picocli.info/groovy-2.5-clibuilder-renewal-part1.html) (also on: [DZone](https://dzone.com/articles/groovy-25-clibuilder-renewal), [Java Code Geeks](https://www.javacodegeeks.com/2018/06/groovy-clibuilder-renewal-part-1.html)), [Part 2](https://picocli.info/groovy-2.5-clibuilder-renewal-part2.html) (also on: [DZone](https://dzone.com/articles/groovy-25-clibuilder-renewal-part-2), [Java Code Geeks](https://www.javacodegeeks.com/2018/06/groovy-clibuilder-renewal-part-2.html)).
* Micronaut user manual for running microservices [standalone with picocli](https://docs.micronaut.io/snapshot/guide/index.html#commandLineApps).
* [Java Command-Line Interfaces (Part 30): Observations](https://marxsoftware.blogspot.jp/2017/11/java-cmd-line-observations.html) by Dustin Marx about picocli 2.0.1 (also on: [DZone](https://dzone.com/articles/java-command-line-interfaces-part-30-finale-observations), [Java Code Geeks](https://www.javacodegeeks.com/2017/11/java-command-line-interfaces-part-30-observations.html))
* [Java Command-Line Interfaces (Part 10): Picocli](https://marxsoftware.blogspot.jp/2017/08/picocli.html) by Dustin Marx about picocli 0.9.7 (also on: [DZone](https://dzone.com/articles/java-command-line-interfaces-part-10-picocli), [Java Code Geeks](https://www.javacodegeeks.com/2017/08/java-command-line-interfaces-part-10-picocli.html))
* [Picocli 2.0: Groovy Scripts on Steroids](https://picocli.info/picocli-2.0-groovy-scripts-on-steroids.html) (also on: [DZone](https://dzone.com/articles/picocli-v2-groovy-scripts-on-steroids), [Java Code Geeks](https://www.javacodegeeks.com/2018/01/picocli-2-0-groovy-scripts-steroids.html))
* [Picocli 2.0: Do More With Less](https://picocli.info/picocli-2.0-do-more-with-less.html) (also on: [DZone](https://dzone.com/articles/whats-new-in-picocli-20), [Java Code Geeks](https://www.javacodegeeks.com/2018/01/picocli-2-0-less.html))
* [Announcing picocli 1.0](https://picocli.info/announcing-picocli-1.0.html) (also on: [DZone](https://dzone.com/articles/announcing-picocli-10))

#### русский
* [Выбор необходимых опций Picocli на основе основного варианта](https://coderoad.ru/61665865/%D0%92%D1%8B%D0%B1%D0%BE%D1%80-%D0%BD%D0%B5%D0%BE%D0%B1%D1%85%D0%BE%D0%B4%D0%B8%D0%BC%D1%8B%D1%85-%D0%BE%D0%BF%D1%86%D0%B8%D0%B9-Picocli-%D0%BD%D0%B0-%D0%BE%D1%81%D0%BD%D0%BE%D0%B2%D0%B5-%D0%BE%D1%81%D0%BD%D0%BE%D0%B2%D0%BD%D0%BE%D0%B3%D0%BE-%D0%B2%D0%B0%D1%80%D0%B8%D0%B0%D0%BD%D1%82%D0%B0) (2020-05-07)
* [Интерфейсы командной строки Java: picocli](https://habr.com/ru/company/otus/blog/419401/) (2018-08-06): Russian translation by [MaxRokatansky](https://habr.com/ru/users/MaxRokatansky/) of Dustin Marx' blog post.

#### Español
* [Quarkus + Picocli: Web scaper para extraer proyectos dependientes en GitHub](https://blog.marcnuri.com/quarkus-picocli-web-scaper-dependientes-github/) (2020-08-15) by [Marc Nuri](https://twitter.com/MarcNuri).
* [Quarkus - Introducción: picocli](https://gerardo.dev/aws-quarkus-picocli.html) (2020-06-15) by [Gerardo Arroyo](https://twitter.com/codewarrior506).
* [VIDEO] [Picocli - Spring Boot example](https://youtu.be/y9ayfjfrTF4) (2020-05-24) 7-minute quick introduction by Gonzalo H. Mendoza.

#### Français
* [Application mobile: Créez de superbes applications CLI natives en Java avec Graalvm et Picocli](https://seodigitalmarketing.net/application-mobile-creez-de-superbes-applications-cli-natives-en-java-avec-graalvm-et-picocli/) (2020-05-07) Translation of [Build Great Native CLI Apps in Java with Graalvm and Picocli](https://www.infoq.com/articles/java-native-cli-graalvm-picocli/) by [bouf1450](https://seodigitalmarketing.net/author/bouf1450/).
* [VIDEO] [Des applications en ligne de commande avec Picocli et GraalVM (N. Peters)](https://www.youtube.com/watch?v=8ENbMwkaFyk) (2019-05-07): 15-minute presentation by Nicolas Peters during Devoxx FR. Presentation slides are [available on GitHub](https://t.co/tXhtpTpAff?amp=1).

#### Português
* [Desenvolva aplicações CLI nativas em Java com Graalvm e Picocli](https://www.infoq.com/br/articles/java-native-cli-graalvm-picocli/) (2020-08-28): Portuguese translation of [Build Great Native CLI Apps in Java with Graalvm and Picocli](https://www.infoq.com/articles/java-native-cli-graalvm-picocli/), thanks to [Rodrigo Ap G Batista](https://www.infoq.com/br/profile/Rodrigo-Ap-G-Batista/).
* [VIDEO] [Quarkus #40: Command Mode com Picocli](https://www.youtube.com/watch?v=LweGDh-Jxlc) (2020-06-23): 13-minute presentation by [Vinícius Ferraz](https://www.youtube.com/channel/UCJNOHl-pTTTj4S9yq60Ps9A) (@viniciusfcf).

#### 日本語
* [CLI applications with GraalVM Native Image](https://logico-jp.io/2020/11/21/cli-applications-with-graalvm-native-image/) (2020-11-21) translation by [Logico_jp](https://logico-jp.io/who-is-logico/) of Oleg Šelajev's [post](https://medium.com/graalvm/cli-applications-with-graalvm-native-image-d629a40aa0be).
* [Picocli + Kotlin + graalvm-native-image plugin でネイティブツールを作る](https://mike-neck.hatenadiary.com/entry/2020/04/24/090000) (2020-04-24) blog post by [mike-neck](https://mike-neck.hatenadiary.com/about) ([引きこもり持田](https://twitter.com/mike_neck) on Twitter).
* [pythonのArgumentParserような使い心地！picocliのご紹介](https://lab.astamuse.co.jp/entry/2020/04/15/115000) (2020-04-15) by [@astamuseLab](https://lab.astamuse.co.jp/)
* [Javaのコマンドラインアプリケーション向けのフレームワーク、picocliで遊ぶ](https://kazuhira-r.hatenablog.com/entry/2020/03/07/013626) (2020-03-07) blog post by [かずひら](https://twitter.com/kazuhira_r).
* [KuromojiのCLIコマンドとpicocliとGraalVM](https://blog.johtani.info/blog/2020/02/28/kuromoji-cli/) (2020-02-28) blog post by [@johtani](https://twitter.com/johtani).
* [GraalVM, PicocliとJavaでときめくネイティブコマンドラインアプリを作ろう](https://remkop.github.io/presentations/20191123/) (2019-11-23) Slides for my presentation at Japan Java User Group's [JJUG CCC 2019 Fall](https://ccc2019fall.java-users.jp/) conference.
* [Picocliを使用してJavaコマンドラインプログラムを作成する - 開発者ドキュメント](https://ja.getdocs.org/java-picocli-create-command-line-program/) (2019-10-18)
* [GraalVM と Picocliで Javaのネイティブコマンドラインアプリを作ろう](https://remkop.github.io/presentations/20190906/) (2019-09-06) Slides for my lightning talk presentation at [【東京】JJUG ナイトセミナー: ビール片手にLT大会 9/6（金）](https://jjug.doorkeeper.jp/events/95987)
* [Picocli＋Spring Boot でコマンドラインアプリケーションを作成してみる](https://ksby.hatenablog.com/entry/2019/07/20/092721) (2019-07-20) by [かんがるーさんの日記](https://ksby.hatenablog.com/).
* [GraalVM の native image を使って Java で爆速 Lambda の夢を見る](https://qiita.com/kencharos/items/69e43965515f368bc4a3) (2019-05-02) by [@kencharos](https://qiita.com/kencharos)

#### 中文
* [Java命令行界面（第10部分）：picocli](https://blog.csdn.net/dnc8371/article/details/106702365) (2020-06-07) translation by [dnc8371](https://blog.csdn.net/dnc8371).
* [如何借助 Graalvm 和 Picocli 构建 Java 编写的原生 CLI 应用](https://www.infoq.cn/article/4RRJuxPRE80h7YsHZJtX) (2020-03-26): Chinese translation of [Build Great Native CLI Apps in Java with Graalvm and Picocli](https://www.infoq.com/articles/java-native-cli-graalvm-picocli/), thanks to [张卫滨](https://www.infoq.cn/profile/1067660).
* [从Commons CLI迁移到Picocli](https://blog.csdn.net/genghaihua/article/details/88529409) (2019-03-13): Chinese translation of Migrating from Commons CLI to picocli, thanks to [genghaihua](https://me.csdn.net/genghaihua).
* [Picocli 2.0: Steroids上的Groovy脚本](https://picocli.info/zh/picocli-2.0-groovy-scripts-on-steroids.html)
* [Picocli 2.0: 以少求多](https://picocli.info/zh/picocli-2.0-do-more-with-less.html)

### Mailing List
Join the [picocli Google group](https://groups.google.com/d/forum/picocli) if you are interested in discussing anything picocli-related and receiving announcements on new releases.

### Credit
<img src=""https://picocli.info/images/logo/horizontal-400x150.png"" height=""100"">

[Reallinfo](https://github.com/reallinfo) designed the picocli logo! Many thanks!

### Commitments

| This project follows [semantic versioning](https://semver.org/) and adheres to the **[Zero Bugs Commitment](https://github.com/classgraph/classgraph/blob/f24fb4e8f2e4f3221065d755be6e65d59939c5d0/Zero-Bugs-Commitment.md)**. |
|------------------------|

## Adoption

<div>
<img src=""https://picocli.info/images/groovy-logo.png"" height=""50"">  <img src=""https://picocli.info/images/1x1.png"" width=""10""> <img src=""https://objectcomputing.com/files/3416/2275/4315/micronaut_horizontal_black.svg"" height=""50""><img src=""https://picocli.info/images/1x1.png"" width=""10""><img src=""https://quarkus.io/assets/images/quarkus_logo_horizontal_rgb_reverse.svg"" style=""background-color:#33475b"" height=""50""><img src=""https://picocli.info/images/1x1.png"" width=""10""><img src=""https://picocli.info/images/junit5logo-172x50.png"" height=""50""> <img src=""https://picocli.info/images/1x1.png"" width=""10""> <img src=""https://picocli.info/images/debian-logo-192x50.png"" height=""50""> <img src=""https://picocli.info/images/1x1.png"" width=""10"">
<img src=""https://spring.io/images/spring-logo.svg"" height=""50"">
<img src=""https://avatars0.githubusercontent.com/u/3299148?s=200&v=4"" height=""50"">
<img src=""https://avatars3.githubusercontent.com/u/39734771?s=200&v=4"" height=""50"">
<img src=""https://avatars3.githubusercontent.com/u/1453152?s=200&v=4"" height=""50"">
<img src=""https://avatars1.githubusercontent.com/u/201120?s=200&v=4"" height=""50"">
<img src=""https://avatars0.githubusercontent.com/u/6154722?s=200&v=4"" height=""50"">
<img src=""https://avatars3.githubusercontent.com/u/453694?s=200&v=4"" height=""50"">
<img src=""https://avatars0.githubusercontent.com/u/82592?s=200&v=4"" height=""50"">
<img src=""https://avatars0.githubusercontent.com/u/9312489?s=200&v=4"" height=""50"">
<img src=""https://avatars0.githubusercontent.com/u/59439283?s=200&v=4"" height=""50"">
<img src=""https://avatars1.githubusercontent.com/u/4186383?s=200&v=4"" height=""50"">
<img src=""https://redis.com/wp-content/uploads/2021/08/redis-logo.png"" height=""50"">
<img src=""https://picocli.info/images/karate-logo.png"" height=""50"" width=""50""/>  <img src=""https://picocli.info/images/checkstyle-logo-260x50.png"" height=""50""><img src=""https://picocli.info/images/1x1.png"" width=""10"">  <img src=""https://picocli.info/images/ballerina-logo.png"" height=""40""><img src=""https://picocli.info/images/1x1.png"" width=""10"">  <img src=""https://picocli.info/images/apache-hive-logo.png"" height=""50""><img src=""https://picocli.info/images/1x1.png"" width=""10"">  <img src=""https://hadoop.apache.org/hadoop-logo.jpg"" height=""50""><img src=""https://picocli.info/images/1x1.png"" width=""10""> <img src=""https://picocli.info/images/apache-ozone-logo.png"" height=""50""> <img src=""https://picocli.info/images/1x1.png"" width=""10"">  <img src=""https://picocli.info/images/stackshare-logo.png"" height=""50""> <img src=""https://ignite.apache.org/images/Ignite_tm_Logo_blk_RGB.svg"" height=""50""> <img src=""https://camo.githubusercontent.com/501aae78d282faf7a904bbb92f46eb8d19445ad5/687474703a2f2f736c696e672e6170616368652e6f72672f7265732f6c6f676f732f736c696e672e706e67"" height=""50"">
<img src=""https://avatars1.githubusercontent.com/u/541152?s=200&v=4"" height=""50"">  <img src=""https://camo.qiitausercontent.com/ec81e80366e061c8488b25c013003267b7a578d4/68747470733a2f2f71696974612d696d6167652d73746f72652e73332e616d617a6f6e6177732e636f6d2f302f3939352f33323331306534352d303537332d383534322d373035652d6530313138643434323632302e706e67"" height=""50"">
<img src=""https://mk0upserved13l70iwek.kinstacdn.com/media/Upserve_LS_Lockup_000000_RGB_Vertical.svg"" height=""50"">
<img src=""https://www.kloudtek.com/logo-dark.png"" height=""50"">
<img src=""https://www.schemacrawler.com/images/schemacrawler_logo.svg"" height=""50"">
<img src=""https://avatars1.githubusercontent.com/u/22600631?s=200&v=4"" height=""50"">
<img src=""https://fisco-bcos-documentation.readthedocs.io/en/latest/_static/images/FISCO_BCOS_Logo.svg"" height=""50"">
<img src=""https://avatars0.githubusercontent.com/u/35625214?s=200&v=4"" height=""50"">
<img src=""https://avatars1.githubusercontent.com/u/2386734?s=200&v=4"" height=""50"">
<img src=""https://www.e-contract.be/images/logo.svg"" height=""50"">
<img src=""https://present.co/images/logn-new@2x.png"" height=""50"">
<img src=""https://avatars2.githubusercontent.com/u/13641167?s=200&v=4"" height=""50"">
<img src=""https://files.pvs-studio.com/static/images/logo.svg"" height=""50"">
<img src=""https://concord.walmartlabs.com/assets/img/logo.png"" height=""50"">
<img src=""https://res-3.cloudinary.com/crunchbase-production/image/upload/c_lpad,h_120,w_120,f_auto,b_white,q_auto:eco/etxip1k2sx4sphvwgkdu"" height=""50"">
<img src=""https://www.minecraftforge.net/forum/uploads/set_resources_2/4eeef9d314eb4c008c0f37dacad2cdd5_logo.svg"" height=""50"">

</div>


* Picocli is now part of Groovy. From Groovy 2.5, all Groovy command line tools are picocli-based, and picocli is the underlying parser for Groovy's [CliBuilder DSL](https://groovy-lang.org/dsls.html#_clibuilder).
* Picocli is now part of Micronaut. The Micronaut CLI has been rewritten with picocli, and Micronaut has dedicated support for running microservices [standalone with picocli](https://docs.micronaut.io/snapshot/guide/index.html#commandLineApps). See also [Micronaut Picocli Guide](https://micronaut-projects.github.io/micronaut-picocli/latest/guide/).
* Quarkus now offers [Command mode with picocli](https://quarkus.io/guides/picocli).
* Picocli is now part of JUnit 5. JUnit 5.3 migrated its `ConsoleLauncher` from jopt-simple to picocli to support @-files (argument files); this helps users who need to specify many tests on the command line and run into system limitations.
* Debian now offers a [libpicocli-java package](https://tracker.debian.org/pkg/picocli). Thanks to [Miroslav Kravec](https://udd.debian.org/dmd/?kravec.miroslav%40gmail.com).
* Picocli is used in the Intuit [Karate](https://github.com/intuit/karate) standalone JAR / executable.
* Picocli is part of [Ballerina](https://ballerina.io/). Ballerina uses picocli for all its command line utilities.
* Picocli is used in the [CheckStyle](https://checkstyle.org/cmdline.html) standalone JAR / executable from Checkstyle 8.15.
* Picocli is included in the [OpenJDK Quality Outreach](https://wiki.openjdk.java.net/display/quality/Quality+Outreach) list of Free Open Source Software (FOSS) projects that actively test against OpenJDK builds.
* Picocli is used in the Apache Hadoop Ozone/HDDS command line tools, the Apache Hive benchmark CLI, Apache [Ignite TensorFlow](https://github.com/apache/ignite), and Apache Sling [Feature Model Converter](https://github.com/apache/sling-org-apache-sling-feature-modelconverter).
* Picocli is listed on [StackShare](https://stackshare.io/picocli). Please add it to your stack and add/upvote reasons why you like picocli!
* Picocli is used in Pinterest [ktlint](https://ktlint.github.io/).
* Picocli is used in Spring IO [nohttp-cli](https://github.com/spring-io/nohttp/tree/main/nohttp-cli).
* The [MinecraftPicocli](https://github.com/Rubydesic/MinecraftPicocli) library facilitates the use of picocli in [Minecraft Forge](https://files.minecraftforge.net/).
* [Simple Java Mail](https://www.simplejavamail.org/) now offers a picocli-based [CLI](https://www.simplejavamail.org/cli.html#navigation).
* [jbang](https://github.com/maxandersen/jbang) not only uses picocli internally, but also has a CLI template","Picocli aims to be the easiest-to-use way to create rich command line
applications that can run on and off the JVM. picocli is a modern library and
framework, written in Java, that contains both an annotations API and a
programmatic API. It features usage help with [ANSI colors and styles), [TAB
autocompletion], and nested subcommands."
392,Qt binding for Go (Golang) with support for Windows / macOS / Linux / FreeBSD / Android / iOS / Sailfish OS / Raspberry Pi / AsteroidOS / Ubuntu Touch / JavaScript / WebAssembly,"Introduction
------------

[Qt](https://en.wikipedia.org/wiki/Qt_(software)) is a free and open-source widget toolkit for creating graphical user interfaces as well as cross-platform applications that run on various software and hardware platforms with little or no change in the underlying codebase.

[Go](https://en.wikipedia.org/wiki/Go_(programming_language)), also known as Golang, is a programming language designed at Google.

[therecipe/qt](https://github.com/therecipe/qt) allows you to write Qt applications entirely in Go, [JavaScript/TypeScript](https://github.com/therecipe/entry), [Dart/Flutter](https://github.com/therecipe/flutter), [Haxe](https://github.com/therecipe/haxe) and [Swift](https://github.com/therecipe/swift)

Beside the language bindings provided, `therecipe/qt` also greatly simplifies the deployment of Qt applications to various software and hardware platforms.

At the time of writing, almost all Qt functions and classes are accessible, and you should be able to find everything you need to build fully featured Qt applications.

Impressions
-----------

[Gallery](https://github.com/therecipe/qt/wiki/Gallery) of example applications.

[JavaScript Demo](https://therecipe.github.io/entry) | *[source](https://github.com/therecipe/entry)*

Installation
------------

The following instructions assume that you already installed [Go](https://golang.org/dl/) and [Git](https://git-scm.com/downloads)

#### (Experimental) cgo-less version (try this first, if you are new and want to test the binding)

##### Windows

```powershell
go get -ldflags=""-w"" github.com/therecipe/examples/basic/widgets && for /f %v in ('go env GOPATH') do %v\bin\widgets.exe
```

##### macOS/Linux

```bash
go get -ldflags=""-w"" github.com/therecipe/examples/basic/widgets && $(go env GOPATH)/bin/widgets
```

#### Default version

##### Windows [(more info)](https://github.com/therecipe/qt/wiki/Installation-on-Windows)

```powershell
set GO111MODULE=off
go get -v github.com/therecipe/qt/cmd/... && for /f %v in ('go env GOPATH') do %v\bin\qtsetup test && %v\bin\qtsetup -test=false
```

##### macOS [(more info)](https://github.com/therecipe/qt/wiki/Installation-on-macOS)

```bash
export GO111MODULE=off; xcode-select --install; go get -v github.com/therecipe/qt/cmd/... && $(go env GOPATH)/bin/qtsetup test && $(go env GOPATH)/bin/qtsetup -test=false
```

##### Linux [(more info)](https://github.com/therecipe/qt/wiki/Installation-on-Linux)

```bash
export GO111MODULE=off; go get -v github.com/therecipe/qt/cmd/... && $(go env GOPATH)/bin/qtsetup test && $(go env GOPATH)/bin/qtsetup -test=false
```

Resources
---------

-	[Installation](https://github.com/therecipe/qt/wiki/Installation)
-	[Getting Started](https://github.com/therecipe/qt/wiki/Getting-Started)
-	[Wiki](https://github.com/therecipe/qt/wiki)
-	[Qt Documentation](https://doc.qt.io/qt-5/classes.html)
-	[FAQ](https://github.com/therecipe/qt/wiki/FAQ)
-	[#qt-binding](https://gophers.slack.com/messages/qt-binding/details) Slack channel ([invite](https://invite.slack.golangbridge.org)\)

Deployment Targets
------------------

| Target                   | Arch             | Linkage                   | Docker Deployment | Host OS |
|:------------------------:|:----------------:|:-------------------------:|:-----------------:|:-------:|
|         Windows          |     32 / 64      |     dynamic / static      |        Yes        |   Any   |
|          macOS           |        64        |          dynamic          |        Yes        |   Any   |
|          Linux           | arm / arm64 / 64 | dynamic / static / system |        Yes        |   Any   |
|     Android (+Wear)      |   arm / arm64    |          dynamic          |        Yes        |   Any   |
| Android-Emulator (+Wear) |        32        |          dynamic          |        Yes        |   Any   |
|        SailfishOS        |       arm        |          system           |        Yes        |   Any   |
|   SailfishOS-Emulator    |        32        |          system           |        Yes        |   Any   |
|   Raspberry Pi (1/2/3)   |       arm        |     dynamic / system      |        Yes        |   Any   |
|       Ubuntu Touch       |     arm / 64     |          system           |        Yes        |   Any   |
|        JavaScript        |        32        |          static           |        Yes        |   Any   |
|       WebAssembly        |        32        |          static           |        Yes        |   Any   |
|           iOS            |      arm64       |          static           |        No         |  macOS  |
|      iOS-Simulator       |        64        |          static           |        No         |  macOS  |
|        AsteroidOS        |       arm        |          system           |        No         |  Linux  |
|         FreeBSD          |     32 / 64      |          system           |        No         | FreeBSD |

License
-------

This package is released under [LGPLv3](https://opensource.org/licenses/LGPL-3.0)

Qt itself is licensed and available under multiple [licenses](https://www.qt.io/licensing).
","Qt is a free and open-source widget toolkit for creating graphical user
interfaces as well as cross-platform applications that run on various software
and hardware platforms with little or no change in the underlying codebase. Go
allows you to write Qt applications entirely in Go, [JavaScript/TypeScript],
[Dart/Flutter], [Haxe] and [Swift."
2697,Cross-platform automation framework for all kinds of your apps built on top of W3C WebDriver protocol,"## Appium

[![NPM version](https://badge.fury.io/js/appium.svg)](https://npmjs.org/package/appium)
[![Monthly Downloads](https://img.shields.io/npm/dm/appium.svg)](https://npmjs.org/package/appium)

[![FOSSA Status](https://app.fossa.io/api/projects/git%2Bhttps%3A%2F%2Fgithub.com%2Fappium%2Fappium.svg?type=shield)](https://app.fossa.io/projects/git%2Bhttps%3A%2F%2Fgithub.com%2Fappium%2Fappium?ref=badge_shield)

[![StandWithUkraine](https://raw.githubusercontent.com/vshymanskyy/StandWithUkraine/main/badges/StandWithUkraine.svg)](https://github.com/vshymanskyy/StandWithUkraine/)

[![Stand With Ukraine](https://raw.githubusercontent.com/vshymanskyy/StandWithUkraine/main/banner2-direct.svg)](https://vshymanskyy.github.io/StandWithUkraine/)

Appium is an open-source, cross-platform test automation tool for native,
hybrid, mobile web and desktop apps. Initially created to automate iOS and Android mobile
applications Appium has grown to a full-featured platform that provides [WebDriver](https://www.w3.org/TR/webdriver/)-based automation possibilities for the whole set of different mobile and desktop platforms.
See [Drivers Maintained By The Appium Team](#drivers-maintained-by-the-appium-team)
and [Drivers Provided By Third Parties](#drivers-provided-by-third-parties) sections below for more details.

:bangbang: Major documentation revision in progress

:bangbang: Appium core team does not maintain Appium 1.x anymore since the 1st of January 2022. All recent versions of officially supported platform drivers are not compatible to Appium 1.x anymore, and require Appium 2 to run. [Please read the migration guide from 1.x to 2.0](https://appium.github.io/appium/docs/en/latest/guides/migrating-1-to-2/) to manage the Appium server.

Appium is in the final stages of a major revision (to version 2.0). As such, the documentation
found around the web may not be correct. The current Appium 2.0 documentation is very much in
progress. Currently, it can be found [here](https://appium.github.io/appium/docs/en/latest/).

### Requirements

- macOS, Linux or Windows operating system
- Node.js 14+
- NPM (Node Package Manager) 8+

These are only server requirements. Each driver might have its own requirements. Consider checking the corresponding driver tutorial for more details.

### Server

To install Appium 2 server using Node Package Manager (npm) run the following command:

```bash
npm install -g appium@next
```

:bangbang: Running `npm install -g appium` would still install Appium 1 because version 2 is in its late beta stage.

### Drivers

Appium supports app automation across a variety of platforms, like iOS,
Android, and Windows. Each platform is supported by one or more ""drivers"",
which know how to automate that particular platform. Since version 2.0
all drivers have been isolated from the Appium server app and can
be managed independently using the [appium driver](https://appiumpro.com/editions/122-installing-appium-20-and-the-driver-and-plugins-cli) command line interface.

In general, the drivers management in Appium 2 is as simple as:

```bash
# To install a new driver from npm
appium driver install --source=npm appium-xcuitest-driver[@<version>]
# To install a driver from a local folder (useful for developers)
appium driver install --source=local /Users/me/sources/appium-xcuitest-driver
# To install a new driver from github (hm, maybe it's time to publish it to NPM?)
appium driver install --source=github appium/appium-xcuitest-driver

# To list already installed drivers
appium driver list --installed

# To update a driver (it must be already installed)
appium driver update xcuitest

# To uninstall a driver (it won't last forever, wouldn't it?)
appium driver uninstall xcuitest
```

You can find a full list of
[officially-supported](https://appium.github.io/appium/docs/en/latest/ecosystem/#drivers) and
[third-party](https://appium.github.io/appium/docs/en/latest/ecosystem/#other-drivers) drivers at
the current Appium 2.0 documentation.

### Plugins

The concept of plugins is something new that has been added exclusively to Appium2. Plugins allow you to extend server functionality without changing the server code. Plugins could be managed similarly to drivers:

```bash
# To install an officially supported plugin
appium plugin install images
# To install a plugin from a local folder (useful for developers)
appium plugin install --source=local /Users/me/sources/images
# To install a new plugin from npm
appium plugin install --source=npm appium-device-farm

# To list already installed plugins
appium plugin list --installed

# To update a plugins (it must be already installed)
appium plugin update appium-device-farm

# To uninstall a plugin
appium plugin uninstall appium-device-farm
```

The main difference between drivers and plugins is that the latter must be explicitly enabled on server startup after it was installed (drivers are enabled by default after installation):

```bash
appium server --use-plugins=device-farm,images
```

You can find a full list of
[officially-supported](https://appium.github.io/appium/docs/en/latest/ecosystem/#plugins) and
[third-party](https://appium.github.io/appium/docs/en/latest/ecosystem/#other-plugins) plugins at
the current Appium 2.0 documentation.


### Server Command Line Interface

In order to start sending commands to Appium over the wire it must be listening
on the URL where your client library expects it to listen.
Use the following commands to run and configure Appium server:

```bash
# Start the server on the default port and host (e.g. http://0.0.0.0:4723/)
appium server
# Start the server on the given port, host and use the base path prefix (the default prefix is /)
appium server -p 9000 -a 127.0.0.1 -pa /wd/hub

# Get the list of all supported command line parameters.
# This list would also include descriptions of driver-specific
# command line arguments for all installed drivers.
# Each driver and plugin must have their command line arguments
# exposed in a special JSON schema declared as a part of the corresponding
# package.json file.
appium server --help
```

Appium supports execution of parallel server processes as well as parallel driver sessions within
single server process. Refer the corresponding driver documentations regarding which mode is optimal
for the particular driver or whether it supports parallel sessions.

### Why Appium?

1. You usually don't have to recompile your app or modify it in any way, due
   to the use of standard automation APIs on all platforms.
2. You can write tests with your favorite dev tools using any
   [WebDriver](https://w3c.github.io/webdriver/webdriver-spec.html)-compatible
   language such as [Java](https://github.com/appium/java-client),
   [JavaScript](https://webdriver.io/), [Python](https://github.com/appium/python-client),
   [Ruby](https://github.com/appium/ruby_lib), [C#](https://github.com/appium/dotnet-client)
   with the Selenium WebDriver API. There are also various third party
   client implementations for other languages.
3. You can use any testing framework.
4. Some drivers, like xcuitest and uiautomator2 ones have built-in mobile web and
   hybrid app support. Within the same script, you can switch seamlessly between native
   app automation and webview automation, all using the WebDriver model that's already
   the standard for web automation.
5. You can run your automated tests locally and in a cloud. There are multiple
   cloud providers that support various Appium drivers (mostly
   targeting iOS and Android mobile automation).
6. [Appium Inspector](https://github.com/appium/appium-inspector) allows
   visual debugging of automated tests and could be extremely useful for
   beginners.

Investing in the
[WebDriver](https://w3c.github.io/webdriver/webdriver-spec.html) protocol means
you are betting on a single, free, and open protocol for testing that has become
a web standard. Don't lock yourself into a proprietary stack.

For example, if you use Apple's XCUITest library without Appium you can only
write tests using Obj-C/Swift, and you can only run tests through Xcode.
Similarly, with Google's UiAutomator or Espresso, you can only write tests in
Java/Kotlin. Appium opens up the possibility of true cross-platform native app
automation, for mobile and beyond. Finally!

If you're new to Appium or want a more comprehensive description of what this is all
about, please read our [Introduction to Appium Concepts](/docs/en/about-appium/intro.md).

### Quickstart

Check out our [Quickstart](https://appium.github.io/appium/docs/en/latest/quickstart/) guide
to get going with Appium.

There is also a sample code that contains [many examples of tests in a variety
of different languages](https://github.com/appium/appium/tree/1.x/sample-code)!

### Documentation

For prettily-rendered docs, please visit [Appium Documentation](https://appium.github.io/appium).
You can always find the full list of Appium doc pages at [Appium's GitHub
Repo](https://github.com/appium/appium/tree/master/packages/appium/docs) as well.

### Contributing

Please take a look at our [contribution documentation](CONTRIBUTING.md)
for instructions on how to build, test, and run Appium from the source.

### Roadmap

Interested in where Appium is heading in the future? Check out the [Roadmap](ROADMAP.md)

### Project History, Credits & Inspiration

* [History](https://appium.github.io/appium/docs/en/latest/intro/history/)

### User Forums

Announcements and debates often take place on the [Discussion Group](https://discuss.appium.io),
be sure to sign up!

### Troubleshooting

We put together a [troubleshooting guide](/docs/en/writing-running-appium/other/troubleshooting.md).
Please have a look here first if you run into any problems. It contains instructions for checking
a lot of common errors and how to get in touch with the community if you're
stumped.

### License

[![FOSSA Status](https://app.fossa.io/api/projects/git%2Bhttps%3A%2F%2Fgithub.com%2Fappium%2Fappium.svg?type=large)](https://app.fossa.io/projects/git%2Bhttps%3A%2F%2Fgithub.com%2Fappium%2Fappium?ref=badge_large)
","Appium is an open-source, cross-platform test automation tool for native,hybrid,
mobile web and desktop apps. Appium supports app automation across a variety of
platforms, like iOS, Android, and Windows. All recent versions of officially
supported platform drivers are not compatible to Appium 1.x anymore, and require
Appium 2 to run."
2843,Image Captcha Solving Using TensorFlow and CNN Model. Accuracy 90%+,"# Captcha Solving Using TensorFlow


## Introduction

1. Solve captcha using TensorFlow.
2. Learn CNN and TensorFlow by a practical project.

Follow the steps,
run the code,
and it works!

the accuracy of 4 digits version can be as high as 99.8%!

There are several more steps to put this prototype on production.

**Ping me for paid technical supports**.

[i@jackon.me](mailto:i@jackon.me)


## Table of Contents

- Solve Captcha Using CNN Model

  - Training: 4-digits Captcha
  - Training: 4-letters Captcha
  - Inference: load trained model and predict given images

- Generate DataSet for Training

  - Usage
  - Example 1: 4 chars per captcha, use digits only
  - Example 2: sampling random images

## Solve Captcha Using CNN Model


old code that using tensorflow 1.x is moved to [tensorflow_v1](tensorflow_v1).


#### Training: 4-digits Captcha

this is a perfect project for beginers.

we will train a model of ~90% accuracy in 1 minute using one single GPU card (GTX 1080 or above).

if we increase the dataset by 10x, the accuracy increases to 98.8%.
we can further increase the accuracy to 99.8% using 1M traning images.

here is the source code and running logs: [captcha-solver-tf2-4digits-AlexNet-98.8.ipynb](captcha-solver-tf2-4digits-AlexNet-98.8.ipynb)

Images, Ground Truth and Predicted Values:

there is 1 predicton error out of the 20 examples below. 9871 -> 9821

![](img-doc/result-preview-4digits.png)

Accuracy and Loss History:

![](img-doc/history-4digits.png)

Model Structure:

- 3 convolutional layers, followed by 2x2 max pooling layer each.
- 1 flatten layer
- 2 dense layer

![](img-doc/model-structure-alexnet-for-4digits.png)


#### Training: 4-letters Captcha

this is a more practical project.

the code is the same as the 4-digits version, but the training dataset is much bigger.

it costs 2-3 hours to generate training dataset and costs 30 min to train a 95% accuracy model.

here is the source code and running logs: [captcha-solver-tf2-4letters-AlexNet.ipynb](captcha-solver-tf2-4letters-AlexNet.ipynb)


#### Inference: load trained model and predict given images

example: [captcha-solver-model-restore.ipynb](captcha-solver-model-restore.ipynb)


## Generate DataSet for Training

#### Usage

```bash
$ python datasets/gen_captcha.py  -h
usage: gen_captcha.py [-h] [-n N] [-c C] [-t T] [-d] [-l] [-u] [--npi NPI] [--data_dir DATA_DIR]

optional arguments:
  -h, --help           show this help message and exit
  -n N                 epoch number of character permutations.
  -c C                 max count of images to generate. default unlimited
  -t T                 ratio of test dataset.
  -d, --digit          use digits in dataset.
  -l, --lower          use lowercase in dataset.
  -u, --upper          use uppercase in dataset.
  --npi NPI            number of characters per image.
  --data_dir DATA_DIR  where data will be saved.
```

examples:

![](img-doc/data-set-example.png)

#### Example 1: 4 chars per captcha, use digits only

1 epoch has `10*9*8*7=5040` images, generate 6 epoches for training.

generating the dataset:

```bash
$ python datasets/gen_captcha.py -d --npi=4 -n 6
10 choices: 0123456789
generating 6 epoches of captchas in ./images/char-4-epoch-6/train
generating 1 epoches of captchas in ./images/char-4-epoch-6/test
write meta info in ./images/char-4-epoch-6/meta.json
```

preview the dataset:

```bash
$ python datasets/base.py images/char-4-epoch-6/
========== Meta Info ==========
num_per_image: 4
label_choices: 0123456789
height: 100
width: 120
n_epoch: 6
label_size: 10
==============================
train images: (30240, 100, 120), labels: (30240, 40)
test images: (5040, 100, 120), labels: (5040, 40)
```

#### Example 2: sampling random images

scenario: use digits/upper cases, 4 chars per captcha image.

1 epoch will have `36*35*34*33=1.4M` images. the dataset is too big to debug.

using `-c 10000` param, sampling 10k *random* images.

generating the dataset:

```bash
$ python3 datasets/gen_captcha.py -du --npi 4 -n 1 -c 10000
36 choices: 0123456789ABCDEFGHIJKLMNOPQRSTUVWXYZ
generating 1 epoches of captchas in ./images/char-4-epoch-1/train.
only 10000 records used in epoche 1. epoche_count: 1413720
```


## Running Jupyter in docker

tensorflow image: [https://hub.docker.com/r/jackon/tensorflow-2.1-gpu](https://hub.docker.com/r/jackon/tensorflow-2.1-gpu)

```bash
docker pull jackon/tensorflow-2.1-gpu
# check if gpu works in docker container
docker run --rm --gpus all -t jackon/tensorflow-2.1-gpu /usr/bin/nvidia-smi
# start jupyter server in docker container
docker run --rm --gpus all -p 8899:8899 -v $(realpath .):/tf/notebooks -t jackon/tensorflow-2.1-gpu
```
","Learn CNN and TensorFlow by a practical project. The accuracy of 4 digits
version can be as high as 99.8%! The code is the same as the 4-digits version,
but the training dataset is much bigger. We will train a model of ~90% accuracy
in 1 minute using one single GPU card (GTX 1080 or above) If we increase the
dataset by 10x, the accuracy increases to 98.8%. We can further increase the
accuracy to 99. 8% using 1M traning images."
1357,Some helper classes for writing functional tests in Symfony,"[![Build Status](https://github.com/liip/LiipFunctionalTestBundle/actions/workflows/tests.yml/badge.svg)](https://github.com/liip/LiipFunctionalTestBundle/actions/workflows/tests.yml)
[![Latest Stable Version](https://poser.pugx.org/liip/functional-test-bundle/v/stable)](https://packagist.org/packages/liip/functional-test-bundle)
[![Latest Unstable Version](https://poser.pugx.org/liip/functional-test-bundle/v/unstable)](https://packagist.org/packages/liip/functional-test-bundle)
[![Scrutinizer Code Quality][Scrutinizer image]
![Scrutinizer][Scrutinizer Coverage Image]][Scrutinizer]

Introduction
============

This Bundle provides base classes for functional tests.
It also provides a DI aware mock builder for unit tests.

Documentation
------------

* [Installation](doc/installation.md)
* [Basic usage](doc/basic.md)
* [Command test](doc/command.md)
* [Logged client](doc/logged.md)
* [Query counter](doc/query.md)
* [Examples](doc/examples.md)
* [Caveats](doc/caveats.md)

To run tests in parallel:
* [Fastest](doc/fastest.md)

[Travis Master]: https://travis-ci.org/liip/LiipFunctionalTestBundle
[Travis Master image]: https://travis-ci.org/liip/LiipFunctionalTestBundle.svg?branch=master
[Scrutinizer]: https://scrutinizer-ci.com/g/liip/LiipFunctionalTestBundle/?branch=master
[Scrutinizer image]: https://scrutinizer-ci.com/g/liip/LiipFunctionalTestBundle/badges/quality-score.png?b=master
[Scrutinizer Coverage image]: https://scrutinizer-ci.com/g/liip/LiipFunctionalTestBundle/badges/coverage.png?b=master
","This Bundle provides base classes for functional tests. It also provides a DI
aware mock builder for unit tests. To run tests in parallel: [Fastest, Fastest,
Logged client, Query counter, Caveats, Coverage Image, Scrutinizer]"
3427,💁‍♀️Your new best friend powered by an artificial neural network,"<h1 align=""center"">
  <br>
  <img src=""https://olivia-ai.org/img/icons/olivia-with-text.png"" alt=""Olivia's character"" width=""300"">
  <br>
</h1>

<h4 align=""center"">💁‍♀️ Your new best friend</h4>

<p align=""center"">
  <a href=""https://goreportcard.com/report/github.com/olivia-ai/olivia""><img src=""https://goreportcard.com/badge/github.com/olivia-ai/olivia""></a>
  <a href=""https://godoc.org/github.com/olivia-ai/olivia""><img src=""https://godoc.org/github.com/olivia-ai/olivia?status.svg"" alt=""GoDoc""></a>
  <a href=""https://app.fossa.io/projects/git%2Bgithub.com%2Folivia-ai%2Folivia?ref=badge_shield""><img src=""https://app.fossa.io/api/projects/git%2Bgithub.com%2Folivia-ai%2Folivia.svg?type=shield""></a>
  <a href=""https://codecov.io/gh/olivia-ai/olivia""><img src=""https://codecov.io/gh/olivia-ai/olivia/branch/master/graph/badge.svg"" /></a>
  <br>
  <img src=""https://github.com/olivia-ai/olivia/workflows/Code%20coverage/badge.svg"">
  <img src=""https://github.com/olivia-ai/olivia/workflows/Docker%20CI/badge.svg"">
  <img src=""https://github.com/olivia-ai/olivia/workflows/Format%20checker/badge.svg"">
</p>

<p align=""center"">
  <a href=""https://twitter.com/oliv_ai""><img alt=""Twitter Follow"" src=""https://img.shields.io/twitter/follow/oliv_ai""></a>
  <a href=""https://discord.gg/wXDwTdy""><img src=""https://img.shields.io/discord/699567909235720224?label=Discord&style=social""></a>
</p>

<p align=""center"">
  <a href=""https://www.youtube.com/watch?v=JRSNnW05suo""><img width=""250"" src=""https://i.imgur.com/kEKJjJn.png""></a>
</p>

<p align=""center"">
  <a href=""https://olivia-ai.org"">Website</a> —
  <a href=""https://docs.olivia-ai.org"">Documentation</a> —
  <a href=""#getting-started"">Getting started</a> —
  <a href=""#introduction"">Introduction</a> —
  <a href=""#translations"">Translations</a> —
  <a href=""#contributors"">Contributors</a> —
  <a href=""#license"">License</a>
</p>

<p align=""center"">
  ⚠️ Please check the <strong><a href=""https://github.com/olivia-ai/olivia/issues"">Call for contributors</a></strong>
</p>

## Introduction
<p align=""center"">
  <img alt=""introduction"" height=""100"" src=""https://i.imgur.com/Ygm9CMc.png"">
</p>

### Description
Olivia is an open-source chatbot built in Golang using Machine Learning technologies.
Its goal is to provide a free and open-source alternative to big services like DialogFlow. 

You can chat with her by speaking (STT) or writing, she replies with a text message but you can enable her voice (TTS).

You can clone the project and customize it as you want using [GitHub](https://github.com/olivia-ai/olivia)
Try it on [her website!](https://olivia-ai.org)

### Why Olivia?
- The only chatbot project in Go that could be modulable and customizable.
- Using daily a privacy-friendly chatbot is great.
- The Website is a Progressive Web Application, which means you can add it to your phone and it seems like a native app!


## Getting started
### Installation 
#### Login to Github 

To get a personal access token from Github go to `Setings > Developer settings > Personal Access Tokens`

Click on Generate new Token and name it you MUST have read and write packages ticked on.
Then click Generate new token

Replace `TOKEN` with the Token that you just made.
```bash
$ export PAT=TOKEN
```

Login to Github (Note: change USERNAME to Gthub username)
```bash
$ echo $PAT | docker login docker.pkg.github.com -u USERNAME --password-stdin
```

#### Docker

<p align=""center"">
  <img alt=""docker installation"" height=""100"" src=""https://i.imgur.com/5NDCfF3.png"">
</p>

Pull the image from GitHub Packages
```bash
$ docker pull docker.pkg.github.com/olivia-ai/olivia/olivia:latest
```

Then start it
```bash
$ docker run -d -e PORT=8080 -p 8080:8080 docker.pkg.github.com/olivia-ai/olivia/olivia:latest
```

You can just use the websocket of Olivia now.

To stop it, get the container id:
```bash
$ docker container ls
```
```bash
CONTAINER ID        IMAGE               COMMAND             CREATED             STATUS              PORTS                    NAMES
311b3abb963a        olivia              ""./main""            7 minutes ago       Up 7 minutes        0.0.0.0:8080->8080/tcp   quizzical_mayer
```

and stop it
```bash
$ docker container stop 311b3abb963a 
```

The app will automatically check for `res/datasets/training.json` file which contains the save of the neural network.
By default when you clone the repository from Github you have a stable save.
If you want to train a new model just delete this file and rerun the app.

#### GitHub
<p align=""center"">
  <img height=""100"" src=""https://i.imgur.com/RRPoP69.png"">
</p>

Clone the project via GitHub:

```bash 
$ git clone git@github.com:olivia-ai/olivia.git
```

Then download the dependencies
```bash
$ go mod download
```

And run it
```bash
$ go run main.go
```

### Frontend and Backend
To install the frontend and the backend together, please use the `docker-compose.yml` file:

```bash
$ docker-compose up
```

And all done!

## Architecture
<p align=""center"">
  <img alt=""architecture"" height=""85"" src=""https://i.imgur.com/95h8WIU.png"">
  <br>
  <img src=""https://i.imgur.com/G9BYf4Y.png"">
</p>

## Translations

<p align=""center"">
  <img alt=""introduction"" height=""130"" src=""https://i.imgur.com/MDKbP0R.png"">
</p>

### Languages supported
- <img src=""https://i.imgur.com/URqxsb0.png"" width=""25""> English
- <img src=""https://i.imgur.com/Oo5BNk0.png"" width=""25""> Spanish
- <img src=""https://i.imgur.com/2DWxeF9.png"" width=""25""> Catalan
- <img src=""https://i.imgur.com/0dVqbjf.png"" width=""25""> French
- <img src=""https://i.imgur.com/sXLQp8e.png"" width=""25""> German
- <img src=""https://i.imgur.com/DGNcrRF.png"" width=""25""> Italian
- <img src=""https://i.imgur.com/kB0RoFZ.png"" width=""25""> Brazilian portuguese - not completed

### Coverage
The coverage of the translations is given [here](https://olivia-ai.org/dashboard/language).
To add a language please read [the documentation for that](https://docs.olivia-ai.org/translations.html).

## Contributors

<p align=""center"">
  <img alt=""docker installation"" height=""85"" src=""https://i.imgur.com/6xr2zdp.png"">
</p>
  
### Contributing
Please refer to the [contributing file](.github/CONTRIBUTING.md)
  
### Code Contributors
Thanks to the people who contribute to Olivia. 

[Contribute](.github/CONTRIBUTING.md)
<a href=""https://github.com/olivia-ai/olivia/graphs/contributors""><img src=""https://opencollective.com/olivia-ai/contributors.svg?width=950&button=false"" /></a>

### Financial Contributors
Become a financial contributor and help Olivia growth. 

Contribute on the GitHub page of [hugolgst](https://github.com/sponsors/hugolgst) ❤️

## License

<p align=""center"">
  <img src=""https://i.imgur.com/9Xxtchv.png"" height=""90"">
</p>

[![FOSSA Status](https://app.fossa.io/api/projects/git%2Bgithub.com%2Folivia-ai%2Folivia.svg?type=large)](https://app.fossa.io/projects/git%2Bgithub.com%2Folivia-ai%2Folivia?ref=badge_large)

<p align=""center"">
  <img width=""60"" src=""https://olivia-ai.org/img/icons/olivia.png"">
<p>

<p align=""center"">
  Made with ❤️ by <a href=""https://github.com/hugolgst"">Hugo Lageneste</a>
</p>

![Olivia's wave](https://olivia-ai.org/img/background-olivia.png)
","Olivia is an open-source chatbot built in Golang using Machine Learning
technologies. You can chat with her by speaking (STT) or writing, she replies
with a text message but you can enable her voice (TTS) You can clone the project
and customize it as you want using [GitHub]. You can also try it on [her
website!](https://olivia-ai.org) The only chatbot project in Go that could be
modulable and customizable."
1222,REST API Client Library,"
# Purest

[![npm-version]][npm] [![test-ci-img]][test-ci-url] [![test-cov-img]][test-cov-url] [![snyk-vulnerabilities]][snyk]

> _REST API Client Library_

```js
var purest = require('purest')
var google = purest({provider: 'google'})

await google
  .query('youtube')
  .select('channels')
  .where({forUsername: 'GitHub'})
  .auth(token)
  .request()
```

## Table of Contents

> _This is Purest **v4**, for older releases take a look at [v3] and [v2]_

- **[Introduction](#introduction)**
- **[Purest Options](#purest-options)**
- **[Request Options](#request-options)**
- **[Examples](#examples)**
- **[Article]**

---

## Introduction

> _**Purest** is a tool for building **expressive** REST API clients_

### Default Endpoint

Here is a basic configuration for Google:

```json
{
  ""google"": {
    ""default"": {
      ""origin"": ""https://www.googleapis.com"",
      ""path"": ""{path}"",
      ""headers"": {
        ""authorization"": ""Bearer {auth}""
      }
    }
  }
}
```

The above configuration can be used to instantiate that provider:

```js
var google = purest({provider: 'google', config})
```

Then we can request some data from YouTube:

```js
var {res, body} = await google
  .get('youtube/v3/channels')
  .qs({forUsername: 'GitHub'})
  .auth(token)
  .request()
```

### Explicit Endpoint

We can define explicit endpoint for accessing the YouTube API:

```json
{
  ""google"": {
    ""default"": {
      ""origin"": ""https://www.googleapis.com"",
      ""path"": ""{path}"",
      ""headers"": {
        ""authorization"": ""Bearer {auth}""
      }
    },
    ""youtube"": {
      ""origin"": ""https://www.googleapis.com"",
      ""path"": ""youtube/{version}/{path}"",
      ""version"": ""v3"",
      ""headers"": {
        ""authorization"": ""Bearer {auth}""
      }
    }
  }
}
```

And then request the same data:

```js
var {res, body} = await google('youtube')
  .get('channels')
  .qs({forUsername: 'GitHub'})
  .auth(token)
  .request()
```

### Defaults

Every method in Purest can also be preconfigured with a value:

```js
var google = purest({provider: 'google', config,
  defaults: {auth: token}
})
```

Then we no longer need to set the access token on each request:

```js
var {res, body} = await google('youtube')
  .get('channels')
  .qs({forUsername: 'GitHub'})
  .request()
```

### Method Aliases

Each method in Purest can have multiple aliases defined for it:

```js
var google = purest({provider: 'google', config,
  defaults: {auth: token},
  methods: {get: ['select'], qs: ['where']}
})
```

And then use it like this:

```js
var {res, body} = await google('youtube')
  .select('channels')
  .where({forUsername: 'GitHub'})
  .request()
```

---

## Purest Options

> _**Purest** is a flexible tool for **abstracting** out REST APIs_

```js
var google = purest({config: {}, provider: 'google', defaults: {}, methods: {}})
```

| Key            | Type | Description
| :-             | :-:  | :-
| **`provider`** | `''` | Provider name to initialize from the list of providers found in `config`
| **`config`**   | `{}` | Providers configuration to use
| **`defaults`** | `{}` | Any supported configuration option set by default, see below
| **`methods`**  | `{}` | List of methods and their aliases to use with this instance

---

## Request Options

> _**Purest** is built on top of a **[powerful HTTP Client][request-compose]**_

### URL Options

| Option      | Description
| :-          | :-
| `origin`    | The protocol and domain part of the URL, can contain `{subdomain}` token
| `path`      | The path part of the URL, can contain `{version}`, `{path}` and `{type}` tokens
| `subdomain` | Subdomain part of the URL to replace in `origin`
| `version`   | Version string to replace in `path`
| `type`      | Type string to replace in `path`, typically `json` or `xml`

### HTTP Methods

All HTTP methods `get` `head` `post` `put` `patch` `options` `delete` `trace` `connect` accept a string to replace the `{path}` configuration token with, or absolute URL to set the entire `url`.

### Request Options

| Option     | Type                  | Description
| :--        | :--                   | :--
| `method`   | `'string'` | Request method, implicitly set if one of the above HTTP Methods is used
| `url`      | `'string'` [`url object`][url-parse] | Absolute URL, automatically constructed if the URL Options above are being used, or absolute URL is passed to any of the HTTP Methods above
| `proxy`    | `'string'` [`url object`][url-parse] | Proxy URL; for HTTPS you have to use [tunneling][tunnel-agent] [agent][proxy-agent] instead
| `qs`       | `{object}` `'string'` | URL querystring
| `headers`  | `{object}` | Request headers
| `form`     | `{object}` `'string'` | `application/x-www-form-urlencoded` request body
| `json`     | `{object}` `'string'` | JSON encoded request body
| `multipart`| `{object}` `[array]`  | `multipart/form-data` as object or `multipart/related` as array request body using [request-multipart]
| `body`     | `'string'` [`Buffer`][buffer] [`Stream`][stream-readable] | Raw request body
| `auth`     | `'string'` `['string', 'string']` `{user, pass}`        | String or array of strings to replace the `{auth}` configuration token with, or Basic authorization as object
| `oauth`    | `{object}` | OAuth 1.0a authorization using [request-oauth]
| `encoding` | [`'string'`][buffer-encoding] | Response body encoding
| `redirect` | `{object}` | HTTP redirect [configuration][redirect-config]
| `timeout`  | `number` | Request timeout in milliseconds
| `agent`    | [`Agent`][agent] | HTTP agent

### Response Options

#### `request`

- buffers the response body
- decompresses `gzip` and `deflate` encoded bodies with valid `content-encoding` header
- converts the response body to string using `utf8` encoding by default
- tries to parse `JSON` and `querystring` encoded bodies with valid `content-type` header

Returns either String or Object.

#### `buffer`

- buffers the response body
- decompresses `gzip` and `deflate` encoded bodies with valid `content-encoding` header

Returns [Buffer][buffer].

#### `stream`

Returns the response [Stream][stream-incoming-message].

### Node Core Options

Any other HTTP request option not explicitly exposed in Purest can be set using any of the response methods:

```js
await google.request({socketPath: ''})
await google.buffer({socketPath: ''})
await google.stream({socketPath: ''})
```

### Endpoint

The explicit `endpoint` configuration can be accessed in various ways:

```js
// as argument to the Purest instance
await google('youtube')
// using the option name
await google.endpoint('youtube')
// or the default method alias defined for it
await google.query('youtube')
```

---

## Examples

> _**Purest** comes with a **[fancy logger][request-logs]**_

```bash
npm i --save-dev request-logs
```

```bash
DEBUG=req,res,body,json node examples/file-name.js 'example name'
```

| Category | Topic | Providers | Example
| :-       | :-    | :-        | :-
| **OAuth 2.0** | _Refresh Access Tokens_ | `box` `google` `twitch` | [Refresh access tokens][refresh-token]
| **OpenID Connect** | *Verify id_token* | `auth0` `google` `microsoft` | [Discover public keys and verify id_token signature][openid-connect]
| **OAuth 1.0a** | _OAuth 1.0a_ | `flickr` `trello` `twitter` | [Get user profile][oauth-1]
| **Storage** | _Multipart, Streams_ | `box` `dropbox` `drive` | [Upload files][file-stream]
| **Storage** | _HTTP Streams_ | `box` `dropbox` | [Stream file from DropBox to Box][http-stream]

> _Get access tokens using **[Grant]**_


  [npm-version]: https://img.shields.io/npm/v/purest.svg?style=flat-square (NPM Version)
  [test-ci-img]: https://img.shields.io/travis/simov/purest/master.svg?style=flat-square (Build Status)
  [test-cov-img]: https://img.shields.io/coveralls/simov/purest.svg?style=flat-square (Test Coverage)
  [snyk-vulnerabilities]: https://img.shields.io/snyk/vulnerabilities/npm/purest.svg?style=flat-square (Vulnerabilities)

  [npm]: https://www.npmjs.com/package/purest
  [test-ci-url]: https://github.com/simov/purest/actions/workflows/test.yml
  [test-cov-url]: https://coveralls.io/r/simov/purest?branch=master
  [snyk]: https://snyk.io/test/npm/purest

  [v3]: https://github.com/simov/purest/tree/3.x
  [v2]: https://github.com/simov/purest/tree/2.x
  [article]: https://dev.to/simov/purest-53k0

  [request-compose]: https://github.com/simov/request-compose
  [request-oauth]: https://github.com/simov/request-oauth
  [request-multipart]: https://github.com/simov/request-multipart
  [request-cookie]: https://github.com/simov/request-cookie
  [request-logs]: https://github.com/simov/request-logs

  [grant]: https://github.com/simov/grant
  [redirect-config]: https://github.com/simov/request-compose#redirect
  [tunnel-agent]: https://github.com/simov/request-compose/blob/master/examples/misc-tunnel-agent.js
  [proxy-agent]: https://github.com/simov/request-compose/blob/master/examples/misc-proxy-agent.js
  [methods.json]: https://github.com/simov/purest/blob/master/config/methods.json

  [refresh-token]: https://github.com/simov/purest/blob/master/examples/refresh-token.js
  [openid-connect]: https://github.com/simov/purest/blob/master/examples/openid-connect.js
  [oauth-1]: https://github.com/simov/purest/blob/master/examples/oauth-1.js
  [file-stream]: https://github.com/simov/purest/blob/master/examples/file-stream.js
  [http-stream]: https://github.com/simov/purest/blob/master/examples/http-stream.js

  [url-parse]: https://nodejs.org/dist/latest-v10.x/docs/api/url.html#url_url_parse_urlstring_parsequerystring_slashesdenotehost
  [buffer]: https://nodejs.org/dist/latest-v10.x/docs/api/buffer.html
  [buffer-encoding]: https://nodejs.org/dist/latest-v10.x/docs/api/buffer.html#buffer_buffers_and_character_encodings
  [stream-readable]: https://nodejs.org/dist/latest-v10.x/docs/api/stream.html#stream_class_stream_readable
  [stream-incoming-message]: https://nodejs.org/dist/latest-v10.x/docs/api/http.html#http_class_http_incomingmessage
  [agent]: https://nodejs.org/docs/latest-v10.x/api/http.html#http_class_http_agent
","Purest is a tool for building expressive REST API clients. It can be used to
instantiate Google, YouTube and GitHub providers. Purest can also be
preconfigured with a value for each method. It is possible to define multiple
methods and aliases for each of them. It's also possible to set an explicit
endpoint for accessing the YouTube API. For more information on Purest, see the
Purest website or visit purest.org. The Purest API is free and open source."
1452,React.js Google Maps integration component,"# react-google-maps
> React.js Google Maps integration component

[![Version][npm-image]][npm-url] [![Travis CI][travis-image]][travis-url] [![Quality][codeclimate-image]][codeclimate-url] [![Coverage][codeclimate-coverage-image]][codeclimate-coverage-url] [![Dependencies][gemnasium-image]][gemnasium-url] [![Gitter][gitter-image]][gitter-url]


## [Introduction](https://tomchentw.github.io/react-google-maps/#introduction)


## [Installation](https://tomchentw.github.io/react-google-maps/#installation)


## [Usage & Configuration](https://tomchentw.github.io/react-google-maps/#usage--configuration)


## [Changelog][changelog-url]

The changelog is automatically generated via [standard-version][standard-version] and can be found in project root as well as npm tarball.


## [Demo App][demo-app-url]

* [Source code][demo-app-source]
* [CodeSandbox](https://codesandbox.io/s/2xyw6n4o9y)

## Getting Help

**Before doing this, did you**:

1. Read the [documentation](https://tomchentw.github.io/react-google-maps)
2. Read the [source code](https://github.com/tomchentw/react-google-maps)


_You can get someone's help in three ways_:

1. Ask on StackOverflow [with a google-maps tag](https://stackoverflow.com/questions/tagged/google-maps?sort=votes&pageSize=50) or [use react-google-maps as a keyword](https://stackoverflow.com/search?q=react-google-maps)
2. Ask in [the chat room][gitter-url]
3. Create a Pull Request with your solutions to your problem

Please, be noted, **no one**, I mean, **no one**, is obligated to help you in **ANY** means. Your time is valuable, so does our contributors. Don't waste our time posting questions like “how do I do X with React-Google-Maps” and “my code doesn't work”. This is not the primary purpose of the issue tracker. Don't abuse.


## For contributors

<details>
  <summary>Some simple guidelines</summary>

* **Don't** manually modify `lib` folder. They're generated during `yarn release` process
* Follow [conventional-commits-specification][conventional-commits-specification]
* [standard-version][standard-version]
* Auto generated: `src/macros` -> `src/components` -> `lib/components`
* Other components are manually maintained
* Use `yarn` and keep `yarn.lock` updated in PR
* Discuss! Discuss! Discuss!

</details>


[npm-image]: https://img.shields.io/npm/v/react-google-maps.svg?style=flat-square
[npm-url]: https://www.npmjs.org/package/react-google-maps

[travis-image]: https://img.shields.io/travis/tomchentw/react-google-maps.svg?style=flat-square
[travis-url]: https://travis-ci.org/tomchentw/react-google-maps
[codeclimate-image]: https://img.shields.io/codeclimate/github/tomchentw/react-google-maps.svg?style=flat-square
[codeclimate-url]: https://codeclimate.com/github/tomchentw/react-google-maps
[codeclimate-coverage-image]: https://img.shields.io/codeclimate/coverage/github/tomchentw/react-google-maps.svg?style=flat-square
[codeclimate-coverage-url]: https://codeclimate.com/github/tomchentw/react-google-maps
[gemnasium-image]: https://img.shields.io/gemnasium/tomchentw/react-google-maps.svg?style=flat-square
[gemnasium-url]: https://gemnasium.com/tomchentw/react-google-maps
[gitter-image]: https://badges.gitter.im/Join%20Chat.svg
[gitter-url]: https://gitter.im/tomchentw/react-google-maps?utm_source=badge&utm_medium=badge&utm_campaign=pr-badge&utm_content=badge

[changelog-url]: https://github.com/tomchentw/react-google-maps/blob/master/CHANGELOG.md
[demo-app-url]: https://tomchentw.github.io/#/demos/react-google-maps
[demo-app-source]: https://github.com/tomchentw/tomchentw.github.io/blob/master/src/Pages/Demos/ReactGoogleMaps.jsx

[standard-version]: https://github.com/conventional-changelog/standard-version
[conventional-commits-specification]: https://conventionalcommits.org/
","React-Google-Maps is a React.js Google Maps integration component. There are
three ways to get help with the project. The changelog is automatically
generated via [standard-version] and can be found in project root as well as npm
tarball."
1309,Java wrapper for the popular chat & VOIP service: Discord https://discord.com,"[maven-central]: https://img.shields.io/maven-central/v/net.dv8tion/JDA?color=blue
[jitpack]: https://img.shields.io/badge/Snapshots-JitPack-blue
[download]: #download
[discord-invite]: https://discord.gg/0hMr4ce0tIl3SLv5
[migration]: https://jda.wiki/introduction/migration-v3-v4/
[jenkins]: https://ci.dv8tion.net/job/JDA5
[license]: https://github.com/DV8FromTheWorld/JDA/tree/master/LICENSE
[faq]: https://jda.wiki/introduction/faq/
[troubleshooting]: https://jda.wiki/using-jda/troubleshooting/
[discord-shield]: https://discord.com/api/guilds/125227483518861312/widget.png
[faq-shield]: https://img.shields.io/badge/Wiki-FAQ-blue.svg
[troubleshooting-shield]: https://img.shields.io/badge/Wiki-Troubleshooting-darkgreen.svg
[jenkins-shield]: https://img.shields.io/badge/Download-Jenkins-purple.svg
[license-shield]: https://img.shields.io/badge/License-Apache%202.0-white.svg
[migration-shield]: https://img.shields.io/badge/Wiki-Migrating%20from%20V3-darkgreen.svg

<img align=""right"" src=""https://github.com/DV8FromTheWorld/JDA/blob/assets/assets/readme/logo.png?raw=true"" height=""200"" width=""200"">

[ ![maven-central][] ][download]
[ ![jitpack][] ](https://jitpack.io/#DV8FromtheWorld/JDA)
[ ![jenkins-shield][] ][jenkins]
[ ![license-shield][] ][license]

[ ![discord-shield][] ][discord-invite]
[ ![faq-shield] ][faq]
[ ![troubleshooting-shield] ][troubleshooting]
[ ![migration-shield][] ][migration]


# JDA (Java Discord API)

JDA strives to provide a clean and full wrapping of the Discord REST api and its Websocket-Events for Java.
This library is a helpful tool that provides the functionality to create a discord bot in java.

## Summary

Due to official statements made by the Discord developers we will no longer support unofficial features. These features
are undocumented API endpoints or protocols that are not available to bot-accounts.

_Please see the [Discord docs](https://discord.com/developers/docs/reference) for more information about bot accounts._

1. [Introduction](#creating-the-jda-object)
2. [Sharding](#sharding-a-bot)
3. [Entity Lifetimes](#entity-lifetimes)
4. [Download](#download)
5. [Documentation](#documentation)
6. [Support](#getting-help)
7. [Extensions And Plugins](#third-party-recommendations)
8. [Contributing](#contributing-to-jda)
9. [Dependencies](#dependencies)
10. [Other Libraries](#related-projects)

## UserBots and SelfBots

Discord is currently prohibiting creation and usage of automated client accounts (AccountType.CLIENT).
We have officially dropped support for client login as of version **4.2.0**!
Note that JDA is not a good tool to build a custom discord client as it loads all servers/guilds on startup unlike
a client which does this via lazy loading instead.
If you need a bot, use a bot account from the [Application Dashboard](https://discord.com/developers/applications).

[Read More](https://support.discord.com/hc/en-us/articles/115002192352-Automated-user-accounts-self-bots-)

## Creating the JDA Object

Creating the JDA Object is done via the JDABuilder class. After setting the token and other options via setters,
the JDA Object is then created by calling the `build()` method. When `build()` returns,
JDA might not have finished starting up. However, you can use `awaitReady()`
on the JDA object to ensure that the entire cache is loaded before proceeding.
Note that this method is blocking and will cause the thread to sleep until startup has completed.

**Example**:

```java
JDA jda = JDABuilder.createDefault(""token"").build();
```

### Configuration

Both the `JDABuilder` and the `DefaultShardManagerBuilder` allow a set of configurations to improve the experience.

**Example**:

```java
public static void main(String[] args) {
    JDABuilder builder = JDABuilder.createDefault(args[0]);
    
    // Disable parts of the cache
    builder.disableCache(CacheFlag.MEMBER_OVERRIDES, CacheFlag.VOICE_STATE);
    // Enable the bulk delete event
    builder.setBulkDeleteSplittingEnabled(false);
    // Set activity (like ""playing Something"")
    builder.setActivity(Activity.watching(""TV""));
    
    builder.build();
}
```

> See [JDABuilder](https://ci.dv8tion.net/job/JDA5/javadoc/net/dv8tion/jda/api/JDABuilder.html)
  and [DefaultShardManagerBuilder](https://ci.dv8tion.net/job/JDA5/javadoc/net/dv8tion/jda/api/sharding/DefaultShardManagerBuilder.html)

You can configure the memory usage by changing enabled `CacheFlags` on the `JDABuilder`.
Additionally, you can change the handling of member/user cache by setting either a `ChunkingFilter`, disabling **intents**, or changing the **member cache policy**.

```java
public void configureMemoryUsage(JDABuilder builder) {
    // Disable cache for member activities (streaming/games/spotify)
    builder.disableCache(CacheFlag.ACTIVITY);

    // Only cache members who are either in a voice channel or owner of the guild
    builder.setMemberCachePolicy(MemberCachePolicy.VOICE.or(MemberCachePolicy.OWNER));

    // Disable member chunking on startup
    builder.setChunkingFilter(ChunkingFilter.NONE);

    // Disable presence updates and typing events
    builder.disableIntents(GatewayIntent.GUILD_PRESENCE, GatewayIntent.GUILD_MESSAGE_TYPING);

    // Consider guilds with more than 50 members as ""large"". 
    // Large guilds will only provide online members in their setup and thus reduce bandwidth if chunking is disabled.
    builder.setLargeThreshold(50);
}
```

### Listening to Events

The event system in JDA is configured through a hierarchy of classes/interfaces.
We offer two implementations for the `IEventManager`:

- **InterfacedEventManager** which uses an `EventListener` interface and the `ListenerAdapter` abstract class
- **AnnotatedEventManager** which uses the `@SubscribeEvent` annotation that can be applied to methods

By default the **InterfacedEventManager** is used.
Since you can create your own implementation of `IEventManager` this is a very versatile and configurable system.
If the aforementioned implementations don't suit your use-case you can simply create a custom implementation and
configure it on the `JDABuilder` with `setEventManager(...)`.

#### Examples:

**Using EventListener**:

```java
public class ReadyListener implements EventListener
{
    public static void main(String[] args)
            throws InterruptedException
    {
        // Note: It is important to register your ReadyListener before building
        JDA jda = JDABuilder.createDefault(""token"")
            .addEventListeners(new ReadyListener())
            .build();

        // optionally block until JDA is ready
        jda.awaitReady();
    }

    @Override
    public void onEvent(GenericEvent event)
    {
        if (event instanceof ReadyEvent)
            System.out.println(""API is ready!"");
    }
}
```

**Using ListenerAdapter**:

```java
public class MessageListener extends ListenerAdapter
{
    public static void main(String[] args)
    {
        JDA jda = JDABuilder.createDefault(""token"")
                .enableIntents(GatewayIntent.MESSAGE_CONTENT) // enables explicit access to message.getContentDisplay()
                .build();
        //You can also add event listeners to the already built JDA instance
        // Note that some events may not be received if the listener is added after calling build()
        // This includes events such as the ReadyEvent
        jda.addEventListener(new MessageListener());
    }

    @Override
    public void onMessageReceived(MessageReceivedEvent event)
    {
        if (event.isFromType(ChannelType.PRIVATE))
        {
            System.out.printf(""[PM] %s: %s\n"", event.getAuthor().getName(),
                                    event.getMessage().getContentDisplay());
        }
        else
        {
            System.out.printf(""[%s][%s] %s: %s\n"", event.getGuild().getName(),
                        event.getTextChannel().getName(), event.getMember().getEffectiveName(),
                        event.getMessage().getContentDisplay());
        }
    }
}
```

**Slash-Commands**:

```java
public class Bot extends ListenerAdapter
{
    public static void main(String[] args)
    {
        if (args.length < 1) {
            System.out.println(""You have to provide a token as first argument!"");
            System.exit(1);
        }
        // args[0] would be the token (using an environment variable or config file is preferred for security)
        // We don't need any intents for this bot. Slash commands work without any intents!
        JDA jda = JDABuilder.createLight(args[0], Collections.emptyList())
            .addEventListeners(new Bot())
            .setActivity(Activity.playing(""Type /ping""))
            .build();

        // Sets the global command list to the provided commands (removing all others)
        jda.updateCommands().addCommands(
            Commands.slash(""ping"", ""Calculate ping of the bot""),
            Commands.slash(""ban"", ""Ban a user from the server"")
                    .setDefaultPermissions(DefaultMemberPermissions.enabledFor(Permission.BAN_MEMBERS)) // only usable with ban permissions
                    .setGuildOnly(true) // Ban command only works inside a guild
                    .addOption(OptionType.USER, ""user"", ""The user to ban"", true) // required option of type user (target to ban)
                    .addOption(OptionType.STRING, ""reason"", ""The ban reason"") // optional reason
        ).queue();
    }
    
    @Override
    public void onSlashCommandInteraction(SlashCommandInteractionEvent event)
    {
        // make sure we handle the right command
        switch (event.getName()) {
            case ""ping"":
                long time = System.currentTimeMillis();
                event.reply(""Pong!"").setEphemeral(true) // reply or acknowledge
                     .flatMap(v ->
                          event.getHook().editOriginalFormat(""Pong: %d ms"", System.currentTimeMillis() - time) // then edit original
                     ).queue(); // Queue both reply and edit
                break;
            case ""ban"":
                // double check permissions, don't trust discord on this!
                if (!event.getMember().hasPermission(Permission.BAN_MEMBERS)) {
                    event.reply(""You cannot ban members! Nice try ;)"").setEphemeral(true).queue();
                    break;
                }
                User target = event.getOption(""user"", OptionMapping::getUser);
                // optionally check for member information
                Member member = event.getOption(""user"", OptionMapping::getMember);
                if (!event.getMember().canInteract(member)) {
                    event.reply(""You cannot ban this user."").setEphemeral(true).queue();
                    break;
                }
                // Before starting our ban request, tell the user we received the command
                // This sends a ""Bot is thinking..."" message which is later edited once we finished
                event.deferReply().queue();
                String reason = event.getOption(""reason"", OptionMapping::getAsString);
                AuditableRestAction<Void> action = event.getGuild().ban(target, 0); // Start building our ban request
                if (reason != null) // reason is optional
                    action = action.reason(reason); // set the reason for the ban in the audit logs and ban log
                action.queue(v -> {
                    // Edit the thinking message with our response on success
                    event.getHook().editOriginal(""**"" + target.getAsTag() + ""** was banned by **"" + event.getUser().getAsTag() + ""**!"").queue();
                }, error -> {
                    // Tell the user we encountered some error
                    event.getHook().editOriginal(""Some error occurred, try again!"").queue();
                    error.printStackTrace();
                });
        }
    }
}
```

### RestAction

Through [RestAction](https://ci.dv8tion.net/job/JDA5/javadoc/net/dv8tion/jda/api/requests/RestAction.html) we provide request handling with
 
 - [callbacks](https://ci.dv8tion.net/job/JDA5/javadoc/net/dv8tion/jda/api/requests/RestAction.html#queue%28java.util.function.Consumer%29)
 - [promises](https://ci.dv8tion.net/job/JDA5/javadoc/net/dv8tion/jda/api/requests/RestAction.html#submit%28%29)
 - and [sync](https://ci.dv8tion.net/job/JDA5/javadoc/net/dv8tion/jda/api/requests/RestAction.html#complete%28%29)

and it is up to the user to decide which pattern to utilize.
It can be combined with reactive libraries such as [reactor-core](https://github.com/reactor/reactor-core) due to being lazy.

The RestAction interface also supports a number of operators to avoid callback hell:

- [`map`](https://ci.dv8tion.net/job/JDA5/javadoc/net/dv8tion/jda/api/requests/RestAction.html#map%28java.util.function.Function%29)
    Convert the result of the `RestAction` to a different value
- [`flatMap`](https://ci.dv8tion.net/job/JDA5/javadoc/net/dv8tion/jda/api/requests/RestAction.html#flatMap%28java.util.function.Function%29)
    Chain another `RestAction` on the result
- [`delay`](https://ci.dv8tion.net/job/JDA5/javadoc/net/dv8tion/jda/api/requests/RestAction.html#delay%28java.time.Duration%29)
    Delay the element of the previous step

**Example**:

```java
public RestAction<Void> selfDestruct(MessageChannel channel, String content) {
    return channel.sendMessage(""The following message will destroy itself in 1 minute!"")
        .delay(10, SECONDS, scheduler) // edit 10 seconds later
        .flatMap((it) -> it.editMessage(content))
        .delay(1, MINUTES, scheduler) // delete 1 minute later
        .flatMap(Message::delete);
}
```

### More Examples

We provide a small set of Examples in the [Example Directory](https://github.com/DV8FromTheWorld/JDA/tree/master/src/examples/java).

<!--
TODO: Find good examples
- [JDA Butler](https://github.com/Almighty-Alpaca/JDA-Butler)

[And many more!](https://github.com/search?q=JDA+discord+bot&type=Repositories&utf8=%E2%9C%93)
-->

## Sharding a Bot

Discord allows Bot-accounts to share load across sessions by limiting them to a fraction of the total connected Guilds/Servers of the bot.
<br>This can be done using **sharding** which will limit JDA to only a certain amount of Guilds/Servers including events and entities.
Sharding will limit the amount of Guilds/Channels/Users visible to the JDA session so it is recommended to have some kind of elevated management to
access information of other shards.

To use sharding in JDA you will need to use `JDABuilder.useSharding(int shardId, int shardTotal)`. The **shardId** is 0-based which means the first shard
has the ID 0. The **shardTotal** is the total amount of shards (not 0-based) which can be seen similar to the length of an array, the last shard has the ID of
`shardTotal - 1`.

The [`SessionController`](https://ci.dv8tion.net/job/JDA5/javadoc/net/dv8tion/jda/api/utils/SessionController.html) is a tool of the JDABuilder
that allows to control state and behaviour between shards (sessions). When using multiple builders to build shards you have to create one instance
of this controller and add the same instance to each builder: `builder.setSessionController(controller)`

Since version **3.4.0** JDA provides a `ShardManager` which automates this building process.

### Example Sharding - Using JDABuilder

```java
public static void main(String[] args) throws Exception
{
    JDABuilder shardBuilder = JDABuilder.createDefault(args[0]);
    //register your listeners here using shardBuilder.addEventListeners(...)
    shardBuilder.addEventListeners(new MessageListener());
    for (int i = 0; i < 10; i++)
    {
        shardBuilder.useSharding(i, 10)
                    .build();
    }
}
```

> When the `useSharding` method is invoked for the first time, the builder automatically sets a SessionController internally (if none is present)

### Example Sharding - Using DefaultShardManager
```java
public static void main(String[] args) throws Exception
{
    DefaultShardManagerBuilder builder = DefaultShardManagerBuilder.createDefault(args[0]);
    builder.addEventListeners(new MessageListener());
    builder.build();
}
```

## Entity Lifetimes

An **Entity** is the term used to describe types such as **GuildChannel**/**Message**/**User** and other entities that Discord provides.
Instances of these entities are created and deleted by JDA when Discord instructs it. This means the lifetime depends on signals provided by the Discord API which are used to create/update/delete entities.
This is done through Gateway Events known as ""dispatches"" that are handled by the JDA WebSocket handlers.
When Discord instructs JDA to delete entities, they are simply removed from the JDA cache and lose their references.
Once that happens, nothing in JDA interacts or updates the instances of those entities, and they become useless.
Discord may instruct to delete these entities randomly for cache synchronization with the API.

**It is not recommended to store _any_ of these entities for a longer period of time!**
Instead of keeping (e.g.) a `User` instance in some field, an ID should be used. With the ID of a user,
you can use `getUserById(id)` to get and keep the user reference in a local variable (see below).

### Entity Updates

When an entity is updated through its manager, they will send a request to the Discord API which will update the state
of the entity. The success of this request **does not** imply the entity has been updated yet. All entities are updated
by the aforementioned **Gateway Events** which means you cannot rely on the cache being updated yet once the
execution of a RestAction has completed. Some requests rely on the cache being updated to correctly update the entity.
An example of this is updating roles of a member which overrides all roles of the member by sending a list of the
new set of roles. This is done by first checking the current cache, the roles the member has right now, and appending
or removing the requested roles. If the cache has not yet been updated by an event, this will result in unexpected behavior.

### Entity Deletion

Discord may request that a client (the JDA session) invalidates its entire cache. When this happens, JDA will
remove all of its current entities and reconnect the session. This is signaled through the `ReconnectEvent`.
When entities are removed from the JDA cache, they lose access to the encapsulating entities. For instance,
a channel loses access to its guild. Once that happens, they are unable to make any API requests through RestAction
and instead throw an `IllegalStateException`. It is **highly recommended** to only keep references to entities
by storing their **id** and using the respective `get...ById(id)` method when needed.

#### Example

```java
public class UserLogger extends ListenerAdapter 
{
    private final long userId;
    
    public UserLogger(User user)
    {
        this.userId = user.getIdLong();
    }
    
    @Override
    public void onMessageReceived(MessageReceivedEvent event)
    {
        User author = event.getAuthor();
        Message message = event.getMessage();
        if (author.getIdLong() == userId)
        {
            // Print the message of the user
            System.out.println(author.getAsTag() + "": "" + message.getContentDisplay());
        }
    }
    
    @Override
    public void onGuildJoin(GuildJoinEvent event)
    {
        JDA api = event.getJDA();
        User user = api.getUserById(userId); // Acquire a reference to the User instance through the id
        user.openPrivateChannel().queue((channel) ->
        {
            // Send a private message to the user
            channel.sendMessageFormat(""I have joined a new guild: **%s**"", event.getGuild().getName()).queue();
        });
    }
}
```

## Download

[ ![maven-central][] ](https://mvnrepository.com/artifact/net.dv8tion/JDA/latest)
[ ![jitpack][] ](https://jitpack.io/#DV8FromtheWorld/JDA)

Latest Release: [GitHub Release](https://github.com/DV8FromTheWorld/JDA/releases/latest) <br>

Be sure to replace the **VERSION** key below with the one of the versions shown above! For snapshots, please use the instructions provided by [JitPack](https://jitpack.io/#DV8FromTheWorld/JDA).

**Maven**
```xml
<dependency>
    <groupId>net.dv8tion</groupId>
    <artifactId>JDA</artifactId>
    <version>VERSION</version>
</dependency>
```

**Maven without Audio**
```xml
<dependency>
    <groupId>net.dv8tion</groupId>
    <artifactId>JDA</artifactId>
    <version>VERSION</version>
    <exclusions>
        <exclusion>
            <groupId>club.minnced</groupId>
            <artifactId>opus-java</artifactId>
        </exclusion>
    </exclusions>
</dependency>
```

**Gradle**
```gradle
repositories {
    mavenCentral()
}

dependencies {
    //Change 'implementation' to 'compile' in old Gradle versions
    implementation(""net.dv8tion:JDA:VERSION"")
}
```

**Gradle without Audio**
```gradle
dependencies {
    //Change 'implementation' to 'compile' in old Gradle versions
    implementation(""net.dv8tion:JDA:VERSION"") {
        exclude module: 'opus-java'
    }
}
```

The snapshot builds are only available via JitPack and require adding the JitPack resolver, you need to specify specific commits to access those builds.
Stable releases are published to [maven-central](https://mvnrepository.com/artifact/net.dv8tion/JDA).

If you do not need any opus de-/encoding done by JDA (voice receive/send with PCM) you can exclude `opus-java` entirely.
This can be done if you only send audio with an `AudioSendHandler` which only sends opus (`isOpus() = true`). (See [lavaplayer](https://github.com/sedmelluq/lavaplayer))

If you want to use a custom opus library you can provide the absolute path to `OpusLibrary.loadFrom(String)` before using
the audio api of JDA. This works without `opus-java-natives` as it only requires `opus-java-api`.
<br>_For this setup you should only exclude `opus-java-natives` as `opus-java-api` is a requirement for en-/decoding._

See [opus-java](https://github.com/discord-java/opus-java)

### Logging Framework - SLF4J

JDA is using [SLF4J](https://www.slf4j.org/) to log its messages.

That means you should add some SLF4J implementation to your build path in addition to JDA.
If no implementation is found, following message will be printed to the console on startup:
```
SLF4J: Failed to load class ""org.slf4j.impl.StaticLoggerBinder"".
SLF4J: Defaulting to no-operation (NOP) logger implementation
SLF4J: See http://www.slf4j.org/codes.html#StaticLoggerBinder for further details.
```

JDA currently provides a fallback Logger in case that no SLF4J implementation is present.
We strongly recommend to use one though, as that can improve speed and allows you to customize the Logger as well as log to files

There is a guide for logback-classic available in our wiki: [Logging Setup](https://jda.wiki/setup/logging/)

## Documentation

Docs can be found on the [Jenkins][jenkins] or directly [here](https://ci.dv8tion.net/job/JDA5/javadoc/)
<br>A simple Wiki can also be found at [jda.wiki](https://jda.wiki/)

### Annotations

We use a number of annotations to indicate future plans for implemented functionality such as new features of
the Discord API.

- [Incubating](https://github.com/DV8FromTheWorld/JDA/blob/master/src/main/java/net/dv8tion/jda/annotations/Incubating.java)
    <br>This annotation is used to indicate that functionality may change in the future. Often used when a new feature is added.
- [ReplaceWith](https://github.com/DV8FromTheWorld/JDA/blob/master/src/main/java/net/dv8tion/jda/annotations/ReplaceWith.java)
    <br>Paired with `@Deprecated` this is used to inform you how the new code-fragment is supposed to look once the hereby annotated functionality is removed.
- [ForRemoval](https://github.com/DV8FromTheWorld/JDA/blob/master/src/main/java/net/dv8tion/jda/annotations/ForRemoval.java)
    <br>Paired with `@Deprecated` this indicates that we plan to entirely remove the hereby annotated functionality in the future.
- [DeprecatedSince](https://github.com/DV8FromTheWorld/JDA/blob/master/src/main/java/net/dv8tion/jda/annotations/DeprecatedSince.java)
    <br>Paired with `@Deprecated` this specifies when a feature was marked as deprecated.

[Sources](https://github.com/DV8FromTheWorld/JDA/tree/master/src/main/java/net/dv8tion/jda/annotations)

## Getting Help

For general troubleshooting you can visit our wiki [Troubleshooting][troubleshooting] and [FAQ][faq].
<br>If you need help, or just want to talk with the JDA or other Devs, you can join the [Official JDA Discord Guild][discord-invite].

Alternatively you can also join the [Unofficial Discord API Guild](https://discord.gg/discord-api).
Once you joined, you can find JDA-specific help in the `#java_jda` channel.

For guides and setup help you can also take a look at the [wiki](https://jda.wiki/)
<br>Especially interesting are the [Getting Started](https://jda.wiki/introduction/jda/)
and [Setup](https://jda.wiki/setup/intellij/) Pages.

## Third Party Recommendations

### [LavaPlayer](https://github.com/sedmelluq/lavaplayer)

Created and maintained by [sedmelluq](https://github.com/sedmelluq)
<br>LavaPlayer is the most popular library used by Music Bots created in Java.
It is highly compatible with JDA and Discord4J and allows to play audio from
Youtube, Soundcloud, Twitch, Bandcamp and [more providers](https://github.com/sedmelluq/lavaplayer#supported-formats).
<br>The library can easily be expanded to more services by implementing your own AudioSourceManager and registering it.

It is recommended to read the [Usage](https://github.com/sedmelluq/lavaplayer#usage) section of LavaPlayer
to understand a proper implementation.
<br>Sedmelluq provided a demo in his repository which presents an example implementation for JDA:
https://github.com/sedmelluq/lavaplayer/tree/master/demo-jda

### [Lavalink](https://github.com/freyacodes/Lavalink)

Maintained by [Freya Arbjerg](https://github.com/freyacodes).

Lavalink is a popular standalone audio sending node based on Lavaplayer. Lavalink was built with scalability in mind,
and allows streaming music via many servers. It supports most of Lavaplayer's features.

Lavalink is used by many large bots, as well as bot developers who can not use a Java library like Lavaplayer.
If you plan on serving music on a smaller scale with JDA it is often preferable to just use Lavaplayer directly
as it is easier.

[Lavalink-Client](https://github.com/FredBoat/Lavalink-Client) is the official Lavalink client for JDA.


### [jda-nas](https://github.com/sedmelluq/jda-nas)

Created and maintained by [sedmelluq](https://github.com/sedmelluq)
<br>Provides a native implementation for the JDA Audio Send-System to avoid GC pauses.

Note that this send system creates an extra UDP-Client which causes audio receive to no longer function properly
since discord identifies the sending UDP-Client as the receiver.

```java
JDABuilder builder = JDABuilder.createDefault(BOT_TOKEN)
    .setAudioSendFactory(new NativeAudioSendFactory());
```

### [jda-ktx](https://github.com/MinnDevelopment/jda-ktx)

Created and maintained by [MinnDevelopment](https://github.com/MinnDevelopment).
<br>Provides [Kotlin](https://kotlinlang.org/) extensions for **RestAction** and events that provide a more idiomatic Kotlin experience.

```kotlin
fun main() {
    val jda = light(BOT_TOKEN)
    
    jda.onCommand(""ping"") { event ->
        val time = measureTime {
            event.reply(""Pong!"").await() // suspending
        }.inWholeMilliseconds

        event.hook.editOriginal(""Pong: $time ms"").queue()
    }
}
```

There is a number of examples available in the [README](https://github.com/MinnDevelopment/jda-ktx/#jda-ktx).

------

More can be found in our github organization: [JDA-Applications](https://github.com/JDA-Applications)

## Contributing to JDA

If you want to contribute to JDA, make sure to base your branch off of our **development** branch (or a feature-branch)
and create your PR into that **same** branch. **We will be rejecting any PRs between branches or into release branches!**
It is very possible that your change might already be in development or you missed something.

More information can be found at the wiki page [Contributing](https://github.com/DV8FromTheWorld/JDA/wiki/5\)-Contributing)

### Deprecation Policy

When a feature is introduced to replace or enhance existing functionality we might deprecate old functionality.

A deprecated method/class usually has a replacement mentioned in its documentation which should be switched to. Deprecated
functionality might or might not exist in the next minor release. (Hint: The minor version is the `MM` of `XX.MM.RR` in our version format)

It is possible that some features are deprecated without replacement, in this case the functionality is no longer supported by either the JDA structure
due to fundamental changes (for example automation of a feature) or due to Discord API changes that cause it to be removed.

We highly recommend discontinuing usage of deprecated functionality and update by going through each minor release instead of jumping.
For instance, when updating from version 3.3.0 to version 3.5.1 you should do the following:

- Update to `3.4.RR` and check for deprecation, replace
- Update to `3.5.1` and check for deprecation, replace

The `RR` in version `3.4.RR` should be replaced by the latest version that was published for `3.4`, you can find out which the latest
version was by looking at the [release page](https://github.com/DV8FromTheWorld/JDA/releases)

## Dependencies:

This project requires **Java 8+**.<br>
All dependencies are managed automatically by Gradle.
 * NV Websocket Client
   * Version: **2.14**
   * [Github](https://github.com/TakahikoKawasaki/nv-websocket-client)
 * OkHttp
   * Version: **4.10.0**
   * [Github](https://github.com/square/okhttp)
 * Apache Commons Collections4
   * Version: **4.4**
   * [Website](https://commons.apache.org/proper/commons-collections)
 * jackson
   * Version: **2.14.1**
   * [Github](https://github.com/FasterXML/jackson)
 * Trove4j
   * Version: **3.0.3**
   * [BitBucket](https://bitbucket.org/trove4j/trove)
 * slf4j-api
   * Version: **1.7.36**
   * [Website](https://www.slf4j.org/)
 * opus-java (optional)
   * Version: **1.1.1**
   * [GitHub](https://github.com/discord-java/opus-java)

## Related Projects

- [Discord4J](https://github.com/Discord4J/Discord4J)
- [Discord.NET](https://github.com/discord-net/Discord.Net)
- [discord.py](https://github.com/Rapptz/discord.py)
- [serenity](https://github.com/serenity-rs/serenity)

**See also:** [Discord API Community Libraries](https://github.com/apacheli/discord-api-libs)
","Discord is currently prohibiting creation and usage of client client accounts.
JDA strives to provide a clean and full wrapping of the Discord REST api and its
Websocket-Events for Java. We will no longer support unofficial features that
are not available to bot-accounts."
1677,✍🏻 这里是写博客的地方 —— Halfrost-Field 冰霜之地,"# Halfrost-Field 冰霜之地

<p align='center'>
<img src='contents/images/background-cover_.png'>
</p>

<p align='center'>
<img src=""https://img.shields.io/badge/Total%20Reading-3.18M-success"">
<img src=""https://img.shields.io/badge/Total%20Word%20Count-578129-success"">
<img src=""https://img.shields.io/badge/build-passing-brightgreen.svg"">
<img src=""https://img.shields.io/badge/platform-%20iOS | Android | Mac | Web%20-ff69b4.svg"">
<img src=""https://img.shields.io/badge/language-Objective--C-orange.svg"">
<img src=""https://img.shields.io/badge/language-Swift-abcdef.svg"">
<img src=""https://img.shields.io/badge/language-JavaScript-yellow.svg"">
<img src=""https://img.shields.io/badge/language-Golang-26C2F0.svg"">
<img src=""https://visitor-badge.laobi.icu/badge?page_id=halfrost.Halfrost-Field"" alt=""visitor badge""/>  
</p>

<p align='center'>
<a href=""https://github.com/halfrost/Halfrost-Field/blob/master/LICENSE""><img alt=""GitHub"" src=""https://img.shields.io/github/license/halfrost/Halfrost-Field?label=License""></a>
<a href=""https://halfrost.com""><img src=""https://img.shields.io/badge/Blog-Halfrost--Field-80d4f9.svg?style=flat""></a>
<a href=""http://weibo.com/halfrost""><img src=""https://img.shields.io/badge/weibo-@halfrost-f974ce.svg?style=flat&colorA=f4292e""></a>
<a href=""https://twitter.com/halffrost""><img src=""https://img.shields.io/badge/twitter-@halffrost-F8E81C.svg?style=flat&colorA=009df2""></a>
<a href=""https://www.zhihu.com/people/halfrost/activities""><img src=""https://img.shields.io/badge/%E7%9F%A5%E4%B9%8E-@halfrost-fd6f32.svg?style=flat&colorA=0083ea""></a>
<img src=""https://img.shields.io/badge/made%20with-=1-blue.svg"">
<a href=""https://github.com/halfrost/Halfrost-Field/pulls""><img src=""https://img.shields.io/badge/PR-Welcome-brightgreen.svg""></a>
</p>

## ⭐️ 为什么要建这个仓库

世人都说阅读开源框架的源代码对于功力有显著的提升，所以我也尝试阅读开源框架的源代码，并对其内容进行详细地分析和理解。在这里将自己阅读开源框架源代码的心得记录下来，希望能对各位开发者有所帮助。我会不断更新这个仓库中的文章，如果想要关注可以点 `star`。



## 📖 目录


# 🐳 Go

| Project | Version | Article |
|:-------:|:-------:|:------|
|Go|1.16 darwin/amd64| [Go 初学者的成长之路](https://github.com/halfrost/Halfrost-Field/blob/master/contents/Go/new_gopher_tips.md)<br>[初探 Go 的编译命令执行过程](https://github.com/halfrost/Halfrost-Field/blob/master/contents/Go/go_command.md)<br>[深入解析 Go Slice 底层实现](https://github.com/halfrost/Halfrost-Field/blob/master/contents/Go/go_slice.md)<br>[如何设计并实现一个线程安全的 Map ？(上篇)](https://github.com/halfrost/Halfrost-Field/blob/master/contents/Go/go_map_chapter_one.md)<br>[如何设计并实现一个线程安全的 Map ？(下篇)](https://github.com/halfrost/Halfrost-Field/blob/master/contents/Go/go_map_chapter_two.md)<br>[面试中 LRU / LFU 的青铜与王者](https://github.com/halfrost/Halfrost-Field/blob/master/contents/Go/LRU:LFU_interview.md)<br>[深入研究 Go interface 底层实现](https://github.com/halfrost/Halfrost-Field/blob/master/contents/Go/go_interface.md)<br>[Go reflection 三定律与最佳实践](https://github.com/halfrost/Halfrost-Field/blob/master/contents/Go/go_reflection.md)<br>[深入 Go 并发原语 — Channel 底层实现](https://github.com/halfrost/Halfrost-Field/blob/master/contents/Go/go_channel.md)<br>|
|空间搜索|golang/geo|[如何理解 n 维空间和 n 维时空](https://github.com/halfrost/Halfrost-Field/blob/master/contents/Go/n-dimensional_space_and_n-dimensional_space-time.md)<br>[高效的多维空间点索引算法 — Geohash 和 Google S2](https://github.com/halfrost/Halfrost-Field/blob/master/contents/Go/go_spatial_search.md)<br>[Google S2 中的 CellID 是如何生成的 ？](https://github.com/halfrost/Halfrost-Field/blob/master/contents/Go/go_s2_CellID.md)<br>[Google S2 中的四叉树求 LCA 最近公共祖先](https://github.com/halfrost/Halfrost-Field/blob/master/contents/Go/go_s2_lowest_common_ancestor.md)<br>[神奇的德布鲁因序列](https://github.com/halfrost/Halfrost-Field/blob/master/contents/Go/go_s2_De_Bruijn.md)<br>[四叉树上如何求希尔伯特曲线的邻居 ？](https://github.com/halfrost/Halfrost-Field/blob/master/contents/Go/go_s2_Hilbert_neighbor.md)<br>[Google S2 是如何解决空间覆盖最优解问题的?](https://github.com/halfrost/Halfrost-Field/blob/master/contents/Go/go_s2_regionCoverer.md)<br>-----------------------------------------------------------------------------<br> [Code \<T\> share keynote](https://github.com/halfrost/Halfrost-Field/blob/master/contents/Go/T_Salon_share.pdf)|


----------------------------

# 🍉 Machine Learning


| Project | Version | Article |
|:-------:|:-------:|:------|
|机器学习|Andrew Ng Stanford University|[目录](https://github.com/halfrost/Halfrost-Field/blob/master/contents/Machine_Learning/contents.md)<br>-----------------------------------------------------------------<br>[Week1 —— What is Machine Learning](https://github.com/halfrost/Halfrost-Field/blob/master/contents/Machine_Learning/What_is_Machine_Learning.md)<br>[Week1 —— Linear Regression with One Variable (Gradient Descent)](https://github.com/halfrost/Halfrost-Field/blob/master/contents/Machine_Learning/Gradient_descent.ipynb)<br>[Week2 —— Multivariate Linear Regression](https://github.com/halfrost/Halfrost-Field/blob/master/contents/Machine_Learning/Multivariate_Linear_Regression.ipynb) <br>[Week2 —— Computing Parameters Analytically](https://github.com/halfrost/Halfrost-Field/blob/master/contents/Machine_Learning/Computing_Parameters_Analytically.ipynb)<br>[Week2 —— Octave Matlab Tutorial](https://github.com/halfrost/Halfrost-Field/blob/master/contents/Machine_Learning/Octave_Matlab_Tutorial.ipynb)<br>[Week3 —— Logistic Regression](https://github.com/halfrost/Halfrost-Field/blob/master/contents/Machine_Learning/Logistic_Regression.ipynb)<br>[Week3 —— Regularization](https://github.com/halfrost/Halfrost-Field/blob/master/contents/Machine_Learning/Regularization.ipynb)<br>[Week4 —— Neural Networks Representation](https://github.com/halfrost/Halfrost-Field/blob/master/contents/Machine_Learning/Neural_Networks_Representation.ipynb)<br>[Week5 —— Neural Networks Learning](https://github.com/halfrost/Halfrost-Field/blob/master/contents/Machine_Learning/Neural_Networks_Learning.ipynb)<br>[Week5 —— Backpropagation in Practice](https://github.com/halfrost/Halfrost-Field/blob/master/contents/Machine_Learning/Backpropagation_in_Practice.ipynb)<br>[Week6 —— Advice for Applying Machine Learning](https://github.com/halfrost/Halfrost-Field/blob/master/contents/Machine_Learning/Advice_for_Applying_Machine_Learning.ipynb)<br>[Week6 —— Machine Learning System Design](https://github.com/halfrost/Halfrost-Field/blob/master/contents/Machine_Learning/Machine_Learning_System_Design.ipynb)<br>[Week7 —— Support Vector Machines](https://github.com/halfrost/Halfrost-Field/blob/master/contents/Machine_Learning/Support_Vector_Machines.ipynb)<br>[Week8 —— Unsupervised Learning](https://github.com/halfrost/Halfrost-Field/blob/master/contents/Machine_Learning/Unsupervised_Learning.ipynb)<br>[Week8 —— Dimensionality Reduction](https://github.com/halfrost/Halfrost-Field/blob/master/contents/Machine_Learning/Dimensionality_Reduction.ipynb)<br>[Week9 —— Anomaly Detection](https://github.com/halfrost/Halfrost-Field/blob/master/contents/Machine_Learning/Anomaly_Detection.ipynb)<br>[Week9 —— Recommender Systems](https://github.com/halfrost/Halfrost-Field/blob/master/contents/Machine_Learning/Recommender_Systems.ipynb)<br>[Week10 —— Large Scale Machine Learning](https://github.com/halfrost/Halfrost-Field/blob/master/contents/Machine_Learning/Large_Scale_Machine_Learning.ipynb)<br>[Week11 —— Application Example: Photo OCR](https://github.com/halfrost/Halfrost-Field/blob/master/contents/Machine_Learning/Application_Photo_OCR.ipynb)|

---------------------------

# 🚀 JavaScript

| Project | Version | Article |
|:-------:|:-------:|:------|
| JavaScript | ECMAScript 6 | [JavaScript 新手的踩坑日记](https://github.com/halfrost/Halfrost-Field/blob/master/contents/JavaScript/lost_in_javascript.md) <br> [从 JavaScript 作用域说开去](https://github.com/halfrost/Halfrost-Field/blob/master/contents/JavaScript/javascript_scope.md)<br> [揭开 this & that 之迷](https://github.com/halfrost/Halfrost-Field/blob/master/contents/JavaScript/%E6%8F%AD%E5%BC%80%20this%20%26%20that%20%E4%B9%8B%E8%BF%B7.md)<br>[JSConf China 2017 Day One — JavaScript Change The World](https://github.com/halfrost/Halfrost-Field/blob/master/contents/JavaScript/JSConf%20China%202017%20Day%20One%20%E2%80%94%20JavaScript%20Change%20The%20World.md) <br> [JSConf China 2017 Day Two — End And Beginning](https://github.com/halfrost/Halfrost-Field/blob/master/contents/JavaScript/jsconf_china_2017_final.md)|
| Vue.js | 2.3.4 | [Vue 全家桶 + Electron 开发的一个跨三端的应用](https://github.com/halfrost/vue-objccn/blob/master/README.md) <br> [大话大前端时代(一) —— Vue 与 iOS 的组件化](https://github.com/halfrost/Halfrost-Field/blob/master/contents/Vue/%E5%A4%A7%E8%AF%9D%E5%A4%A7%E5%89%8D%E7%AB%AF%E6%97%B6%E4%BB%A3(%E4%B8%80)%20%E2%80%94%E2%80%94%20Vue%20%E4%B8%8E%20iOS%20%E7%9A%84%E7%BB%84%E4%BB%B6%E5%8C%96.md) <br>|
| Ghost | 1.24.8 | [Ghost 博客搭建日记](https://github.com/halfrost/Halfrost-Field/blob/master/contents/iOS/Ghost/ghost_build.md)<br> [Ghost 博客升级指南](https://github.com/halfrost/Halfrost-Field/blob/master/contents/iOS/Ghost/ghost_update.md) <br>[Ghost 博客炫技""新""玩法](https://github.com/halfrost/Halfrost-Field/blob/master/contents/iOS/Ghost/ghost_feature.md) <br>[博客跑分优化](https://github.com/halfrost/Halfrost-Field/blob/master/contents/iOS/Ghost/ghost_fast.md)<br>--------------------------------------------------------------------------------<br>|

-------

# 📱 iOS



| Project | Version | Article |
|:-------:|:-------:|:------|
| Weex | 0.10.0 | [Weex 是如何在 iOS 客户端上跑起来的](https://github.com/halfrost/Halfrost-Field/blob/master/contents/iOS/Weex/Weex_how_to_work_in_iOS.md)<br> [由 FlexBox 算法强力驱动的 Weex 布局引擎](https://github.com/halfrost/Halfrost-Field/blob/master/contents/iOS/Weex/Weex_layout_engine_powered_by_Flexbox's_algorithm.md)<br> [Weex 事件传递的那些事儿](https://github.com/halfrost/Halfrost-Field/blob/master/contents/iOS/Weex/Weex_events.md) <br>[Weex 中别具匠心的 JS Framework](https://github.com/halfrost/Halfrost-Field/blob/master/contents/iOS/Weex/Weex_ingenuity_JS_framework.md)<br>[iOS 开发者的 Weex 伪最佳实践指北](https://github.com/halfrost/Halfrost-Field/blob/master/contents/iOS/Weex/Weex_pseudo-best_practices_for_iOS_developers.md)<br> |
| BeeHive | v1.2.0 | [BeeHive —— 一个优雅但还在完善中的解耦框架](https://github.com/halfrost/Halfrost-Field/blob/master/contents/iOS/beehive.md)<br>|
| 组件化 | 路由与解耦 | [iOS 组件化 —— 路由设计思路分析](https://github.com/halfrost/Halfrost-Field/blob/master/contents/iOS/iOSRouter/iOS_Router.md)<br>|
| ReactiveObjC | 2.1.2 |[函数响应式编程 (FRP) 从入门到 ""放弃""—— 基础概念篇](https://github.com/halfrost/Halfrost-Field/blob/master/contents/iOS/RAC/functional_reactive_programming_concept.md) <br> [函数响应式编程 (FRP) 从入门到 ""放弃""—— 图解 RACSignal 篇](https://github.com/halfrost/Halfrost-Field/blob/master/contents/iOS/RAC/ios_rac_racsignal.md) <br> [ReactiveCocoa 中 RACSignal 是如何发送信号的](https://github.com/halfrost/Halfrost-Field/blob/master/contents/iOS/RAC/reactivecocoa_racsignal.md) <br> [ReactiveCocoa 中 RACSignal 所有变换操作底层实现分析(上)](https://github.com/halfrost/Halfrost-Field/blob/master/contents/iOS/RAC/reactivecocoa_racsignal_operations1.md)<br>[ReactiveCocoa 中 RACSignal 所有变换操作底层实现分析(中)](https://github.com/halfrost/Halfrost-Field/blob/master/contents/iOS/RAC/reactivecocoa_racsignal_operations2.md) <br> [ReactiveCocoa 中 RACSignal 所有变换操作底层实现分析(下)](https://github.com/halfrost/Halfrost-Field/blob/master/contents/iOS/RAC/reactivecocoa_racsignal_operations3.md) <br> [ReactiveCocoa 中 RACSignal 冷信号和热信号底层实现分析](https://github.com/halfrost/Halfrost-Field/blob/master/contents/iOS/RAC/reactivecocoa_hot_cold_signal.md)<br> [ReactiveCocoa 中 集合类 RACSequence 和 RACTuple 底层实现分析](https://github.com/halfrost/Halfrost-Field/blob/master/contents/iOS/RAC/reactivecocoa_racsequence_ractuple.md) <br> [ReactiveCocoa 中 RACScheduler 是如何封装 GCD 的](https://github.com/halfrost/Halfrost-Field/blob/master/contents/iOS/RAC/reactivecocoa_racscheduler.md) <br> [ReactiveCocoa 中 RACCommand 底层实现分析](https://github.com/halfrost/Halfrost-Field/blob/master/contents/iOS/RAC/reactivecocoa_raccommand.md)<br> [ReactiveCocoa 中 奇妙无比的“宏”魔法](https://github.com/halfrost/Halfrost-Field/blob/master/contents/iOS/RAC/reactivecocoa_macro.md)|
| Aspect |  | [iOS 如何实现Aspect Oriented Programming (上)](https://github.com/halfrost/Halfrost-Field/blob/master/contents/iOS/Aspect/ios_aspect.md)<br>[iOS 如何实现Aspect Oriented Programming (下)](https://github.com/halfrost/Halfrost-Field/blob/master/contents/iOS/Aspect/ios_aspect.md)<br> |
| ObjC | objc runtime 680 |  [神经病院 Objective-C Runtime 入院第一天—— isa 和 Class](https://github.com/halfrost/Halfrost-Field/blob/master/contents/iOS/ObjC/objc_runtime_isa_class.md)<br>[神经病院 Objective-C Runtime 住院第二天——消息发送与转发](https://github.com/halfrost/Halfrost-Field/blob/master/contents/iOS/ObjC/objc_runtime_objc_msgsend.md) <br>[神经病院 Objective-C Runtime 出院第三天——如何正确使用 Runtime](https://github.com/halfrost/Halfrost-Field/blob/master/contents/iOS/ObjC/how_to_use_runtime.md) <br> [ObjC 对象的今生今世](https://github.com/halfrost/Halfrost-Field/blob/master/contents/iOS/ObjC/objc_life.md)<br>|
| iOS Block |  | [深入研究 Block 捕获外部变量和 __block 实现原理](https://github.com/halfrost/Halfrost-Field/blob/master/contents/iOS/Block/ios_block.md) <br> [深入研究 Block 用 weakSelf、strongSelf、@weakify、@strongify 解决循环引用](https://github.com/halfrost/Halfrost-Field/blob/master/contents/iOS/Block/ios_block_retain_circle.md)<br> |
| iOS Simulator |  | [给iOS 模拟器“安装”app文件](https://github.com/halfrost/Halfrost-Field/blob/master/contents/iOS/ios_simulator_ios_sim.md) <br> [Remote debugging on iOS with Safari Web Inspector](https://github.com/halfrost/Halfrost-Field/blob/master/contents/iOS/remote_debugging_on_ios_with_safari_web_inspector.md) |
| xcconfig |  | [手把手教你给一个 iOS app 配置多个环境变量](https://github.com/halfrost/Halfrost-Field/blob/master/contents/iOS/ios_multienvironments.md) <br>  |
| Jenkins | Weekly Release 2.15 | [手把手教你利用 Jenkins 持续集成 iOS 项目](https://github.com/halfrost/Halfrost-Field/blob/master/contents/iOS/ios_jenkins.md) <br>  |
| StoryBoard |  | [关于 IB_DESIGNABLE / IBInspectable 的那些需要注意的事](https://github.com/halfrost/Halfrost-Field/blob/master/contents/iOS/ios_ib_designable_ibinspectable.md) <br>  |
| WWDC 2016 |  | [WWDC2016 Session 笔记 - Xcode 8 Auto Layout 新特性](https://github.com/halfrost/Halfrost-Field/blob/master/contents/iOS/WWDC%202016/WWDC_2016_iOS10_Xcode8_AutoLayout.md) <br>[WWDC2016 Session 笔记 - iOS 10 UICollectionView 新特性](https://github.com/halfrost/Halfrost-Field/blob/master/contents/iOS/WWDC%202016/WWDC_2016_iOS10_UICollectionView.md) <br>[WWDC2016 Session 笔记 - iOS 10  推送 Notification 新特性](https://github.com/halfrost/Halfrost-Field/blob/master/contents/iOS/WWDC%202016/WWDC_2016_iOS10_Notification.md) <br>  |
| Jekyll |  | [如何快速给自己构建一个温馨的""家""——用 Jekyll 搭建静态博客](https://github.com/halfrost/Halfrost-Field/blob/master/contents/iOS/Jekyll/Jekyll.md) <br>|
| Swift | 2.2 | [iOS如何优雅的处理“回调地狱Callback hell”(二)——使用Swift](https://github.com/halfrost/Halfrost-Field/blob/master/contents/iOS/Swift/iOS_Callback_Hell_Swift.md) <br>  |
| PromiseKit |  | [iOS如何优雅的处理“回调地狱Callback hell”(一)——使用PromiseKit](https://github.com/halfrost/Halfrost-Field/blob/master/contents/iOS/PromiseKit/iOS_Callback_Hell_PromiseKit.md) <br>  |
| WebSocket |  | [微信,QQ 这类 IM app 怎么做——谈谈 Websocket](https://github.com/halfrost/Halfrost-Field/blob/master/contents/iOS/WebSocket/iOS_WebSocket.md) <br>|
| Realm |  | [Realm 数据库 从入门到“放弃”](https://github.com/halfrost/Halfrost-Field/blob/master/contents/iOS/Realm/Realm%E6%95%B0%E6%8D%AE%E5%BA%93%20%E4%BB%8E%E5%85%A5%E9%97%A8%E5%88%B0%E2%80%9C%E6%94%BE%E5%BC%83%E2%80%9D.md) <br>[手把手教你从 Core Data 迁移到 Realm](https://github.com/halfrost/Halfrost-Field/blob/master/contents/iOS/Realm/%E6%89%8B%E6%8A%8A%E6%89%8B%E6%95%99%E4%BD%A0%E4%BB%8ECore%20Data%E8%BF%81%E7%A7%BB%E5%88%B0Realm.md) <br> |
| Core Data |  | [iOS Core Data 数据迁移 指南](https://github.com/halfrost/Halfrost-Field/blob/master/contents/iOS/CoreData/iOS_Core_Data.md) <br> |
| Cordova |  | [iOS Hybrid 框架 ——PhoneGap](https://github.com/halfrost/Halfrost-Field/blob/master/contents/iOS/Cordova/iOS%20Hybrid%20%E6%A1%86%E6%9E%B6%20%E2%80%94%E2%80%94PhoneGap.md)<br> [Remote debugging on iOS with Safari Web Inspector](https://github.com/halfrost/Halfrost-Field/blob/master/contents/iOS/Cordova/Remote_debug.md) <br>|
| Animation |  | [iOS app 旧貌换新颜(一) — Launch Page 让 Logo ""飞""出屏幕](https://github.com/halfrost/Halfrost-Field/blob/master/contents/iOS/Launchpage/iOS_launchpage_logo_fly.md) <br> |
| Interview |  | [iOS 面试总结](https://github.com/halfrost/Halfrost-Field/blob/master/contents/iOS/ios_interview.md) <br> |
| Phabricator |  | [搭建Phabricator我遇到的那些坑](https://github.com/halfrost/Halfrost-Field/blob/master/contents/iOS/Phabricator/%E6%90%AD%E5%BB%BAPhabricator%E6%88%91%E9%81%87%E5%88%B0%E7%9A%84%E9%82%A3%E4%BA%9B%E5%9D%91.md)<br> [Code review - Phabricator Use guide introduce](https://github.com/halfrost/Halfrost-Field/blob/master/contents/iOS/Phabricator/Code%20review%20-%20Phabricator%20Use%20guide%20introduce.md)<br>-----------------------------------------------------------------------<br>|

----------------------------




# 📝 Protocol

| Project | Version | Article |
|:-------:|:-------:|:------|
|HTTP|1.1|[HTTP 基础概述](https://github.com/halfrost/Halfrost-Field/blob/master/contents/Protocol/HTTP.md)<br>|
|HTTP|2|[[RFC 7540] Hypertext Transfer Protocol Version 2 (HTTP/2)](https://github.com/halfrost/Halfrost-Field/blob/master/contents/Protocol/HTTP:2_RFC7540.md)<br>[解开 HTTP/2 的面纱：HTTP/2 是如何建立连接的](https://github.com/halfrost/Halfrost-Field/blob/master/contents/Protocol/HTTP:2-begin.md)<br>[HTTP/2 中的 HTTP 帧和流的多路复用](https://github.com/halfrost/Halfrost-Field/blob/master/contents/Protocol/HTTP:2-HTTP-Frames.md)<br>[HTTP/2 中的帧定义](https://github.com/halfrost/Halfrost-Field/blob/master/contents/Protocol/HTTP:2-HTTP-Frames-Definitions.md)<br>[HTTP/2 中的 HTTP 语义](https://github.com/halfrost/Halfrost-Field/blob/master/contents/Protocol/HTTP:2-HTTP-Semantics.md)<br>[HTTP/2 中的注意事项](https://github.com/halfrost/Halfrost-Field/blob/master/contents/Protocol/HTTP:2-Considerations.md)<br>[HTTP/2 中的常见问题](https://github.com/halfrost/Halfrost-Field/blob/master/contents/Protocol/HTTP:2-Frequently-Asked-Questions.md)<br>[[RFC 7541] HPACK: Header Compression for HTTP/2](https://github.com/halfrost/Halfrost-Field/blob/master/contents/Protocol/HTTP:2_RFC7541.md)<br>[详解 HTTP/2 头压缩算法 —— HPACK](https://github.com/halfrost/Halfrost-Field/blob/master/contents/Protocol/HTTP:2_Header-Compression.md)<br>[HTTP/2 HPACK 实际应用举例](https://github.com/halfrost/Halfrost-Field/blob/master/contents/Protocol/HTTP:2_HPACK-Example.md)<br>[[RFC 7301] TLS Application-Layer Protocol Negotiation Extension](https://github.com/halfrost/Halfrost-Field/blob/master/contents/Protocol/TLS_ALPN.md)|
|WebSocket|Version 13|[全双工通信的 WebSocket](https://github.com/halfrost/Halfrost-Field/blob/master/contents/Protocol/WebSocket.md)<br>|
|Protocol-buffers|proto3|[高效的数据压缩编码方式 Protobuf](https://github.com/halfrost/Halfrost-Field/blob/master/contents/Protocol/Protocol-buffers-encode.md)<br>[高效的序列化/反序列化数据方式 Protobuf](https://github.com/halfrost/Halfrost-Field/blob/master/contents/Protocol/Protocol-buffers-decode.md)|
| FlatBuffers |1.9.0|[深入浅出 FlatBuffers 之 Schema](https://github.com/halfrost/Halfrost-Field/blob/master/contents/Protocol/FlatBuffers-schema.md)<br>[深入浅出 FlatBuffers 之 Encode](https://github.com/halfrost/Halfrost-Field/blob/master/contents/Protocol/FlatBuffers-encode.md)<br>[深入浅出 FlatBuffers 之 FlexBuffers](https://github.com/halfrost/Halfrost-Field/blob/master/contents/Protocol/FlatBuffers-flexBuffers.md)|
|TCP||[TCP/IP 基础概述](https://github.com/halfrost/Halfrost-Field/blob/master/contents/Protocol/TCP:IP.md)<br>[Advance\_TCP](https://github.com/halfrost/Halfrost-Field/blob/master/contents/Protocol/Advance_TCP.md)|
|TLS|Cryptography<br>|[密码学概述](https://github.com/halfrost/Halfrost-Field/blob/master/contents/Protocol/HTTPS-cryptography-overview.md)<br>[漫游对称加密算法](https://github.com/halfrost/Halfrost-Field/blob/master/contents/Protocol/HTTPS-symmetric-encryption.md)<br>[翱游公钥密码算法](https://github.com/halfrost/Halfrost-Field/blob/master/contents/Protocol/HTTPS-asymmetric-encryption.md)<br>[消息的“指纹”是什么？](https://github.com/halfrost/Halfrost-Field/blob/master/contents/Protocol/HTTPS-one-way-hash.md)<br>[消息认证码是怎么一回事？](https://github.com/halfrost/Halfrost-Field/blob/master/contents/Protocol/HTTPS-message-authentication-code.md)<br>[无处不在的数字签名](https://github.com/halfrost/Halfrost-Field/blob/master/contents/Protocol/HTTPS-digital-signature.md)<br>[随处可见的公钥证书](https://github.com/halfrost/Halfrost-Field/blob/master/contents/Protocol/HTTPS-digital-certificate.md)<br>[秘密的实质——密钥](https://github.com/halfrost/Halfrost-Field/blob/master/contents/Protocol/HTTPS-cipherkey.md)<br>[无法预测的根源——随机数](https://github.com/halfrost/Halfrost-Field/blob/master/contents/Protocol/HTTPS-random-number.md)
|TLS|TLS 1.3<br>|[如何部署 TLS 1.3 ？](https://github.com/halfrost/Halfrost-Field/blob/master/contents/Protocol/TLS1.3_start.md)<br>[[RFC 6520] TLS & DTLS Heartbeat Extension](https://github.com/halfrost/Halfrost-Field/blob/master/contents/Protocol/TLS_Heartbeat.md)<br>[[RFC 8446] The Transport Layer Security (TLS) Protocol Version 1.3](https://github.com/halfrost/Halfrost-Field/blob/master/contents/Protocol/TLS_1.3_RFC8446.md)<br>[TLS 1.3 Introduction](https://github.com/halfrost/Halfrost-Field/blob/master/contents/Protocol/TLS_1.3_Introduction.md)<br>[TLS 1.3 Handshake Protocol](https://github.com/halfrost/Halfrost-Field/blob/master/contents/Protocol/TLS_1.3_Handshake_Protocol.md)<br>[TLS 1.3 Record Protocol](https://github.com/halfrost/Halfrost-Field/blob/master/contents/Protocol/TLS_1.3_Record_Protocol.md)<br>[TLS 1.3 Alert Protocol](https://github.com/halfrost/Halfrost-Field/blob/master/contents/Protocol/TLS_1.3_Alert_Protocol.md)<br>[TLS 1.3 Cryptographic Computations](https://github.com/halfrost/Halfrost-Field/blob/master/contents/Protocol/TLS_1.3_Cryptographic_Computations.md)<br>[TLS 1.3 0-RTT and Anti-Replay](https://github.com/halfrost/Halfrost-Field/blob/master/contents/Protocol/TLS_1.3_0-RTT.md)<br>[TLS 1.3 Compliance Requirements](https://github.com/halfrost/Halfrost-Field/blob/master/contents/Protocol/TLS_1.3_Compliance_Requirements.md)<br>[TLS 1.3 Implementation Notes](https://github.com/halfrost/Halfrost-Field/blob/master/contents/Protocol/TLS_1.3_Implementation_Notes.md)<br>[TLS 1.3 Backward Compatibility](https://github.com/halfrost/Halfrost-Field/blob/master/contents/Protocol/TLS_1.3_Backward_Compatibility.md)<br>[TLS 1.3 Overview of Security Properties](https://github.com/halfrost/Halfrost-Field/blob/master/contents/Protocol/TLS_1.3_Security_Properties.md)|
|HTTPS|TLS 1.2/TLS 1.3|[HTTPS 温故知新（一） —— 开篇](https://github.com/halfrost/Halfrost-Field/blob/master/contents/Protocol/HTTPS-begin.md)<br>[HTTPS 温故知新（二） —— TLS 记录层协议](https://github.com/halfrost/Halfrost-Field/blob/master/contents/Protocol/HTTPS-record-layer.md)<br>[HTTPS 温故知新（三） —— 直观感受 TLS 握手流程(上)](https://github.com/halfrost/Halfrost-Field/blob/master/contents/Protocol/HTTPS-TLS1.2_handshake.md)<br>[HTTPS 温故知新（四） —— 直观感受 TLS 握手流程(下)](https://github.com/halfrost/Halfrost-Field/blob/master/contents/Protocol/HTTPS-TLS1.3_handshake.md)<br>[HTTPS 温故知新（五） —— TLS 中的密钥计算](https://github.com/halfrost/Halfrost-Field/blob/master/contents/Protocol/HTTPS-key-cipher.md)<br>[HTTPS 温故知新（六） —— TLS 中的 Extensions](https://github.com/halfrost/Halfrost-Field/blob/master/contents/Protocol/HTTPS-extensions.md)<br>|
|QUIC|v44|[如何部署 QUIC ？](https://github.com/halfrost/Halfrost-Field/blob/master/contents/Protocol/QUIC_start.md)<br>------------------------------------------------------------------------<br>|


----------------------------


# ❄️ 星霜荏苒


| Project | Version | Article |
|:-------:|:-------:|:------|
| 开篇 |  | [开篇](https://github.com/halfrost/Halfrost-Field/blob/master/contents/TimeElapse/start.md)|
| 2017 |  |[【星霜荏苒】 - 程序员如何在技术浪潮的更迭中保持较高的成长速度 ？](https://github.com/halfrost/Halfrost-Field/blob/master/contents/TimeElapse/2017.md)|
| 2018 |  |[【星霜荏苒】 - 如何看待软件开发 ？](https://github.com/halfrost/Halfrost-Field/blob/master/contents/TimeElapse/2018.md)|
| 2019 |  |[【星霜荏苒】 - 不甘当学渣，努力作学霸，最终是学民](https://github.com/halfrost/Halfrost-Field/blob/master/contents/TimeElapse/2019.md)|
| 2020 |  |[【星霜荏苒】 - 下一个五年计划起航 ！](https://github.com/halfrost/Halfrost-Field/blob/master/contents/TimeElapse/2020.md)|
| 2021 |  |[后疫情时代下美国留学 CS Master 申请纪实](https://github.com/halfrost/Halfrost-Field/blob/master/contents/TimeElapse/2021.md)<br>-----------------------------------------------------------------------------------------<br>|


## ❗️ 勘误

+ 如果在文章中发现了问题，欢迎提交 PR 或者 issue，欢迎大神们多多指点🙏🙏🙏


## ♥️ 感谢

感谢Star！

[![Stargazers over time](https://starchart.cc/halfrost/Halfrost-Field.svg)](https://starchart.cc/halfrost/Halfrost-Field)

## 🌈 公众号

![](./contents/images/wechat-qr-code.png)

## ©️ 转载

<a rel=""license"" href=""http://creativecommons.org/licenses/by/4.0/""><img alt=""知识共享许可协议"" style=""border-width:0"" src=""https://i.creativecommons.org/l/by/4.0/88x31.png"" /></a><br />本<span xmlns:dct=""http://purl.org/dc/terms/"" href=""http://purl.org/dc/dcmitype/Text"" rel=""dct:type"">作品</span>由 <a xmlns:cc=""http://creativecommons.org/ns#"" href=""https://github.com/halfrost/Halfrost-Field"" property=""cc:attributionName"" rel=""cc:attributionURL"">halfrost</a> 创作，采用<a rel=""license"" href=""http://creativecommons.org/licenses/by/4.0/"">知识共享署名 4.0 国际许可协议</a>进行许可。","Summarize: # Halfrost-Field is a badge for iOS, Android, Mac, and Web users. The
badge can be downloaded from GitHub or downloaded from the Halfrost website. It
can also be downloaded as an app from the App Store."
1048,"aka ""Bayesian Methods for Hackers"": An introduction to Bayesian methods + probabilistic programming with a computation/understanding-first, mathematics-second point of view. All in pure Python ;)  ","# [Bayesian Methods for Hackers](http://camdavidsonpilon.github.io/Probabilistic-Programming-and-Bayesian-Methods-for-Hackers/)
#### *Using Python and PyMC*


The Bayesian method is the natural approach to inference, yet it is hidden from readers behind chapters of slow, mathematical analysis. The typical text on Bayesian inference involves two to three chapters on probability theory, then enters what Bayesian inference is. Unfortunately, due to mathematical intractability of most Bayesian models, the reader is only shown simple, artificial examples. This can leave the user with a *so-what* feeling about Bayesian inference. In fact, this was the author's own prior opinion.

After some recent success of Bayesian methods in machine-learning competitions, I decided to investigate the subject again. Even with my mathematical background, it took me three straight-days of reading examples and trying to put the pieces together to understand the methods. There was simply not enough literature bridging theory to practice. The problem with my misunderstanding was the disconnect between Bayesian mathematics and probabilistic programming. That being said, I suffered then so the reader would not have to now. This book attempts to bridge the gap.

If Bayesian inference is the destination, then mathematical analysis is a particular path towards it. On the other hand, computing power is cheap enough that we can afford to take an alternate route via probabilistic programming. The latter path is much more useful, as it denies the necessity of mathematical intervention at each step, that is, we remove often-intractable mathematical analysis as a prerequisite to Bayesian inference. Simply put, this latter computational path proceeds via small intermediate jumps from beginning to end, where as the first path proceeds by enormous leaps, often landing far away from our target. Furthermore, without a strong mathematical background, the analysis required by the first path cannot even take place.

*Bayesian Methods for Hackers* is designed as an introduction to Bayesian inference from a computational/understanding-first, and mathematics-second, point of view. Of course as an introductory book, we can only leave it at that: an introductory book. For the mathematically trained, they may cure the curiosity this text generates with other texts designed with mathematical analysis in mind. For the enthusiast with less mathematical background, or one who is not interested in the mathematics but simply the practice of Bayesian methods, this text should be sufficient and entertaining.

The choice of PyMC as the probabilistic programming language is two-fold. As of this writing, there is currently no central resource for examples and explanations in the PyMC universe. The official documentation assumes prior knowledge of Bayesian inference and probabilistic programming. We hope this book encourages users at every level to look at PyMC. Secondly, with recent core developments and popularity of the scientific stack in Python, PyMC is likely to become a core component soon enough.

PyMC does have dependencies to run, namely NumPy and (optionally) SciPy. To not limit the user, the examples in this book will rely only on PyMC, NumPy, SciPy and Matplotlib.


Printed Version by Addison-Wesley
------
<div style=""float: right; margin-left: 30px;""><img title=""Bayesian Methods for Hackersg""style=""float: right;margin-left: 30px;"" src=""http://www-fp.pearsonhighered.com/assets/hip/images/bigcovers/0133902838.jpg"" align=right height = 200 /></div>

**Bayesian Methods for Hackers is now available as a printed book!** You can pick up a copy on [Amazon](http://www.amazon.com/Bayesian-Methods-Hackers-Probabilistic-Addison-Wesley/dp/0133902838). What are the differences between the online version and the printed version?

 - Additional Chapter on Bayesian A/B testing
 - Updated examples
 - Answers to the end of chapter questions
 - Additional explanation, and rewritten sections to aid the reader. 


Contents
------

See the project homepage [here](http://camdavidsonpilon.github.io/Probabilistic-Programming-and-Bayesian-Methods-for-Hackers/) for examples, too.


The below chapters are rendered via the *nbviewer* at
[nbviewer.jupyter.org/](http://nbviewer.jupyter.org/), and is read-only and rendered in real-time.
Interactive notebooks + examples can be downloaded by cloning! 

### PyMC2

* [**Prologue:**](http://nbviewer.jupyter.org/urls/raw.github.com/CamDavidsonPilon/Probabilistic-Programming-and-Bayesian-Methods-for-Hackers/master/Prologue/Prologue.ipynb) Why we do it.

* [**Chapter 1: Introduction to Bayesian Methods**](http://nbviewer.jupyter.org/urls/raw.github.com/CamDavidsonPilon/Probabilistic-Programming-and-Bayesian-Methods-for-Hackers/master/Chapter1_Introduction/Ch1_Introduction_PyMC2.ipynb)
    Introduction to the philosophy and practice of Bayesian methods and answering the question, ""What is probabilistic programming?"" Examples include:
    - Inferring human behaviour changes from text message rates
    
* [**Chapter 2: A little more on PyMC**](http://nbviewer.jupyter.org/urls/raw.github.com/CamDavidsonPilon/Probabilistic-Programming-and-Bayesian-Methods-for-Hackers/master/Chapter2_MorePyMC/Ch2_MorePyMC_PyMC2.ipynb)
    We explore modeling Bayesian problems using Python's PyMC library through examples. How do we create Bayesian models? Examples include:
    - Detecting the frequency of cheating students, while avoiding liars
    - Calculating probabilities of the Challenger space-shuttle disaster
    
* [**Chapter 3: Opening the Black Box of MCMC**](http://nbviewer.jupyter.org/urls/raw.github.com/CamDavidsonPilon/Probabilistic-Programming-and-Bayesian-Methods-for-Hackers/master/Chapter3_MCMC/Ch3_IntroMCMC_PyMC2.ipynb)
    We discuss how MCMC operates and diagnostic tools. Examples include:
    - Bayesian clustering with mixture models
    
* [**Chapter 4: The Greatest Theorem Never Told**](http://nbviewer.jupyter.org/urls/raw.github.com/CamDavidsonPilon/Probabilistic-Programming-and-Bayesian-Methods-for-Hackers/master/Chapter4_TheGreatestTheoremNeverTold/Ch4_LawOfLargeNumbers_PyMC2.ipynb)
    We explore an incredibly useful, and dangerous, theorem: The Law of Large Numbers. Examples include:
    - Exploring a Kaggle dataset and the pitfalls of naive analysis
    - How to sort Reddit comments from best to worst (not as easy as you think)
    
* [**Chapter 5: Would you rather lose an arm or a leg?**](http://nbviewer.jupyter.org/urls/raw.github.com/CamDavidsonPilon/Probabilistic-Programming-and-Bayesian-Methods-for-Hackers/master/Chapter5_LossFunctions/Ch5_LossFunctions_PyMC2.ipynb)
    The introduction of loss functions and their (awesome) use in Bayesian methods.  Examples include:
    - Solving the *Price is Right*'s Showdown
    - Optimizing financial predictions
    - Winning solution to the Kaggle Dark World's competition
    
* [**Chapter 6: Getting our *prior*-ities straight**](http://nbviewer.jupyter.org/urls/raw.github.com/CamDavidsonPilon/Probabilistic-Programming-and-Bayesian-Methods-for-Hackers/master/Chapter6_Priorities/Ch6_Priors_PyMC2.ipynb)
    Probably the most important chapter. We draw on expert opinions to answer questions. Examples include:
    - Multi-Armed Bandits and the Bayesian Bandit solution.
    - What is the relationship between data sample size and prior?
    - Estimating financial unknowns using expert priors
    
    We explore useful tips to be objective in analysis as well as common pitfalls of priors. 

### PyMC3

* [**Prologue:**](http://nbviewer.jupyter.org/urls/raw.github.com/CamDavidsonPilon/Probabilistic-Programming-and-Bayesian-Methods-for-Hackers/master/Prologue/Prologue.ipynb) Why we do it.

* [**Chapter 1: Introduction to Bayesian Methods**](http://nbviewer.jupyter.org/urls/raw.github.com/CamDavidsonPilon/Probabilistic-Programming-and-Bayesian-Methods-for-Hackers/master/Chapter1_Introduction/Ch1_Introduction_PyMC3.ipynb)
    Introduction to the philosophy and practice of Bayesian methods and answering the question, ""What is probabilistic programming?"" Examples include:
    - Inferring human behaviour changes from text message rates
    
* [**Chapter 2: A little more on PyMC**](http://nbviewer.jupyter.org/urls/raw.github.com/CamDavidsonPilon/Probabilistic-Programming-and-Bayesian-Methods-for-Hackers/master/Chapter2_MorePyMC/Ch2_MorePyMC_PyMC3.ipynb)
    We explore modeling Bayesian problems using Python's PyMC library through examples. How do we create Bayesian models? Examples include:
    - Detecting the frequency of cheating students, while avoiding liars
    - Calculating probabilities of the Challenger space-shuttle disaster
    
* [**Chapter 3: Opening the Black Box of MCMC**](http://nbviewer.jupyter.org/urls/raw.github.com/CamDavidsonPilon/Probabilistic-Programming-and-Bayesian-Methods-for-Hackers/master/Chapter3_MCMC/Ch3_IntroMCMC_PyMC3.ipynb)
    We discuss how MCMC operates and diagnostic tools. Examples include:
    - Bayesian clustering with mixture models
    
* [**Chapter 4: The Greatest Theorem Never Told**](http://nbviewer.jupyter.org/urls/raw.github.com/CamDavidsonPilon/Probabilistic-Programming-and-Bayesian-Methods-for-Hackers/master/Chapter4_TheGreatestTheoremNeverTold/Ch4_LawOfLargeNumbers_PyMC3.ipynb)
    We explore an incredibly useful, and dangerous, theorem: The Law of Large Numbers. Examples include:
    - Exploring a Kaggle dataset and the pitfalls of naive analysis
    - How to sort Reddit comments from best to worst (not as easy as you think)
    
* [**Chapter 5: Would you rather lose an arm or a leg?**](http://nbviewer.jupyter.org/urls/raw.github.com/CamDavidsonPilon/Probabilistic-Programming-and-Bayesian-Methods-for-Hackers/master/Chapter5_LossFunctions/Ch5_LossFunctions_PyMC3.ipynb)
    The introduction of loss functions and their (awesome) use in Bayesian methods.  Examples include:
    - Solving the *Price is Right*'s Showdown
    - Optimizing financial predictions
    - Winning solution to the Kaggle Dark World's competition
    
* [**Chapter 6: Getting our *prior*-ities straight**](http://nbviewer.jupyter.org/urls/raw.github.com/CamDavidsonPilon/Probabilistic-Programming-and-Bayesian-Methods-for-Hackers/master/Chapter6_Priorities/Ch6_Priors_PyMC3.ipynb)
    Probably the most important chapter. We draw on expert opinions to answer questions. Examples include:
    - Multi-Armed Bandits and the Bayesian Bandit solution.
    - What is the relationship between data sample size and prior?
    - Estimating financial unknowns using expert priors
    
    We explore useful tips to be objective in analysis as well as common pitfalls of priors. 



    
**More questions about PyMC?**
Please post your modeling, convergence, or any other PyMC question on [cross-validated](http://stats.stackexchange.com/), the statistics stack-exchange.
    
    
Using the book
-------

The book can be read in three different ways, starting from most recommended to least recommended: 

1. The most recommended option is to clone the repository to download the .ipynb files to your local machine. If you have Jupyter installed, you can view the 
chapters in your browser *plus* edit and run the code provided (and try some practice questions). This is the preferred option to read
this book, though it comes with some dependencies. 
    -  Jupyter is a requirement to view the ipynb files. It can be downloaded [here](http://jupyter.org/). Jupyter notebooks can be run by `(your-virtualenv) ~/path/to/the/book/Chapter1_Introduction $ jupyter notebook`
    -  For Linux users, you should not have a problem installing NumPy, SciPy, Matplotlib and PyMC. For Windows users, check out [pre-compiled versions](http://www.lfd.uci.edu/~gohlke/pythonlibs/) if you have difficulty. 
    -  In the styles/ directory are a number of files (.matplotlirc) that used to make things pretty. These are not only designed for the book, but they offer many improvements over the default settings of matplotlib.
2. The second, preferred, option is to use the nbviewer.jupyter.org site, which display Jupyter notebooks in the browser ([example](http://nbviewer.jupyter.org/urls/raw.github.com/CamDavidsonPilon/Probabilistic-Programming-and-Bayesian-Methods-for-Hackers/master/Chapter1_Introduction/Ch1_Introduction_PyMC2.ipynb)).
The contents are updated synchronously as commits are made to the book. You can use the Contents section above to link to the chapters.
 
3. PDFs are the least-preferred method to read the book, as PDFs are static and non-interactive. If PDFs are desired, they can be created dynamically using the [nbconvert](https://github.com/jupyter/nbconvert) utility.
 

Installation and configuration
------


If you would like to run the Jupyter notebooks locally, (option 1. above), you'll need to install the following:

-  Jupyter is a requirement to view the ipynb files. It can be downloaded [here](http://jupyter.org/install.html) 
- Necessary packages are PyMC, NumPy, SciPy and Matplotlib.   
   -  For Linux/OSX users, you should not have a problem installing the above, [*except for Matplotlib on OSX*](http://www.penandpants.com/2012/02/24/install-python/).
   -  For Windows users, check out [pre-compiled versions](http://www.lfd.uci.edu/~gohlke/pythonlibs/) if you have difficulty. 
   - also recommended, for data-mining exercises, are [PRAW](https://github.com/praw-dev/praw) and [requests](https://github.com/kennethreitz/requests). 
- New to Python or Jupyter, and help with the namespaces? Check out [this answer](http://stackoverflow.com/questions/12987624/confusion-between-numpy-scipy-matplotlib-and-pylab). 

-  In the styles/ directory are a number of files that are customized for the notebook. 
These are not only designed for the book, but they offer many improvements over the 
default settings of matplotlib and the Jupyter notebook. The in notebook style has not been finalized yet.



Development
------

This book has an unusual development design. The content is open-sourced, meaning anyone can be an author. 
Authors submit content or revisions using the GitHub interface. 

### How to contribute

#### What to contribute?

-  The current chapter list is not finalized. If you see something that is missing (MCMC, MAP, Bayesian networks, good prior choices, Potential classes etc.),
feel free to start there. 
-  Cleaning up Python code and making code more PyMC-esque
-  Giving better explanations
-  Spelling/grammar mistakes
-  Suggestions
-  Contributing to the Jupyter notebook styles


#### Commiting

-  All commits are welcome, even if they are minor ;)
-  If you are unfamiliar with Github, you can email me contributions to the email below.

Reviews
------
*these are satirical, but real*

""No, but it looks good"" - [John D. Cook](https://twitter.com/JohnDCook/status/359672133695184896)

""I ... read this book ... I like it!"" - [Andrew Gelman](http://www.andrewgelman.com/2013/07/21/bayes-related)

""This book is a godsend, and a direct refutation to that 'hmph! you don't know maths, piss off!' school of thought...
The publishing model is so unusual. Not only is it open source but it relies on pull requests from anyone in order to progress the book. This is ingenious and heartening"" - [excited Reddit user](http://www.reddit.com/r/Python/comments/1alnal/probabilistic_programming_and_bayesian_methods/)



Contributions and Thanks
-----


Thanks to all our contributing authors, including (in chronological order):

Authors | | | |
--- | --- | --- | ---
[Cameron Davidson-Pilon](http://www.camdp.com) |  [Stef Gibson](http://stefgibson.com) | [Vincent Ohprecio](http://bigsnarf.wordpress.com/) |[Lars Buitinck](https://github.com/larsman)
[Paul Magwene](http://github.com/pmagwene) |  [Matthias Bussonnier](https://github.com/Carreau) | [Jens Rantil](https://github.com/JensRantil) |  [y-p](https://github.com/y-p)
[Ethan Brown](http://www.etano.net/) |  [Jonathan Whitmore](http://jonathanwhitmore.com/) | [Mattia Rigotti](https://github.com/matrig) |  [Colby Lemon](https://github.com/colibius)
[Gustav W Delius](https://github.com/gustavdelius) |  [Matthew Conlen](http://www.mathisonian.com/)  | [Jim Radford](https://github.com/radford) |  [Vannessa Sabino](http://baniverso.com/)
[Thomas Bratt](https://github.com/thomasbratt) |  [Nisan Haramati](https://github.com/nisanharamati) |  [Robert Grant](https://github.com/bgrant) | [Matthew Wampler-Doty](https://github.com/xcthulhu)
[Yaroslav Halchenko](https://github.com/yarikoptic) |  [Alex Garel](https://github.com/alexgarel) | [Oleksandr Lysenko](https://twitter.com/sash_ko) |  [liori](https://github.com/liori)
[ducky427](https://github.com/ducky427) |  [Pablo de Oliveira Castro](https://github.com/pablooliveira) | [sergeyfogelson](https://github.com/sergeyfogelson) |  [Mattia Rigotti](http://neurotheory.columbia.edu/~mrigotti/)
[Matt Bauman](https://github.com/mbauman) | [Andrew Duberstein](http://www.andrewduberstein.com/) | [Carsten Brandt](http://cebe.cc/) |  [Bob Jansen](http://web2docx.com)
 [ugurthemaster](https://github.com/ugurthemaster)   | [William Scott](https://github.com/williamscott)   |  [Min RK](http://twitter.com/minrk)  |  [Bulwersator](https://github.com/Bulwersator)
  [elpres](https://github.com/elpres)  |  [Augusto Hack](https://github.com/hackaugusto)  | [Michael Feldmann](https://github.com/michaf)   | [Youki](https://github.com/Youki)
   [Jens Rantil](http://jensrantil.github.io) |  [Kyle Meyer](http://kyleam.com)  |  [Eric Martin](http://ericmart.in)  | [Inconditus](https://github.com/Inconditus)
 [Kleptine](https://github.com/Kleptine)   |  [Stuart Layton](https://github.com/slayton)  |  [Antonino Ingargiola](https://github.com/tritemio)  |  [vsl9](https://github.com/vsl9)
  [Tom Christie](https://github.com/tom-christie)  |  [bclow](https://github.com/bclow)  |  [Simon Potter](http://sjp.co.nz/)  | [Garth Snyder](https://github.com/GarthSnyder)
 [Daniel Beauchamp](http://twitter.com/pushmatrix)  |  [Philipp Singer](http://www.philippsinger.info)  | [gbenmartin](https://github.com/gbenmartin) | [Peadar Coyle](https://twitter.com/Springcoil)

We would like to thank the Python community for building an amazing architecture. We would like to thank the 
statistics community for building an amazing architecture. 

Similarly, the book is only possible because of the [PyMC](http://github.com/pymc-devs/pymc) library. A big thanks to the core devs of PyMC: Chris Fonnesbeck, Anand Patil, David Huard and John Salvatier.

One final thanks. This book was generated by Jupyter Notebook, a wonderful tool for developing in Python. We thank the IPython/Jupyter 
community for developing the Notebook interface. All Jupyter notebook files are available for download on the GitHub repository. 



#### Contact
Contact the main author, Cam Davidson-Pilon at cam.davidson.pilon@gmail.com or [@cmrndp](https://twitter.com/cmrn_dp)


![Imgur](http://i.imgur.com/Zb79QZb.png)
","Bayesian Methods for Hackers is an introduction to Bayesian inference. The book
is written using Python and the probabilistic programming language PyMC. It is
designed as an introduction from a computational/understanding-first, and
mathematics-second, point of view. The examples will rely only on PyMC, NumPy,
SciPy and Matplotlib."
1304,"Apache Linkis builds a computation middleware layer to facilitate connection, governance and orchestration between the upper applications and the underlying data engines.","<h2 align=""center"">
  Apache Linkis
</h2>

<p align=""center"">
  <strong> Linkis builds a computation middleware layer to facilitate connection, 
    governance and orchestration between the upper applications and the underlying data engines. </strong>
</p>
<p align=""center"">
  <a href=""https://linkis.apache.org/"">https://linkis.apache.org/</a>
</p>

<p align=""center"">
  <a href=""https://linkis.apache.org/docs/latest/introduction/"" >
    <img src=""https://img.shields.io/badge/document-English-blue.svg"" alt=""EN docs"" />
  </a>
  <a href=""https://linkis.apache.org/zh-CN/docs/latest/introduction/"">
    <img src=""https://img.shields.io/badge/文档-简体中文-blue.svg"" alt=""简体中文文档"" />
  </a>
</p>

<p align=""center"">
    <a target=""_blank"" href=""https://search.maven.org/search?q=g:org.apache.linkis%20AND%20a:linkis"">
        <img src=""https://img.shields.io/maven-central/v/org.apache.linkis/linkis.svg?label=maven%20central"" />
    </a>
    <a target=""_blank"" href=""https://github.com/apache/linkis/blob/master/LICENSE"">
        <img src=""https://img.shields.io/badge/License-Apache%202.0-blue.svg?label=license"" />
    </a>
    <a target=""_blank"" href=""https://www.oracle.com/technetwork/java/javase/downloads/index.html"">
        <img src=""https://img.shields.io/badge/JDK-8-green.svg"" />
    </a>
    <a target=""_blank"" href=""https://github.com/apache/linkis/actions"">
        <img src=""https://github.com/apache/linkis/actions/workflows//build-backend.yml/badge.svg"" />
    </a>

   <a target=""_blank"" href='https://github.com/apache/linkis'>
        <img src=""https://img.shields.io/github/forks/apache/linkis.svg"" alt=""github forks""/>
   </a>
   <a target=""_blank"" href='https://github.com/apache/linkis'>
        <img src=""https://img.shields.io/github/stars/apache/linkis.svg"" alt=""github stars""/>
   </a>
   <a target=""_blank"" href='https://github.com/apache/linkis'>
        <img src=""https://img.shields.io/github/contributors/apache/linkis.svg"" alt=""github contributors""/>
   </a>
  <a target=""_blank"" href=""https://badges.toozhao.com/stats/01G7TRNN1PH9PMSCYWDF3EK4QT"">
       <img src=""https://badges.toozhao.com/badges/01G7TRNN1PH9PMSCYWDF3EK4QT/green.svg"" />
  </a>
  
</p>
<br/>

---
[English](README.md) | [中文](README_CN.md)

# Introduction

 Linkis builds a layer of computation middleware between upper applications and underlying engines. By using standard interfaces such as REST/WS/JDBC provided by Linkis, the upper applications can easily access the underlying engines such as MySQL/Spark/Hive/Presto/Flink, etc., and achieve the intercommunication of user resources like unified variables, scripts, UDFs, functions and resource files at the same time.

As a computation middleware, Linkis provides powerful connectivity, reuse, orchestration, expansion, and governance capabilities. By decoupling the application layer and the engine layer, it simplifies the complex network call relationship, and thus reduces the overall complexity and saves the development and maintenance costs as well.

Since the first release of Linkis in 2019, it has accumulated more than **700** trial companies and **1000+** sandbox trial users, which involving diverse industries, from finance, banking, tele-communication, to manufactory, internet companies and so on. Lots of companies have already used Linkis as a unified entrance for the underlying computation and storage engines of the big data platform.

![linkis-intro-01](https://user-images.githubusercontent.com/7869972/148767375-aeb11b93-16ca-46d7-a30e-92fbefe2bd5e.png)

![linkis-intro-03](https://user-images.githubusercontent.com/7869972/148767380-c34f44b2-9320-4633-9ec8-662701f41d15.png)

# Features

- **Support for diverse underlying computation storage engines**  
  - Currently supported computation/storage engines: Spark、Hive、Flink、Python、Pipeline、Sqoop、openLooKeng、Presto、ElasticSearch、JDBC, Shell, etc
  - Computation/storage engines to be supported: Trino (planned 1.3.1), SeaTunnel (planned 1.3.1), etc
  - Supported scripting languages: SparkSQL、HiveQL、Python、Shell、Pyspark、R、Scala and JDBC, etc

- **Powerful task/request governance capabilities** With services such as Orchestrator, Label Manager and customized Spring Cloud Gateway, Linkis is able to provide multi-level labels based, cross-cluster/cross-IDC fine-grained routing, load balance, multi-tenancy, traffic control, resource control, and orchestration strategies like dual-active, active-standby, etc

- **Support full stack computation/storage engine** As a computation middleware, it will receive, execute and manage tasks and requests for various computation storage engines, including batch tasks, interactive query tasks, real-time streaming tasks and storage tasks

- **Resource management capabilities**  ResourceManager is not only capable of managing resources for Yarn and Linkis EngineManger, but also able to provide label-based multi-level resource allocation and recycling, allowing itself to have powerful resource management capabilities across multiple Yarn clusters and multiple computation resource types

- **Unified Context Service** Generate Context ID for each task/request,  associate and manage user and system resource files (JAR, ZIP, Properties, etc.), result set, parameter variable, function, etc., across user, system, and computing engine. Set in one place, automatic reference everywhere

- **Unified materials** System and user-level unified material management, which can be shared and transferred across users and systems

# Supported Engine Types

| **Engine Name** | **Suppor Component Version<br/>(Default Dependent Version)** | **Linkis Version Requirements** | **Included in Release Package<br/> By Default** | **Description** |
|:---- |:---- |:---- |:---- |:---- |
|Spark|Apache 2.0.0~2.4.7, <br/>CDH >= 5.4.0, <br/>(default Apache Spark 2.4.3)|\>=1.0.3|Yes|Spark EngineConn, supports SQL , Scala, Pyspark and R code|
|Hive|Apache >= 1.0.0, <br/>CDH >= 5.4.0, <br/>(default Apache Hive 2.3.3)|\>=1.0.3|Yes |Hive EngineConn, supports HiveQL code|
|Python|Python >= 2.6, <br/>(default Python2*)|\>=1.0.3|Yes |Python EngineConn, supports python code|
|Shell|Bash >= 2.0|\>=1.0.3|Yes|Shell EngineConn, supports Bash shell code|
|JDBC|MySQL >= 5.0, Hive >=1.2.1, <br/>(default Hive-jdbc 2.3.4)|\>=1.0.3|No|JDBC EngineConn, already supports MySQL and HiveQL, can be extended quickly Support other engines with JDBC Driver package, such as Oracle|
|Flink |Flink >= 1.12.2, <br/>(default Apache Flink 1.12.2)|\>=1.0.3|No |Flink EngineConn, supports FlinkSQL code, also supports starting a new Yarn in the form of Flink Jar Application |
|Pipeline|-|\>=1.0.3|No|Pipeline EngineConn, supports file import and export|
|openLooKeng|openLooKeng >= 1.5.0, <br/>(default openLookEng 1.5.0)|\>=1.1.1|No|openLooKeng EngineConn, supports querying data virtualization engine with Sql openLooKeng|
|Sqoop| Sqoop >= 1.4.6, <br/>(default Apache Sqoop 1.4.6)|\>=1.1.2|No|Sqoop EngineConn, support data migration tool Sqoop engine|
|Presto|Presto >= 0.180, <br/>(default Presto 0.234)|\>=1.2.0|-|Presto EngineConn, supports Presto SQL code|
|ElasticSearch|ElasticSearch >=6.0, <br/>(default ElasticSearch 7.6.2)|\>=1.2.0|-|ElasticSearch EngineConn, supports SQL and DSL code|
|Impala|Impala >= 3.2.0, CDH >=6.3.0|ongoing|-|Impala EngineConn, supports Impala SQL code|
|MLSQL| MLSQL >=1.1.0|ongoing|-|MLSQL EngineConn, supports MLSQL code.|
|Hadoop|Apache >=2.6.0, <br/>CDH >=5.4.0|ongoing|-|Hadoop EngineConn, supports Hadoop MR/YARN application|
|TiSpark|1.1|ongoing|-|TiSpark EngineConn, supports querying TiDB with SparkSQL|


# Download

Please go to the [Linkis Releases Page](https://linkis.apache.org/download/main) to download a compiled distribution or a source code package of Linkis.

# Compile and Deploy

> For more detailed guidance see:
>- [[Backend Compile]](https://linkis.apache.org/docs/latest/development/build)
>- [[Management Console Build]](https://linkis.apache.org/docs/latest/development/build-console)

```shell

Note: If you want use `-Dlinkis.build.web=true` to build  linkis-web image, you need to compile linkis-web first.

## compile backend
### Mac OS/Linux

# 1. When compiling for the first time, execute the following command first
./mvnw -N install

# 2. make the linkis distribution package
# - Option 1: make the linkis distribution package only
./mvnw clean install -Dmaven.javadoc.skip=true -Dmaven.test.skip=true

# - Option 2: make the linkis distribution package and docker image
#   - Option 2.1: image without mysql jdbc jars
./mvnw clean install -Pdocker -Dmaven.javadoc.skip=true -Dmaven.test.skip=true
#   - Option 2.2: image with mysql jdbc jars
./mvnw clean install -Pdocker -Dmaven.javadoc.skip=true -Dmaven.test.skip=true -Dlinkis.build.with.jdbc=true

# - Option 3: linkis distribution package and docker image (included web)
./mvnw clean install -Pdocker -Dmaven.javadoc.skip=true -Dmaven.test.skip=true -Dlinkis.build.web=true

# - Option 4: linkis distribution package and docker image (included web and ldh (hadoop all in one for test))
./mvnw clean install -Pdocker -Dmaven.javadoc.skip=true -Dmaven.test.skip=true -Dlinkis.build.web=true -Dlinkis.build.ldh=true -Dlinkis.build.with.jdbc=true

### Windows
mvnw.cmd -N install
mvnw.cmd clean install -Dmaven.javadoc.skip=true -Dmaven.test.skip=true

## compile web
cd linkis/linkis-web
npm install
npm run build
```

### Bundled with MySQL JDBC Driver
Due to the MySQL licensing restrictions, the MySQL Java Database Connectivity (JDBC) driver is not bundled with the 
official released linkis image by default. However, at current stage, linkis still relies on this library to work properly.
To solve this problem, we provide a script which can help to creating a custom image with mysql jdbc from the official 
linkis image by yourself, the image created by this tool will be tagged as `linkis:with-jdbc` by default.

```shell
$> LINKIS_IMAGE=linkis:1.3.1 
$> ./linkis-dist/docker/scripts/make-linikis-image-with-mysql-jdbc.sh
```


Please refer to [Quick Deployment](https://linkis.apache.org/docs/latest/deployment/deploy-quick/) to do the deployment.

# Examples and Guidance
- [User Manual](https://linkis.apache.org/docs/latest/user-guide/how-to-use)
- [Engine Usage Documents](https://linkis.apache.org/docs/latest/engine-usage/overview) 
- [API Documents](https://linkis.apache.org/docs/latest/api/overview)

# Documentation & Vedio

- The documentation of linkis is in [Linkis-Website Git Repository](https://github.com/apache/linkis-website)
- Meetup videos on [Bilibili](https://space.bilibili.com/598542776?from=search&seid=14344213924133040656)

# Architecture
Linkis services could be divided into three categories: computation governance services, public enhancement services and microservice governance services
- The computation governance services, support the 3 major stages of processing a task/request: submission -> preparation -> execution
- The public enhancement services, including the material library service, context service, and data source service
- The microservice governance services, including Spring Cloud Gateway, Eureka and Open Feign

Below is the Linkis architecture diagram. You can find more detailed architecture docs in [Linkis-Doc/Architecture](https://linkis.apache.org/docs/latest/architecture/overview).
![architecture](https://user-images.githubusercontent.com/7869972/148767383-f87e84ba-5baa-4125-8b6e-d0aa4f7d3a66.png)

# Contributing

Contributions are always welcomed, we need more contributors to build Linkis together. either code, or doc, or other supports that could help the community.  
For code and documentation contributions, please follow the [contribution guide](https://linkis.apache.org/community/how-to-contribute).

# Contact Us


- Any questions or suggestions please kindly submit an [issue](https://github.com/apache/linkis/issues).  
- By mail [dev@linkis.apache.org](mailto:dev@linkis.apache.org)
- You can scan the QR code below to join our WeChat group to get more immediate response

![wechatgroup](https://linkis.apache.org/Images/wedatasphere_contact_01.png)


# Who is Using Linkis

We opened an issue [[Who is Using Linkis]](https://github.com/apache/linkis/issues/23) for users to feedback and record who is using Linkis.  
Since the first release of Linkis in 2019, it has accumulated more than **700** trial companies and **1000+** sandbox trial users, which involving diverse industries, from finance, banking, tele-communication, to manufactory, internet companies and so on.
","Linkis builds a layer of computation middleware between upper applications and
underlying engines. By using standard interfaces such as REST/WS/JDBC provided
by Linkis, the upper applications can easily access the underlying engines such
as MySQL/Spark/Hive/Presto/Flink. Since the first release of Linkis in 2019, it
has accumulated more than **700** trial companies and **1000+** sandbox trial
users, which involving diverse industries, from finance, banking, tele-
communication, to manufactory, internet companies and so on."
2345,"The ""Python Machine Learning (1st edition)""  book code repository and info resource","# Python Machine Learning book code repository


[![Google Group](https://img.shields.io/badge/-Google%20Group-lightgrey.svg)](https://groups.google.com/forum/#!forum/python-machine-learning-reader-discussion-board)

---

#### IMPORTANT NOTE (09/21/2017):

This GitHub repository contains the code examples of the **1st Edition** of Python Machine Learning book. If you are looking for the code examples of the **2nd Edition**, please refer to [this](https://github.com/rasbt/python-machine-learning-book-2nd-edition#whats-new-in-the-second-edition-from-the-first-edition) repository instead. 

---

What you can expect are 400 pages rich in useful material just about everything you need to know to get started with machine learning ... from theory to the actual code that you can directly put into action! This is not yet just another ""this is how scikit-learn works"" book. I aim to explain all the underlying concepts, tell you everything you need to know in terms of best practices and caveats, and
we will put those concepts into action mainly using NumPy, scikit-learn, and Theano.

You are not sure if this book is for you? Please checkout the excerpts from the [Foreword](./docs/foreword_ro.pdf) and [Preface](./docs/preface_sr.pdf), or take a look at the [FAQ](#faq) section for further information.



---

[![](./images/pymle_cover_double_small.jpg)](https://www.amazon.com/Python-Machine-Learning-Sebastian-Raschka/dp/1783555130/ref=sr_1_1?ie=UTF8&qid=1470882464&sr=8-1&keywords=python+machine+learning)

1st edition, published September 23rd 2015<br>
Paperback: 454 pages<br>
Publisher: Packt Publishing<br>  
Language: English<br>
ISBN-10: 1783555130<br>  
ISBN-13: 978-1783555130<br>
Kindle ASIN: B00YSILNL0<br>

<br>

[![](./images/CRBadgeNotableBook.jpg)](http://www.computingreviews.com/recommend/bestof/notableitems.cfm?bestYear=2016)

<br>

German ISBN-13: 978-3958454224<br>
Japanese ISBN-13: 978-4844380603<br>
Italian ISBN-13: 978-8850333974<br>
Chinese (traditional) ISBN-13: 978-9864341405<br>
Chinese (mainland) ISBN-13: 978-7111558804<br>
Korean ISBN-13: 979-1187497035<br>
Russian ISBN-13: 978-5970604090<br>



## Table of Contents and Code Notebooks


Simply click on the `ipynb`/`nbviewer` links next to the chapter headlines to view the code examples (currently, the internal document links are only supported by the NbViewer version).
**Please note that these are just the code examples accompanying the book, which I uploaded for your convenience; be aware that these notebooks may not be useful without the formulae and descriptive text.**   


- Excerpts from the [Foreword](./docs/foreword_ro.pdf) and [Preface](./docs/preface_sr.pdf)
- [Instructions for setting up Python and the Jupiter Notebook](./code/ch01/README.md)  

<br>

1. Machine Learning - Giving Computers the Ability to Learn from Data [[dir](./code/ch01)] [[ipynb](./code/ch01/ch01.ipynb)] [[nbviewer](http://nbviewer.ipython.org/github/rasbt/python-machine-learning-book/blob/master/code/ch01/ch01.ipynb)]
2. Training Machine Learning Algorithms for Classification [[dir](./code/ch02)] [[ipynb](./code/ch02/ch02.ipynb)] [[nbviewer](http://nbviewer.ipython.org/github/rasbt/python-machine-learning-book/blob/master/code/ch02/ch02.ipynb)]
3. A Tour of Machine Learning Classifiers Using Scikit-Learn [[dir](./code/ch03)] [[ipynb](./code/ch03/ch03.ipynb)] [[nbviewer](http://nbviewer.ipython.org/github/rasbt/python-machine-learning-book/blob/master/code/ch03/ch03.ipynb)]
4. Building Good Training Sets – Data Pre-Processing [[dir](./code/ch04)] [[ipynb](./code/ch04/ch04.ipynb)] [[nbviewer](http://nbviewer.ipython.org/github/rasbt/python-machine-learning-book/blob/master/code/ch04/ch04.ipynb)]
5. Compressing Data via Dimensionality Reduction [[dir](./code/ch05)] [[ipynb](./code/ch05/ch05.ipynb)] [[nbviewer](http://nbviewer.ipython.org/github/rasbt/python-machine-learning-book/blob/master/code/ch05/ch05.ipynb)]
6. Learning Best Practices for Model Evaluation and Hyperparameter Optimization [[dir](./code/ch06)] [[ipynb](./code/ch06/ch06.ipynb)] [[nbviewer](http://nbviewer.ipython.org/github/rasbt/python-machine-learning-book/blob/master/code/ch06/ch06.ipynb)]
7. Combining Different Models for Ensemble Learning [[dir](./code/ch07)] [[ipynb](./code/ch07/ch07.ipynb)] [[nbviewer](http://nbviewer.ipython.org/github/rasbt/python-machine-learning-book/blob/master/code/ch07/ch07.ipynb)]
8. Applying Machine Learning to Sentiment Analysis [[dir](./code/ch08)] [[ipynb](./code/ch08/ch08.ipynb)] [[nbviewer](http://nbviewer.ipython.org/github/rasbt/python-machine-learning-book/blob/master/code/ch08/ch08.ipynb)]
9. Embedding a Machine Learning Model into a Web Application [[dir](./code/ch09)] [[ipynb](./code/ch09/ch09.ipynb)] [[nbviewer](http://nbviewer.ipython.org/github/rasbt/python-machine-learning-book/blob/master/code/ch09/ch09.ipynb)]
10. Predicting Continuous Target Variables with Regression Analysis [[dir](./code/ch10)] [[ipynb](./code/ch10/ch10.ipynb)] [[nbviewer](http://nbviewer.ipython.org/github/rasbt/python-machine-learning-book/blob/master/code/ch10/ch10.ipynb)]
11. Working with Unlabeled Data – Clustering Analysis [[dir](./code/ch11)] [[ipynb](./code/ch11/ch11.ipynb)] [[nbviewer](http://nbviewer.ipython.org/github/rasbt/python-machine-learning-book/blob/master/code/ch11/ch11.ipynb)]
12. Training Artificial Neural Networks for Image Recognition [[dir](./code/ch12)] [[ipynb](./code/ch12/ch12.ipynb)] [[nbviewer](http://nbviewer.ipython.org/github/rasbt/python-machine-learning-book/blob/master/code/ch12/ch12.ipynb)]
13. Parallelizing Neural Network Training via Theano [[dir](./code/ch13)] [[ipynb](./code/ch13/ch13.ipynb)] [[nbviewer](http://nbviewer.ipython.org/github/rasbt/python-machine-learning-book/blob/master/code/ch13/ch13.ipynb)]

<br>

#### Equation Reference

<a href=""https://github.com/rasbt/python-machine-learning-book/tree/master/docs/equations""><img src=""images/equation-ref-logo.png"" width=""200"" height=""200"" /></a>

[[PDF](./docs/equations/pymle-equations.pdf)] [[TEX](./docs/equations/pymle-equations.tex)]

#### Slides for Teaching

A big thanks to [Dmitriy Dligach](dmitriydligach) for sharing his slides from his machine learning course that is currently offered at [Loyola University Chicago](http://www.luc.edu/cs/). 

- [https://github.com/dmitriydligach/PyMLSlides](https://github.com/dmitriydligach/PyMLSlides)
- 



#### Additional Math and NumPy Resources

Some readers were asking about Math and NumPy primers, since they were not included due to length limitations. However, I recently put together such resources for another book, but I made these *chapters* freely available online in hope that they also serve as helpful background material for this book:


- Algebra Basics [[PDF](https://sebastianraschka.com/pdf/books/dlb/appendix_b_algebra.pdf)] [[EPUB](https://sebastianraschka.com/pdf/books/dlb/appendix_b_algebra.epub)]

- A Calculus and Differentiation Primer [[PDF](https://sebastianraschka.com/pdf/books/dlb/appendix_d_calculus.pdf)] [[EPUB](https://sebastianraschka.com/pdf/books/dlb/appendix_d_calculus.epub)]

- Introduction to NumPy [[PDF](https://sebastianraschka.com/pdf/books/dlb/appendix_f_numpy-intro.pdf)] [[EPUB](https://sebastianraschka.com/pdf/books/dlb/appendix_f_numpy-intro.epub)] [[Code Notebook](https://github.com/rasbt/deep-learning-book/blob/master/code/appendix_f_numpy-intro/appendix_f_numpy-intro.ipynb)]



---

#### Citing this Book

You are very welcome to re-use the code snippets or other contents from this book
in scientific publications and other works;
in this case, I would appreciate citations to the original source:

**BibTeX**:

```
@Book{raschka2015python,
 author = {Raschka, Sebastian},
 title = {Python Machine Learning},
 publisher = {Packt Publishing},
 year = {2015},
 address = {Birmingham, UK},
 isbn = {1783555130}
 }
```


**MLA**:


Raschka, Sebastian. *Python machine learning*. Birmingham, UK: Packt Publishing, 2015. Print.

---

### [Feedback & Reviews](./docs/feedback.md)

#### [Short review snippets](./docs/feedback.md)

[![](./images/pymle_amzn.png)](https://www.amazon.com/Python-Machine-Learning-Sebastian-Raschka/dp/1783555130/ref=sr_1_1?ie=UTF8&qid=1472342570&sr=8-1&keywords=sebastian+raschka)

---
> *Sebastian Raschka’s new book, Python Machine Learning, has just been released. I got a chance to read a review copy and it’s just as I expected - really great! It’s well organized, super easy to follow, and it not only offers a good foundation for smart, non-experts, practitioners will get some ideas and learn new tricks here as well.*  
– Lon Riesberg at [Data Elixir](http://dataelixir.com/issues/55#start)

> *Superb job! Thus far, for me it seems to have hit the right balance of theory and practice…math and code!*   
– [Brian Thomas](http://sebastianraschka.com/blog/2015/writing-pymle.html#comment-2295668894)

> *I've read (virtually) every Machine Learning title based around Scikit-learn and this is hands-down the best one out there.*    
– [Jason Wolosonovich](https://www.linkedin.com/pulse/python-machine-learning-sebastian-raschka-review-jason-wolosonovich?trk=prof-post)

> *The best book I've seen to come out of PACKT Publishing. This is a very well written introduction to machine learning with Python. As others have noted, a perfect mixture of theory and application.*    
– [Josh D.](https://www.amazon.com/gp/customer-reviews/R27WB1GWTNGIR2/ref=cm_cr_getr_d_rvw_ttl?ie=UTF8&ASIN=1783555130)

> *A book with a blend of qualities that is hard to come by: combines the needed mathematics to control the theory with the applied coding in Python. Also great to see it doesn't waste paper in giving a primer on Python as many other books do just to appeal to the greater audience. You can tell it's been written by knowledgeable writers and not just DIY geeks.*    
– [Amazon Customer](https://www.amazon.com/gp/customer-reviews/RZWY4TF66Z6V0/ref=cm_cr_getr_d_rvw_ttl?ie=UTF8&ASIN=1783555130)

> *Sebastian Raschka created an amazing machine learning tutorial which combines theory with practice. The book explains machine learning from a theoretical perspective and has tons of coded examples to show how you would actually use the machine learning technique. It can be read by a beginner or advanced programmer.*
- William P. Ross, [7 Must Read Python Books](http://williampross.com/7-must-read-python-books/)

#### Longer reviews

If you need help to decide whether this book is for you, check out some of the ""longer"" reviews linked below. (If you wrote a review, please let me know, and I'd be happy to add it to the list).

- [Python Machine Learning Review](http://www.bcs.org/content/conWebDoc/55586) by Patrick Hill at the Chartered Institute for IT
- [Book Review: Python Machine Learning by Sebastian Raschka](http://whatpixel.com/python-machine-learning-book-review/) by Alex Turner at WhatPixel

---

## Links

- ebook and paperback at [Amazon.com](http://www.amazon.com/Python-Machine-Learning-Sebastian-Raschka/dp/1783555130/ref=sr_1_2?ie=UTF8&qid=1437754343&sr=8-2&keywords=python+machine+learning+essentials), [Amazon.co.uk](http://www.amazon.co.uk/Python-Machine-Learning-Sebastian-Raschka/dp/1783555130), [Amazon.de](http://www.amazon.de/s/ref=nb_sb_noss_2?__mk_de_DE=ÅMÅŽÕÑ&url=search-alias%3Daps&field-keywords=python+machine+learning)
- [ebook and paperback](https://www.packtpub.com/big-data-and-business-intelligence/python-machine-learning) from Packt (the publisher)
- at other book stores: [Google Books](https://books.google.com/books?id=GOVOCwAAQBAJ&source=gbs_slider_cls_metadata_7_mylibrary), [O'Reilly](http://shop.oreilly.com/product/9781783555130.do), [Safari](https://www.safaribooksonline.com/library/view/python-machine-learning/9781783555130/), [Barnes & Noble](http://www.barnesandnoble.com/w/python-machine-learning-essentials-sebastian-raschka/1121999969?ean=9781783555130), [Apple iBooks](https://itunes.apple.com/us/book/python-machine-learning/id1028207310?mt=11), ...
- social platforms: [Goodreads](https://www.goodreads.com/book/show/25545994-python-machine-learning)

#### Translations

- [Italian translation](https://www.amazon.it/learning-Costruire-algoritmi-generare-conoscenza/dp/8850333978/) via ""Apogeo""
- [German translation](https://www.amazon.de/Machine-Learning-Python-mitp-Professional/dp/3958454224/) via ""mitp Verlag""
- [Japanese translation](http://www.amazon.co.jp/gp/product/4844380605/) via ""Impress Top Gear""
- [Chinese translation (traditional Chinese)](https://taiwan.kinokuniya.com/bw/9789864341405)
- [Chinese translation (simple Chinese)](https://book.douban.com/subject/27000110/)
- [Korean translation](http://www.kyobobook.co.kr/product/detailViewKor.laf?mallGb=KOR&ejkGb=KOR&barcode=9791187497035) via ""Kyobo""
- [Polish translation](https://www.amazon.de/Python-Uczenie-maszynowe-Sebastian-Raschka/dp/8328336138/ref=sr_1_11?ie=UTF8&qid=1513601461&sr=8-11&keywords=sebastian+raschka) via ""Helion""

---

### [Literature References & Further Reading Resources](./docs/references.md)

### [Errata](./docs/errata.md)


---

### Bonus Notebooks (not in the book)

- Logistic Regression Implementation [[dir](./code/bonus)] [[ipynb](./code/bonus/logistic_regression.ipynb)] [[nbviewer](http://nbviewer.ipython.org/github/rasbt/python-machine-learning-book/blob/master/code/bonus/logistic_regression.ipynb)]
- A Basic Pipeline and Grid Search Setup [[dir](./code/bonus)] [[ipynb](./code/bonus/svm_iris_pipeline_and_gridsearch.ipynb)] [[nbviewer](http://nbviewer.ipython.org/github/rasbt/python-machine-learning-book/blob/master/code/bonus/svm_iris_pipeline_and_gridsearch.ipynb)]
- An Extended Nested Cross-Validation Example [[dir](./code/bonus)] [[ipynb](./code/bonus/nested_cross_validation.ipynb)] [[nbviewer](http://nbviewer.ipython.org/github/rasbt/python-machine-learning-book/blob/master/code/bonus/nested_cross_validation.ipynb)]
- A Simple Barebones Flask Webapp Template [[view directory](./code/bonus/flask_webapp_ex01)][[download as zip-file](https://github.com/rasbt/python-machine-learning-book/raw/master/code/bonus/flask_webapp_ex01/flask_webapp_ex01.zip)]
- Reading handwritten digits from MNIST into NumPy arrays [[GitHub ipynb](./code/bonus/reading_mnist.ipynb)] [[nbviewer](http://nbviewer.ipython.org/github/rasbt/python-machine-learning-book/blob/master/code/bonus/reading_mnist.ipynb)]
- Scikit-learn Model Persistence using JSON [[GitHub ipynb](./code/bonus/scikit-model-to-json.ipynb)] [[nbviewer](http://nbviewer.ipython.org/github/rasbt/python-machine-learning-book/blob/master/code/bonus/scikit-model-to-json.ipynb)]
- Multinomial logistic regression / softmax regression [[GitHub ipynb](./code/bonus/softmax-regression.ipynb)] [[nbviewer](http://nbviewer.ipython.org/github/rasbt/python-machine-learning-book/blob/master/code/bonus/softmax-regression.ipynb)]

<hr>

**""Related Content"" (not in the book)**

- [Model evaluation, model selection, and algorithm selection in machine learning - Part I](http://sebastianraschka.com/blog/2016/model-evaluation-selection-part1.html)
- [Model evaluation, model selection, and algorithm selection in machine learning - Part II](http://sebastianraschka.com/blog/2016/model-evaluation-selection-part2.html)
- [Model evaluation, model selection, and algorithm selection in machine learning - Part III](http://sebastianraschka.com/blog/2016/model-evaluation-selection-part3.html)

---

#### SciPy 2016

We had such a great time at [SciPy 2016](http://scipy2016.scipy.org/ehome/index.php?eventid=146062&tabid=332930&) in Austin! It was a real pleasure to meet and chat with so many readers of my book. Thanks so much for all the nice words and feedback! And in case you missed it, Andreas Mueller and I gave an **Introduction to Machine Learning with Scikit-learn**; if you are interested, the video recordings of [Part I](https://www.youtube.com/watch?v=OB1reY6IX-o&index=91&list=PLYx7XA2nY5Gf37zYZMw6OqGFRPjB1jCy6) and [Part II](https://www.youtube.com/watch?v=Cte8FYCpylk&list=PLYx7XA2nY5Gf37zYZMw6OqGFRPjB1jCy6&index=90) are now online!

[![](images/scipy2016.jpg)](https://www.youtube.com/watch?v=OB1reY6IX-o&index=91&list=PLYx7XA2nY5Gf37zYZMw6OqGFRPjB1jCy6)

#### PyData Chicago 2016

I attempted the rather challenging task of introducing scikit-learn & machine learning in *just* 90 minutes at PyData Chicago 2016. The slides and tutorial material are available at ""[Learning scikit-learn -- An Introduction to Machine Learning in Python](https://github.com/rasbt/pydata-chicago2016-ml-tutorial).""


---

**Note**

I have set up a separate library, [`mlxtend`](http://rasbt.github.io/mlxtend/), containing additional implementations of machine learning (and general ""data science"") algorithms. I also added implementations from this book (for example, the decision region plot, the artificial neural network, and sequential feature selection algorithms) with additional functionality.

[![](./images/mlxtend_logo.png)](http://rasbt.github.io/mlxtend/)


<br>

<hr>

### Translations

[![](./images/pymle-cover_it.jpg)](https://www.amazon.it/learning-Costruire-algoritmi-generare-conoscenza/dp/8850333978/)
[![](./images/pymle-cover_de.jpg)](https://www.amazon.de/Machine-Learning-Python-mitp-Professional/dp/3958454224/)
[![](./images/pymle-cover_jp.jpg)](http://www.amazon.co.jp/gp/product/4844380605/)
[![](./images/pymle-cover_cn.jpg)](https://taiwan.kinokuniya.com/bw/9789864341405)
[![](./images/pymle-cover_cn_mainland.jpg)](https://book.douban.com/subject/27000110/)
[![](./images/pymle-cover_kr.jpg)](http://www.kyobobook.co.kr/product/detailViewKor.laf?ejkGb=KOR&mallGb=KOR&barcode=9791187497035&orderClick=LEA&Kc=)
[![](./images/pymle-cover_ru.jpg)](http://www.ozon.ru/context/detail/id/140152222/)
[![](./images/pymle-cover_pl.jpg)](https://www.amazon.de/Python-Uczenie-maszynowe-Sebastian-Raschka/dp/8328336138/ref=sr_1_11?ie=UTF8&qid=1513601461&sr=8-11&keywords=sebastian+raschka)

<hr>

---

***Dear readers***,  
first of all, I want to thank all of you for the great support! I am really happy about all the great feedback you sent me so far, and I am glad that the book has been so useful to a broad audience.

Over the last couple of months, I received hundreds of emails, and I tried to answer as many as possible in the available time I have. To make them useful to other readers as well, I collected many of my answers in the FAQ section (below).

In addition, some of you asked me about a platform for readers to discuss the contents of the book. I hope that this would provide an opportunity for you to discuss and share your knowledge with other readers:

#### [Google Groups Discussion Board](https://groups.google.com/forum/#!forum/python-machine-learning-reader-discussion-board)

(And I will try my best to answer questions myself if time allows! :))

> The only thing to do with good advice is to pass it on. It is never of any use to oneself.  
— Oscar Wilde

---

## Examples and Applications by Readers

Once again, I have to say (big!) THANKS for all the nice feedback about the book. I've received many emails from readers, who
put the concepts and examples from this book out into the real world and make good use of them in their projects. In this section, I am
starting to gather some of these great applications, and I'd be more than happy to add your project to this list -- just shoot me a quick mail!

- [40 scripts on Optical Character Recognition](https://github.com/rrlyman/PythonMachineLearingExamples) by [Richard Lyman](https://github.com/rrlyman)
- [Code experiments](https://github.com/jeremyn/python-machine-learning-book) by [Jeremy Nation](https://github.com/jeremyn)
- [What I Learned Implementing a Classifier from Scratch in Python](http://www.jeannicholashould.com) by [Jean-Nicholas Hould](http://www.jeannicholashould.com)

## FAQ

### General Questions

- [What are machine learning and data science?](./faq/datascience-ml.md)
- [Why do you and other people sometimes implement machine learning algorithms from scratch?](./faq/implementing-from-scratch.md)
- [What learning path/discipline in data science I should focus on?](./faq/data-science-career.md)
- [At what point should one start contributing to open source?](./faq/open-source.md)
- [How important do you think having a mentor is to the learning process?](./faq/mentor.md)
- [Where are the best online communities centered around data science/machine learning or python?](./faq/ml-python-communities.md)
- [How would you explain machine learning to a software engineer?](./faq/ml-to-a-programmer.md)
- [How would your curriculum for a machine learning beginner look like?](./faq/ml-curriculum.md)
- [What is the Definition of Data Science?](./faq/definition_data-science.md)
- [How do Data Scientists perform model selection? Is it different from Kaggle?](./faq/model-selection-in-datascience.md)

### Questions about the Machine Learning Field

- [How are Artificial Intelligence and Machine Learning related?](./faq/ai-and-ml.md)
- [What are some real-world examples of applications of machine learning in the field?](./faq/ml-examples.md)
- [What are the different fields of study in data mining?](./faq/datamining-overview.md)
- [What are differences in research nature between the two fields: machine learning & data mining?](./faq/datamining-vs-ml.md)
- [How do I know if the problem is solvable through machine learning?](./faq/ml-solvable.md)
- [What are the origins of machine learning?](./faq/ml-origins.md)
- [How was classification, as a learning machine, developed?](./faq/classifier-history.md)
- [Which machine learning algorithms can be considered as among the best?](./faq/best-ml-algo.md)
- [What are the broad categories of classifiers?](./faq/classifier-categories.md)
- [What is the difference between a classifier and a model?](./faq/difference_classifier_model.md)
- [What is the difference between a parametric learning algorithm and a nonparametric learning algorithm?](./faq/parametric_vs_nonparametric.md)
- [What is the difference between a cost function and a loss function in machine learning?](./faq/cost-vs-loss.md)

### Questions about ML Concepts and Statistics

##### Cost Functions and Optimization

- [Fitting a model via closed-form equations vs. Gradient Descent vs Stochastic Gradient Descent vs Mini-Batch Learning -- what is the difference?](./faq/closed-form-vs-gd.md)
- [How do you derive the Gradient Descent rule for Linear Regression and Adaline?](./faq/linear-gradient-derivative.md)

##### Regression Analysis

- [What is the difference between Pearson R and Simple Linear Regression?](./faq/pearson-r-vs-linear-regr.md)

##### Tree models

- [How does the random forest model work? How is it different from bagging and boosting in ensemble models?](./faq/bagging-boosting-rf.md)
- [What are the disadvantages of using classic decision tree algorithm for a large dataset?](./faq/decision-tree-disadvantages.md)
- [Why are implementations of decision tree algorithms usually binary, and what are the advantages of the different impurity metrics?](./faq/decision-tree-binary.md)
- [Why are we growing decision trees via entropy instead of the classification error?](./faq/decisiontree-error-vs-entropy.md)
- [When can a random forest perform terribly?](./faq/random-forest-perform-terribly.md)

##### Model evaluation

- [What is overfitting?](./faq/overfitting.md)
- [How can I avoid overfitting?](./faq/avoid-overfitting.md)
- [Is it always better to have the largest possible number of folds when performing cross validation?](./faq/number-of-kfolds.md)
- [When training an SVM classifier, is it better to have a large or small number of support vectors?](./faq/num-support-vectors.md)
- [How do I evaluate a model?](./faq/evaluate-a-model.md)
- [What is the best validation metric for multi-class classification?](./faq/multiclass-metric.md)
- [What factors should I consider when choosing a predictive model technique?](./faq/choosing-technique.md)
- [What are the best toy datasets to help visualize and understand classifier behavior?](./faq/clf-behavior-data.md)
- [How do I select SVM kernels?](./faq/select_svm_kernels.md)
- [Interlude: Comparing and Computing Performance Metrics in Cross-Validation -- Imbalanced Class Problems and 3 Different Ways to Compute the F1 Score](./faq/computing-the-f1-score.md)

##### Logistic Regression

- [What is Softmax regression and how is it related to Logistic regression?](./faq/softmax_regression.md)
- [Why is logistic regression considered a linear model?](./faq/logistic_regression_linear.md)
- [What is the probabilistic interpretation of regularized logistic regression?](./faq/probablistic-logistic-regression.md)
- [Does regularization in logistic regression always results in better fit and better generalization?](./faq/regularized-logistic-regression-performance.md)
- [What is the major difference between naive Bayes and logistic regression?](./faq/naive-bayes-vs-logistic-regression.md)
- [What exactly is the ""softmax and the multinomial logistic loss"" in the context of machine learning?](./faq/softmax.md)
- [What is the relation between Loigistic Regression and Neural Networks and when to use which?](./faq/logisticregr-neuralnet.md)
- [Logistic Regression: Why sigmoid function?](./faq/logistic-why-sigmoid.md)
- [Is there an analytical solution to Logistic Regression similar to the Normal Equation for Linear Regression?](./faq/logistic-analytical.md)


##### Neural Networks and Deep Learning

- [What is the difference between deep learning and usual machine learning?](./faq/difference-deep-and-normal-learning.md)
- [Can you give a visual explanation for the back propagation algorithm for neural networks?](./faq/visual-backpropagation.md)
- [Why did it take so long for deep networks to be invented?](./faq/inventing-deeplearning.md)
- [What are some good books/papers for learning deep learning?](./faq/deep-learning-resources.md)
- [Why are there so many deep learning libraries?](./faq/many-deeplearning-libs.md)
- [Why do some people hate neural networks/deep learning?](./faq/deeplearning-criticism.md)
- [How can I know if Deep Learning works better for a specific problem than SVM or random forest?](./faq/deeplearn-vs-svm-randomforest.md)
- [What is wrong when my neural network's error increases?](./faq/neuralnet-error.md)
- [How do I debug an artificial neural network algorithm?](./faq/nnet-debugging-checklist.md)
- [What is the difference between a Perceptron, Adaline, and neural network model?](./faq/diff-perceptron-adaline-neuralnet.md)
- [What is the basic idea behind the dropout technique?](./faq/dropout.md)


##### Other Algorithms for Supervised Learning

- [Why is Nearest Neighbor a Lazy Algorithm?](./faq/lazy-knn.md)

##### Unsupervised Learning

- [What are some of the issues with clustering?](./faq/issues-with-clustering.md)

##### Semi-Supervised Learning

- [What are the advantages of semi-supervised learning over supervised and unsupervised learning?](./faq/semi-vs-supervised.md)

##### Ensemble Methods

- [Is Combining Classifiers with Stacking Better than Selecting the Best One?](./faq/logistic-boosting.md)

##### Preprocessing, Feature Selection and Extraction

- [Why do we need to re-use training parameters to transform test data?](./faq/scale-training-test.md)
- [What are the different dimensionality reduction methods in machine learning?](./faq/dimensionality-reduction.md)
- [What is the difference between LDA and PCA for dimensionality reduction?](./faq/lda-vs-pca.md)
- [When should I apply data normalization/standardization?](./faq/when-to-standardize.md)
- [Does mean centering or feature scaling affect a Principal Component Analysis?](./faq/pca-scaling.md)
- [How do you attack a machine learning problem with a large number of features?](./faq/large-num-features.md)
- [What are some common approaches for dealing with missing data?](./faq/missing-data.md)
- [What is the difference between filter, wrapper, and embedded methods for feature selection?](./faq/feature_sele_categories.md)
- [Should data preparation/pre-processing step be considered one part of feature engineering? Why or why not?](./faq/dataprep-vs-dataengin.md)
- [Is a bag of words feature representation for text classification considered as a sparse matrix?](./faq/bag-of-words-sparsity.md)

##### Naive Bayes

- [Why is the Naive Bayes Classifier naive?](./faq/naive-naive-bayes.md)
- [What is the decision boundary for Naive Bayes?](./faq/naive-bayes-boundary.md)
- [Can I use Naive Bayes classifiers for mixed variable types?](./faq/naive-bayes-vartypes.md)
- [Is it possible to mix different variable types in Naive Bayes, for example, binary and continues features?](./naive-bayes-vartypes.md)

##### Other

- [What is Euclidean distance in terms of machine learning?](./faq/euclidean-distance.md)
- [When should one use median, as opposed to the mean or average?](./faq/median-vs-mean.md)

##### Programming Languages and Libraries for Data Science and Machine Learning

- [Is R used extensively today in data science?](./faq/r-in-datascience.md)
- [What is the main difference between TensorFlow and scikit-learn?](./faq/tensorflow-vs-scikitlearn.md)

<br>





### Questions about the Book

- [Can I use paragraphs and images from the book in presentations or my blog?](./faq/copyright.md)
- [How is this different from other machine learning books?](./faq/different.md)
- [Which version of Python was used in the code examples?](./faq/py2py3.md)
- [Which technologies and libraries are being used?](./faq/technologies.md)
- [Which book version/format would you recommend?](./faq/version.md)
- [Why did you choose Python for machine learning?](./faq/why-python.md)
- [Why do you use so many leading and trailing underscores in the code examples?](./faq/underscore-convention.md)
- [What is the purpose of the `return self` idioms in your code examples?](./faq/return_self_idiom.md)
- [Are there any prerequisites and recommended pre-readings?](./faq/prerequisites.md)
- [How can I apply SVM to categorical data?](./faq/svm_for_categorical.md)


## Contact

I am happy to answer questions! Just write me an [email](mailto:mail@sebastianraschka.com)
or consider asking the question on the [Google Groups Email List](https://groups.google.com/forum/#!forum/python-machine-learning-book).

If you are interested in keeping in touch, I have quite a lively twitter stream ([@rasbt](https://twitter.com/rasbt)) all about data science and machine learning. I also maintain a [blog](http://sebastianraschka.com/articles.html) where I post all of the things I am particularly excited about.
","This GitHub repository contains the code examples of the **1st Edition** of
Python Machine Learning book. Please refer to [this] repository instead. 400
pages rich in useful material just about everything you need to know to get
started with machine learning... from theory to the actual code that you can
directly put into action."
3087,Kotlin multiplatform / multi-format serialization,"# Kotlin multiplatform / multi-format reflectionless serialization

[![Kotlin Stable](https://kotl.in/badges/stable.svg)](https://kotlinlang.org/docs/components-stability.html)
[![JetBrains official project](https://jb.gg/badges/official.svg)](https://confluence.jetbrains.com/display/ALL/JetBrains+on+GitHub)
[![GitHub license](https://img.shields.io/badge/license-Apache%20License%202.0-blue.svg?style=flat)](http://www.apache.org/licenses/LICENSE-2.0)
[![TeamCity build](https://img.shields.io/teamcity/http/teamcity.jetbrains.com/s/KotlinTools_KotlinxSerialization_Ko.svg)](https://teamcity.jetbrains.com/viewType.html?buildTypeId=KotlinTools_KotlinxSerialization_Ko&guest=1)
[![Kotlin](https://img.shields.io/badge/kotlin-1.8.0-blue.svg?logo=kotlin)](http://kotlinlang.org)
[![Maven Central](https://img.shields.io/maven-central/v/org.jetbrains.kotlinx/kotlinx-serialization-core/1.5.0-RC)](https://search.maven.org/artifact/org.jetbrains.kotlinx/kotlinx-serialization-core/1.5.0-RC/pom)
[![KDoc link](https://img.shields.io/badge/API_reference-KDoc-blue)](https://kotlinlang.org/api/kotlinx.serialization/)
[![Slack channel](https://img.shields.io/badge/chat-slack-blue.svg?logo=slack)](https://kotlinlang.slack.com/messages/serialization/)

Kotlin serialization consists of a compiler plugin, that generates visitor code for serializable classes,
 runtime library with core serialization API and support libraries with various serialization formats.

* Supports Kotlin classes marked as `@Serializable` and standard collections.
* Provides [JSON](formats/README.md#JSON), [Protobuf](formats/README.md#ProtoBuf), [CBOR](formats/README.md#CBOR), [Hocon](formats/README.md#HOCON) and [Properties](formats/README.md#properties) formats.
* Complete multiplatform support: JVM, JS and Native.

## Table of contents

<!--- TOC -->

* [Introduction and references](#introduction-and-references)
* [Setup](#setup)
  * [Gradle](#gradle)
    * [Using the `plugins` block](#using-the-plugins-block)
    * [Using `apply plugin` (the old way)](#using-apply-plugin-the-old-way)
    * [Dependency on the JSON library](#dependency-on-the-json-library)
  * [Android](#android)
  * [Multiplatform (Common, JS, Native)](#multiplatform-common-js-native)
  * [Maven](#maven)
  * [Bazel](#bazel)

<!--- END -->

* **Additional links**
  * [Kotlin Serialization Guide](docs/serialization-guide.md)
  * [Full API reference](https://kotlinlang.org/api/kotlinx.serialization/)
  * [Submitting issues and PRs](CONTRIBUTING.md)
  * [Building this library](docs/building.md)

## Introduction and references

Here is a small example.

```kotlin
import kotlinx.serialization.*
import kotlinx.serialization.json.*

@Serializable 
data class Project(val name: String, val language: String)

fun main() {
    // Serializing objects
    val data = Project(""kotlinx.serialization"", ""Kotlin"")
    val string = Json.encodeToString(data)  
    println(string) // {""name"":""kotlinx.serialization"",""language"":""Kotlin""} 
    // Deserializing back into objects
    val obj = Json.decodeFromString<Project>(string)
    println(obj) // Project(name=kotlinx.serialization, language=Kotlin)
}
``` 

> You can get the full code [here](guide/example/example-readme-01.kt).

<!--- TEST_NAME ReadmeTest -->

<!--- TEST 
{""name"":""kotlinx.serialization"",""language"":""Kotlin""}
Project(name=kotlinx.serialization, language=Kotlin)
-->

**Read the [Kotlin Serialization Guide](docs/serialization-guide.md) for all details.**

You can find auto-generated documentation website on [kotlinlang.org](https://kotlinlang.org/api/kotlinx.serialization/).

## Setup

Kotlin serialization plugin is shipped with the Kotlin compiler distribution, and the IDEA plugin is bundled into the Kotlin plugin.

Using Kotlin Serialization requires Kotlin compiler `1.4.0` or higher.
Make sure you have the corresponding Kotlin plugin installed in the IDE, no additional plugins for IDE are required.

### Gradle

#### Using the `plugins` block

You can set up the serialization plugin with the Kotlin plugin using 
[Gradle plugins DSL](https://docs.gradle.org/current/userguide/plugins.html#sec:plugins_block):

Kotlin DSL:

```kotlin
plugins {
    kotlin(""jvm"") version ""1.8.0"" // or kotlin(""multiplatform"") or any other kotlin plugin
    kotlin(""plugin.serialization"") version ""1.8.0""
}
```       

Groovy DSL:

```gradle
plugins {
    id 'org.jetbrains.kotlin.multiplatform' version '1.8.0'
    id 'org.jetbrains.kotlin.plugin.serialization' version '1.8.0'
}
```

> Kotlin versions before 1.4.0 are not supported by the stable release of Kotlin serialization

#### Using `apply plugin` (the old way)

First, you have to add the serialization plugin to your classpath as the other [compiler plugins](https://kotlinlang.org/docs/reference/compiler-plugins.html):

Kotlin DSL:

```kotlin
buildscript {
    repositories { mavenCentral() }

    dependencies {
        val kotlinVersion = ""1.8.0""
        classpath(kotlin(""gradle-plugin"", version = kotlinVersion))
        classpath(kotlin(""serialization"", version = kotlinVersion))
    }
}
```

Groovy DSL:

```gradle
buildscript {
    ext.kotlin_version = '1.8.0'
    repositories { mavenCentral() }

    dependencies {
        classpath ""org.jetbrains.kotlin:kotlin-serialization:$kotlin_version""
    }
}
```

Then you can `apply plugin` (example in Groovy):

```gradle
apply plugin: 'kotlin' // or 'kotlin-multiplatform' for multiplatform projects
apply plugin: 'kotlinx-serialization'
```

#### Dependency on the JSON library

After setting up the plugin one way or another, you have to add a dependency on the serialization library.
Note that while the plugin has version the same as the compiler one, runtime library has different coordinates, repository and versioning.

Kotlin DSL:

```kotlin
repositories {
    mavenCentral()
}

dependencies {
    implementation(""org.jetbrains.kotlinx:kotlinx-serialization-json:1.5.0-RC"")
}
```

Groovy DSL:

```gradle
repositories {
    mavenCentral()
}

dependencies {
    implementation ""org.jetbrains.kotlinx:kotlinx-serialization-json:1.5.0-RC""
}
```

>We also provide `kotlinx-serialization-core` artifact that contains all serialization API but does not have bundled serialization format with it

### Android

By default, proguard rules are supplied with the library.
[These rules](rules/common.pro) keep serializers for _all_ serializable classes that are retained after shrinking,
so you don't need additional setup.

**However, these rules do not affect serializable classes if they have named companion objects.**

If you want to serialize classes with named companion objects, you need to add and edit rules below to your `proguard-rules.pro` configuration. 

Note that the rules for R8 differ depending on the [compatibility mode](https://r8.googlesource.com/r8/+/refs/heads/master/compatibility-faq.md) used.

<details>
<summary>Example of named companion rules for ProGuard and R8 compatibility mode</summary>

```proguard
# Serializer for classes with named companion objects are retrieved using `getDeclaredClasses`.
# If you have any, replace classes with those containing named companion objects.
-keepattributes InnerClasses # Needed for `getDeclaredClasses`.

-if @kotlinx.serialization.Serializable class
com.example.myapplication.HasNamedCompanion, # <-- List serializable classes with named companions.
com.example.myapplication.HasNamedCompanion2
{
    static **$* *;
}
-keepnames class <1>$$serializer { # -keepnames suffices; class is kept when serializer() is kept.
    static <1>$$serializer INSTANCE;
}
```
</details>


<details>
<summary>Example of named companion rules for R8 full mode</summary>

```proguard
# Serializer for classes with named companion objects are retrieved using `getDeclaredClasses`.
# If you have any, replace classes with those containing named companion objects.
-keepattributes InnerClasses # Needed for `getDeclaredClasses`.

-if @kotlinx.serialization.Serializable class
com.example.myapplication.HasNamedCompanion, # <-- List serializable classes with named companions.
com.example.myapplication.HasNamedCompanion2
{
    static **$* *;
}
-keepnames class <1>$$serializer { # -keepnames suffices; class is kept when serializer() is kept.
    static <1>$$serializer INSTANCE;
}

# Keep both serializer and serializable classes to save the attribute InnerClasses
-keepclasseswithmembers, allowshrinking, allowobfuscation, allowaccessmodification class
com.example.myapplication.HasNamedCompanion, # <-- List serializable classes with named companions.
com.example.myapplication.HasNamedCompanion2
{
    *;
}
```
</details>

In case you want to exclude serializable classes that are used, but never serialized at runtime,
you will need to write custom rules with narrower [class specifications](https://www.guardsquare.com/manual/configuration/usage).

### Multiplatform (Common, JS, Native)

Most of the modules are also available for Kotlin/JS and Kotlin/Native.
You can add dependency to the required module right to the common source set:
```gradle
commonMain {
    dependencies {
        // Works as common dependency as well as the platform one
        implementation ""org.jetbrains.kotlinx:kotlinx-serialization-json:$serialization_version""
    }
}
```
The same artifact coordinates can be used to depend on platform-specific artifact in platform-specific source-set.

### Maven

Ensure the proper version of Kotlin and serialization version:

```xml
<properties>
    <kotlin.version>1.8.0</kotlin.version>
    <serialization.version>1.5.0-RC</serialization.version>
</properties>
```

Add serialization plugin to Kotlin compiler plugin:

```xml
<build>
    <plugins>
        <plugin>
            <groupId>org.jetbrains.kotlin</groupId>
            <artifactId>kotlin-maven-plugin</artifactId>
            <version>${kotlin.version}</version>
            <executions>
                <execution>
                    <id>compile</id>
                    <phase>compile</phase>
                    <goals>
                        <goal>compile</goal>
                    </goals>
                </execution>
            </executions>
            <configuration>
                <compilerPlugins>
                    <plugin>kotlinx-serialization</plugin>
                </compilerPlugins>
            </configuration>
            <dependencies>
                <dependency>
                    <groupId>org.jetbrains.kotlin</groupId>
                    <artifactId>kotlin-maven-serialization</artifactId>
                    <version>${kotlin.version}</version>
                </dependency>
            </dependencies>
        </plugin>
    </plugins>
</build>
```

Add dependency on serialization runtime library:

```xml
<dependency>
    <groupId>org.jetbrains.kotlinx</groupId>
    <artifactId>kotlinx-serialization-json</artifactId>
    <version>${serialization.version}</version>
</dependency>
```

### Bazel

To setup the Kotlin compiler plugin for Bazel, follow [the
example](https://github.com/bazelbuild/rules_kotlin/tree/master/examples/plugin/src/serialization)
from the `rules_kotlin` repository.
","Using Kotlin Serialization requires Kotlin compiler `1.4.0 or higher. Make sure
you have the corresponding Kotlin plugin installed in the IDE, no additional
plugins for IDE are required. You can get the full code
[here](guide/example/example-readme-01.kt). You can find auto-generated
documentation website on [kotlinlang.org/api/Kotlinx.serialization/). The
serialization plugin is shipped with the Kotlin compilation distribution, and
the IDEA plugin is bundled into Kotlin."
597,OpenPrinting CUPS Sources,"OpenPrinting CUPS v2.4.2
========================

![Version](https://img.shields.io/github/v/release/openprinting/cups?include_prereleases)
![Apache 2.0](https://img.shields.io/github/license/openprinting/cups)
[![Build and Test](https://github.com/OpenPrinting/cups/workflows/Build%20and%20Test/badge.svg)](https://github.com/OpenPrinting/cups/actions/workflows/build.yml)
[![Coverity Scan](https://img.shields.io/coverity/scan/23806)](https://scan.coverity.com/projects/openprinting-cups)


Introduction
------------

OpenPrinting CUPS is the most current version of CUPS, a standards-based, open
source printing system for Linux® and other Unix®-like operating systems.  CUPS
supports printing to:

- [AirPrint™][1] and [IPP Everywhere™][2] printers,
- Network and local (USB) printers with Printer Applications, and
- Network and local (USB) printers with (legacy) PPD-based printer drivers.

CUPS provides the System V (""lp"") and Berkeley (""lpr"") command-line interfaces,
a configurable web interface, a C API, and common print filters, drivers, and
backends for printing.  The [cups-filters][3] project provides additional
filters and drivers.

CUPS is licensed under the Apache License Version 2.0 with an exception to allow
linking against GNU GPL2-only software.  See the files `LICENSE` and `NOTICE`
for more information.

> Note: Apple maintains a separate repository for the CUPS that ships with macOS
> and iOS at <https://github.com/apple/cups>.

[1]: https://support.apple.com/en-us/HT201311
[2]: https://www.pwg.org/ipp/everywhere.html
[3]: https://github.com/openprinting/cups-filters


Reading the Documentation
-------------------------

Initial documentation to get you started is provided in the root directory of
the CUPS sources:

- `CHANGES.md`: A list of changes in the current major release of CUPS.
- `CONTRIBUTING.md`: Guidelines for contributing to the CUPS project.
- `CREDITS.md`: A list of past contributors to the CUPS project.
- `DEVELOPING.md`: Guidelines for developing code for the CUPS project.
- `INSTALL.md`: Instructions for building and installing CUPS.
- `LICENSE`: The CUPS license agreement (Apache 2.0).
- `NOTICE`: Copyright notices and exceptions to the CUPS license agreement.
- `README.md`: This file.
- `REPORTING_ISSUES.md`: Instructions what information to provide when reporting an issue.

Once you have installed the software you can access the documentation (and a
bunch of other stuff) online at <http://localhost:631/> and using the `man`
command, for example `man cups`.

If you're having trouble getting that far, the documentation is located under
the `doc/help` and `man` directories.

*Please read the documentation before asking questions.*


Setting Up Printers
-------------------

CUPS includes a web-based administration tool that allows you to manage
printers, classes, and jobs on your server.  Open <http://localhost:631/admin/>
in your browser to access the printer administration tools.  You will be asked
for the administration password (root or any other user in the ""sys"", ""system"",
""root"", ""admin"", or ""lpadmin"" group on your system) when performing any
administrative function.

The `lpadmin` command is used to manage printers from the command-line.  For
example, the following command creates a print queue called ""myprinter"" for an
IPP Everywhere printer at address ""11.22.33.44"":

    lpadmin -p myprinter -E -v ""ipp://11.22.33.44/ipp/print"" -m everywhere

The `-p` option specifies the printer name.  The `-E` option enables the printer
and accepts new print jobs immediately.  The `-v` option specifies the *device
URI* for the printer, which tells CUPS how to communicate with the printer.  And
the `-m` option specifies the model (driver) to use, in this case the IPP
Everywhere (""everywhere"") driver that is used for AirPrint and IPP Everywhere
printers as well as shared printers and printers supported through Printer
Applications.

Legacy printers are supported using PPD (PostScript Printer Description) files
that describe printer capabilities and driver programs needed for each printer.
CUPS includes several sample PPD files for common legacy printers:

   Driver                       | PPD Name
   -----------------------------|------------------------------
   Dymo Label Printers          | drv:///sample.drv/dymo.ppd
   Intellitech Intellibar       | drv:///sample.drv/intelbar.ppd
   EPSON 9-pin Series           | drv:///sample.drv/epson9.ppd
   EPSON 24-pin Series          | drv:///sample.drv/epson24.ppd
   Generic PCL Laser Printer    | drv:///sample.drv/generpcl.ppd
   Generic PostScript Printer   | drv:///sample.drv/generic.ppd
   HP DeskJet Series            | drv:///sample.drv/deskjet.ppd
   HP LaserJet Series           | drv:///sample.drv/laserjet.ppd
   OKIDATA 9-Pin Series         | drv:///sample.drv/okidata9.ppd
   OKIDATA 24-Pin Series        | drv:///sample.drv/okidat24.ppd
   Zebra CPCL Label Printer     | drv:///sample.drv/zebracpl.ppd
   Zebra EPL1 Label Printer     | drv:///sample.drv/zebraep1.ppd
   Zebra EPL2 Label Printer     | drv:///sample.drv/zebraep2.ppd
   Zebra ZPL Label Printer      | drv:///sample.drv/zebra.ppd

The sample drivers provide basic printing capabilities, but generally do not
exercise the full potential of the printers or CUPS.  Other drivers provide
greater printing capabilities.

You can run the `lpinfo -m` command to list all of the available drivers:

    lpinfo -m

Similarly, the `lpinfo -v` command lists the available printers and their device
URIs:

    lpinfo -v

Once you know the device URI and driver name, add the printer using the
`lpadmin` command:

    lpadmin -p PRINTER-NAME -E -v ""DEVICE-URI"" -m DRIVER-NAME


Printing Files
--------------

CUPS provides both the System V `lp` and Berkeley `lpr` commands for printing:

    lp FILENAME
    lpr FILENAME

Both the `lp` and `lpr` commands support printing options:

    lp -o media=A4 -o resolution=600dpi FILENAME
    lpr -o media=A4 -o resolution=600dpi FILENAME

CUPS recognizes many types of images files as well as PDF, PostScript, and text
files, so you can print those files directly rather than through an application.

If you have an application that generates output specifically for your printer
then you need to use the `-oraw` or `-l` options:

    lp -o raw FILENAME
    lpr -l FILENAME

This will prevent the filters from misinterpreting your print file.


Legal Stuff
-----------

Copyright © 2020-2023 by OpenPrinting

Copyright © 2007-2020 by Apple Inc.

Copyright © 1997-2007 by Easy Software Products.

CUPS is provided under the terms of the Apache License, Version 2.0 with
exceptions for GPL2/LGPL2 software.  A copy of this license can be found in the
file `LICENSE`.  Additional legal information is provided in the file `NOTICE`.

Unless required by applicable law or agreed to in writing, software distributed
under the License is distributed on an ""AS IS"" BASIS, WITHOUT WARRANTIES OR
CONDITIONS OF ANY KIND, either express or implied.  See the License for the
specific language governing permissions and limitations under the License.
","OpenPrinting CUPS is a standards-based, open-source printing system for Linux
and other Unix-like operating systems. CUPS includes a web-based administration
tool that allows you to manage printers, classes, and jobs on your server. The
software is licensed under the Apache License Version 2.0."
2718,A cryptographically verifiable code review system for the cargo (Rust) package manager.,cargo-crev/README.md,"summarize: cargo-crev/README.md Cargo-Crev is an open-source cargo container
system. Cargo- Crev is designed to be used in a variety of ways. It can be used
to transport cargo, as well as data."
2919,This is Andrew NG Coursera Handwritten Notes.,"# Andrew NG Notes Collection

**This is the first course of the deep learning specialization at [Coursera](https://www.coursera.org/specializations/deep-learning) which is moderated by [DeepLearning.ai](http://deeplearning.ai/). The course is taught by Andrew Ng.**

**<Span style=""color:red;"">Andrew NG Machine Learning Notebooks  :</span>**  [**Reading**](https://github.com/ashishpatel26/Andrew-NG-Notes/tree/master/Machine%20Learning%20notebooks%20By%20Andrew%20NG)   

**<Span style=""color:red;"">Deep learning Specialization Notes in One pdf :</span>**  [**Reading**](https://github.com/ashishpatel26/Andrew-NG-Notes/blob/master/Deep%20learning%20by%20AndrewNG%20Tutorial%20%20Notes.pdf)

| **Sr No** | **Article Reading**                                          |
| --------- | :----------------------------------------------------------- |
| **1.**    | **[Neural Network Deep Learning](https://github.com/ashishpatel26/Andrew-NG-Notes/blob/master/andrewng-p-1-neural-network-deep-learning.md)** |
| **2.**    | **[Improving Deep learning Network](https://github.com/ashishpatel26/Andrew-NG-Notes/blob/master/andrewng-p-2-improving-deep-learning-network.md)** |
| **3.**    | **[Structure of ML Projects](https://github.com/ashishpatel26/Andrew-NG-Notes/blob/master/andrewng-p-3-structuring-ml-projects.md)** |
| **4.**    | **[Convolutions Neural Network](https://github.com/ashishpatel26/Andrew-NG-Notes/blob/master/andrewng-p-4-convolutional-neural-network.md)** |
| **5.**    | **[Sequence Models](https://github.com/ashishpatel26/Andrew-NG-Notes/blob/master/andrewng-p-5-sequence-models.md)** |

| Sr. No | MOOC LECTURE LINK                                            |
| ------ | ------------------------------------------------------------ |
| 1.     | [**Machine learning by Andrew-NG**](https://www.youtube.com/playlist?list=PLLssT5z_DsK-h9vYZkQkYNWcItqhlRJLN) |
|        | **DEEP LEARNING SERIES**                                     |
| 1.     | [**Neural Network and Deep Learning**](https://www.youtube.com/playlist?list=PLkDaE6sCZn6Ec-XTbcX1uRg2_u4xOEky0) |
| 2.     | [**Improving deep neural networks: hyperparameter tuning, regularization and optimization**](https://www.youtube.com/playlist?list=PLkDaE6sCZn6Hn0vK8co82zjQtt3T2Nkqc) |
| 3.     | [**Structuring Machine Learning Projects**](https://www.youtube.com/playlist?list=PLkDaE6sCZn6E7jZ9sN_xHwSHOdjUxUW_b) |
| 4.     | [**Convolution Neural Network**](https://www.youtube.com/playlist?list=PLkDaE6sCZn6Gl29AoE31iwdVwSG-KnDzF) |
| 5.     | [**Sequence Models**](https://www.youtube.com/playlist?list=PLkDaE6sCZn6F6wUI9tvS_Gw1vaFAx6rd6) |
| 6.     | [**CS230: Deep Learning \| Autumn 2018**](https://www.youtube.com/playlist?list=PLoROMvodv4rOABXSygHTsbvUz4G_YQhOb ) |

## [**1.Neural Network Deep Learning**](https://github.com/ashishpatel26/Andrew-NG-Notes/blob/master/andrewng-p-1-neural-network-deep-learning.md)   

## ![](https://systweak1.vo.llnwd.net/content/wp/systweakblogsnew/uploads_new/2018/03/hidden-layers-in-network.gif)

* **This Notes Give you brief introduction about :** 
  * [**What is neural network? How it's work?**](https://github.com/ashishpatel26/Andrew-NG-Notes/blob/master/andrewng-p-1-neural-network-deep-learning.md#what-is-a-neural-network-nn)
  * [**Supervised Learning using Neural Network**](https://github.com/ashishpatel26/Andrew-NG-Notes/blob/master/andrewng-p-1-neural-network-deep-learning.md#neural-networks-basics)
  * [**Shallow Neural Network Design**](https://github.com/ashishpatel26/Andrew-NG-Notes/blob/master/andrewng-p-1-neural-network-deep-learning.md#shallow-neural-networks)
  * [**Deep Neural Network**](https://github.com/ashishpatel26/Andrew-NG-Notes/blob/master/andrewng-p-1-neural-network-deep-learning.md#deep-neural-networks)
*  **Notebooks** :
  * Week1 - [**Introduction to deep learning**](https://github.com/ashishpatel26/Andrew-NG-Notes/tree/master/Deep%20Learning%20Notebooks%20by%20Andrew%20NG/Convolutional%20Neural%20Networks/Week1)
  * Week2 - [**Neural Networks Basics**](https://nbviewer.jupyter.org/github/ashishpatel26/Andrew-NG-Notes/blob/master/Deep%20Learning%20Notebooks%20by%20Andrew%20NG/Neural%20Networks%20and%20Deep%20Learning/Logistic%20Regression%20with%20a%20Neural%20Network%20mindset.ipynb)
  * Week3 - [**Shallow neural networks**](https://nbviewer.jupyter.org/github/ashishpatel26/Andrew-NG-Notes/blob/master/Deep%20Learning%20Notebooks%20by%20Andrew%20NG/Neural%20Networks%20and%20Deep%20Learning/Logistic%20Regression%20with%20a%20Neural%20Network%20mindset.ipynb)
  * Week4 - [**Deep Neural Networks**](https://nbviewer.jupyter.org/github/ashishpatel26/Andrew-NG-Notes/blob/master/Deep%20Learning%20Notebooks%20by%20Andrew%20NG/Neural%20Networks%20and%20Deep%20Learning/Building%20your%20Deep%20Neural%20Network%20-%20Step%20by%20Step.ipynb) 

## [**2 Improving Deep learning Network**](https://github.com/ashishpatel26/Andrew-NG-Notes/blob/master/andrewng-p-2-improving-deep-learning-network.md)

## ![](https://i.pinimg.com/originals/63/62/8f/63628f546ad55fd31091e23c623cb9f5.gif)



* **This Notes Give you introduction about :** 
  * [**Practical aspects of Deep Learning**](https://github.com/ashishpatel26/Andrew-NG-Notes/blob/master/andrewng-p-2-improving-deep-learning-network.md#practical-aspects-of-deep-learning)
  * [**Optimization algorithms**](https://github.com/ashishpatel26/Andrew-NG-Notes/blob/master/andrewng-p-2-improving-deep-learning-network.md#optimization-algorithms)
  * [**Hyperparameter tuning, Batch Normalization and Programming Frameworks**](https://github.com/ashishpatel26/Andrew-NG-Notes/blob/master/andrewng-p-2-improving-deep-learning-network.md#hyperparameter-tuning-batch-normalization-and-programming-frameworks)
* **Notebooks**:
  * Week1 - [**Practical aspects of Deep Learning**](https://github.com/ashishpatel26/Andrew-NG-Notes/tree/master/Deep%20Learning%20Notebooks%20by%20Andrew%20NG/Improving%20Deep%20Neural%20Networks%20Hyperparameter%20tuning%2C%20Regularization%20and%20Optimization)
       - Setting up your Machine Learning Application
    - Regularizing your neural network
    - Setting up your optimization problem
  * Week2 - [**Optimization algorithms**](https://nbviewer.jupyter.org/github/ashishpatel26/Andrew-NG-Notes/blob/master/Deep%20Learning%20Notebooks%20by%20Andrew%20NG/Improving%20Deep%20Neural%20Networks%20Hyperparameter%20tuning%2C%20Regularization%20and%20Optimization/Optimization%20methods.ipynb)
  * Week3 - [**Hyperparameter tuning, Batch Normalization and Programming Frameworks**](https://github.com/ashishpatel26/Andrew-NG-Notes/tree/master/Deep%20Learning%20Notebooks%20by%20Andrew%20NG/Improving%20Deep%20Neural%20Networks%20Hyperparameter%20tuning%2C%20Regularization%20and%20Optimization)

## [**3.Structure ML Projects**](https://github.com/ashishpatel26/Andrew-NG-Notes/blob/master/andrewng-p-3-structuring-ml-projects.md)

![](https://i.pinimg.com/originals/9b/fa/97/9bfa978a4cf40fe2cdf8c710deb9b6f9.png)



* **In This Notes, you can learn about How to Structure Machine Learning Project:**
  * [**Why ML Structure?**](https://github.com/ashishpatel26/Andrew-NG-Notes/blob/master/andrewng-p-3-structuring-ml-projects.md#ml-strategy-1)
  * [**Error Analysis**](https://github.com/ashishpatel26/Andrew-NG-Notes/blob/master/andrewng-p-3-structuring-ml-projects.md#ml-strategy-2)
* **Notebooks:**
  * Week1 - [**Introduction to ML Strategy**](https://github.com/ashishpatel26/Andrew-NG-Notes/blob/master/Deep%20Learning%20Notebooks%20by%20Andrew%20NG/Structuring%20Machine%20Learning%20Projects/Week%201%20Quiz%20-%20Bird%20recognition%20in%20the%20city%20of%20Peacetopia%20(case%20study).md)
       - Setting up your goal
    - Comparing to human-level performance
  * Week2 - [**ML Strategy (2)**](https://github.com/ashishpatel26/Andrew-NG-Notes/blob/master/Deep%20Learning%20Notebooks%20by%20Andrew%20NG/Structuring%20Machine%20Learning%20Projects/Week%202%20Quiz%20-%20Autonomous%20driving%20(case%20study).md)
       - Error Analysis
    - Mismatched training and dev/test set
    - Learning from multiple tasks
    - End-to-end deep learning

## [**4.Convolution Neural Network**](https://github.com/ashishpatel26/Andrew-NG-Notes/blob/master/andrewng-p-4-convolutional-neural-network.md)

* **Matrix Multiplication Between Image and Kernel Known as *Convolution Operation***

![](https://i.stack.imgur.com/9OZKF.gif)



![](https://cdn-images-1.medium.com/max/600/1*GdxHFaUDbvTXJreKg3S8SQ.gif)







![](https://www.guru99.com/images/tensorflow/082918_1325_ConvNetConv9.gif)



* **In This Notes, you can learn about Brief architecture CNN:**
  * [**Foundations of CNNs**](https://github.com/ashishpatel26/Andrew-NG-Notes/blob/master/andrewng-p-4-convolutional-neural-network.md#foundations-of-cnns)
  * [**Deep convolutional models: case studies**](https://github.com/ashishpatel26/Andrew-NG-Notes/blob/master/andrewng-p-4-convolutional-neural-network.md#deep-convolutional-models-case-studies)
  * [**Object detection**](https://github.com/ashishpatel26/Andrew-NG-Notes/blob/master/andrewng-p-4-convolutional-neural-network.md#object-detection)
  * [**Special applications: Face recognition & Neural style transfer**](https://github.com/ashishpatel26/Andrew-NG-Notes/blob/master/andrewng-p-4-convolutional-neural-network.md#special-applications-face-recognition--neural-style-transfer)
*  **Notebooks :** 
  * Week1 - [**Foundations of Convolutional Neural Networks**](https://nbviewer.jupyter.org/github/ashishpatel26/Andrew-NG-Notes/blob/master/Deep%20Learning%20Notebooks%20by%20Andrew%20NG/Convolutional%20Neural%20Networks/Week1/Convolution%20model%20-%20Step%20by%20Step.ipynb)
  * Week2 - [**Deep convolutional models: case studies**](https://nbviewer.jupyter.org/github/ashishpatel26/Andrew-NG-Notes/blob/master/Deep%20Learning%20Notebooks%20by%20Andrew%20NG/Convolutional%20Neural%20Networks/Week2/ResNets/Residual%20Networks.ipynb) 
    - **Papers for read:**  
      - [**ImageNet Classification with Deep Convolutional Neural Networks**](https://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf)
      - [**Very Deep Convolutional Networks For Large-Scale Image Recognition**](https://arxiv.org/pdf/1409.1556.pdf)
  * Week3 - [**Object detection**](https://nbviewer.jupyter.org/github/ashishpatel26/Andrew-NG-Notes/blob/master/Deep%20Learning%20Notebooks%20by%20Andrew%20NG/Convolutional%20Neural%20Networks/Week3/Car%20detection%20for%20Autonomous%20Driving/Autonomous%20driving%20application%20-%20Car%20detection.ipynb) 
    - **Papers for read:** 
      - [**You Only Look Once: Unified, Real-Time Object Detection**](https://arxiv.org/pdf/1506.02640.pdf)
      - [**YOLO**](https://arxiv.org/pdf/1612.08242.pdf)
  * Week4 - [**Special applications: Face recognition & Neural style transfer**](https://github.com/ashishpatel26/Andrew-NG-Notes/tree/master/Deep%20Learning%20Notebooks%20by%20Andrew%20NG/Convolutional%20Neural%20Networks/Week4) 
    - **Papers for read:** 
      - [**DeepFace**](https://www.cs.toronto.edu/~ranzato/publications/taigman_cvpr14.pdf) ([**Notebook**](https://nbviewer.jupyter.org/github/ashishpatel26/Andrew-NG-Notes/blob/master/Deep%20Learning%20Notebooks%20by%20Andrew%20NG/Convolutional%20Neural%20Networks/Week4/Face%20Recognition/Face%20Recognition%20for%20the%20Happy%20House.ipynb))
      - [**FaceNet**](https://www.cv-foundation.org/openaccess/content_cvpr_2015/papers/Schroff_FaceNet_A_Unified_2015_CVPR_paper.pdf)
      - [**Neural Style Transfer**](https://nbviewer.jupyter.org/github/ashishpatel26/Andrew-NG-Notes/blob/master/Deep%20Learning%20Notebooks%20by%20Andrew%20NG/Convolutional%20Neural%20Networks/Week4/Neural%20Style%20Transfer/Art%20Generation%20with%20Neural%20Style%20Transfer.ipynb)

## [**5.Sequence Models**](https://github.com/ashishpatel26/Andrew-NG-Notes/blob/master/andrewng-p-5-sequence-models.md)

![](https://3.bp.blogspot.com/-3Pbj_dvt0Vo/V-qe-Nl6P5I/AAAAAAAABQc/z0_6WtVWtvARtMk0i9_AtLeyyGyV6AI4wCLcB/s1600/nmt-model-fast.gif)

---

* **Vanila RNN**

  ![](https://cdn-images-1.medium.com/max/880/1*xn5kA92_J5KLaKcP7BMRLA.gif)

* **LSTM**

![](https://cdn-images-1.medium.com/max/880/1*goJVQs-p9kgLODFNyhl9zA.gif)

* **GRU**

![](https://cdn-images-1.medium.com/max/880/1*FpRS0C3EHQnELVaWRvb8bg.gif)

* **In This Section, you can learn about Sequence to Sequence Learning**

  * [**Recurrent Neural Networks**](https://github.com/ashishpatel26/Andrew-NG-Notes/blob/master/andrewng-p-5-sequence-models.md#recurrent-neural-networks)
  * [**Natural Language Processing & Word Embeddings**](https://github.com/ashishpatel26/Andrew-NG-Notes/blob/master/andrewng-p-5-sequence-models.md#natural-language-processing--word-embeddings)
  * [**Sequence models & Attention mechanism**](https://github.com/ashishpatel26/Andrew-NG-Notes/blob/master/andrewng-p-5-sequence-models.md#sequence-models--attention-mechanism)

* **Notebooks:**

  * Week1 - [**Recurrent Neural Networks**](https://nbviewer.jupyter.org/github/ashishpatel26/Andrew-NG-Notes/blob/master/Deep%20Learning%20Notebooks%20by%20Andrew%20NG/Sequence%20Models/Week1/Building%20a%20Recurrent%20Neural%20Network%20-%20Step%20by%20Step/Building%20a%20Recurrent%20Neural%20Network%20-%20Step%20by%20Step.ipynb)
  * Week2 - [**Natural Language Processing & Word Embeddings**](https://github.com/ashishpatel26/Deep-Learning-Coursera/tree/master/Sequence%20Models/Week2)
  * Week3 - [**Sequence models & Attention mechanism**](https://github.com/ashishpatel26/Deep-Learning-Coursera/tree/master/Sequence%20Models/Week3)

  

**Thanks for Reading....Happy Learning...!!!**
","This is the first course of the deep learning specialization at [Coursera]. It
is moderated by [DeepLearning.ai](http://deeplearning.ai/). The course is taught
by Andrew Ng.summarize: # Andrew NG Notes Collection."
1243,Vulkan best practice for mobile developers,"<!--
- Copyright (c) 2019, Arm Limited and Contributors
-
- SPDX-License-Identifier: MIT
-
- Permission is hereby granted, free of charge,
- to any person obtaining a copy of this software and associated documentation files (the ""Software""),
- to deal in the Software without restriction, including without limitation the rights to
- use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software,
- and to permit persons to whom the Software is furnished to do so, subject to the following conditions:
-
- The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.
-
- THE SOFTWARE IS PROVIDED ""AS IS"", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED,
- INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
- FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.
- IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY,
- WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
- OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.
-
-->

# Vulkan Best Practice for Mobile Developers <!-- omit in toc -->

![Vulkan Best Practice for Mobile Developers banner](banner.jpg)

***
This project has been donated to Khronos Group. Development has now moved to:

- [Vulkan-Samples](https://github.com/khronosGroup/Vulkan-samples)

Please open issues and pull requests there.
***

## Contents <!-- omit in toc -->

- [Introduction](#introduction)
  - [Goals](#goals)
- [Tutorials](#tutorials)
- [Setup](#setup)
- [Build](#build)
  - [Supported Platforms](#supported-platforms)
- [Usage](#usage)
- [Testing](#tests)
- [License](#license)
  - [Trademarks](#trademarks)
- [Contributions](#contributions)
- [Related resources](#related-resources)

## Introduction

The Vulkan Best Practice for Mobile Developers is collection of resources to help you develop optimized Vulkan applications for mobile platforms.

### Goals
- Create a collection of resources that demonstrate best-practice recommendations in Vulkan
- Create tutorials that explain the implementation of best-practices and include performance analysis guides
- Create a framework that can be used as reference material and also as a sandbox for advanced experimentation with Vulkan

> **Disclaimer:** This project covers advanced Vulkan concepts. If you are new to Vulkan here are a few links to get you started:
> - [Beginners Guide to Vulkan](https://www.khronos.org/blog/beginners-guide-to-vulkan)
> - [Get Started in Vulkan](https://vulkan-tutorial.com/)

## Tutorials
- **Project Basics**
  - [Controls](./docs/misc.md#controls)
  - [Debug window](./docs/misc.md#debug-window)
  - [Create a Sample](./docs/create_sample.md)
- **Vulkan Essentials**  
  - [How does Vulkan compare to OpenGL ES? What should you expect when targeting Vulkan?](./samples/vulkan_basics.md)
- **Vulkan Swapchains**  
  - [Appropriate use of N-buffering](./samples/performance/swapchain_images/swapchain_images_tutorial.md)
  - [Appropriate use of surface rotation](./samples/performance/surface_rotation/surface_rotation_tutorial.md)
- **Pipelines**
  - [Use of pipeline caches to avoid startup latency](./samples/performance/pipeline_cache/pipeline_cache_tutorial.md)
  - [Utilizing Specialization Constants](./samples/performance/specialization_constants/specialization_constants_tutorial.md)
- **Descriptors**
  - [Descriptor and buffer management](./samples/performance/descriptor_management/descriptor_management_tutorial.md)
- **Render Passes**
  - [Appropriate use of load/store operations, and use of transient attachments](./samples/performance/render_passes/render_passes_tutorial.md)
  - [Choosing the correct layout when transitioning images](./samples/performance/layout_transitions/layout_transitions_tutorial.md)
- **Render Subpasses**
  - [Benefits of subpasses over multiple render passes, use of transient attachments, and G-buffer recommended size](./samples/performance/render_subpasses/render_subpasses_tutorial.md)
- **Workload Synchronization**
  - [Using pipeline barriers efficiently](./samples/performance/pipeline_barriers/pipeline_barriers_tutorial.md)
  - [How to synchronize back to the CPU and avoid stalling](./samples/performance/wait_idle/wait_idle_tutorial.md)
- **Command Buffers**
  - [Allocation and management of command buffers](./samples/performance/command_buffer_usage/command_buffer_usage_tutorial.md#Recycling-strategies)
  - [Multi-threaded recording with secondary command buffers](./samples/performance/command_buffer_usage/command_buffer_usage_tutorial.md#Multi-threaded-recording)
- **AFBC**
  - [Appropriate use of AFBC](./samples/performance/afbc/afbc_tutorial.md)
- **Misc**
  - [Driver version](./docs/misc.md#driver-version)
  - [Memory limits](./docs/memory_limits.md)
  - [Vulkan FAQ](./docs/faq.md)

## Setup

Clone the repo with submodules using the following command:

```
git clone --recurse-submodules https://github.com/ARM-software/vulkan_best_practice_for_mobile_developers.git
cd vulkan_best_practice_for_mobile_developers
```

Follow build instructions for your platform below.

## Build

### Supported Platforms
- Windows - [Build Guide](./docs/build.md#windows ""Windows Build Guide"")
- Linux - [Build Guide](./docs/build.md#linux ""Linux Build Guide"")
- macOS - [Build Guide](./docs/build.md#macos ""macOS Build Guide"")
- Android - [Build Guide](./docs/build.md#android ""Android Build Guide"")

## Usage

The following shows some example command line usage on how to configure and run the Vulkan Best Practices.

```
# Run Swapchain Images sample
vulkan_best_practice swapchain_images

# Run AFBC sample in benchmark mode for 5000 frames
vulkan_best_practice --sample afbc --benchmark 5000

# Run bonza test offscreen
vulkan_best_practice --test bonza --hide

# Run all the performance samples
vulkan_best_practice --batch performance
```


## Tests

- System Test - [Usage Guide](docs/testing.md#system-test ""System Test Guide"")
- Generate Sample - [Usage Guide](docs/testing.md#generate-sample-test ""Generate Sample Test Guide"")


## License

See [LICENSE](LICENSE).

This project has some third-party dependencies, each of which may have independent licensing:

- [astc-encoder](https://github.com/ARM-software/astc-encoder): ASTC Evaluation Codec
- [CTPL](https://github.com/vit-vit/CTPL): Thread Pool Library
- [docopt](https://github.com/docopt/docopt.cpp): A C++11 port of the Python argument parsing library
- [glfw](https://github.com/glfw/glfw): A multi-platform library for OpenGL, OpenGL ES, Vulkan, window and input
- [glm](https://github.com/g-truc/glm): OpenGL Mathematics
- [glslang](https://github.com/KhronosGroup/glslang): Shader front end and validator
- [dear imgui](https://github.com/ocornut/imgui): Immediate Mode Graphical User Interface
  - [dear imgui shaders](https://github.com/SaschaWillems/Vulkan/tree/master/data/shaders/imgui): GLSL shaders for dear imgui
- [HWCPipe](https://github.com/ARM-software/HWCPipe): Interface to mobile Hardware Counters
- [KTX-Software](https://github.com/KhronosGroup/KTX-Software): Khronos Texture Library and Tools
- [spdlog](https://github.com/gabime/spdlog): Fast C++ logging library
- [SPIRV-Cross](https://github.com/KhronosGroup/SPIRV-Cross): Parses and converts SPIR-V to other shader languages
- [stb](https://github.com/nothings/stb): Single-file public domain (or MIT licensed) libraries
- [tinygltf](https://github.com/syoyo/tinygltf): Header only C++11 tiny glTF 2.0 library
  - [nlohmann json](https://github.com/nlohmann/json): C++ JSON Library (included by [tinygltf](https://github.com/syoyo/tinygltf))
- [vma](https://github.com/GPUOpen-LibrariesAndSDKs/VulkanMemoryAllocator): Vulkan Memory Allocator
- [volk](https://github.com/zeux/volk): Meta loader for Vulkan API
- [vulkan](https://github.com/KhronosGroup/Vulkan-Docs): Sources for the formal documentation of the Vulkan API

This project uses the following 3D models. Each one has its own licence.

- Sponza: [CC BY 3.0 license](https://creativecommons.org/licenses/by/3.0/) with the following modifications:
   - All textures are converted to ASTC in .ktx format.
   - Converted to gltf using [Blender exporter](https://github.com/KhronosGroup/glTF-Blender-IO).
- Bonza: [MIT license](LICENSE)
- Space Module: [MIT license](LICENSE)

Sponza model downloaded from Morgan McGuire's [Computer Graphics Archive](https://casual-effects.com/data).

Fonts downloaded from [Google Fonts](https://fonts.google.com), under license [Apache 2.0](http://www.apache.org/licenses/LICENSE-2.0)

PBR References:

- [Frostbite to PBR course notes](https://seblagarde.files.wordpress.com/2015/07/course_notes_moving_frostbite_to_pbr_v32.pdf)
- [Learn OpenGL](https://learnopengl.com/PBR/Theory)


### Trademarks

Vulkan is a registered trademark of the Khronos Group Inc.

## Contributions

All contributions are accepted under the same [LICENSE](LICENSE).

## Related resources

- [Mali GPU Best Practices](https://developer.arm.com/solutions/graphics/developer-guides/advanced-guides/mali-gpu-best-practices): A document with recommendations for efficient API usage
- [PerfDoc](https://github.com/ARM-software/perfdoc): A Vulkan layer which aims to validate applications against Mali GPU Best Practices
","The Vulkan Best Practice for Mobile Developers is a collection of resources to
help you develop optimized Vulkan applications for mobile platforms. This
project covers advanced Vulkan concepts. It is intended to be a framework that
can be used as reference material and also as a sandbox for advanced
experimentation with Vulkan. The project is open-source and can be downloaded
from the GitHub repository. It has been written in C, C++, C#, Python, Ruby,
iOS, Android, Windows, and Mac OS X. There are no plans to add any additional
features."
2992,Web component JS frameworks overview by their syntax and features,"![Component Party 🎉](.github/banner.webp)

> Web component JS frameworks quick overview by their syntax and features

**Website: <https://component-party.dev>**

## 🤔 Why ?

Many JS developers don't have a good overview of every existing JS framework with their own syntax and features.
How do we solve this ? Developers love having framework overview by examples. It's a quick introduction before going deeper.

## 🔥 Progression

<details>
<summary>
<img width=""18"" height=""18"" src=""public/framework/svelte.svg"" />
<b>Svelte</b>
<img src=""https://us-central1-progress-markdown.cloudfunctions.net/progress/100"" /></summary>

- [x] Reactivity
  - [x] Declare state
  - [x] Update state
  - [x] Computed state
- [x] Templating
  - [x] Minimal template
  - [x] Styling
  - [x] Loop
  - [x] Event click
  - [x] Dom ref
  - [x] Conditional
- [x] Lifecycle
  - [x] On mount
  - [x] On unmount
- [x] Component composition
  - [x] Props
  - [x] Emit to parent
  - [x] Slot
  - [x] Slot fallback
  - [x] Context
- [x] Form input
  - [x] Input text
  - [x] Checkbox
  - [x] Radio
  - [x] Select
- [x] Webapp features
  - [x] Render app
  - [x] Fetch data
  - [x] Router link
  - [x] Routing

</details><details>
        <summary>
            <img width=""18"" height=""18"" src=""public/framework/react.svg"" />
            <b>React</b>
            <img src=""https://us-central1-progress-markdown.cloudfunctions.net/progress/100"" /></summary>

- [x] Reactivity
  - [x] Declare state
  - [x] Update state
  - [x] Computed state
- [x] Templating
  - [x] Minimal template
  - [x] Styling
  - [x] Loop
  - [x] Event click
  - [x] Dom ref
  - [x] Conditional
- [x] Lifecycle
  - [x] On mount
  - [x] On unmount
- [x] Component composition
  - [x] Props
  - [x] Emit to parent
  - [x] Slot
  - [x] Slot fallback
  - [x] Context
- [x] Form input
  - [x] Input text
  - [x] Checkbox
  - [x] Radio
  - [x] Select
- [x] Webapp features
  - [x] Render app
  - [x] Fetch data
  - [x] Router link
  - [x] Routing

</details><details>
        <summary>
            <img width=""18"" height=""18"" src=""public/framework/vue.svg"" />
            <b>Vue 3</b>
            <img src=""https://us-central1-progress-markdown.cloudfunctions.net/progress/96"" /></summary>

- [x] Reactivity
  - [x] Declare state
  - [x] Update state
  - [x] Computed state
- [x] Templating
  - [x] Minimal template
  - [x] Styling
  - [x] Loop
  - [x] Event click
  - [x] Dom ref
  - [x] Conditional
- [x] Lifecycle
  - [x] On mount
  - [x] On unmount
- [ ] Component composition
  - [x] Props
  - [x] Emit to parent
  - [x] Slot
  - [x] Slot fallback
  - [ ] Context
- [x] Form input
  - [x] Input text
  - [x] Checkbox
  - [x] Radio
  - [x] Select
- [x] Webapp features
  - [x] Render app
  - [x] Fetch data
  - [x] Router link
  - [x] Routing

</details><details>
        <summary>
            <img width=""18"" height=""18"" src=""public/framework/solid.svg"" />
            <b>SolidJS</b>
            <img src=""https://us-central1-progress-markdown.cloudfunctions.net/progress/92"" /></summary>

- [x] Reactivity
  - [x] Declare state
  - [x] Update state
  - [x] Computed state
- [x] Templating
  - [x] Minimal template
  - [x] Styling
  - [x] Loop
  - [x] Event click
  - [x] Dom ref
  - [x] Conditional
- [x] Lifecycle
  - [x] On mount
  - [x] On unmount
- [ ] Component composition
  - [x] Props
  - [x] Emit to parent
  - [x] Slot
  - [x] Slot fallback
  - [ ] Context
- [x] Form input
  - [x] Input text
  - [x] Checkbox
  - [x] Radio
  - [x] Select
- [ ] Webapp features
  - [ ] Render app
  - [x] Fetch data
  - [x] Router link
  - [x] Routing

</details><details>
        <summary>
            <img width=""18"" height=""18"" src=""public/framework/qwik.svg"" />
            <b>Qwik</b>
            <img src=""https://us-central1-progress-markdown.cloudfunctions.net/progress/92"" /></summary>

- [x] Reactivity
  - [x] Declare state
  - [x] Update state
  - [x] Computed state
- [x] Templating
  - [x] Minimal template
  - [x] Styling
  - [x] Loop
  - [x] Event click
  - [x] Dom ref
  - [x] Conditional
- [x] Lifecycle
  - [x] On mount
  - [x] On unmount
- [ ] Component composition
  - [x] Props
  - [x] Emit to parent
  - [x] Slot
  - [x] Slot fallback
  - [ ] Context
- [x] Form input
  - [x] Input text
  - [x] Checkbox
  - [x] Radio
  - [x] Select
- [ ] Webapp features
  - [ ] Render app
  - [x] Fetch data
  - [x] Router link
  - [x] Routing

</details><details>
        <summary>
            <img width=""18"" height=""18"" src=""public/framework/angular.svg"" />
            <b>Angular</b>
            <img src=""https://us-central1-progress-markdown.cloudfunctions.net/progress/92"" /></summary>

- [x] Reactivity
  - [x] Declare state
  - [x] Update state
  - [x] Computed state
- [x] Templating
  - [x] Minimal template
  - [x] Styling
  - [x] Loop
  - [x] Event click
  - [x] Dom ref
  - [x] Conditional
- [x] Lifecycle
  - [x] On mount
  - [x] On unmount
- [ ] Component composition
  - [x] Props
  - [x] Emit to parent
  - [x] Slot
  - [x] Slot fallback
  - [ ] Context
- [x] Form input
  - [x] Input text
  - [x] Checkbox
  - [x] Radio
  - [x] Select
- [ ] Webapp features
  - [ ] Render app
  - [x] Fetch data
  - [x] Router link
  - [x] Routing

</details><details>
        <summary>
            <img width=""18"" height=""18"" src=""public/framework/lit.svg"" />
            <b>Lit</b>
            <img src=""https://us-central1-progress-markdown.cloudfunctions.net/progress/96"" /></summary>

- [x] Reactivity
  - [x] Declare state
  - [x] Update state
  - [x] Computed state
- [x] Templating
  - [x] Minimal template
  - [x] Styling
  - [x] Loop
  - [x] Event click
  - [x] Dom ref
  - [x] Conditional
- [x] Lifecycle
  - [x] On mount
  - [x] On unmount
- [ ] Component composition
  - [x] Props
  - [x] Emit to parent
  - [x] Slot
  - [x] Slot fallback
  - [ ] Context
- [x] Form input
  - [x] Input text
  - [x] Checkbox
  - [x] Radio
  - [x] Select
- [x] Webapp features
  - [x] Render app
  - [x] Fetch data
  - [x] Router link
  - [x] Routing

</details><details>
        <summary>
            <img width=""18"" height=""18"" src=""public/framework/vue.svg"" />
            <b>Vue 2</b>
            <img src=""https://us-central1-progress-markdown.cloudfunctions.net/progress/96"" /></summary>

- [x] Reactivity
  - [x] Declare state
  - [x] Update state
  - [x] Computed state
- [x] Templating
  - [x] Minimal template
  - [x] Styling
  - [x] Loop
  - [x] Event click
  - [x] Dom ref
  - [x] Conditional
- [x] Lifecycle
  - [x] On mount
  - [x] On unmount
- [ ] Component composition
  - [x] Props
  - [x] Emit to parent
  - [x] Slot
  - [x] Slot fallback
  - [ ] Context
- [x] Form input
  - [x] Input text
  - [x] Checkbox
  - [x] Radio
  - [x] Select
- [x] Webapp features
  - [x] Render app
  - [x] Fetch data
  - [x] Router link
  - [x] Routing

</details><details>
        <summary>
            <img width=""18"" height=""18"" src=""public/framework/ember.svg"" />
            <b>Ember</b>
            <img src=""https://us-central1-progress-markdown.cloudfunctions.net/progress/92"" /></summary>

- [x] Reactivity
  - [x] Declare state
  - [x] Update state
  - [x] Computed state
- [x] Templating
  - [x] Minimal template
  - [x] Styling
  - [x] Loop
  - [x] Event click
  - [x] Dom ref
  - [x] Conditional
- [x] Lifecycle
  - [x] On mount
  - [x] On unmount
- [ ] Component composition
  - [x] Props
  - [x] Emit to parent
  - [x] Slot
  - [x] Slot fallback
  - [ ] Context
- [x] Form input
  - [x] Input text
  - [x] Checkbox
  - [x] Radio
  - [x] Select
- [ ] Webapp features
  - [ ] Render app
  - [x] Fetch data
  - [x] Router link
  - [x] Routing

</details><details>
        <summary>
            <img width=""18"" height=""18"" src=""public/framework/alpine.svg"" />
            <b>Alpine</b>
            <img src=""https://us-central1-progress-markdown.cloudfunctions.net/progress/96"" /></summary>

- [x] Reactivity
  - [x] Declare state
  - [x] Update state
  - [x] Computed state
- [x] Templating
  - [x] Minimal template
  - [x] Styling
  - [x] Loop
  - [x] Event click
  - [x] Dom ref
  - [x] Conditional
- [x] Lifecycle
  - [x] On mount
  - [x] On unmount
- [ ] Component composition
  - [x] Props
  - [x] Emit to parent
  - [x] Slot
  - [x] Slot fallback
  - [ ] Context
- [x] Form input
  - [x] Input text
  - [x] Checkbox
  - [x] Radio
  - [x] Select
- [x] Webapp features
  - [x] Render app
  - [x] Fetch data
  - [x] Router link
  - [x] Routing

</details><details>
        <summary>
            <img width=""18"" height=""18"" src=""public/framework/aurelia.svg"" />
            <b>Aurelia 1</b>
            <img src=""https://us-central1-progress-markdown.cloudfunctions.net/progress/92"" /></summary>

- [x] Reactivity
  - [x] Declare state
  - [x] Update state
  - [x] Computed state
- [x] Templating
  - [x] Minimal template
  - [x] Styling
  - [x] Loop
  - [x] Event click
  - [x] Dom ref
  - [x] Conditional
- [x] Lifecycle
  - [x] On mount
  - [x] On unmount
- [ ] Component composition
  - [x] Props
  - [x] Emit to parent
  - [x] Slot
  - [x] Slot fallback
  - [ ] Context
- [x] Form input
  - [x] Input text
  - [x] Checkbox
  - [x] Radio
  - [x] Select
- [ ] Webapp features
  - [ ] Render app
  - [x] Fetch data
  - [x] Router link
  - [x] Routing

</details>

## 🤝 Contributing

This site is built with [Vite](https://vitejs.dev) and [Svelte](https://svelte.dev). Site content is written in Markdown format located in `content`. For simple edits, you can directly edit the file on GitHub and generate a Pull Request.

For local development, [pnpm](https://pnpm.io/) is preferred as package manager:

```bash
pnpm i
pnpm run dev
```

This project requires Node.js to be `v16.0.0` or higher.

### Add a framework

1.  Fork the project and create a new branch
2.  Add the new framework SVG logo in `public/framework`
3.  Install the ESLint plugin associated to the framework
4.  In `frameworks.mjs`, add a new entry with SVG link and ESLint configuration

## 🧑‍💻 Contributors

This project exists thanks to all the people who contribute. \[[Contribute](CONTRIBUTING.md)].
[![Contributors](https://opencollective.com/component-party/contributors.svg?width=890&button=false)](https://github.com/matschik/component-party/graphs/contributors)

## ⚖️ License

MIT. Made with 💖
","Many JS developers don't have a good overview of every existing JS framework
with their own syntax and features. Developers love having framework overview by
examples. It's a quick introduction before going deeper. We'll show you how to
use React in a Web component."
2188,Blockchain and Crytocurrency Resources,"# Blockchain-stuff

Curated list of blockchain and general cryptocurrency resources

# Table of Contents

- [Bitcoin Books](#bitcoin)
- [Blockchain Art](#blockchain-art)
- [Blockchain Books](#blockchain-books)
- [Courses](#courses)
- [Documentaries](#documentaries)
- [Ethereum and Smart Contracts](#ethereum-and-smart-contracts)
- [Explorers](#explorers)
- [Infographics](#infographics)
- [Talks](#talks)
- [White Papers](#white-papers)
- [Youtube Channels](#youtube-channels)
- [Assets](#assets)
- [Private Blockchains](#private-blockchain)




### Blockchain Books
* [Blockchain Explained: A Technology Guide to the Bitcoin and Cryptocurrency Fintech Revolution](https://www.amazon.com/Blockchain-Explained-Technology-Cryptocurrency-Revolution/dp/1535315946/ref=pd_sim_14_5?_encoding=UTF8&pd_rd_i=1535315946&pd_rd_r=615DFBPATQX6GX4RBPWP&pd_rd_w=96Va0&pd_rd_wg=M6xmm&psc=1&refRID=615DFBPATQX6GX4RBPWP) - R.J Simmons
* [Blockchain Fast and Simple - What It Is, How It Works, Why It Matters: Understand the basics, join the revolution](https://www.amazon.com/Blockchain-Fast-Simple-Understand-revolution-ebook/dp/B01M1J671W/ref=sr_1_1?s=books&ie=UTF8&qid=1476984683&sr=1-1&keywords=Blockchain+Fast+and+Simple+-+What+It+Is%2C+How+It+Works%2C+Why+It+Matters%3A+Understand+the+basics%2C+join+the+revolution) - Pierro Martini
* [Cryptocurrency Investment: How to Invest in Cryptocurrencies and Make Money in the Long-term](https://www.amazon.com/dp/B07588PNMR) - Tamas Torok
* [Blockchain Revolution: How the Technology behind Bitcoin Is Changing Money, Business, and the World](https://www.amazon.com/Blockchain-Revolution-Technology-Changing-Business/dp/1101980133/ref=pd_sim_14_11?_encoding=UTF8&pd_rd_i=1101980133&pd_rd_r=KF66S03S94P6CMSN0K29&pd_rd_w=Dibne&pd_rd_wg=jRGoU&psc=1&refRID=KF66S03S94P6CMSN0K29) -  Don and AlexTapscott
* [Blockchain Revolution: The Ultimate Guide to Mastering Bitcoin and How to Use Blockchain for Your Benefit](https://www.amazon.com/Blockchain-Revolution-Technology-Changing-Business/dp/1101980133/ref=pd_bxgy_14_img_3?_encoding=UTF8&pd_rd_i=1101980133&pd_rd_r=JMGHCB5WB1SFP0HYMK6E&pd_rd_w=uHeeo&pd_rd_wg=cburT&psc=1&refRID=JMGHCB5WB1SFP0HYMK6E) - Phil Stein
* [Blockchain The Ultimate Guide to Understanding the Hidden Economy](https://www.amazon.com/Blockchain-Ultimate-Understanding-Hidden-Economy/dp/1534839720/ref=pd_sim_14_5?_encoding=UTF8&pd_rd_i=1534839720&pd_rd_r=6W5M79GD2JFECEZDHPJF&pd_rd_w=19drm&pd_rd_wg=DMS0s&psc=1&refRID=6W5M79GD2JFECEZDHPJF) -s Oscar Flynt
* [Blockchain: Blueprint for a New Economy](https://www.amazon.com/Blockchain-Blueprint-Economy-Melanie-Swan/dp/1491920491/ref=pd_sim_14_3?_encoding=UTF8&pd_rd_i=1491920491&pd_rd_r=3KQXC5RXYM1R64CDQ0DW&pd_rd_w=YGgzx&pd_rd_wg=udR6C&psc=1&refRID=3KQXC5RXYM1R64CDQ0DW) - Melanie Swan
* [Blockchain: Easiest Ultimate Guide To Understand Blockchain](https://www.amazon.com/Blockchain-Understand-Programming-Contracts-Revolution/dp/1537533371/ref=pd_sim_14_3?_encoding=UTF8&pd_rd_i=1537533371&pd_rd_r=904DCPSY2QZX2VM23XQD&pd_rd_w=3oCFL&pd_rd_wg=jJFBs&psc=1&refRID=904DCPSY2QZX2VM23XQD) - Jared Norton
* [Blockchain: Quick Start Guide to Understanding Blockchain, the Biggest Revolution in Financial Technology and Beyond Since the Internet](https://www.amazon.com/Blockchain-Understanding-Revolution-Financial-Technology/dp/153469093X/ref=pd_sim_14_1?_encoding=UTF8&pd_rd_i=153469093X&pd_rd_r=D7A8BRAQA9GNYQYES830&pd_rd_w=76sME&pd_rd_wg=SCgV1&psc=1&refRID=D7A8BRAQA9GNYQYES830) - Seth Ramsey
* [Blockchain: The Comprehensive Guide to Mastering the Hidden Economy](https://www.amazon.com/Blockchain-Comprehensive-Mastering-Technology-Financial/dp/1537272039/ref=pd_sim_14_9?_encoding=UTF8&pd_rd_i=1537272039&pd_rd_r=D7A8BRAQA9GNYQYES830&pd_rd_w=76sME&pd_rd_wg=SCgV1&psc=1&refRID=D7A8BRAQA9GNYQYES830) - Timothy Short
* [Blockchain: The Essential Guide to Understanding the Blockchain Revolution](https://www.amazon.com/Blockchain-Essential-Guide-Understanding-Revolution/dp/1537317504/ref=pd_sim_14_2?_encoding=UTF8&pd_rd_i=1537317504&pd_rd_r=N3211HRZ6T4ETTER3MY3&pd_rd_w=I44Hf&pd_rd_wg=evC6k&psc=1&refRID=N3211HRZ6T4ETTER3MY3) - Jeff Reed
* [Blockchain: The Future of Internet Innovation - Ideas, Applications and Uses for Blockchain Technology](https://www.amazon.com/Blockchain-Innovation-Applications-Cryptocurrencies-Technological-ebook/dp/B01G80V3O2/ref=sr_1_2?ie=UTF8&qid=1476985977&sr=8-2&keywords=Blockchain+contracts+and+CyberLaw) - Jerry Kershen
* [Blockchain: The Simple Guide To Everything You Need To Know](https://www.amazon.com/Blockchain-Simple-Guide-Everything-Need/dp/1533161577/ref=pd_sim_14_23?_encoding=UTF8&pd_rd_i=1533161577&pd_rd_r=26RQGPJBS5V65WXKFS9Z&pd_rd_w=DJMVN&pd_rd_wg=E1guu&psc=1&refRID=26RQGPJBS5V65WXKFS9Z) - Jacob William
* [Bye Bye Banks?: How Retail Banks are Being Displaced, Diminished and Disintermediated by Tech Startups and What They Can Do to Survive](https://www.amazon.com/Bye-Banks-Displaced-Diminished-Disintermediated/dp/0993220649/ref=sr_1_1?ie=UTF8&qid=1476986040&sr=8-1&keywords=Bye+Bye+Banks%3F) - James Haycock
* [Decentralized Applications: Harnessing Bitcoin's Blockchain Technology](https://www.amazon.com/Decentralized-Applications-Harnessing-Blockchain-Technology/dp/1491924543/ref=pd_sim_14_3?_encoding=UTF8&pd_rd_i=1491924543&pd_rd_r=7XN6AJY2PX75QDZTZAPM&pd_rd_w=ZDHwi&pd_rd_wg=oQ9Te&psc=1&refRID=7XN6AJY2PX75QDZTZAPM) - Siraj Raval
* [Financial Technology: This Book Bundle Includes FinTech and Blockchain](https://www.amazon.com/Financial-Technology-Bundle-FinTech-Blockchain/dp/1533477299/ref=pd_sim_14_3?_encoding=UTF8&pd_rd_i=1533477299&pd_rd_r=D7A8BRAQA9GNYQYES830&pd_rd_w=76sME&pd_rd_wg=SCgV1&psc=1&refRID=D7A8BRAQA9GNYQYES830) -  Jacob William
* [How to Program a Block Chain Explorer with Python and Bitcoin](https://www.amazon.com/Program-Block-Explorer-Python-Bitcoin-ebook/dp/B014B6890G/ref=sr_1_1?s=books&ie=UTF8&qid=1476984581&sr=1-1&keywords=How+to+Program+a+Block+Chain+Explorer+with+Python+and+Bitcoin) - Alex Gorale
* [The Business Blockchain: Promise, Practice, and Application of the Next Internet Technology](https://www.amazon.com/FINTECH-Book-Technology-Entrepreneurs-Visionaries/dp/111921887X/ref=pd_bxgy_14_img_3?_encoding=UTF8&pd_rd_i=111921887X&pd_rd_r=Z5ZRQN8RG5TEQTMKYHA9&pd_rd_w=qIgXN&pd_rd_wg=wZM9d&psc=1&refRID=Z5ZRQN8RG5TEQTMKYHA9) -  William Mougayar
* [The FinTech Book: The Financial Technology Handbook for Investors, Entrepreneurs and Visionaries](https://www.amazon.com/FINTECH-Book-Technology-Entrepreneurs-Visionaries/dp/111921887X/ref=pd_bxgy_14_img_3?_encoding=UTF8&pd_rd_i=111921887X&pd_rd_r=Z5ZRQN8RG5TEQTMKYHA9&pd_rd_w=qIgXN&pd_rd_wg=wZM9d&psc=1&refRID=Z5ZRQN8RG5TEQTMKYHA9) - Susanne Chishti and Janos Barberis
* [The Fourth Industrial Revolution](https://www.amazon.com/Fourth-Industrial-Revolution-Klaus-Schwab/dp/1944835008/ref=sr_1_1?s=books&ie=UTF8&qid=1476984488&sr=1-1&keywords=The+Fourth+Industrial+Revolution) - Prof Klaus Schwab
* [The Science of the Blockchain](https://www.amazon.com/Science-Blockchain-Inverted-Forest-Publishing/dp/1522751831/ref=pd_sim_14_10?_encoding=UTF8&pd_rd_i=1522751831&pd_rd_r=FF7D9XVT7EPCACXH29Z8&pd_rd_w=JXBSj&pd_rd_wg=pcc0Z&psc=1&refRID=FF7D9XVT7EPCACXH29Z8) - Roger Wattenhofer
* [ValueWeb: How FinTech firms are using mobile and blockchain technologies to create the Internet of Value](https://www.amazon.com/ValueWeb-Fintech-Blockchain-Technologies-Internet/dp/9814677175/ref=pd_sim_14_10?_encoding=UTF8&pd_rd_i=9814677175&pd_rd_r=BCCHSTJWGE32H74XN9GZ&pd_rd_w=2YGDw&pd_rd_wg=UB9kN&psc=1&refRID=BCCHSTJWGE32H74XN9GZ) -Chris Skinner
* [Building Ethereum ĐApps](https://www.manning.com/books/building-ethereum-dapps) -Roberto Infante


### White papers
* [A Fistful of Bitcoins: Characterizing Payments Among Men with No Names](http://cseweb.ucsd.edu/~smeiklejohn/files/imc13.pdf) - University of San Diego California
* [A brave new world? What impact will distributed ledger technology have on the financial industry?](https://www.ecb.europa.eu/paym/pdf/infocus/20160422_infocus_dlt.pdf) -  The European Central Bank
* [An Architecture for the Internet of Money](https://docs.google.com/document/d/1Bc-kZXROTeMzG6AvH7rrTrUy24UwHoEcgiL7ALHMO0A/pub) - Meher Roy
* [Banking in a world of programmable assets](https://www.accenture.com/t20160509T223022__w__/us-en/_acnmedia/PDF-16/Accenture-Strategy-Banking-World-of-Programmable-Assets.pdf) - Accenture
* [Bitcoin Primer](http://www.macroriskadvisors.com/layout/pdf/bitcoin%20primer%20BTC.pdf) - Macro Risk Advisors
* [Bitcoin as Money?](http://www.bostonfed.org/economic/current-policy-perspectives/2014/cpp1404.pdf) - Stephanie Lo and J. Christina Wang
* [Bitcoin](http://research.microsoft.com/pubs/156072/bitcoin.pdf) - Microsoft Research
* [BlockChain Technology Beyond Bitcoin](http://scet.berkeley.edu/wp-content/uploads/BlockchainPaper.pdf) - University of California,Berkeley
* [Blockchain: practical implications of a revolutionary technology for financial markets and beyond](https://www.dlapiper.com/en/uk/insights/events/2016/04/blockchain-practical-implications/11-apr-2016/)  - DLA Piper
* [Blockchain: the solution for transparency in product supply chains](https://www.provenance.org/whitepaper) - Project Provenance Ltd
* [Blockstack: A Global Naming and Storage System Secured by Blockchains](https://blockstack.org/blockstack.pdf) - Muneeb Ali, Jude Nelson, Ryan Shea and Michael J. Freedman
* [Bootstrapping Trust in Distributed Systems with Blockchains](https://blockstack.org/blockstack-login.pdf) - Muneeb Ali, Jude Nelson, Ryan Shea and Michael J. Freedman
* [Consensus – Immutable agreement for the internet of value](https://assets.kpmg.com/content/dam/kpmg/pdf/2016/06/kpmg-blockchain-consensus-mechanism.pdf) - KPMG
* [Distributed Ledger Technology: beyond block chain](https://www.gov.uk/government/uploads/system/uploads/attachment_data/file/492972/gs-16-1-distributed-ledger-technology.pdf) - UK Government Chief Scientific Adviser
* [Economics of Bitcoin](http://nakamotoinstitute.org/static/docs/economics-of-bitcoin.pdf) - Peter Surda
* [Enabling Blockchain Innovations with Pegged Sidechains](https://blockstream.com/sidechains.pdf) - Adam Back, Matt Corallo, Luke Dashjr, Mark Friedenbach, Gregory Maxwell, Andrew Miller, Andrew Poelstra, Jorge Timón, and Pieter Wuille
* [Extending Existing Blockchains with Virtualchain](https://blockstack.org/virtualchain.pdf) - Jude Nelson, Muneeb Ali, Ryan Shea and Michael J. Freedman
* [The Impact and Potential of Blockchain on the Securities Transaction Lifecycle](http://www.zyen.com/Publications/The%20Impact%20and%20Potential%20of%20Blockchain%20on%20the%20Securities%20Transaction%20Lif....pdf) - The Swift Institute
* [World Citizenship by Creating Affordable Private Passport Service](https://docs.google.com/document/d/1hq52GT0sQ8mJBZ3_qr-LIpZTBFqIDA2WV8vb_1m8i4U/edit#) - Chris Ellis

### Bitcoin
* [Who is Bitcoin address owner, mentions on the Internet, forums, scam alerts, and other metadata.](https://allprivatekeys.com/whose-bitcoin-address.php) - Maksim Boyarov
* [Anonymous Cryptocurrencies: The rise of bitcoin alternatives that offer true anonymity](https://www.amazon.com/Cryptocurrencies-bitcoin-alternatives-offer-anonymity/dp/1500682586/ref=pd_sim_14_24?_encoding=UTF8&pd_rd_i=1500682586&pd_rd_r=PMB5GABNHVFM2VHE3WBH&pd_rd_w=6yGsW&pd_rd_wg=yVxm8&psc=1&refRID=PMB5GABNHVFM2VHE3WBH) - Will Martin
* [Bitcoin and Lightning Network on Raspberry Pi](https://www.amazon.com/Bitcoin-Lightning-Network-Raspberry-Pi/dp/1484255216) - Harris Brakmic
* [Bit by Bit: How P2P Is Freeing the World](https://www.amazon.com/Bit-How-P2P-Freeing-World-ebook/dp/B00S085TRS/ref=sr_1_1?ie=UTF8&qid=1476985273&sr=8-1&keywords=Bit+by+Bit) - Jeffery Tucker
* [Bitcoin : A Complete Beginner's Guide - Master The Game](https://www.amazon.com/Bitcoin-Complete-Beginners-Guide-Master-ebook/dp/B01JU6KD9C/ref=sr_1_2?ie=UTF8&qid=1476986332&sr=8-2&keywords=The+Bitcoin+Tutorial%3A) - Luke Sutton
* [Bitcoin Basics](https://www.amazon.com/Bitcoin-Basics-Creating-Investing-Bitcoins/dp/1508478945/ref=pd_sim_14_4?_encoding=UTF8&pd_rd_i=1508478945&pd_rd_r=YMYPCM376H2JNJ9NVB6D&pd_rd_w=0gtr5&pd_rd_wg=iqdC9&psc=1&refRID=YMYPCM376H2JNJ9NVB6D) - Benjamin Tideas
* [Bitcoin Decoded: Bitcoin Beginner's Guide to Mining and the Strategies to Make Money with Cryptocurrencies](https://www.amazon.com/Bitcoin-Decoded-Beginners-Strategies-Cryptocurrencies/dp/061595524X/ref=pd_sim_14_12?_encoding=UTF8&pd_rd_i=061595524X&pd_rd_r=KF66S03S94P6CMSN0K29&pd_rd_w=Dibne&pd_rd_wg=jRGoU&psc=1&refRID=KF66S03S94P6CMSN0K29) -  Brett Combs,Tom Mitsoff
* [Bitcoin For Dummies](https://www.amazon.com/Bitcoin-Dummies-Prypto/dp/1119076137/ref=pd_sim_14_30?_encoding=UTF8&pd_rd_i=1119076137&pd_rd_r=26RQGPJBS5V65WXKFS9Z&pd_rd_w=DJMVN&pd_rd_wg=E1guu&psc=1&refRID=26RQGPJBS5V65WXKFS9Z) - Prypto
* [Bitcoin Internals: A Technical Guide to Bitcoin](https://www.amazon.com/Bitcoin-Internals-Technical-Guide-ebook/dp/B00DG8EPT0/ref=sr_1_1?ie=UTF8&qid=1476985144&sr=8-1&keywords=Bitcoin+Internals%3A) - Chris Clark
* [Bitcoin Step by Step for Beginners: How to Invest and Profit from Bitcoin Today!](https://www.amazon.com/Bitcoin-Step-Beginners-Invest-Profit-ebook/dp/B00K5RUKEE/ref=sr_1_1?ie=UTF8&qid=1476986366&sr=8-1&keywords=Bitcoin+Step+by+Step) - Leo Kallstrom
* [Bitcoin The Future of Money](https://www.amazon.com/Bitcoin-future-money-Dominic-Frisby/dp/1783521023/ref=pd_sim_14_19?_encoding=UTF8&pd_rd_i=1783521023&pd_rd_r=KF66S03S94P6CMSN0K29&pd_rd_w=Dibne&pd_rd_wg=jRGoU&psc=1&refRID=KF66S03S94P6CMSN0K29) - Dominic Frisby
* [Bitcoin and Cryptocurrency Technologies: A Comprehensive Introduction](https://www.amazon.com/Bitcoin-Cryptocurrency-Technologies-Comprehensive-Introduction/dp/0691171696/ref=pd_sim_14_8?_encoding=UTF8&pd_rd_i=0691171696&pd_rd_r=0CHWWTBSREYE58R7P0SX&pd_rd_w=gCU04&pd_rd_wg=gZavr&psc=1&refRID=0CHWWTBSREYE58R7P0SX) - Arvind Narayanan,Joseph Bonneau,Edward Felten, Andrew Miller,Steven Goldfeder ([free version of first draft](https://d28rh4a8wq0iu5.cloudfront.net/bitcointech/readings/princeton_bitcoin_book.pdf?a=1))
* [Bitcoin and The Future of Money](https://www.amazon.com/Bitcoin-Future-Money-Jose-Pagliery/dp/1629370363/ref=pd_sim_14_14?_encoding=UTF8&pd_rd_i=1629370363&pd_rd_r=NHZ4SY5ACXYYFA2FN5PK&pd_rd_w=WI1XD&pd_rd_wg=LtNFM&psc=1&refRID=NHZ4SY5ACXYYFA2FN5PK) - Jose Pagliery
* [Bitcoin for the Befuddled](https://www.amazon.com/Bitcoin-Befuddled-Conrad-Barski/dp/1593275730/ref=pd_sim_14_8?_encoding=UTF8&pd_rd_i=1593275730&pd_rd_r=KF66S03S94P6CMSN0K29&pd_rd_w=Dibne&pd_rd_wg=jRGoU&psc=1&refRID=KF66S03S94P6CMSN0K29) - Conrad Barski and Chris Wilmer
* [Bitcoin in English](https://www.amazon.com/Bitcoin-English-Understanding-HOW-Works-ebook/dp/B00X09LBX8/ref=sr_1_1?ie=UTF8&qid=1476985191&sr=8-1&keywords=Bitcoin+in+English) - Peter H Le
* [Bitcoin: Mastering Bitcoin & Cyptocurrency for Beginners](https://www.amazon.com/Bitcoin-Mastering-Cyptocurrency-Reinventing-Currencies/dp/153342733X/ref=pd_sim_14_6?_encoding=UTF8&pd_rd_i=153342733X&pd_rd_r=TJJ3Y2F85RACYQSF23GZ&pd_rd_w=kwfLQ&pd_rd_wg=koGbV&psc=1&refRID=TJJ3Y2F85RACYQSF23GZ) - Tim Harris
* [Digital Gold: The Untold Story of Bitcoin](https://www.amazon.com/Digital-Gold-Bitcoin-Millionaires-Reinvent/dp/0062362496/ref=pd_sim_14_1?_encoding=UTF8&pd_rd_i=0062362496&pd_rd_r=D7KMJCP493PPH9ADVPCR&pd_rd_w=g5Hrb&pd_rd_wg=KsfK5&psc=1&refRID=D7KMJCP493PPH9ADVPCR) -  Nathaniel Popper
* [Everything you need to know about buying, selling and investing in Bitcoin](https://www.amazon.com/Everything-selling-investing-Bitcoin-Technology/dp/1493699474/ref=pd_sim_14_17?_encoding=UTF8&pd_rd_i=1493699474&pd_rd_r=KF66S03S94P6CMSN0K29&pd_rd_w=Dibne&pd_rd_wg=jRGoU&psc=1&refRID=KF66S03S94P6CMSN0K29) - A. H Smithers
* [Mastering Bitcoin: Unlocking Digital Cryptocurrencies](https://www.amazon.com/Mastering-Bitcoin-Unlocking-Digital-Cryptocurrencies/dp/1449374042/ref=sr_1_1?ie=UTF8&qid=1476978890&sr=8-1&keywords=Mastering+Bitcoin%3A+Unlocking+Digital+Cryptocurrencies) Andreas M.  Antonopoulos
* [The Age of Cryptocurrency: How Bitcoin and Digital Money are challenging the Global Economic Order](https://www.amazon.com/Age-Cryptocurrency-Bitcoin-Challenging-Economic/dp/1250065631/ref=pd_sim_14_6?_encoding=UTF8&pd_rd_i=1250065631&pd_rd_r=7XN6AJY2PX75QDZTZAPM&pd_rd_w=ZDHwi&pd_rd_wg=oQ9Te&psc=1&refRID=7XN6AJY2PX75QDZTZAPM) - Paul Vigna and Michael J. Casey
* [The Anatomy of a Money-Like Informational Commodity: A study of Bitcoin](https://www.amazon.com/Anatomy-Money-like-Informational-Commodity-Bitcoin-ebook/dp/B00MEAO7XK/ref=sr_1_1?ie=UTF8&qid=1476985224&sr=8-1&keywords=The+Anatomy+of+a+Money) - Tim Swanson
* [The Bitcoin Bible](https://www.amazon.com/Bitcoin-Bible-Gold-Benjamin-Guttmann/dp/3732296962/ref=pd_sim_14_18?_encoding=UTF8&pd_rd_i=3732296962&pd_rd_r=KF66S03S94P6CMSN0K29&pd_rd_w=Dibne&pd_rd_wg=jRGoU&psc=1&refRID=KF66S03S94P6CMSN0K29) - Benjamin Guttmann
* [The Bitcoin Big Bang: How Alternative Currencies Are About to Change the World](https://www.amazon.com/Bitcoin-Big-Bang-Alternative-Currencies/dp/1118963660/ref=pd_sim_14_13?_encoding=UTF8&pd_rd_i=1118963660&pd_rd_r=KF66S03S94P6CMSN0K29&pd_rd_w=Dibne&pd_rd_wg=jRGoU&psc=1&refRID=KF66S03S94P6CMSN0K29) - Brian Kelly
* [The Bitcoin Tutor: Unlocking the Secrets of Bitcoin](https://www.amazon.com/Bitcoin-Tutor-Unlocking-Secrets/dp/0979864917/ref=pd_sim_14_5?_encoding=UTF8&pd_rd_i=0979864917&pd_rd_r=QZN41AYGXJSCS7Q32WA7&pd_rd_w=2i7o1&pd_rd_wg=nbCJJ&psc=1&refRID=QZN41AYGXJSCS7Q32WA7) - Marc A. Carignan
* [The Bitcoin Tutorial: Develop an intuitive understanding of the currency and blockchain technology](https://www.amazon.com/Bitcoin-Tutorial-understanding-blockchain-technology-ebook/dp/B01EP9SVE8/ref=sr_1_1?ie=UTF8&qid=1476986332&sr=8-1&keywords=The+Bitcoin+Tutorial%3A) - Bruce Kleinman
* [The Black Book of Bitcoin: A Step-by-Step Bitcoin Guide on Everything You Need to Know About this New Currency](https://www.amazon.com/Black-Book-Bitcoin-Step-Step/dp/1519284527/ref=pd_sim_14_22?_encoding=UTF8&pd_rd_i=1519284527&pd_rd_r=PMB5GABNHVFM2VHE3WBH&pd_rd_w=6yGsW&pd_rd_wg=yVxm8&psc=1&refRID=PMB5GABNHVFM2VHE3WBH) - Mark Janniro
* [The Book of Satoshi](https://www.amazon.com/Book-Satoshi-Collected-Writings-Nakamoto/dp/0996061312/ref=pd_sim_14_8?_encoding=UTF8&pd_rd_i=0996061312&pd_rd_r=9QB4ZB20S6CY4NGE029X&pd_rd_w=2TjP2&pd_rd_wg=VjLqC&psc=1&refRID=9QB4ZB20S6CY4NGE029X) - Paul Champagne
* [The Digital Money Game: Competing in the multi-trillion dollar payments industry](https://www.amazon.com/Digital-Money-Game-Competing-multi-trillion-ebook/dp/B00LZ3T66K/ref=sr_1_1?ie=UTF8&qid=1476985249&sr=8-1&keywords=The+Digital+Money+Game%3A) - Charmaine Oak
* [The Internet of Money - Andreas M Antonopoulos](https://www.amazon.com/Internet-Money-Andreas-M-Antonopoulos/dp/1537000454/ref=pd_bxgy_14_img_2?_encoding=UTF8&pd_rd_i=1537000454&pd_rd_r=XPR2XE7MNFCYAB70VZDM&pd_rd_w=xn5TU&pd_rd_wg=4Sqi0&psc=1&refRID=XPR2XE7MNFCYAB70VZDM)
* [Understanding Bitcoin: Cryptography, Engineering and Economics](https://www.amazon.com/Understanding-Bitcoin-Cryptography-Engineering-Economics/dp/1119019168/ref=pd_sim_14_16?_encoding=UTF8&pd_rd_i=1119019168&pd_rd_r=KF66S03S94P6CMSN0K29&pd_rd_w=Dibne&pd_rd_wg=jRGoU&psc=1&refRID=KF66S03S94P6CMSN0K29) - Pedro Franco
* [Virtual Billions: The Genius, the Drug Lord, and the Ivy League Twins behind the Rise of Bitcoin](https://www.amazon.com/Virtual-Billions-Genius-League-Bitcoin/dp/163388144X/ref=sr_1_1?ie=UTF8&qid=1476986258&sr=8-1&keywords=Virtual+Billions%3A+The+Genius) - Eric Geissinger
* [Wildcat Currency](https://www.amazon.com/Wildcat-Currency-Virtual-Revolution-Transforming/dp/0300186134/ref=sr_1_1?ie=UTF8&qid=1476986207&sr=8-1&keywords=Wildcat+Currency) - Edward Castronova
* [The Bitcoin Standard](https://www.amazon.com/Bitcoin-Standard-Decentralized-Alternative-Central/dp/1119473861) - Saifedean Ammous

### Ethereum and Smart Contracts
* [A Proof of Stake Design Philosophy](https://medium.com/@VitalikButerin/a-proof-of-stake-design-philosophy-506585978d51#.43e2aeta8) - Vitalik Buterin
* [Blockchain contracts and CyberLaw](https://www.amazon.com/BLOCKCHAIN-CONTRACTS-CYBERLAW-PAVAN-DUGGAL-ebook/dp/B019S2I1CE/ref=sr_1_1?ie=UTF8&qid=1476985977&sr=8-1&keywords=Blockchain+contracts+and+CyberLaw) - Pavan Duggal
* [EatTheBlocks](https://eattheblocks.com)
* [Ethereum Builder's Guide](https://www.gitbook.com/book/ethereumbuilders/guide/details) - Ethereum
* [Ethereum Frontier Guide](https://ethereum.gitbooks.io/frontier-guide/) - Ethereum
* [Ethereum: A look into the world of Ethereum and everything you need to know about it's trade and investment](https://www.amazon.com/Ethereum-everything-investment-Blockchain-Cryptocurrency-ebook/dp/B01IC6NT8S/ref=sr_1_1?ie=UTF8&qid=1476984793&sr=8-1&keywords=Ethereum%3A+A+look+into+the+world+of+Ethereum+and+everything+you+need+to+know+about+it%27s+trade+and+investment%21) - Ben Abner
* [Ethereum: The Complete Beginners Guide -Blockchain, Cryptocurrencies, Ethereum](https://www.amazon.com/s/ref=nb_sb_noss?url=search-alias%3Daps&field-keywords=Ethereum%3A+The+Complete+Beginners+Guide)  - Ray Hammond
* [FinTech: Financial Technology and Modern Finance in the 21st Century](https://www.amazon.com/FinTech-Financial-Technology-Blockchain-Contracts-ebook/dp/B01MEFL03W/ref=sr_1_1?ie=UTF8&qid=1476985691&sr=8-1&keywords=FinTech%3A+Financial+Technology+and+Modern+Finance+in+the+21st+Century) - Jeff Reed
* [Great Chain of Numbers: A Guide to Smart Contracts, Smart Property and Trustless Asset Management](https://www.amazon.com/Great-Chain-Numbers-Contracts-Management-ebook/dp/B00IRUBMXO/ref=sr_1_1?ie=UTF8&qid=1476985949&sr=8-1&keywords=Great+Chain+of+Numbers%3A+A+Guide+to+Smart+Contracts%2C+Smart+Property+and+Trustless+Asset+Management) - Tim Swanson
* [Learn Ethereum Dapps: Build a ToDo List with a Solidity smart contract](https://eattheblocks.com/learn-to-build-an-ethereum-dapp-step-by-step-ebook-tutorial-for-beginners/)
* [Investing In Ethereum: The Complete Guide To Smart Investing - Learn How To Easily Profit From Cryptocurrencies!](https://www.amazon.com/Investing-Ethereum-Complete-Easily-Cryptocurrencies/dp/1537677209/ref=sr_1_fkmr0_1?ie=UTF8&qid=1476985775&sr=8-1-fkmr0&keywords=Ethereum%3A+The+Complete+Beginners+Guide) - 	Thomas Sanders
* [Investing in Ethereum: The Ultimate Guide to Learning and Profiting from--Cryptocurrencies](https://www.amazon.com/Investing-Ethereum-Learning-Profiting-Cryptocurrencies/dp/153530281X/ref=pd_sim_14_5?_encoding=UTF8&pd_rd_i=153530281X&pd_rd_r=EH8VPZEJ5BMM540BQEZW&pd_rd_w=CywQ3&pd_rd_wg=p4U9s&psc=1&refRID=EH8VPZEJ5BMM540BQEZW) - Oscar Flynt
* [Investing in Ethereum: Understanding Cryptocurrencies for the Smart Investor](https://www.amazon.com/Investing-Ethereum-Understanding-Cryptocurrencies-Investor-ebook/dp/B01DD6XVJE/ref=sr_1_1?ie=UTF8&qid=1476985905&sr=8-1&keywords=investing+in+Ethereum%3A+Understanding) - Michael K Nungesser
* [Practical Guide to Smart Contracts](https://www.gitbook.com/book/smart-contract-japan/prictical-guide-of-smart-contracts/details) - Smart Contract Japan
* [Smart Contracts: How to Use Blockchain Smart Contracts for Cryptocurrency Exchange](https://www.amazon.com/Smart-Contracts-Blockchain-Cryptocurrency-Exchange-ebook/dp/B01IQJM53Q/ref=sr_1_1?ie=UTF8&qid=1476984876&sr=8-1&keywords=Smart+Contracts%3A+How+to+Use+Blockchain) - Oscar Flynt
* [Smart Contracts: The Essential Guide to Using Blockchain Smart Contracts for Cryptocurrency Exchange](https://www.amazon.com/Smart-Contracts-Essential-Blockchain-Cryptocurrency-ebook/dp/B01LXGO7GH/ref=sr_1_1?ie=UTF8&qid=1476985747&sr=8-1&keywords=Smart+Contracts%3A+The+Essential+Guide) - Jeff Reed
* [Smart Contracts: The Ultimate Guide To Blockchain Smart Contracts - Learn How To Use Smart Contracts For Cryptocurrency Exchange!](https://www.amazon.com/Smart-Contracts-Ultimate-Blockchain-Cryptocurrency-ebook/dp/B01LYK175F/ref=sr_1_2?ie=UTF8&qid=1476984876&sr=8-2&keywords=Smart+Contracts%3A+How+to+Use+Blockchain) - Terry Parker
* [The Modern Ethereum](https://www.amazon.com/Modern-Ethereum-Ryan-Venter-ebook/dp/B01KIRQZ0S/ref=sr_1_1?ie=UTF8&qid=1476985723&sr=8-1&keywords=The+Modern+Ethereum) - Ryan Venter
* [TurboEthereum Guide](https://www.gitbook.com/book/gavofyork/turboethereum/details) - Gavin Wood
* [Building Ethereum ĐApps](https://www.manning.com/books/building-ethereum-dapps) -Roberto Infante


### Infographics
- [Bitcoin's History 2008-2014](https://i.imgur.com/kVF3kFu.png)
- [How a Transaction Works](https://i.imgur.com/fZyX3Od.jpg)
- [Crypto Table - A Periodic Table of Cryptocurrencies](https://jes.al/crypto-table/)

### Talks
* [Balaji Srinivasan gives a quick talk at Goldman Sachs. (14 min)](https://www.youtube.com/watch?v=7-vYEsfsa30)
* [Balaji Srinivasan on Silicon Valley’s ultimate exit, the USA the Microsoft of nations (16 min)](https://www.youtube.com/watch?v=cOubCHLXT6A)
* [Beyond Bitcoin - Block Chains and the Future of Trustless Computing (27 min)](https://www.youtube.com/watch?v=IgETC2JMUBI)
* [Bitcoin Is Exciting Because It's Cheap](https://www.youtube.com/watch?t=26&v=DyAufA2lWn0) - Bill Gates
* [Bitcoin threatens Kleptocracy (7 min):](http://youtu.be/jaHqtXvGxy4)
* [Bitcoin. Sweat. Tide. Meet the future of branded currency.(11min)](https://www.ted.com/talks/paul_kemp_robertson_bitcoin_sweat_tide_meet_the_future_of_branded_currency?language=en) - Paul Kemp-Robertson
* [Convergex Group, Nick Colas (3min):](https://www.youtube.com/watch?v=CdVVECKKSXo)
* [Defining bitcoin ownership, 2 min](https://www.youtube.com/watch?v=TANjGSo16Uk)
* [Ending the Federal Reserve's Monopoly (6 min):](http://vimeo.com/94697840)
* [Everything You Need to Know About Bitcoin](https://www.youtube.com/watch?v=SNssKmeXrGs) - Reihan Salams
* [How Cryptocurrencies Can Succeed: the Stripe Perspective(20min)](https://www.youtube.com/watch?v=6qZwl7mukZ8) - Greg Brockman
* [How the Blockchain is Changing Money and Business (19 min)](https://www.ted.com/talks/don_tapscott_how_the_blockchain_is_changing_money_and_business?language=en) - Don Tapscott
* [Internet vs Bitcoin (3min):](https://www.youtube.com/watch?v=s0luLPVHkO4)
* [Join The Bitcoin Revolution (4min):](https://www.youtube.com/watch?v=24ce5tV-pgg)
* [TEDx, Crytpocurrencies like Bitcoin are coming, and it's a good thing (11min):](https://www.youtube.com/watch?v=0GL9PTQiqxw) - Juan Llanos
* [Powerful Technology Transforming Society: (6min)](http://www.youtube.com/watch?v=YIVAluSL9SUA)
* [Quick Introduction to Bitcoin (5min)](https://www.youtube.com/watch?v=slFuj5N4twc)
* [Stefan Molyneux- Money, Power and Politics (30min):](https://www.youtube.com/watch?v=_bmlVqs9qSY)
* [Stopping War: (1 min)](https://www.youtube.com/watch?v=eyU3TgQqtV8)
* [TEDx, Distributing Power & Trust (18min)](https://www.youtube.com/watch?v=WI1pbHi1fww) -  Eric Spano
* [Testimony for the Australian Senate Commitee on Economics References(36min)](https://www.youtube.com/watch?v=XotOwt8bTeI&feature=youtu.be)
* [The Future of Bitcoin: New Applications and Rebuilding the banking system: (28min)](https://www.youtube.com/watch?v=mD4L7xDNCmA) - Mike Hearn
* [The Story of Genesis: (3min)](http://youtu.be/gD4llSr-Ik8)
* [The future will be decentralized (14mins)](https://www.youtube.com/watch?v=97ufCT6lQcY) - Charles Hoskinson
* [Xapo, the history of money (5 min):](http://youtu.be/IP0jCjyrew8)
* [Masters of Blockchain (11 episodes)](http://mastersofblockchain.org/)


### Youtube Channels
* [AirBitz](https://www.youtube.com/channel/UCJaTFo0_z9lEG_v7L_LT2pw/videos)
* [Andreas Antonopolous](https://www.youtube.com/user/aantonop)
* [Andy Ofiesh](https://www.youtube.com/user/JellyBaby68/videos)
* [Bitcoin Embassy](https://www.youtube.com/user/JellyBaby68/videos)
* [Bitcoin Foundation](https://www.youtube.com/user/BitcoinFoundation/videos)
* [Bitcoin Wednesday](https://www.youtube.com/channel/UCt-Po2gFQxiUngwJXh6s04w/videos)
* [Blockchain University](https://www.youtube.com/channel/UCJ5uHx90mZGlK0lC-GSmtzw/videos)
* [Blockstack](https://www.youtube.com/channel/UC3J2iHnyt2JtOvtGVf_jpHQ)
* [Bruce Fenton First Mover](https://www.youtube.com/user/BruceFenton/videos)
* [Coin Brief](https://www.youtube.com/user/Coinbrief/videos)
* [Decentral.tv](https://www.youtube.com/user/decentralTV/videos)
* [EatTheBlocks](https://www.youtube.com/c/eattheblocks)
* [Ethereum for Dummies - Dr. Gavin Wood](https://www.youtube.com/watch?v=U_LK0t_qaPo)
* [Draper University](https://www.youtube.com/user/TimothyDraper/videos)
* [EtherCasts](https://www.youtube.com/user/EtherCasts)
* [Ethereum Project](https://www.youtube.com/user/ethereumproject)
* [EverydayCrpto](https://www.youtube.com/user/Cryptoeveryday/videos)
* [Let's Talk Bitcoin](https://www.youtube.com/user/LetsTalkBitcoinChan)
* [MIT Bitcoin Club](https://www.youtube.com/user/MITBitcoinClub/videos)
* [SF Bitcoin Meetup Industry](https://www.youtube.com/channel/UCOLeHoKV7SHwAAS0zBwsV-A/videos)
* [Satoshi Pollen Technical](https://www.youtube.com/user/IamSatoshiNakamoto/videos)
* [Texas Bitcoin Conference](https://www.youtube.com/channel/UCI_T5wLHpVh6URSkxG6-x_g)
* [University Of Nicosia](https://www.youtube.com/user/MScDigitalCurrency/videos)
* [WBN](https://www.youtube.com/channel/UCgo7FCCPuylVk4luP3JAgVw/videos)
* [World Crypto Network](https://www.youtube.com/user/WorldCryptoNetwork)
* [deBitcoin](https://www.youtube.com/user/deBitcoin/videos)
* [Trust Disrupted](https://www.youtube.com/playlist?list=PLHRxVckaE8daSH4OEReWshCKWu3iIOIS-)
* [Introduction to Ethereum and Smart Contracts](https://www.youtube.com/watch?v=r7GVVk8v2Ik)
* [BitcoinLectures.tv](http://bitcoinlectures.tv)

### Courses
* [EatTheBlocks Pro](http://pro.eattheblocks.com)
* [Ethereum DApps In Motion: build a decentralized exchange with Solidity & Truffle](https://www.manning.com/livevideo/ethereum-dapps-in-motion?a_aid=eattheblocks)
* [Bitcoin and Cryptocurrency Technologies ](https://www.coursera.org/learn/cryptocurrency) - Princeton University
* [Bitcoin or How I learned to stop worrying and love Crypto ](https://www.udemy.com/bitcoin-or-how-i-learned-to-stop-worrying-and-love-crypto/#/) - Udemy
* [Bitcoin](https://www.khanacademy.org/economics-finance-domain/core-finance/money-and-banking/bitcoin/v/bitcoin-what-is-it) - Khan Academy Series
* [Crypto Currencies, the Blockchain, and Smart Contracts](https://crypto.stanford.edu/cs251/) - Standford
* [Ethereum Developer: Build A Decentralised Blockchain App](https://www.udemy.com/ethereum-developer/) - Udemy
* [Introduction to Bitcoin and Decentralized Technology By Scott Driscoll](https://www.pluralsight.com/courses/bitcoin-decentralized-technology) - Pluralsight
* [The Basics of Blockchain: A Beginner's Guide to Blockchain](https://www.udemy.com/the-basics-of-blockchain/) - Udemy
* [The Complete Ethereum Course](https://www.udemy.com/ethereum/?couponCode=DEVCON) - udemy
* [Blockchain for Finance Professionals](https://www.experfy.com/training/courses/blockchain-for-finance-professionals) - Experfy
* [Blockchain Technology Fundamentals](https://www.experfy.com/training/courses/blockchain-technology-fundamentals) - Experfy
* [Introduction to Digital Currencies](https://www.unic.ac.cy/blockchain/free-mooc/) - University of Nicosia


### Documentaries
* [Banking on Bitcoin(Trailer)](https://www.youtube.com/watch?v=LJsbebFyM48)
* [Bitcoin in Uganda](https://www.youtube.com/watch?v=BrRXP1tp6Kw)
* [Inside Man with Morgan Spurlock ](http://www.disclose.tv/action/viewvideo/198650/Morgan_Spurlock__Living_On_Bitcoin__The_Inside_Man_Bitcoin_CNN_Full_Documentary/)
* [Bitcoin: Liberating Organic Farmers](http://www.youtube.com/watch?v=fBLpx6gQtUU)
* [Bitcoins in Argentina](http://www.youtube.com/watch?v=e__m-w4N7NI)
* [Life Inside of a Secret Chinese Bitcoin Mine](https://www.youtube.com/watch?v=K8kua5B5K3I)
* [The Bitcoin Doco](https://vimeo.com/112223859)
* [The Rise and Rise of Bitcoin](https://vimeo.com/ondemand/bitcoindoc)


### Blockchain Art
* [Artlery](https://artlery.com)
* [Ascribe](https://www.ascribe.io)
* [Bitmark](https://bitmark.com)
* [Blockai](https://blockai.com)
* [Everledger](http://www.everledger.io)
* [MediaChain Labs](http://www.mediachainlabs.com)
* [Monegraph](https://monegraph.com)
* [Tagsmart](http://www.tagsmart.com)
* [Verisart](https://www.verisart.com)


### Explorers
* [Apirone.com](https://apirone.com/btc/)
* [Bitaps](https://bitaps.com/)
* [Bitinfocharts](https://bitinfocharts.com/bitcoin/explorer/)
* [Block Explorer](https://blockexplorer.com/)
* [Blockchain Size:](https://blockchain.info/charts/blocks-size)
* [Blockonomics](https://www.blockonomics.co/)
* [Blockstack Explorer](https://explorer.blockstack.org/)
* [Blockr](http://blockr.io/)
* [Blocktrail](https://www.blocktrail.com/BTC)
* [Btc Chain](https://btc.com/)
* [Chain Flyer](http://chainflyer.bitf","Curated list of blockchain and general cryptocurrency resources. Table of
Contents: [Bitcoin Books], [Blockchain Art], [Courses], [Documentaries],
[Infographics], [Talks], [White Papers], [Youtube Channels."
405,"A smooth, highly customizable wheel view and picker view, support 3D effects like iOS. 一个顺滑的、高度自定义的滚轮控件和选择器，支持类似 iOS 的 3D 效果","![](https://github.com/zyyoona7/WheelPicker/blob/master/perview/banner.png)

![](https://img.shields.io/badge/platform-android-brightgreen.svg)
[![API](https://img.shields.io/badge/API-16%2B-brightgreen.svg?style=flat)](https://android-arsenal.com/api?level=16)
[![](https://img.shields.io/badge/pickerview-1.1.1-brightgreen.svg)](https://bintray.com/zyyoona7/maven/pickerview)
[![](https://img.shields.io/badge/wheelview-1.0.9-brightgreen.svg)](https://bintray.com/zyyoona7/maven/wheelview)
[![](https://img.shields.io/github/license/zyyoona7/WheelPicker.svg)](https://github.com/zyyoona7/WheelPicker#license)
### 简介（Introduction）

自定义 View 实现滑动流畅、功能齐全、用法简单、高度自定义的 WheelView，并在 WheelView 基础之上封装了常用的日期选择器（包括年、月、日 WheelView）、选项选择器。

### 版本说明

2019/07/11 发布了 pickerview 1.0.8 版本和 wheelview 1.0.6 版本，其中 pickerview 对包结构有所调整，升级时请先阅读[更新日志](https://github.com/zyyoona7/WheelPicker#pickerview-update-logs)，wheelview 也增加了一些[新功能](https://github.com/zyyoona7/WheelPicker#wheelview-update-logs)，欢迎大家尝鲜~感谢大家反馈的问题，如有新问题也请及时提 issue。

### 特性（Features）
#### 1. WheelView Features

- 如丝般顺滑的滚动效果，无论快速滚动还是缓慢滚动
- 灵活数据设置，通过泛型设置数据类型，灵活、安全
- 支持类似 iOS 的滚动变化音效
- 支持类似 iOS 的 3D 效果
- 3D 效果下，支持圆弧偏移效果，使其看起来更加立体
- 支持嵌套滚动、循环滚动
- 丰富的滑动监听，支持选中监听、滚动状态改变监听等
- 两种分割线类型可以设置，还有其他分割线骚操作
- 支持自动调整字体大小以使得长文字显示完全
- 支持设置显示条目、设置字体大小、设置字体、设置行间距等常规操作
- 更多自定义操作尽在其中

#### 2. DatePickerView Features

- 支持年月日，年月，月日的日期选择
- 支持格式化数据，可以为 item 显示指定格式化的数据
- 拥有 WheelView 特性，可单独设置每个 WheelView 的效果

#### 3. OptionsPickerView Features

- 支持联动包括二级联动和三级联动，设置数据时把控严格，避免滚动时数据异常

### 效果图（Preview）

#### WheelView Preview

![WheelView 1](https://github.com/zyyoona7/WheelPicker/blob/master/perview/wheel_view_1.gif)
①  ②
![WheelView 2](https://github.com/zyyoona7/WheelPicker/blob/master/perview/wheel_view_2.gif)
<br><br>
![WheelView 3](https://github.com/zyyoona7/WheelPicker/blob/master/perview/wheel_view_3.gif)
③  ④
![WheelView 4](https://github.com/zyyoona7/WheelPicker/blob/master/perview/wheel_view_4.gif)

#### DatePickerView Preview

![DatePickerView_1](https://github.com/zyyoona7/WheelPicker/blob/master/perview/date_picker_view_1.gif)
①  ②
![DatePickerView_2](https://github.com/zyyoona7/WheelPicker/blob/master/perview/date_picker_view_2.gif)

#### OptionsPickerView Preview

![OptionsPickerView_1](https://github.com/zyyoona7/WheelPicker/blob/master/perview/options_picker_view_1.gif)
①  ②
![OptionsPickerView_2](https://github.com/zyyoona7/WheelPicker/blob/master/perview/options_picker_view_2.gif)

### 使用（Usage）

#### WheelView Usage

#### 1.依赖（dependency）

```groovy
    implementation 'com.github.zyyoona7:wheelview:1.0.7'
```

#### 2.基本用法（Basic Usage）
在布局文件中添加
```xml
    <com.zyyoona7.wheel.WheelView
        android:id=""@+id/wheelview""
        android:layout_width=""wrap_content""
        android:layout_height=""wrap_content""/>
```
在代码中
```java
    //泛型为数据类型
    final WheelView<Integer> wheelView = findViewById(R.id.wheelview);
    //初始化数据
    List<Integer> list = new ArrayList<>(1);
    for (int i = 0; i < 20; i++) {
        list.add(i);
    }
    //设置数据
    wheelView.setData(list);

    //尽请使用各种方法
    wheelView.setTextSize(24f,true);
    //more...
```
#### 2.进阶用法（Advanced Usage）

> 问：我已经有了创建好的实体怎么办？

> 答：好办~

**我已城市列表为例（其他实体同理）**

我的城市列表实体是这样的：
```java 
public class CityEntity implements IWheelEntity, Serializable {

    //国家
    public static final String LEVEL_COUNTRY = ""country"";
    //省
    public static final String LEVEL_PROVINCE = ""province"";
    //市
    public static final String LEVEL_CITY = ""city"";
    //区
    public static final String LEVEL_DISTRICT = ""district"";

    private String citycode;
    private String adcode;
    private String name;
    private String center;
    private String level;
    private List<CityEntity> districts;

    public String getCitycode() {
        return citycode;
    }

    public void setCitycode(String citycode) {
        this.citycode = citycode;
    }

    public String getAdcode() {
        return adcode;
    }

    public void setAdcode(String adcode) {
        this.adcode = adcode;
    }

    public String getName() {
        return name == null ? """" : name;
    }

    public void setName(String name) {
        this.name = name;
    }

    public String getCenter() {
        return center;
    }

    public void setCenter(String center) {
        this.center = center;
    }

    public String getLevel() {
        return level;
    }

    public void setLevel(String level) {
        this.level = level;
    }

    public List<CityEntity> getDistricts() {
        return districts == null ? new ArrayList<CityEntity>(1) : districts;
    }

    public void setDistricts(List<CityEntity> districts) {
        this.districts = districts;
    }

    @Override
    public String toString() {
        return ""CityEntity{"" +
                ""citycode='"" + citycode + '\'' +
                "", adcode='"" + adcode + '\'' +
                "", name='"" + name + '\'' +
                "", center='"" + center + '\'' +
                "", level='"" + level + '\'' +
                "", districts="" + districts +
                '}';
    }

    /**
     * 重点：重写此方法，返回 WheelView 显示的文字
     * @return
     */
    @Override
    public String getWheelText() {
        return name == null ? """" : name;
    }
}
```
注意，我的 CityEntity 中多实现了一个 IWheelEntity 接口，这个接口是在 WheelView 库中定义好的，实现之后在 getWheelText() 方法返回你想在 WheelView 中展示的字段就大功告成了。

MainActivity WheelView 相关代码：
```java 
    WheelView<CityEntity> cityWv=findViewById(R.id.wv_city);
    //解析城市列表
    List<CityEntity> cityData= ParseHelper.parseTwoLevelCityList(this);
    cityWv.setData(cityData);
```
然后，效果图是这样的~

![WheelView_City](https://github.com/zyyoona7/WheelPicker/blob/master/perview/wheel_view_city.gif)

> 冷知识：其实不实现 IWheelEntity 也是可以的，偷偷给你们看下源码：
```java
    //WheelView.java
    /**
     * 获取item text
     *
     * @param item item数据
     * @return 文本内容
     */
    protected String getDataText(T item) {
        if (item == null) {
            return """";
        } else if (item instanceof IWheelEntity) {
            return ((IWheelEntity) item).getWheelText();
        } else if (item instanceof Integer) {
            //如果为整形则最少保留两位数.
            return isIntegerNeedFormat ? String.format(Locale.getDefault(), mIntegerFormat, (Integer) item)
                    : String.valueOf(item);
        } else if (item instanceof String) {
            return (String) item;
        }
        return item.toString();
    }
```
如果条件都不满足的话会默认执行 toString() 方法，所以理论上也可以在实体的 toString() 方法返回你想展示的字段，但是**不推荐**，毕竟 toString() 方法以我个人的习惯都是输出 CityEntity 那种的信息~你也可能输出别的信息。

#### PickerView Usage

```groovy
    implementation 'com.github.zyyoona7:pickerview:1.0.9'
```

#### DatePickerView Usage

在布局文件中：
```xml
    <com.zyyoona7.picker.DatePickerView
        android:id=""@+id/dpv_default""
        android:layout_width=""wrap_content""
        android:layout_height=""wrap_content""
        android:layout_marginTop=""16dp""
        app:layout_constraintEnd_toEndOf=""parent""
        app:layout_constraintStart_toStartOf=""parent""
        app:layout_constraintTop_toBottomOf=""@id/tv_datePickerView"" />
```

代码中：
```java
    DatePickerView defaultDpv = findViewById(R.id.dpv_default);
    defaultDpv.setTextSize(24, true);
    defaultDpv.setLabelTextSize(20);
    
    //选中回调
    defaultDpv.setOnDateSelectedListener(new DatePickerView.OnDateSelectedListener() {
        @Override
        public void onDateSelected(DatePickerView datePickerView, int year, int month, int day, @Nullable Date date) {
            Toast.makeText(Main3Activity.this, ""选中的日期："" + year + ""-"" + month + ""-"" + day, Toast.LENGTH_SHORT).show();
        }
    });
```
> 问：我想要每一项都加入年字怎么写？

> 答：简单。

**定制格式**

我们需要先把自带显示年、月、日的 TextView 隐藏，然后设置格式化：

```java
    //隐藏年月日
    customDpv3.setShowLabel(false);    

    //获取年月日 WheelView
    YearWheelView yearWv3 = customDpv3.getYearWv();
    MonthWheelView monthWv3 = customDpv3.getMonthWv();
    DayWheelView dayWv3 = customDpv3.getDayWv();
    //注意：setIntegerNeedFormat(String integerFormat)方法 integerFormat 中必须包含并且只能包含一个格式说明符（format specifier）
    //更多请查看该方法参数说明
    yearWv3.setIntegerNeedFormat(""%d年"");
    monthWv3.setIntegerNeedFormat(""%d月"");
    dayWv3.setIntegerNeedFormat(""%02d日"");
```

没错就是这么简单，而且回调内容依旧不变~更多操作请查看 [Main3Activity](https://github.com/zyyoona7/WheelPicker/blob/master/app/src/main/java/com/zyyoona7/demo/Main3Activity.java)

#### OptionsPickerView

布局文件中：

```xml
    <com.zyyoona7.picker.OptionsPickerView
        android:id=""@+id/opv_three_linkage""
        android:layout_width=""0dp""
        android:layout_height=""wrap_content""
        android:layout_marginTop=""16dp""
        app:layout_constraintEnd_toEndOf=""parent""
        app:layout_constraintStart_toStartOf=""parent""
        app:layout_constraintTop_toBottomOf=""@id/opv_two_linkage""
        android:background=""#DCDCDC""/>
```

代码中：

```java
    final OptionsPickerView<CityEntity> threeLinkageOpv = findViewById(R.id.opv_three_linkage);
    //设置数据
    threeLinkageOpv.setLinkageData(p3List, c3List, d3List);
    //定制样式
    threeLinkageOpv.setVisibleItems(7);
    threeLinkageOpv.setResetSelectedPosition(true);
    threeLinkageOpv.setDrawSelectedRect(true);
    threeLinkageOpv.setSelectedRectColor(Color.parseColor(""#D3D3D3""));
    threeLinkageOpv.setNormalItemTextColor(Color.parseColor(""#808080""));
    threeLinkageOpv.setTextSize(22f,true);
    threeLinkageOpv.setSoundEffect(true);
    threeLinkageOpv.setSoundEffectResource(R.raw.button_choose);

    //设置选中回调
    threeLinkageOpv.setOnOptionsSelectedListener(new OptionsPickerView.OnOptionsSelectedListener<CityEntity>() {
        @Override
        public void onOptionsSelected(int opt1Pos, @Nullable CityEntity opt1Data, int opt2Pos,
                                      @Nullable CityEntity opt2Data, int opt3Pos, @Nullable CityEntity opt3Data) {
            if (opt1Data == null || opt2Data == null || opt3Data == null) {
                return;
            }
            Log.d(TAG, ""onOptionsSelected: three Linkage op1Pos="" + opt1Pos + "",op1Data="" + opt1Data.getName() + "",op2Pos="" + opt2Pos
                        + "",op2Data="" + opt2Data.getName() + "",op3Pos="" + opt3Pos + "",op3Data="" + opt3Data.getName());
        }
    });
```

更多请查看 [Main4Activity](https://github.com/zyyoona7/WheelPicker/blob/master/app/src/main/java/com/zyyoona7/demo/Main4Activity.java)

### 更新日志（Update Logs）

#### WheelView Update Logs

- **2019/09/27 发布 1.0.7 版本**
  - 修复数据为空时，触摸 WheelView 导致崩溃问题
  - 增加 `onWheelScroll()` 等同监听器的方法供子类使用

- **2019/07/11 发布 1.0.6 版本**
  - 修复 [#18](https://github.com/zyyoona7/WheelPicker/issues/18) 的问题
  - 增加 [#6](https://github.com/zyyoona7/WheelPicker/issues/6) 新功能，在非 3D 的情况下也可以设置选中字体和非选中字体的大小，通过 setRefractRatio() 方法设置，并且标记  ```wv_curvedRefractRatio``` 属性和 setCurvedRefractRatio() 过时，会在新版本删除这两个方法
  - 增加扩大选中区域的间距，通过 ``` wv_dividerOffset``` 属性设置偏移，原理是扩大分割线和选中区域的上下偏移距离来实现看起来的间距扩大效果，并未真正的修改行间距
  - 增加 [#12](https://github.com/zyyoona7/WheelPicker/issues/12) 新功能，可以设置选中条目字体加粗，其他条目不会加粗操作，通过 setTypeface(typeface,true) 方法设置，详细信息请看方法注释
  - 支持禁止滑动，只需设置 setEnabled(false) 将不处理 onTouchEvent() 事件

- **2019/02/22 发布 1.0.5 版本**
    - 修复 [#5](https://github.com/zyyoona7/WheelPicker/issues/5)、[#7](https://github.com/zyyoona7/WheelPicker/issues/7)

- **2018/10/10 发布 1.0.4 版本**
    - 在编写布局时可以实时预览
    
- **2018/08/29 发布 1.0.2 版本**
    - 修复 setSelectedItemPosition() 方法没有执行 onWheelSelected() 问题

- **2018/08/23 发布 1.0.1 版本**
    - 规范命名，将方法名和属性名保持一致命名
    - 增加绘制选中区域，设置选中区域颜色
    - 增加 getItemData(int position) 方法：获取指定 position 的数据
    - 增加 getSelectedItemData() 方法：获取当前选中的item数据
    - 增加 setIntegerNeedFormat(String integerFormat) 方法：同时设置 isIntegerNeedFormat=true 和 mIntegerFormat=integerFormat 两个属性
    - 增加 setResetSelectedPosition(boolean isResetSelectedPosition) 方法：设置当数据变化时，是否重置选中下标到第一个
    - 修改 mCurrentItemPosition 为 mSelectedItemPosition，并同时修改了对应的 getter/setter 方法及属性名
    - 修改 mSelectedItemColor 为 mSelectedItemTextColor，并同时修改了对应的 getter/setter 方法名
    - 修改 setSelectedItemPosition(int position) 默认不开启平滑滚动
    - 修复单次滑动 onItemSelected() 可能执行两次的问题
    - 修复 setSelectedItemPosition() 不开启平滑滚动时，未保存当前选中下标
    - 修复更新数据时，mSelectedItemPosition 越界的情况
    - 修复播放音效代码写错位置
    - 优化滚动监听和选中监听回调次数，回调更加精准，减少不必要的重绘
    - 优化滚动监听执行位置，onDraw() 方法不再处理任何回调

- **2018/08/20 发布 1.0.0 版本**
    - 泛型设置数据类型
    - 滚动音效，3D 效果等
    - 增加自动调整字体大小以使得长文字显示完全（需手动开启）
    - 丰富的监听器
    
#### PickerView Update Logs

- **2019/09/27 发布 1.0.9 版本**
  - DatePickerView 增加最大选择日期和最小选择日期设置，超出此范围会自动选中最大或最小日期，方便选择生日等最大日期不能超过当天的场景

- **2019/07/11 发布 1.0.8 版本**
  - 调整包结构，将所有 pickerview 的监听器放入 listener 包中
  - 重构 DatePickerView 代码，新增 BaseDatePickerView 可以更加灵活的定制 DatePickerView 的样式，只需要继承 BaseDatePickerView 并实现抽象方法即可（详情请看 Demo 中的 [CustomDatePickerView](https://github.com/zyyoona7/WheelPicker/blob/master/app/src/main/java/com/zyyoona7/demo/CustomDatePickerView.java)）
  - 调整 OnDateSelectedListener 中 onDateSelected() 方法的第一个参数类型，由原来的 DatePickerView 改成 BaseDatePickerVIew
- **2019/03/12 发布 1.0.7 版本**
    - 增加滚动状态监听

- **2019/02/22 发布 1.0.6 版本**
    - 同步 wheelview 版本

- **2018/11/17 发布 1.0.5 版本**
    - 修复 YearWheelView 中设置年份范围时不包括结束年的问题

- **2018/10/10 发布 1.0.4 版本**
    - 同步 wheelview 版本，pickerview 终于可以正常导入，只有 1.0.4 版本可用

- ~~**2018/09/14 发布 1.0.2 版本**~~
    -  ~~修复 pickerview 引入失败问题~~

- ~~**2018/08/29 发布 1.0.1 版本**~~
    - ~~同步 WheelView 版本~~

- ~~**2018/08/24 发布 1.0.0 版本**~~
    - ~~YearWheelView、MonthWheelView、DayWheelView 封装~~
    - ~~日期选择器、选项选择器~~
    
### 交流群
![qrcode](https://github.com/zyyoona7/WheelPicker/blob/master/perview/QQ_qrcode.png)

### 感谢（Thanks）
[**WheelPicker**](https://github.com/AigeStudio/WheelPicker)<br>
[**Android-PickerView**](https://github.com/Bigkoo/Android-PickerView)<br>
[**WheelView**](https://github.com/CNCoderX/WheelView)<br>
[**WheelView-3d**](https://github.com/youxiaochen/WheelView-3d)<br>
[**DatePicker**](https://github.com/chenglei1986/DatePicker)

### LICENSE
```
Copyright 2018 zyyoona7

Licensed under the Apache License, Version 2.0 (the ""License"");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an ""AS IS"" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
```
","Summarize:![](https://github.com/zyyoona7/WheelPicker/blob/master/perview/banner
.png)!(https://img.shields.io/badge/platform-android-brightgreen.svg)!
(https://bintray.com /maven/pickerview/1.1.0.1-bright green.svG)! [![API]
(http://android-arsenal.com/#/api?level=16)"
2152,"AriaNg, a modern web frontend making aria2 easier to use.","# AriaNg
[![License](https://img.shields.io/github/license/mayswind/AriaNg.svg?style=flat)](https://github.com/mayswind/AriaNg/blob/master/LICENSE)
[![Lastest Build](https://img.shields.io/circleci/project/github/mayswind/AriaNg.svg?style=flat)](https://circleci.com/gh/mayswind/AriaNg/tree/master)
[![Lastest Release](https://img.shields.io/github/release/mayswind/AriaNg.svg?style=flat)](https://github.com/mayswind/AriaNg/releases)

## Introduction
AriaNg is a modern web frontend making [aria2](https://github.com/aria2/aria2) easier to use. AriaNg is written in pure html & javascript, thus it does not need any compilers or runtime environment. You can just put AriaNg in your web server and open it in your browser. AriaNg uses responsive layout, and supports any desktop or mobile devices.

## Features
1. Pure Html & Javascript, no runtime required
2. Responsive design, supporting desktop and mobile devices
3. User-friendly interface
    * Sort tasks (by name, size, progress, remaining time, download speed, etc.), files, bittorrent peers
    * Search tasks
    * Retry tasks
    * Adjust task order by dragging
    * More information of tasks (health percentage, client information of bt peers, etc.)
    * Filter files by specified file types (videos, audios, pictures, documents, applications, archives, etc.) or file extensions
    * Tree view for multi-directory task
    * Download / upload speed chart for aria2 or single task
    * Full support for aria2 settings
4. Dark theme
5. Url command line api support
6. Download finished notification
7. Multi-languages support
8. Multi aria2 RPC host support
9. Exporting and Importing settings support
10. Less bandwidth usage, only requesting incremental data

## Screenshots
#### Desktop
![AriaNg](https://raw.githubusercontent.com/mayswind/AriaNg-WebSite/master/screenshots/desktop.png)
#### Mobile Device
![AriaNg](https://raw.githubusercontent.com/mayswind/AriaNg-WebSite/master/screenshots/mobile.png)

## Installation
AriaNg now provides three versions, standard version, all-in-one version and [AriaNg Native](https://github.com/mayswind/AriaNg-Native). Standard version is suitable for deployment in the web server, and provides on-demand loading. All-In-One version is suitable for local using, and you can download it and just open the only html file in browser. [AriaNg Native](https://github.com/mayswind/AriaNg-Native) is also suitable for local using, and is no need for browser. 

#### Prebuilt release
Latest Release: [https://github.com/mayswind/AriaNg/releases](https://github.com/mayswind/AriaNg/releases)

Latest Daily Build (Standard Version): [https://github.com/mayswind/AriaNg-DailyBuild/archive/master.zip](https://github.com/mayswind/AriaNg-DailyBuild/archive/master.zip)

#### Building from source
Make sure you have [Node.js](https://nodejs.org/), [NPM](https://www.npmjs.com/) and [Gulp](https://gulpjs.com/) installed. Then download the source code, and follow these steps.

##### Standard Version

    $ npm install
    $ gulp clean build

##### All-In-One Version

    $ npm install
    $ gulp clean build-bundle

The builds will be placed in the dist directory.

#### Usage Notes
Since AriaNg standard version loads language resources asynchronously, you may not open index.html directly on the local file system to run AriaNg. It is recommended that you can use the all-in-one version or deploy AriaNg in a web container or download [AriaNg Native](https://github.com/mayswind/AriaNg-Native) that does not require a browser to run.

## Documents
1. [English](http://ariang.mayswind.net)
2. [Simplified Chinese (简体中文)](http://ariang.mayswind.net/zh_Hans)

## Demo
Please visit [http://ariang.mayswind.net/latest](http://ariang.mayswind.net/latest)

## Third Party Extensions
There are some third-party applications based on AriaNg, so you can use AriaNg in more scenarios or devices. Please visit [Third Party Extensions](http://ariang.mayswind.net/3rd-extensions.html) for more information.

## License
[MIT](https://github.com/mayswind/AriaNg/blob/master/LICENSE)
","AriaNg is a modern web frontend making [aria2] easier to use. It is written in
pure html & javascript, so it does not need any compilers or runtime
environment. AriaNg uses responsive layout, and supports any desktop or mobile
devices. It now provides three versions, standard version, all-in-one version
and [Aria ng Native] First, download the source code, and follow these steps.
Then download the latest Daily Build (Standard Version) and the latest Release
(All-In-One Version)"
